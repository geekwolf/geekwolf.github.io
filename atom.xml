<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Geekwolf&#39;s Blog</title>
  
  <subtitle>Quick notes</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.simlinux.com/"/>
  <updated>2017-09-12T01:12:15.139Z</updated>
  <id>http://www.simlinux.com/</id>
  
  <author>
    <name>Geekwolf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>k8s部署之分布式KV存储Etcd</title>
    <link href="http://www.simlinux.com/2017/09/08/k8s-etcd-deploy-test.html"/>
    <id>http://www.simlinux.com/2017/09/08/k8s-etcd-deploy-test.html</id>
    <published>2017-09-08T11:16:09.000Z</published>
    <updated>2017-09-12T01:12:15.139Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Etcd是什么"><a href="#Etcd是什么" class="headerlink" title="Etcd是什么"></a>Etcd是什么</h4><blockquote><p>Etcd是一个分布式、使用Raft算法维护一致性的kv存储系统，与其类似产品有Zookeeper(老牌经典)、Consul等，Etcd相对ZK，更加轻量、易运维。具体三者之间的对比可参考 <a href="https://luyiisme.github.io/2017/04/22/spring-cloud-service-discovery-products/" target="_blank" rel="external">https://luyiisme.github.io/2017/04/22/spring-cloud-service-discovery-products/</a></p></blockquote><h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>和zk、consul等类似，使用场景多用于:</p><ul><li>服务发现</li><li>消息发布与订阅</li><li>负载均衡</li><li>分布式锁</li><li>分布式队列</li></ul><h4 id="读写性能"><a href="#读写性能" class="headerlink" title="读写性能"></a>读写性能</h4><p>压测数据参考官方：<br><a href="https://coreos.com/etcd/docs/latest/op-guide/performance.html" target="_blank" rel="external">https://coreos.com/etcd/docs/latest/op-guide/performance.html</a></p><h4 id="本地集群部署"><a href="#本地集群部署" class="headerlink" title="本地集群部署"></a>本地集群部署</h4><ul><li>操作系统:Debian8 x64</li><li>Etcd v3.2.7</li></ul><p>A. 安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">wget https://github.com/coreos/etcd/releases/download/v3.2.7/etcd-v3.2.7-linux-arm64.tar.gz</div><div class="line">tar xf etcd-v3.2.7-linux-arm64.tar.gz</div><div class="line">cd etcd-v3.2.7-linux-amd64</div><div class="line">cp etc* /usr/local/bin/</div><div class="line"></div><div class="line">etcd: Etcd服务端文件</div><div class="line">etcdctl: 供用户使用的命令客户端</div></pre></td></tr></table></figure></p><p>B. 启动服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">root@a4c8d490:/home/geekwolf# etcd</div><div class="line">2017-09-07 15:42:23.957656 I | etcdmain: etcd Version: 3.2.7</div><div class="line">2017-09-07 15:42:23.957699 I | etcdmain: Git SHA: bb66589</div><div class="line">2017-09-07 15:42:23.957718 I | etcdmain: Go Version: go1.8.3</div><div class="line">2017-09-07 15:42:23.957723 I | etcdmain: Go OS/Arch: linux/amd64</div><div class="line">2017-09-07 15:42:23.957729 I | etcdmain: setting maximum number of CPUs to 8, total number of available CPUs is 8</div><div class="line">2017-09-07 15:42:23.957739 W | etcdmain: no data-dir provided, using default data-dir ./default.etcd</div><div class="line">2017-09-07 15:42:23.957764 N | etcdmain: the server is already initialized as member before, starting as etcd member...</div><div class="line">2017-09-07 15:42:23.957995 I | embed: listening for peers on http://localhost:2380</div><div class="line">2017-09-07 15:42:23.958107 I | embed: listening for client requests on localhost:2379</div><div class="line">2017-09-07 15:42:23.964607 I | etcdserver: name = default</div><div class="line">2017-09-07 15:42:23.964633 I | etcdserver: data dir = default.etcd</div><div class="line">2017-09-07 15:42:23.964652 I | etcdserver: member dir = default.etcd/member</div><div class="line">2017-09-07 15:42:23.964657 I | etcdserver: heartbeat = 100ms</div><div class="line">2017-09-07 15:42:23.964663 I | etcdserver: election = 1000ms</div><div class="line">2017-09-07 15:42:23.964668 I | etcdserver: snapshot count = 100000</div><div class="line">2017-09-07 15:42:23.964680 I | etcdserver: advertise client URLs = http://localhost:2379</div><div class="line">2017-09-07 15:42:23.973007 I | etcdserver: restarting member 8e9e05c52164694d in cluster cdf818194e3a8c32 at commit index 14</div><div class="line">2017-09-07 15:42:23.973041 I | raft: 8e9e05c52164694d became follower at term 2</div><div class="line">2017-09-07 15:42:23.973065 I | raft: newRaft 8e9e05c52164694d [peers: [], term: 2, commit: 14, applied: 0, lastindex: 14, lastterm: 2]</div><div class="line">2017-09-07 15:42:23.984367 W | auth: simple token is not cryptographically signed</div><div class="line">2017-09-07 15:42:23.993237 I | etcdserver: starting server... [version: 3.2.7, cluster version: to_be_decided]</div><div class="line">2017-09-07 15:42:23.993659 I | etcdserver/membership: added member 8e9e05c52164694d [http://localhost:2380] to cluster cdf818194e3a8c32</div><div class="line">2017-09-07 15:42:23.993754 N | etcdserver/membership: set the initial cluster version to 3.2</div><div class="line">2017-09-07 15:42:23.993796 I | etcdserver/api: enabled capabilities for version 3.2</div><div class="line">2017-09-07 15:42:24.473288 I | raft: 8e9e05c52164694d is starting a new election at term 2</div><div class="line">2017-09-07 15:42:24.473451 I | raft: 8e9e05c52164694d became candidate at term 3</div><div class="line">2017-09-07 15:42:24.473519 I | raft: 8e9e05c52164694d received MsgVoteResp from 8e9e05c52164694d at term 3</div><div class="line">2017-09-07 15:42:24.473568 I | raft: 8e9e05c52164694d became leader at term 3</div><div class="line">2017-09-07 15:42:24.473605 I | raft: raft.node: 8e9e05c52164694d elected leader 8e9e05c52164694d at term 3</div><div class="line">2017-09-07 15:42:24.478746 I | etcdserver: published &#123;Name:default ClientURLs:[http://localhost:2379]&#125; to cluster cdf818194e3a8c32</div><div class="line">2017-09-07 15:42:24.478824 I | embed: ready to serve client requests</div><div class="line">2017-09-07 15:42:24.479116 N | embed: serving insecure client requests on 127.0.0.1:2379, this is strongly discouraged!</div></pre></td></tr></table></figure></p><p>由上面的输出可知：</p><ul><li>etcd服务之间通信端口是2380，暴露给客户端端口为2379</li><li>默认将数据存放到当前路径default.etcd/目录下</li><li>该节点的名称默认为default</li><li>集群和节点都会生成唯一的uuid</li><li>启动服务时，会根据raft算法，选举leader</li></ul><p>C. 测试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">查看api版本（默认api版本是v2）</div><div class="line">root@a4c8d490:~/k8s/etcd-v3.2.7-linux-amd64# etcdctl  --version</div><div class="line">etcdctl version: 3.2.7</div><div class="line">API version: 2</div><div class="line"></div><div class="line">使用API V3方法：</div><div class="line">Etcd服务端和客户端添加变量 export ETCDCTL_API=3,重新启动etcd服务即可</div><div class="line">以下操作在api v3版本:</div><div class="line">写入key: etcdctl put foo bar</div><div class="line">读取key: etcdctl get foo</div><div class="line">多key范围读取: etcdctl get foo foo9(会将foo..foo8的key读取,不包括foo9)</div><div class="line">读取过往版本key的值(Etcd键值对的修改都会增加全局修订版本号,--rev为版本号):</div><div class="line"> etcdctl get --rev=4 foo foo9</div><div class="line">删除key: etcdctl del foo</div><div class="line">范围删除(foo-&amp;gt;foo9):etcdctl del foo foo9</div><div class="line">观察key变化:etcdctl watch foo</div><div class="line">观察范围key变化: etcdctl watch foo foo9</div><div class="line">从rev=2版本开始观察key变化: etcdctl watch --rev=2 foo</div><div class="line">压缩版本5之前的修订版本(压缩后5之前的版本不可能访问): etcdctl compact 5</div><div class="line">授予key有效期:</div><div class="line">创建租约: </div><div class="line">$ etcdctl lease grant 10</div><div class="line">lease 694d5e5b63a74f31 granted with TTL(10s)</div><div class="line">附加key foo到租约694d5e5b63a74f31，该租约过期后，会删除附加的所有key</div><div class="line">撤销租约(撤销后，附加改租约的所有key被删除): etcdctl lease revoke 32695410dcc0ca06</div><div class="line">维持租约(执行后，会一直维持该租约): etcdctl lease keep-alive 32695410dcc0ca0</div><div class="line"></div><div class="line">其他参数可参考 etcdctl --help</div><div class="line">通过HTTP操作：</div><div class="line">Etcd v2: https://coreos.com/etcd/docs/latest/v2/api.html</div><div class="line">Etcd v3: https://coreos.com/etcd/docs/latest/dev-guide/api_grpc_gateway.html</div></pre></td></tr></table></figure></p><h4 id="多节点集群部署"><a href="#多节点集群部署" class="headerlink" title="多节点集群部署"></a>多节点集群部署</h4><h5 id="静态模式部署"><a href="#静态模式部署" class="headerlink" title="静态模式部署"></a>静态模式部署</h5><h6 id="环境说明-三节点集群"><a href="#环境说明-三节点集群" class="headerlink" title="环境说明(三节点集群)"></a>环境说明(三节点集群)</h6><table><thead><tr><th style="text-align:left">节点</th><th style="text-align:left">地址</th><th style="text-align:left">主机</th></tr></thead><tbody><tr><td style="text-align:left">etcd1</td><td style="text-align:left">192.168.234.133</td><td style="text-align:left">etcd1.simlinux.com</td></tr><tr><td style="text-align:left">etcd2</td><td style="text-align:left">192.168.234.133</td><td style="text-align:left">etcd2.simlinux.com</td></tr><tr><td style="text-align:left">etcd3</td><td style="text-align:left">192.168.234.133</td><td style="text-align:left">etcd3.simlinux.com</td></tr></tbody></table><h6 id="初始化环境"><a href="#初始化环境" class="headerlink" title="初始化环境"></a>初始化环境</h6><p>三个节点分别设置主机名:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hostnamectl --static  set-hostname etcd1.simlinux.com</div><div class="line">hostnamectl --static  set-hostname etcd2.simlinux.com</div><div class="line">hostnamectl --static  set-hostname etcd3.simlinux.com</div></pre></td></tr></table></figure></p><p>三个节点hosts文件添加:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">vim /etc/hosts</div><div class="line">192.168.234.133 etcd1.simlinux.com </div><div class="line">192.168.234.133 etcd2.simlinux.com </div><div class="line">192.168.234.133 etcd3.simlinux.com</div></pre></td></tr></table></figure></p><p><strong>生成etcd证书(用于etcd间、客户端与etcd通信)</strong></p><blockquote><p>由上篇<a href="http://www.simlinux.com/archives/1953.html">k8s部署之使用CFSSL创建证书</a>的CA来生成</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">cat  etcd.json </div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;etcd&quot;,</div><div class="line">    &quot;hosts&quot;: [</div><div class="line">        &quot;127.0.0.1&quot;,</div><div class="line">        &quot;192.168.234.133&quot;,</div><div class="line">        &quot;192.168.234.134&quot;,</div><div class="line">        &quot;192.168.234.135&quot;</div><div class="line">    ],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;ShangHai&quot;,</div><div class="line">            &quot;ST&quot;: &quot;ShangHai&quot;,</div><div class="line">            &quot;O&quot;: &quot;K8s&quot;,</div><div class="line">            &quot;OU&quot;: &quot;System&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer etcd.json | cfssljson -bare etcd</div><div class="line">将CA和etcd证书拷贝到etcd所有节点:</div><div class="line">cp ca.pem  etcd-key.pem  etcd.pem /etc/etcd/ssl/</div></pre></td></tr></table></figure><h6 id="安装etcd节点-所有节点"><a href="#安装etcd节点-所有节点" class="headerlink" title="安装etcd节点(所有节点)"></a>安装etcd节点(所有节点)</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">wget https://github.com/coreos/etcd/releases/download/v3.2.7/etcd-v3.2.7-linux-amd64.tar.gz</div><div class="line">tar xf etcd-v3.2.7-linux-amd64.tar.gz</div><div class="line">cd etcd-v3.2.7-linux-amd64</div><div class="line">chmod +x etcd*</div><div class="line">cp etcd* /bin</div></pre></td></tr></table></figure><h6 id="etcd配置"><a href="#etcd配置" class="headerlink" title="etcd配置"></a>etcd配置</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">服务管理(所有节点相同):</div><div class="line">vim /usr/lib/systemd/system/etcd.service</div><div class="line">[Unit]</div><div class="line">Description=Etcd Server</div><div class="line">After=network.target</div><div class="line">After=network-online.target</div><div class="line">Wants=network-online.target</div><div class="line">Documentation=https://github.com/coreos</div><div class="line">[Service]</div><div class="line">Type=notify</div><div class="line">WorkingDirectory=/data/k8s/etcd/</div><div class="line">EnvironmentFile=/etc/etcd/etcd.conf</div><div class="line">ExecStart=/bin/etcd </div><div class="line">  --name=$&#123;NAME&#125; </div><div class="line">  --cert-file=/etc/etcd/ssl/etcd.pem </div><div class="line">  --key-file=/etc/etcd/ssl/etcd-key.pem </div><div class="line">  --peer-cert-file=/etc/etcd/ssl/etcd.pem </div><div class="line">  --peer-key-file=/etc/etcd/ssl/etcd-key.pem </div><div class="line">  --trusted-ca-file=/etc/etcd/ssl/ca.pem </div><div class="line">  --peer-trusted-ca-file=/etc/etcd/ssl/ca.pem </div><div class="line">  --initial-advertise-peer-urls=$&#123;INITIAL_ADVERTISE_PEER_URLS&#125; </div><div class="line">  --listen-peer-urls=$&#123;LISTEN_PEER_URLS&#125; </div><div class="line">  --listen-client-urls=$&#123;LISTEN_CLIENT_URLS&#125; </div><div class="line">  --advertise-client-urls=$&#123;ADVERTISE_CLIENT_URLS&#125; </div><div class="line">  --initial-cluster-token=$&#123;INITIAL_CLUSTER_TOKEN&#125; </div><div class="line">  --initial-cluster=$&#123;INITIAL_CLUSTER&#125; </div><div class="line">  --initial-cluster-state=new </div><div class="line">  --data-dir=$&#123;DATA_DIR&#125;</div><div class="line">Restart=on-failure</div><div class="line">RestartSec=5</div><div class="line">LimitNOFILE=65536</div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure><p>配置文件:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">vim /etc/etcd/etcd.conf</div><div class="line">#节点名称</div><div class="line">NAME=&quot;etcd1&quot;</div><div class="line">#etcd数据存放目录</div><div class="line">DATA_DIR=&quot;/data/k8s/etcd&quot;</div><div class="line">#etcd节点间通信监听地址</div><div class="line">LISTEN_PEER_URLS=&quot;https://192.168.234.133:2380&quot;</div><div class="line">#对外提供服务的地址</div><div class="line">LISTEN_CLIENT_URLS=&quot;https://192.168.234.133:2379,https://127.0.0.1:2379&quot;</div><div class="line">#通知其他etcd节点本实例地址</div><div class="line">INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.234.133:2380&quot;</div><div class="line">#初始化集群内节点地址</div><div class="line">INITIAL_CLUSTER=&quot;etcd1=https://192.168.234.133:2380,etcd2=https://192.168.234.134:2380,etcd3=https://192.168.234.135:2380&quot;</div><div class="line">#初始化状态.new表示新建,已经存在的集群使用existing</div><div class="line">INITIAL_CLUSTER_STATE=&quot;new&quot;</div><div class="line">#创建集群的token,每个集群唯一</div><div class="line">INITIAL_CLUSTER_TOKEN=&quot;k8s-etcd-cluster&quot;</div><div class="line">#告知其他集群本节点客户端监听地址</div><div class="line">ADVERTISE_CLIENT_URLS=&quot;https://192.168.234.133:2379&quot;</div><div class="line">ETCDCTL_API=3</div><div class="line">其中NAME/LISTEN_PEER_URLS/LISTEN_CLIENT_URLS/INITIAL_ADVERTISE_PEER_URLS/ADVERTISE_CLIENT_URLS替换成相应节点名称和地址</div></pre></td></tr></table></figure></p><h6 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl start etcd.service</div><div class="line">systemctl stop etcd.service</div><div class="line">systemctl status etcd.service(查看服务状态及日志)</div></pre></td></tr></table></figure><h6 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">[root@etcd1 ~]# export etcd1=192.168.234.133</div><div class="line">[root@etcd1 ~]# export etcd2=192.168.234.134</div><div class="line">[root@etcd1 ~]# export etcd3=192.168.234.135</div><div class="line">[root@etcd1 ~]# export ENDPOINTS=$etcd1:2379,$etcd2:2379,$etcd3:2379</div><div class="line">查看集群成员:</div><div class="line">[root@etcd1 etcd]#  etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem member list</div><div class="line">+------------------+---------+-------+------------------------------+------------------------------+</div><div class="line">|        ID        | STATUS  | NAME  |          PEER ADDRS          |         CLIENT ADDRS         |</div><div class="line">+------------------+---------+-------+------------------------------+------------------------------+</div><div class="line">| 1a4a83ef243ff1c9 | started | etcd2 | https://192.168.234.134:2380 | https://192.168.234.134:2379 |</div><div class="line">| 68243ef8797bd1ce | started | etcd1 | https://192.168.234.133:2380 | https://192.168.234.133:2379 |</div><div class="line">| fa30209a63d949b0 | started | etcd3 | https://192.168.234.135:2380 | https://192.168.234.135:2379 |</div><div class="line">+------------------+---------+-------+------------------------------+------------------------------+</div><div class="line">查看集群状态:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem endpoint status</div><div class="line">+----------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">|       ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</div><div class="line">+----------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">| 192.168.234.133:2379 | 68243ef8797bd1ce |   3.2.7 |   25 kB |     false |        10 |          9 |</div><div class="line">| 192.168.234.134:2379 | 1a4a83ef243ff1c9 |   3.2.7 |   25 kB |     false |        10 |          9 |</div><div class="line">| 192.168.234.135:2379 | fa30209a63d949b0 |   3.2.7 |   25 kB |      true |        10 |          9 |</div><div class="line">+----------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem endpoint health</div><div class="line">192.168.234.135:2379 is healthy: successfully committed proposal: took = 1.374345ms</div><div class="line">192.168.234.134:2379 is healthy: successfully committed proposal: took = 2.217525ms</div><div class="line">192.168.234.133:2379 is healthy: successfully committed proposal: took = 1.996245ms</div><div class="line">保存快照:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem snapshot save my.db</div><div class="line">Snapshot saved at my.db</div><div class="line">查看快照状态:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem snapshot status my.db</div><div class="line">+----------+----------+------------+------------+</div><div class="line">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</div><div class="line">+----------+----------+------------+------------+</div><div class="line">| 9a496339 |        3 |          8 |      25 kB |</div><div class="line">+----------+----------+------------+------------+</div><div class="line">恢复数据(要先删除原来数据目录,所有节点操作)：</div><div class="line">[root@etcd1 ~]# etcdctl  --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem snapshot restore my.db  --data-dir=/data/k8s/etcd/</div><div class="line">2017-09-09 02:28:52.439616 I | etcdserver/membership: added member 8e9e05c52164694d [http://localhost:2380] to cluster cdf818194e3a8c32</div><div class="line">删除节点:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem member remove 68243ef8797bd1ce</div><div class="line">更新节点:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem member update 68243ef8797bd1ce https://192.168.234.133:1111(INITIAL_ADVERTISE_PEER_URLS)</div><div class="line">添加节点(删除etcd3，添加etcd4):</div><div class="line">export etcd4=192.168.234.136</div><div class="line">[root@etcd1 ~]#  etcdctl --endpoints=$&#123;etcd1&#125;:2379,$&#123;etcd2&#125;:2379 --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem  member add etcd4 --peer-urls=http://192.168.234.136:2380</div></pre></td></tr></table></figure><blockquote><p>Etcd:从应用场景到实现原理的全方位解读 <a href="http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle" target="_blank" rel="external">http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle</a><br>  Eetcd集群管理 <a href="https://coreos.com/etcd/docs/latest/demo.html" target="_blank" rel="external">https://coreos.com/etcd/docs/latest/demo.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Etcd是什么&quot;&gt;&lt;a href=&quot;#Etcd是什么&quot; class=&quot;headerlink&quot; title=&quot;Etcd是什么&quot;&gt;&lt;/a&gt;Etcd是什么&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;Etcd是一个分布式、使用Raft算法维护一致性的kv存储系统，与其类似产
      
    
    </summary>
    
      <category term="docker" scheme="http://www.simlinux.com/categories/docker/"/>
    
    
      <category term="docker" scheme="http://www.simlinux.com/tags/docker/"/>
    
      <category term="etcd" scheme="http://www.simlinux.com/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>k8s部署之使用CFSSL创建证书</title>
    <link href="http://www.simlinux.com/2017/09/07/k8s-cfssl-install-cert.html"/>
    <id>http://www.simlinux.com/2017/09/07/k8s-cfssl-install-cert.html</id>
    <published>2017-09-07T11:39:05.000Z</published>
    <updated>2017-09-12T01:12:15.139Z</updated>
    
    <content type="html"><![CDATA[<h4 id="安装CFSSL"><a href="#安装CFSSL" class="headerlink" title="安装CFSSL"></a>安装CFSSL</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">curl -s -L -o /bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</div><div class="line">curl -s -L -o /bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</div><div class="line">curl -s -L -o /bin/cfssl-certinfo https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</div><div class="line">chmod +x /bin/cfssl*</div></pre></td></tr></table></figure><h4 id="容器相关证书类型"><a href="#容器相关证书类型" class="headerlink" title="容器相关证书类型"></a>容器相关证书类型</h4><blockquote><p>client certificate： 用于服务端认证客户端,例如etcdctl、etcd proxy、fleetctl、docker客户端<br>server certificate:  服务端使用，客户端以此验证服务端身份,例如docker服务端、kube-apiserver<br>peer certificate: 双向证书，用于etcd集群成员间通信</p></blockquote><h4 id="创建CA证书"><a href="#创建CA证书" class="headerlink" title="创建CA证书"></a>创建CA证书</h4><h5 id="生成默认CA配置"><a href="#生成默认CA配置" class="headerlink" title="生成默认CA配置"></a>生成默认CA配置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mkdir /opt/ssl</div><div class="line">cd /opt/ssl</div><div class="line">cfssl print-defaults config &gt; ca-config.json</div><div class="line">cfssl print-defaults csr &gt; ca-csr.json</div></pre></td></tr></table></figure><p><strong>修改ca-config.json,分别配置针对三种不同证书类型的profile,其中有效期43800h为5年</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">    &#123;</div><div class="line">    &quot;signing&quot;: &#123;</div><div class="line">        &quot;default&quot;: &#123;</div><div class="line">            &quot;expiry&quot;: &quot;43800h&quot;</div><div class="line">        &#125;,</div><div class="line">        &quot;profiles&quot;: &#123;</div><div class="line">            &quot;server&quot;: &#123;</div><div class="line">                &quot;expiry&quot;: &quot;43800h&quot;,</div><div class="line">                &quot;usages&quot;: [</div><div class="line">                    &quot;signing&quot;,</div><div class="line">                    &quot;key encipherment&quot;,</div><div class="line">                    &quot;server auth&quot;</div><div class="line">                ]</div><div class="line">            &#125;,</div><div class="line">            &quot;client&quot;: &#123;</div><div class="line">                &quot;expiry&quot;: &quot;43800h&quot;,</div><div class="line">                &quot;usages&quot;: [</div><div class="line">                    &quot;signing&quot;,</div><div class="line">                    &quot;key encipherment&quot;,</div><div class="line">                    &quot;client auth&quot;</div><div class="line">                ]</div><div class="line">            &#125;,</div><div class="line">            &quot;peer&quot;: &#123;</div><div class="line">                &quot;expiry&quot;: &quot;43800h&quot;,</div><div class="line">                &quot;usages&quot;: [</div><div class="line">                    &quot;signing&quot;,</div><div class="line">                    &quot;key encipherment&quot;,</div><div class="line">                    &quot;server auth&quot;,</div><div class="line">                    &quot;client auth&quot;</div><div class="line">                ]</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p><strong>修改ca-csr.config</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">    &#123;</div><div class="line">    &quot;CN&quot;: &quot;Self Signed Ca&quot;,</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;rsa&quot;,</div><div class="line">        &quot;size&quot;: 2048</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;O&quot;: &quot;Netease&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;,            </div><div class="line">            &quot;OU&quot;: &quot;OT&quot;</div><div class="line">        &#125;    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p><strong>生成CA证书和私钥</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</div><div class="line">生成ca.pem、ca.csr、ca-key.pem(CA私钥,需妥善保管)</div></pre></td></tr></table></figure></p><h5 id="签发Server-Certificate"><a href="#签发Server-Certificate" class="headerlink" title="签发Server Certificate"></a>签发Server Certificate</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">cfssl print-defaults csr &amp;gt; server.json</div><div class="line">vim server.json</div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;Server&quot;,</div><div class="line">    &quot;hosts&quot;: [</div><div class="line">        &quot;192.168.1.1&quot;</div><div class="line">       ],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">生成服务端证书和私钥</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server</div></pre></td></tr></table></figure><h5 id="签发Client-Certificate"><a href="#签发Client-Certificate" class="headerlink" title="签发Client Certificate"></a>签发Client Certificate</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">cfssl print-defaults csr &amp;gt; client.json</div><div class="line">vim client.json</div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;Client&quot;,</div><div class="line">    &quot;hosts&quot;: [],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">生成客户端证书和私钥</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client</div></pre></td></tr></table></figure><h5 id="签发peer-certificate"><a href="#签发peer-certificate" class="headerlink" title="签发peer certificate"></a>签发peer certificate</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">cfssl print-defaults csr &amp;gt; member1.json</div><div class="line">vim member1.json</div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;member1&quot;,</div><div class="line">    &quot;hosts&quot;: [</div><div class="line">        &quot;192.168.1.1&quot;</div><div class="line">    ],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">为节点member1生成证书和私钥:</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer member1.json | cfssljson -bare member1</div><div class="line">针对etcd服务,每个etcd节点上按照上述方法生成相应的证书和私钥</div></pre></td></tr></table></figure><h5 id="最后校验证书"><a href="#最后校验证书" class="headerlink" title="最后校验证书"></a>最后校验证书</h5><p>校验生成的证书是否和配置相符<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">openssl x509 -in ca.pem -text -noout</div><div class="line">openssl x509 -in server.pem -text -noout</div><div class="line">openssl x509 -in client.pem -text -noout</div></pre></td></tr></table></figure></p><h4 id="k8s集群所需证书"><a href="#k8s集群所需证书" class="headerlink" title="k8s集群所需证书"></a>k8s集群所需证书</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/09/cert.jpg" alt=""></p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><blockquote><p><a href="https://coreos.com/os/docs/latest/generate-self-signed-certificates.html" target="_blank" rel="external">https://coreos.com/os/docs/latest/generate-self-signed-certificates.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;安装CFSSL&quot;&gt;&lt;a href=&quot;#安装CFSSL&quot; class=&quot;headerlink&quot; title=&quot;安装CFSSL&quot;&gt;&lt;/a&gt;安装CFSSL&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=
      
    
    </summary>
    
      <category term="docker" scheme="http://www.simlinux.com/categories/docker/"/>
    
    
  </entry>
  
  <entry>
    <title>Django模板无法使用perms变量问题</title>
    <link href="http://www.simlinux.com/2017/09/06/django-e6-a8-a1-e6-9d-bf-e6-97-a0-e6-b3-95-e4-bd-bf-e7-94-a8perms-e5-8f-98-e9-87-8f-e9-97-ae-e9-a2-98.html"/>
    <id>http://www.simlinux.com/2017/09/06/django-e6-a8-a1-e6-9d-bf-e6-97-a0-e6-b3-95-e4-bd-bf-e7-94-a8perms-e5-8f-98-e9-87-8f-e9-97-ae-e9-a2-98.html</id>
    <published>2017-09-06T08:33:00.000Z</published>
    <updated>2017-09-12T01:12:15.115Z</updated>
    
    <content type="html"><![CDATA[<p>首先,在使用Django内置权限管理系统时,settings.py文件要添加</p><pre><code>INSTALLED_APPS添加:&apos;django.contrib.auth&apos;,MIDDLEWARE添加:&apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;,&apos;django.contrib.auth.context_processors.auth&apos;,TEMPLATES = [    {        &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;,        &apos;DIRS&apos;: [os.path.join(BASE_DIR, &apos;templates&apos;)],        &apos;APP_DIRS&apos;: True,        &apos;OPTIONS&apos;: {            &apos;context_processors&apos;: [                &apos;django.template.context_processors.debug&apos;,                &apos;django.template.context_processors.i18n&apos;,                &apos;django.template.context_processors.media&apos;,                &apos;django.template.context_processors.static&apos;,                &apos;django.template.context_processors.tz&apos;,                &apos;django.contrib.messages.context_processors.messages&apos;,                &apos;django.template.context_processors.request&apos;,                &apos;django.contrib.auth.context_processors.auth&apos;,            ],        },    },]`&lt;/pre&gt;如何在模板进行权限检查呢？根据官网说明 https://docs.djangoproject.com/en/1.11/topics/auth/default/#permissions ,已登录用户权限保存在模板{{ perms }}变量中,是权限模板代理django.contrib.auth.context_processors.PermWrapper的一个实例，具体可以查看django/contrib/auth/context_processors.py源码测试用例:![](http://www.simlinux.com/wp-content/uploads/2017/09/codeexample.jpg)测试过程中,发现{{ perms }}变量压根不存在,没有任何输出;好吧,只能取Debug Django的源码了&lt;pre&gt;`def auth(request):    &quot;&quot;&quot;    Returns context variables required by apps that use Django&apos;s authentication    system.    If there is no &apos;user&apos; attribute in the request, uses AnonymousUser (from    django.contrib.auth).    &quot;&quot;&quot;    if hasattr(request, &apos;user&apos;):        user = request.user    else:        from django.contrib.auth.models import AnonymousUser        user = AnonymousUser()    print(user, PermWrapper(user), &apos;-----------------------&apos;)    return {        &apos;user&apos;: user,        &apos;perms&apos;: PermWrapper(user),    }`&lt;/pre&gt;测试访问接口,发现有的接口有打印权限信息,有的没有，似乎恍然醒悟&lt;pre&gt;`可以打印权限信息的接口返回: return render(request, &apos;fms/fms_add.html&apos;, {&apos;request&apos;: request, &apos;form&apos;: form, &apos;error&apos;: error})不能打印权限新的接口返回: return render_to_response( &apos;fms/fms.html&apos;, data)`&lt;/pre&gt;render和render_to_response区别render是比render_to_reponse更便捷渲染模板的方法,会自动使用RequestContext,而后者需要手动添加:&lt;pre&gt;`return render_to_response(request, &apos;fms/fms_add.html&apos;, {&apos;request&apos;: request, &apos;form&apos;: form, &apos;error&apos;: error},context_instance=RequestContext(request))</code></pre><p>其中RequestContext是django.template.Context的子类.接受request和context_processors,从而将上下文填充渲染到模板<br>问题已经很明确，由于使用了render_to_response方法,没有手动添加context_instance=RequestContext(request)导致模板不能使用变量</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;首先,在使用Django内置权限管理系统时,settings.py文件要添加&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INSTALLED_APPS添加:
&amp;apos;django.contrib.auth&amp;apos;,

MIDDLEWARE添加:
&amp;apos;django.cont
      
    
    </summary>
    
      <category term="Python" scheme="http://www.simlinux.com/categories/Python/"/>
    
    
  </entry>
  
  <entry>
    <title>企业级Docker私有仓库部署(https)</title>
    <link href="http://www.simlinux.com/2017/08/05/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e9-83-a8-e7-bd-b2https.html"/>
    <id>http://www.simlinux.com/2017/08/05/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e9-83-a8-e7-bd-b2https.html</id>
    <published>2017-08-05T01:52:42.000Z</published>
    <updated>2017-09-12T01:12:15.117Z</updated>
    
    <content type="html"><![CDATA[<h4 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h4><ul><li>Centos7.3 x64</li><li>docker-ce-17.06.0</li><li>docker-compose-1.15.0</li><li>Python-2.7.5(系统默认)</li></ul><h4 id="部署目标"><a href="#部署目标" class="headerlink" title="部署目标"></a>部署目标</h4><ul><li>使用HTTPS协议</li><li>支持Clair(在Harbor1.2版本会支持)</li></ul><h5 id="支持HTTPS"><a href="#支持HTTPS" class="headerlink" title="支持HTTPS"></a>支持HTTPS</h5><p>生产环境最好由权威CA机构签发证书(免费的推荐StartSSL,可参考<a href="https://www.wosign.com/Support/Nginx.html),这里为了测试方便使用自签发的证书" target="_blank" rel="external">https://www.wosign.com/Support/Nginx.html),这里为了测试方便使用自签发的证书</a></p><ul><li><p>创建CA证书</p><pre><code>openssl req  -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt</code></pre><p> `</p></li><li><p>生成CSR公钥</p><pre>`  openssl req  -newkey rsa:4096 -nodes -sha256 -keyout hub.wow.key  -out hub.wow.csr`</pre></li><li><p>颁发证书<br>*</p><pre>`  openssl x509 -req -days 365 -in hub.wow.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out hub.wow.crt`</pre></li><li><p>部署证书</p><pre>`cp hub.wow.crt hub.wow.key   /data/harbor/keys/vim /data/harbor/harbor.cfg  hostname = hub.wow  ui_url_protocol = https  ssl_cert = /data/harbor/keys/hub.wow.crt  ssl_cert_key = /data/harbor/keys/hub.wow.key    cd /data/harbor    ./prepare  重新生成配置文件    docker-compose down    docker-compose up`</pre></li><li><p>通过HTTPS访问私有仓库</p><p><pre>`WebUI: <a href="https://how.wow" target="_blank" rel="external">https://how.wow</a><br>Docker Client:</pre></p><p>[root@hub ~]# docker login -u admin -p Harbor12345 hub.wow<br>Login Succeeded</p></li></ul><p><strong>问题</strong> ：<br>docker login时提示x509: certificate signed by unknown authority<br>解决方法: 自签名的证书不被系统信任,需要cp ca.crt /etc/docker/certs.d/hub.wow/,  无需重启docker</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;部署环境&quot;&gt;&lt;a href=&quot;#部署环境&quot; class=&quot;headerlink&quot; title=&quot;部署环境&quot;&gt;&lt;/a&gt;部署环境&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Centos7.3 x64&lt;/li&gt;
&lt;li&gt;docker-ce-17.06.0&lt;/li&gt;
&lt;li&gt;docker
      
    
    </summary>
    
      <category term="docker" scheme="http://www.simlinux.com/categories/docker/"/>
    
    
  </entry>
  
  <entry>
    <title>企业级Docker私有仓库之Harbor部署(http)</title>
    <link href="http://www.simlinux.com/2017/08/04/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e4-b9-8bharbor-e9-83-a8-e7-bd-b2http.html"/>
    <id>http://www.simlinux.com/2017/08/04/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e4-b9-8bharbor-e9-83-a8-e7-bd-b2http.html</id>
    <published>2017-08-04T04:20:14.000Z</published>
    <updated>2017-09-12T01:12:15.116Z</updated>
    
    <content type="html"><![CDATA[<h4 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h4><ul><li>Centos7.3 x64</li><li>docker-ce-17.06.0</li><li>docker-compose-1.15.0</li><li>Python-2.7.5(系统默认)</li></ul><h4 id="Docker及Docker-compose安装"><a href="#Docker及Docker-compose安装" class="headerlink" title="Docker及Docker-compose安装"></a>Docker及Docker-compose安装</h4><pre><code> yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager \    --add-repo \    https://download.docker.com/linux/centos/docker-ce.repo yum-config-manager --enable docker-ce-edge yum makecache fast systemctl start docker  systemctl enable dockercurl -L https://github.com/docker/compose/releases/download/1.15.0/docker-compose-`uname -s`-`uname -m` &amp;gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose`&lt;/pre&gt;#### Habor部署配置&lt;pre&gt;`wget https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgztar xf harbor-offline-installer-v1.1.2.tgzcd harbor/vim harbor.cfghostname = hub.wow其他默认(http协议)./install.sh安装成功后，可以通过http://hub.wow/访问`&lt;/pre&gt;![](http://www.simlinux.com/wp-content/uploads/2017/08/harborui.jpg)#### Docker客户端使用由于Harbor默认使用的http协议,故需要在Docker client上的Dockerd服务增加--insecure-registry hub.wowCentos7修改方式为:&lt;pre&gt;`vim /lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd  --insecure-registry hub.wowsystemctl daemon-reloadsystemctl reload docker`&lt;/pre&gt;&lt;pre&gt;`[root@localhost harbor]# docker login -u admin -p Harbor12345 hub.wow官方仓库下载busybox镜像[root@localhost harbor]# docker pull busybox [root@localhost harbor]# docker imagesREPOSITORY                  TAG                 IMAGE ID            CREATED             SIZEbusybox                     latest              efe10ee6727f        2 weeks ago         1.13MB本地基于busybox:latest创建标记hub.wow/busybox:latest[root@localhost harbor]# docker tag busybox:latest hub.wow/project_name/busybox:latest推送本地镜像busybox:latest 到hub.wow私有仓库[root@localhost harbor]# docker push hub.wow/project_name/busybox:latest</code></pre><h4 id="Harbor服务管理"><a href="#Harbor服务管理" class="headerlink" title="Harbor服务管理"></a>Harbor服务管理</h4><p>cd harbor/<br> docker-compose -f ./docker-compose.yml  [ up|down|ps|stop|start ]</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;部署环境&quot;&gt;&lt;a href=&quot;#部署环境&quot; class=&quot;headerlink&quot; title=&quot;部署环境&quot;&gt;&lt;/a&gt;部署环境&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Centos7.3 x64&lt;/li&gt;
&lt;li&gt;docker-ce-17.06.0&lt;/li&gt;
&lt;li&gt;docker
      
    
    </summary>
    
      <category term="docker" scheme="http://www.simlinux.com/categories/docker/"/>
    
    
  </entry>
  
  <entry>
    <title>企业级Docker私有仓库之Harbor</title>
    <link href="http://www.simlinux.com/2017/08/04/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e4-b9-8bharbor.html"/>
    <id>http://www.simlinux.com/2017/08/04/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e4-b9-8bharbor.html</id>
    <published>2017-08-04T04:11:59.000Z</published>
    <updated>2017-09-12T01:12:15.117Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Harbor特性"><a href="#Harbor特性" class="headerlink" title="Harbor特性"></a><strong>Harbor特性</strong></h4><ul><li>基于角色的访问控制: 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限</li><li>基于策略的镜像复制: 镜像可以在不同的Registry实例之间复制,尤其适合LB，HA，多数据中心，混合云和多云的场景</li><li>支持LDAP/AD</li><li>镜像可以被删除，空间可以被回收</li><li>Notary服务(Docker官方,详细参考<a href="https://github.com/docker/notary/blob/master/docs/service_architecture.md)：" target="_blank" rel="external">https://github.com/docker/notary/blob/master/docs/service_architecture.md)：</a> 确认镜像来源是否合法及内容完整性等</li><li>友好的Web管理界面</li><li>支持审计：所有的容器操作都会被跟踪记录</li><li>支持RESTful API</li><li>在Harbor1.2中支持Clair</li></ul><h4 id="Harbor主要组件"><a href="#Harbor主要组件" class="headerlink" title="Harbor主要组件"></a><strong>Harbor主要组件</strong></h4><p>Harbor系统由七个容器组成：Proxy(Nginx)、Jobservice、UI、Adminserver、Registry、Database(MySQL)、Log</p><ul><li>Proxy(Nginx): 提供反向代理、用户的不同请求由Proxy分发到后端UI、Registry等</li><li>Jobservice(harbor-jobservice): 负责处理不同Harbor实例间镜像的复制</li><li>UI(harbor-ui): 该容器包含了Harbor的UI、认证及API服务*   Adminserver(harbor-adminserver): 管理系统配置，并提供相应的WEB页面和api共用户操作</li><li>Registry： Docker官方的Registry镜像，主要提供镜像的存储和分发功能</li><li>Log(harbor-log): 负责搜集其他容器日志</li><li>Database(harbor-db): 提供数据持久化服务,使用的MySQL</li></ul><h4 id="Harbor通信架构"><a href="#Harbor通信架构" class="headerlink" title="Harbor通信架构"></a>Harbor通信架构</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/08/harbor.jpg" alt=""></p><p>详细可以通过官网了解: <a href="https://github.com/vmware/harbor/wiki/Architecture-Overview-of-Harbor" target="_blank" rel="external">https://github.com/vmware/harbor/wiki/Architecture-Overview-of-Harbor</a></p><h4 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h4><ul><li>Docker1.10.0+</li><li>Docker-compose1.6.0+</li><li>Python2.7+</li></ul><h4 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h4><p>配置文件harbor.cfg中的参数有两类:<br>1. 必选参数(更新harbor.cfg,重新安装harbor后生效)<br>2. 可选参数(一般安装时默认设置,安装后通过WebUI配置，且优先级高，会忽略harbor.cfg中的配置),HarborV1.1.2新增AdminServer服务用于管理配置<br> <strong>注</strong>：在注册或者创建harbor用户前，必须正确设置auth&#95;mode;系统中除了默认的admin用户外，其他用户的auth_mode不能更改</p><h5 id="必选参数"><a href="#必选参数" class="headerlink" title="必选参数"></a>必选参数</h5><pre><code>hostname: 设置除localhost/127.0.0.1外的IP或者域名.用于访问WebUI和registry服务ui_url_protocol： (http/https,默认http),用于访问WebUI和token/notification服务的协议，如果Notary启用，则需要设置成httpsdb_password： MySQL数据库密码max_job_workers： 默认3，在job服务里面最大并发复制进程数(将镜像的所有tag同步到远端实例)customize_crt： on or off,默认on,将会创建私钥和根证书用于生成和校验tokenssl_cert： 证书路径,开启https时生效ssl_cert_key： 秘钥路径，开启https时生效secretkey_path： 用于在复制过程过程中加解密远程实例密码的秘钥路径`&lt;/pre&gt;##### 可选参数&lt;pre&gt;`邮箱设置：用于发送重置密码邮件给用户email_server = smtp.mydomain.comemail_server_port = 25email_identity =email_username = sample_admin@mydomain.comemail_password = abc    email_from = admin sample_admin@mydomain.comemail_ssl = falseharbor_admin_password: 第一次登录Harbor WebUI的初始管理员密码admin/Harbor12345auth_mode: 用户登录认证方式，默认db_auth;也可通过ldap_auth(在升级harbor时要确保和旧的harbor认证方式一致)ldap_url: LDAP URL，如ldaps://ldap.mydomain.com，当auth_mode设置成ldap_auth时生效ldap_searchdn: LDAP搜索域如uid=admin,ou=people,dc=mydomain,dc=comldap_search_pwd: 指定ldap_searchdn密码ldap_basedn: LDAP根域如ou=people,dc=mydomain,dc=comldap_filter: 搜索过滤如objectClass=personldap_uid: 通过指定属性匹配用户，如uid、cn、email和其他属性ldap_scope: 搜索用户范围1-LDAP_SCOPE_BASE, 2-LDAP_SCOPE_ONELEVEL, 3-LDAP_SCOPE_SUBTREE,默认3self_registration： on or off，关闭时，新用户只能通过该admin用户在Harbor后台添加；启用时，用户可以自己注册;当auth_mode是ldap_auth时，注册功能是关闭的token_expiration： token service生成的token有效期,默认30分钟(单位:分)project_creation_restriction： 创建项目限制；默认所有用户都可以创建项目,设置为adminonly时，只有admin用户可以创建verify_remote_cert: on or off,默认on;Harbor和远端registry实例通信时是否校验SSL/TLS证书；通常远端实例自己签发或者不信任的证书时，设置off</code></pre><h4 id="配置Harbor后端存储"><a href="#配置Harbor后端存储" class="headerlink" title="配置Harbor后端存储"></a>配置Harbor后端存储</h4><p>默认Harbor会将镜像存储在本地文件系统，也支持S3、Openstack Swift、Ceph等，可以通过修改common/templates/registry/config.yml文件进行配置,可参考 <a href="https://docs.docker.com/registry/configuration/" target="_blank" rel="external">https://docs.docker.com/registry/configuration/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Harbor特性&quot;&gt;&lt;a href=&quot;#Harbor特性&quot; class=&quot;headerlink&quot; title=&quot;Harbor特性&quot;&gt;&lt;/a&gt;&lt;strong&gt;Harbor特性&lt;/strong&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;基于角色的访问控制: 用户与Docker镜像仓
      
    
    </summary>
    
      <category term="docker" scheme="http://www.simlinux.com/categories/docker/"/>
    
    
  </entry>
  
  <entry>
    <title>使用Zabbix LLD实现进程数监控</title>
    <link href="http://www.simlinux.com/2017/04/19/e4-bd-bf-e7-94-a8zabbix-lld-e5-ae-9e-e7-8e-b0-e8-bf-9b-e7-a8-8b-e6-95-b0-e7-9b-91-e6-8e-a7.html"/>
    <id>http://www.simlinux.com/2017/04/19/e4-bd-bf-e7-94-a8zabbix-lld-e5-ae-9e-e7-8e-b0-e8-bf-9b-e7-a8-8b-e6-95-b0-e7-9b-91-e6-8e-a7.html</id>
    <published>2017-04-19T06:52:09.000Z</published>
    <updated>2017-09-12T01:12:15.118Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a><strong>目的</strong></h3><ul><li>针对特定进程数量做监控报警</li></ul><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a><strong>思路</strong></h3><ol><li>通过Zabbix LLD自动发现：每台机器都跑了什么服务、每个服务应该跑多少进程</li><li>Zabbix Agent 30s将当前机器跑了哪些服务、每个服务进程数上报Zabbix Server</li><li>开发给定配置文件proccessInfo.txt:  IP 服务名称 进程数量,此配置作为监控依据</li><li>proccessInfo.txt配置文件需在每次变更配置时，自动生成最新</li></ol><h3 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a><strong>配置流程</strong></h3><ol><li>LLD自动发现脚本</li><li>数据采集脚本</li><li>Agent添加Key</li><li>Zabbix Server添加模板组</li><li>创建自动发现规则(监控项、报警触发器)</li><li>添加当前进程数监控项(通过Zabbix Trapper方式，由Agent端)</li><li>定义报警内容</li></ol><h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a><strong>具体步骤</strong></h3><h4 id="LLD自动发现脚本"><a href="#LLD自动发现脚本" class="headerlink" title="LLD自动发现脚本"></a><strong>LLD自动发现脚本</strong></h4><pre><code>LLD自动发现,将进程名称及进程总数上报Zabbix Server：/usr/bin/python services.py services_list{    &quot;data&quot;: [        {            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_q1_server&quot;,             &quot;{#TRIGGER_VALUE}&quot;: 3        },         {            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_world_d2_server&quot;,             &quot;{#TRIGGER_VALUE}&quot;: 1        },         {            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_gate_server&quot;,             &quot;{#TRIGGER_VALUE}&quot;: 2        },         {            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_world_d1_server&quot;,             &quot;{#TRIGGER_VALUE}&quot;: 1        }    ]}数据采集上报： /usr/bin/python services.py {HOST.HOST}`&lt;/pre&gt;&lt;pre&gt;`# -*- coding: utf-8 -*-import jsonimport commandsimport subprocessimport reimport sysclass services_monitor:        def __init__(self):            self.zabbix_server_ip = &apos;192.168.1.1&apos;            self.info_path = &apos;/home/proccessInfo.txt&apos;            self.data_path = &apos;/tmp/.process_number_monitor.log&apos;        def ip(self):            ipstr = &apos;([0-9]{1,3}\.){3}[0-9]{1,3}&apos;            ipconfig_process = subprocess.Popen(&quot;ifconfig&quot;, stdout=subprocess.PIPE)            output = ipconfig_process.stdout.read()            ip_pattern = re.compile(&apos;(inet addr:%s)&apos; % ipstr)            pattern = re.compile(ipstr)            iplist = []            for ipaddr in re.finditer(ip_pattern, str(output)):                ip = pattern.search(ipaddr.group())                if ip.group() != &quot;127.0.0.1&quot;:                    iplist.append(ip.group())            ip = &apos;|&apos;.join(iplist)            return ip        def check_proc(self,proc_name):            cmd = &apos;ps -ef |grep  %s|grep -v grep|wc -l&apos; % proc_name            proccess_info = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE)            # list=proccess_info.stdout.read().strip().split(&apos;\n&apos;)            procss_num = proccess_info.communicate()[0]            return procss_num        def get_info(self,ip):            service = []            status, result = commands.getstatusoutput(&quot;grep -E &apos;%s&apos; %s&quot; % (str(ip),self.info_path))            result = result.split(&apos;\n&apos;)            for i in result:                i = list(i.split(&apos; &apos;))                service.append({&quot;{#SERVICENAME}&quot;: i[0].strip() + &quot;-&quot; + i[1].strip(), &quot;{#TRIGGER_VALUE}&quot;:int(i[2].strip())})            data = json.dumps({&apos;data&apos;: service}, sort_keys=True, indent=4)            return data        def collect_data(self,data):            data = json.loads(data)[&quot;data&quot;]            commands.getstatusoutput(&apos;cat /dev/null &amp;gt;%s&apos; % self.data_path)            f = open(self.data_path,&apos;a&apos;)            for i  in data:                name = i[&apos;{#SERVICENAME}&apos;].split(&apos;-&apos;)                ip = name[0]                proc_name =  name[1]                f.write(&apos;%s\tproc_num[%s]\t%s&apos; %(ip,i[&apos;{#SERVICENAME}&apos;],self.check_proc(proc_name)))            f.close()        def send_data(self,data_path):            status,output = commands.getstatusoutput(&apos;/bin/bash -c &quot;zabbix_sender -z  %s  -i  %s &amp;amp;&amp;gt;/dev/null&quot;&apos; % (self.zabbix_server_ip,self.data_path))            print status,outputif __name__ == &apos;__main__&apos;:    services = services_monitor()    ip = services.ip()    data = services.get_info(ip)    try:        argv = sys.argv[1]        if argv == &quot;services_list&quot;:            print data        else:            services.collect_data(data)            services.send_data(services.data_path)    except IndexError:        print data`&lt;/pre&gt;#### **Agent添加Key**&lt;pre&gt;`vim /usr/local/etc/zabbix_agentd.confUserParameter=dzpt.service.process.discovery,/usr/bin/python /home/opt/scripts/services.py services_listUserParameter=dzpt.service.process.exec[*],/usr/bin/python /home/opt/scripts/services.py  $1</code></pre><h4 id="创建自动发现规则-监控项Trapper方式、报警触发器"><a href="#创建自动发现规则-监控项Trapper方式、报警触发器" class="headerlink" title="创建自动发现规则(监控项Trapper方式、报警触发器)"></a><strong>创建自动发现规则(监控项Trapper方式、报警触发器)</strong></h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/rules.jpg" alt=""></p><p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/roles-items.jpg" alt=""></p><p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/roles-triggers.jpg" alt=""></p><h4 id="添加当前进程数监控项"><a href="#添加当前进程数监控项" class="headerlink" title="添加当前进程数监控项"></a><strong>添加当前进程数监控项</strong></h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/process-stat.jpg" alt=""></p><h4 id="定义报警内容"><a href="#定义报警内容" class="headerlink" title="定义报警内容"></a><strong>定义报警内容</strong></h4><p>Action中定义(此处略)</p><h4 id="将定义好的模板链接到主机或者其他模板即可"><a href="#将定义好的模板链接到主机或者其他模板即可" class="headerlink" title="将定义好的模板链接到主机或者其他模板即可"></a><strong>将定义好的模板链接到主机或者其他模板即可</strong></h4><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a><strong>最后</strong></h3><p>使用Zabbix LLD之后，可以设定多久更新一次监控项及监控阀值；当配置文件变更时，无需人为调整阀值和监控项</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;&lt;strong&gt;目的&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;针对特定进程数量做监控报警&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;思路&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>架构学习之路-高可用高并发系统设计原则</title>
    <link href="http://www.simlinux.com/2017/04/13/e6-9e-b6-e6-9e-84-e5-ad-a6-e4-b9-a0-e4-b9-8b-e8-b7-af-e9-ab-98-e5-8f-af-e7-94-a8-e9-ab-98-e5-b9-b6-e5-8f-91-e7-b3-bb-e7-bb-9f-e8-ae-be-e8-ae-a1-e5-8e-9f-e5-88-99.html"/>
    <id>http://www.simlinux.com/2017/04/13/e6-9e-b6-e6-9e-84-e5-ad-a6-e4-b9-a0-e4-b9-8b-e8-b7-af-e9-ab-98-e5-8f-af-e7-94-a8-e9-ab-98-e5-b9-b6-e5-8f-91-e7-b3-bb-e7-bb-9f-e8-ae-be-e8-ae-a1-e5-8e-9f-e5-88-99.html</id>
    <published>2017-04-13T11:00:05.000Z</published>
    <updated>2017-09-12T01:12:15.126Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本系列博客主要是学习开涛《亿级流量网站架构核心技术》一书学习笔记及自己的感悟：</p></blockquote><h4 id="架构设计三大定律"><a href="#架构设计三大定律" class="headerlink" title="架构设计三大定律"></a>架构设计三大定律</h4><blockquote><p>墨菲定律</p><ul><li>任何事没有表面看起来那么简单</li><li>所有的事都会比预计的时间长</li><li>可能出错的事情总会出错</li><li><p>担心某种事情发生，那么它就更有可能发生</p><p>康威定律</p></li></ul></blockquote><ul><li>系统架构师公司组织架构的反映</li><li>按照业务闭环进行系统拆分/组织架构划分，实现闭环、高内聚、低耦合，减少沟通成本</li><li>如果沟通出现问题，应该考虑进行系统和组织架构的调整</li><li>适合时机进行系统拆分，不要一开始就吧系统、服务拆分拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高</li><li>微服务架构的理论基础 - 康威定律 <a href="https://yq.aliyun.com/articles/8611" target="_blank" rel="external">https://yq.aliyun.com/articles/8611</a></li><li>每个架构师都应该研究下康威定律 <a href="http://36kr.com/p/5042735.html" target="_blank" rel="external">http://36kr.com/p/5042735.html</a></li></ul><blockquote><p>二八定律</p></blockquote><ul><li>80%的结果取决于20%的原因</li></ul><h4 id="系统设计遵循的原则"><a href="#系统设计遵循的原则" class="headerlink" title="系统设计遵循的原则"></a>系统设计遵循的原则</h4><h5 id="1-高并发原则"><a href="#1-高并发原则" class="headerlink" title="1. 高并发原则"></a>1. 高并发原则</h5><blockquote><p>无状态</p></blockquote><ul><li>无状态应用，便于水平扩展</li><li>有状态配置可通过配置中心实现无状态</li><li>实践: Disconf、Yaconf、Zookpeer、Consul、Confd、Diamond、Xdiamond等</li></ul><blockquote><p>拆分</p></blockquote><ul><li>系统维度：按照系统功能、业务拆分，如购物车，结算，订单等</li><li>功能维度：对系统功能在做细粒度拆分</li><li>读写维度：根据读写比例特征拆分；读多，可考虑多级缓存；写多，可考虑分库分表</li><li>AOP维度： 根据访问特征，按照AOP进行拆分，比如商品详情页可分为CDN、页面渲染系统，CDN就是一个AOP系统</li><li>模块维度：对整体代码结构划分Web、Service、DAO</li></ul><blockquote><p>服务化</p></blockquote><ul><li>服务化演进: 进程内服务-单机远程服务-集群手动注册服务-自动注册和发现服务-服务的分组、隔离、路由-服务治理</li><li>考虑服务分组、隔离、限流、黑白名单、超时、重试机制、路由、故障补偿等</li><li>实践：利用Nginx、HaProxy、LVS等实现负载均衡，ZooKeeper、Consul等实现自动注册和发现服</li></ul><blockquote><p>消息队列</p></blockquote><ul><li>目的: 服务解耦(一对多消费)、异步处理、流量削峰缓冲等</li><li>大流量缓冲： 牺牲强一致性，保证最终一致性(案例：库存扣减，现在Redis中做扣减，记录扣减日志，通过后台进程将扣减日志应用到DB)</li><li>数据校对: 解决异步消息机制下消息丢失问题</li></ul><blockquote><p>数据异构</p></blockquote><ul><li>数据异构: 通过消息队列机制接收数据变更，原子化存储</li><li>数据闭环: 屏蔽多从数据来源，将数据异构存储，形成闭环</li></ul><blockquote><p>缓存银弹</p></blockquote><ul><li><p>用户层:</p><pre><code>*   DNS缓存</code></pre><ul><li>浏览器DNS缓存</li><li>操作系统DNS缓存</li><li>本地DNS服务商缓存</li><li>DNS服务器缓存</li><li>客户端缓存</li><li>浏览器缓存(Expires、Cache-Control、Last-Modified、Etag)*   App客户缓存(js/css/image…)</li></ul></li><li><p>代理层：</p><pre><code>*   CDN缓存(一般基于ATS、Varnish、Nginx、Squid等构建,边缘节点-二级节点-中心节点-源站)</code></pre></li><li><p>接入层：</p><pre><code>*   Nginx为例：    *   Proxy_cache： 代理缓存,可以存储到/dev/shm或者SSD*   FastCGI Cache*   Nginx+Lua+Redis: 业务数据缓存</code></pre><ul><li><p>PHP为例：</p><pre><code>*   Opcache： 缓存PHP的Opcodes</code></pre></li></ul></li><li><p>应用层：</p><pre><code>*   页面静态化</code></pre><ul><li>业务数据缓存(Redis/Memcached/本地文件等)</li><li>消息队列</li></ul></li><li><p>数据层：</p><pre><code>*   NoSQL： Redis、Memcache、SSDB等</code></pre><ul><li>MySQL： Innodb/MyISAM等Query Cache、Key Cache、Innodb Buffer Size等</li></ul></li><li><p>系统层：</p><pre><code>*   CPU : L1/L2/L3 Cache/NUMA</code></pre><ul><li>内存</li><li>磁盘：磁盘本身缓存、dirty_ratio/dirty_background_ratio、阵列卡本身缓存</li></ul></li></ul><blockquote><p>并发化</p></blockquote><h5 id="2-高可用原则"><a href="#2-高可用原则" class="headerlink" title="2. 高可用原则"></a>2. 高可用原则</h5><blockquote><p>降级</p></blockquote><ul><li>降级开关集中化管理：将开关配置信息推送到各个应用</li><li>可降级的多级读服务：如服务调用降级为只读本地缓存</li><li>开关前置化：如Nginx+lua(OpenResty)配置降级策略，引流流量；可基于此做灰度策略</li><li>业务降级：高并发下，保证核心功能，次要功能可由同步改为异步策略或屏蔽功能</li></ul><blockquote><p>限流</p></blockquote><ul><li>目的: 防止恶意请求攻击或超出系统峰值</li><li><p>实践：</p><pre><code>*   恶意请求流量只访问到Cache</code></pre><ul><li>穿透后端应用的流量使用Nginx的limit处理</li><li>恶意IP使用Nginx Deny策略或者iptables拒绝</li></ul></li></ul><blockquote><p>切流量</p></blockquote><ul><li>目的：屏蔽故障机器</li><li><p>实践:</p><pre><code>*   DNS: 更改域名解析入口，如DNSPOD可以添加备用IP，正常IP故障时，会自主切换到备用地址;生效实践较慢</code></pre><ul><li>HttpDNS: 为了绕过运营商LocalDNS实现的精准流量调度</li><li>LVS/HaProxy/Nginx: 摘除故障节点</li></ul></li></ul><blockquote><p>可回滚</p></blockquote><ul><li>发布版本失败时可随时快速回退到上一个稳定版本</li></ul><h5 id="3-业务设计原则"><a href="#3-业务设计原则" class="headerlink" title="3. 业务设计原则"></a>3. 业务设计原则</h5><ul><li>防重设计</li><li>幂等设计</li><li>流程定义</li><li>状态与状态机</li><li>后台系统操作可反馈</li><li>后台系统审批化</li><li>文档注释</li><li>备份</li></ul><h5 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h5><p>先行规划和设计时有必要的，要对现有问题有方案，对未来有预案;欠下的技术债，迟早都是要还的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;本系列博客主要是学习开涛《亿级流量网站架构核心技术》一书学习笔记及自己的感悟：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;架构设计三大定律&quot;&gt;&lt;a href=&quot;#架构设计三大定律&quot; class=&quot;headerlink&quot; title=&quot;架构
      
    
    </summary>
    
      <category term="架构之路" scheme="http://www.simlinux.com/categories/%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%B7%AF/"/>
    
    
  </entry>
  
  <entry>
    <title>CPU工作模式及调频</title>
    <link href="http://www.simlinux.com/2017/03/24/cpu-e5-b7-a5-e4-bd-9c-e6-a8-a1-e5-bc-8f-e5-8f-8a-e8-b0-83-e9-a2-91.html"/>
    <id>http://www.simlinux.com/2017/03/24/cpu-e5-b7-a5-e4-bd-9c-e6-a8-a1-e5-bc-8f-e5-8f-8a-e8-b0-83-e9-a2-91.html</id>
    <published>2017-03-24T04:42:18.000Z</published>
    <updated>2017-09-12T01:12:15.115Z</updated>
    
    <content type="html"><![CDATA[<h5 id="安装i7z及cpufrequtils"><a href="#安装i7z及cpufrequtils" class="headerlink" title="安装i7z及cpufrequtils"></a>安装i7z及cpufrequtils</h5><pre><code> apt-get install i7z cpufrequtils`&lt;/pre&gt;##### 常见的CPU工作模式&lt;table&gt;&lt;thead&gt;&lt;tr&gt;  &lt;th&gt;调速器&lt;/th&gt;  &lt;th align=&quot;left&quot;&gt;描述&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;  &lt;td&gt;ondemand&lt;/td&gt;  &lt;td align=&quot;left&quot;&gt;按需快速动态调整CPU频率， 一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率（阙值为 95%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;  &lt;td&gt;performance&lt;/td&gt;  &lt;td align=&quot;left&quot;&gt;运行于最大频率&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;  &lt;td&gt;conservative&lt;/td&gt;  &lt;td align=&quot;left&quot;&gt;按需快速动态调整CPU频率， 一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率（阙值为 75%）&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;  &lt;td&gt;powersave&lt;/td&gt;  &lt;td align=&quot;left&quot;&gt;运行于最小频率&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;  &lt;td&gt;userspace&lt;/td&gt;  &lt;td align=&quot;left&quot;&gt;运行于用户指定的频率&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;##### 查看当前CPU工作模式&lt;pre&gt;`查看CPU当前的工作模式cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor查看支持的CPU工作模式cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors`&lt;/pre&gt;由于在Debian 8下默认使用intel_pstate驱动,只支持performance和powersave模式,不同频率驱动程序支持的模式不同具体可以参考：CPU frequency scaling  http://t.cn/R6cQXvp##### 调整最高性能模式&lt;pre&gt;`echo &apos;performance&apos; |tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor`&lt;/pre&gt;##### CPU调频&lt;pre&gt;`Usage: cpufreq-set [options] Options:-c CPU, --cpu CPU       #指定CPU核心号，请注意上图的analyzing CPU数字。-d FREQ, --min FREQ     #手工指定最小主频速度。（在userspace策略）-u FREQ, --max FREQ     #手工指定最大主频速度。（在userspace策略）-g GOV, --governor GOV  #设置工作策略-f FREQ, --freq FREQ    #设定特定的工作频率（CPU默认档次）#请参考上图的available frequency steps-h, --help            #输出这个帮助信息cpufreq-set  -d 2.4Ghz -u 2.4Ghz</code></pre><h5 id="实时查看频率"><a href="#实时查看频率" class="headerlink" title="实时查看频率"></a>实时查看频率</h5><p>通过i7z命令可实时查看当前CPU的工作频率</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;安装i7z及cpufrequtils&quot;&gt;&lt;a href=&quot;#安装i7z及cpufrequtils&quot; class=&quot;headerlink&quot; title=&quot;安装i7z及cpufrequtils&quot;&gt;&lt;/a&gt;安装i7z及cpufrequtils&lt;/h5&gt;&lt;pre&gt;&lt;cod
      
    
    </summary>
    
      <category term="Linux运维" scheme="http://www.simlinux.com/categories/Linux%E8%BF%90%E7%BB%B4/"/>
    
    
  </entry>
  
  <entry>
    <title>Nginx/Haproxy作为反向代理或负载均衡时如何获取客户真实IP？</title>
    <link href="http://www.simlinux.com/2017/03/01/nginxhaproxy-e4-bd-9c-e4-b8-ba-e5-8f-8d-e5-90-91-e4-bb-a3-e7-90-86-e6-88-96-e8-b4-9f-e8-bd-bd-e5-9d-87-e8-a1-a1-e6-97-b6-e5-a6-82-e4-bd-95-e8-8e-b7-e5-8f-96-e5-ae-a2-e6-88-b7-e7-9c-9f-e5-ae-9eip.html"/>
    <id>http://www.simlinux.com/2017/03/01/nginxhaproxy-e4-bd-9c-e4-b8-ba-e5-8f-8d-e5-90-91-e4-bb-a3-e7-90-86-e6-88-96-e8-b4-9f-e8-bd-bd-e5-9d-87-e8-a1-a1-e6-97-b6-e5-a6-82-e4-bd-95-e8-8e-b7-e5-8f-96-e5-ae-a2-e6-88-b7-e7-9c-9f-e5-ae-9eip.html</id>
    <published>2017-03-01T08:51:27.000Z</published>
    <updated>2017-09-12T01:12:15.158Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Nginx代理配置"><a href="#Nginx代理配置" class="headerlink" title="Nginx代理配置"></a>Nginx代理配置</h5><p>增加如下配置:</p><pre><code>proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X_FORWARDED_PROTO https;proxy_set_header Host $host;`&lt;/pre&gt;##### Haproxy配置&lt;pre&gt;`option forwardfor`&lt;/pre&gt;##### 后端Nginx配置&lt;pre&gt;`set_real_ip_from  1.1.1.1;  前端Nginx代理或者负载均衡的IP(在后端Nginx日志中显示的)real_ip_header  X-Forwarded-For;real_ip_recursive  on;`&lt;/pre&gt;##### 后端Nginx访问控制&lt;pre&gt;`location ~ /test/api/ {        set $allow false;        if ($http_x_forwarded_for ~ &quot;2.2.2.2&quot;) {            set $allow false;                        }        if ($allow = false) { return 403;}            proxy_pass  http://web;        }}</code></pre><h5 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h5><blockquote><ul><li><a href="http://www.wkii.org/nginx-cdn-get-user-real-ip.html" target="_blank" rel="external">http://www.wkii.org/nginx-cdn-get-user-real-ip.html</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h5 id=&quot;Nginx代理配置&quot;&gt;&lt;a href=&quot;#Nginx代理配置&quot; class=&quot;headerlink&quot; title=&quot;Nginx代理配置&quot;&gt;&lt;/a&gt;Nginx代理配置&lt;/h5&gt;&lt;p&gt;增加如下配置:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;proxy_set_header X-
      
    
    </summary>
    
      <category term="Linux运维" scheme="http://www.simlinux.com/categories/Linux%E8%BF%90%E7%BB%B4/"/>
    
    
  </entry>
  
  <entry>
    <title>网卡软中断过高问题优化总结</title>
    <link href="http://www.simlinux.com/2017/02/28/e7-bd-91-e5-8d-a1-e8-bd-af-e4-b8-ad-e6-96-ad-e8-bf-87-e9-ab-98-e9-97-ae-e9-a2-98-e4-bc-98-e5-8c-96-e6-80-bb-e7-bb-93.html"/>
    <id>http://www.simlinux.com/2017/02/28/e7-bd-91-e5-8d-a1-e8-bd-af-e4-b8-ad-e6-96-ad-e8-bf-87-e9-ab-98-e9-97-ae-e9-a2-98-e4-bc-98-e5-8c-96-e6-80-bb-e7-bb-93.html</id>
    <published>2017-02-28T11:06:50.000Z</published>
    <updated>2017-09-12T01:12:15.129Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>游戏网关高峰期时出网络丢包,CPU0软中断%sys高达90%</p><h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><h4 id="什么是中断"><a href="#什么是中断" class="headerlink" title="什么是中断?"></a>什么是中断?</h4><p>由于接收来自外围硬件(相对于CPU和内存)的异步信号或者来自软件的同步信号，而进行相应的硬件、软件处理；发出这样的信号称为进行中断请求(interrupt request, IRQ)</p><h4 id="硬中断与软中断"><a href="#硬中断与软中断" class="headerlink" title="硬中断与软中断?"></a>硬中断与软中断?</h4><ul><li><strong>硬中断</strong>：外围硬件发给CPU或者内存的异步信号就称之为硬中断</li><li><strong>软中断</strong>：由软件系统本身发给操作系统内核的中断信号，称之为软中断。通常是由硬中断处理程序或进程调度程序对操作系统内核的中断，也就是我们常说的系统调用(System Call)</li></ul><h4 id="硬中断与软中断之区别与联系？"><a href="#硬中断与软中断之区别与联系？" class="headerlink" title="硬中断与软中断之区别与联系？"></a>硬中断与软中断之区别与联系？</h4><ol><li>硬中断是有外设硬件发出的，需要有中断控制器之参与。其过程是外设侦测到变化，告知中断控制器，中断控制器通过CPU或内存的中断脚通知CPU，然后硬件进行程序计数器及堆栈寄存器之现场保存工作（引发上下文切换），并根据中断向量调用硬中断处理程序进行中断处理</li><li>软中断则通常是由硬中断处理程序或者进程调度程序等软件程序发出的中断信号，无需中断控制器之参与，直接以一个CPU指令之形式指示CPU进行程序计数器及堆栈寄存器之现场保存工作(亦会引发上下文切换)，并调用相应的软中断处理程序进行中断处理(即我们通常所言之系统调用)</li><li>硬中断直接以硬件的方式引发，处理速度快。软中断以软件指令之方式适合于对响应速度要求不是特别严格的场景</li><li>硬中断通过设置CPU的屏蔽位可进行屏蔽，软中断则由于是指令之方式给出，不能屏蔽</li><li>硬中断发生后，通常会在硬中断处理程序中调用一个软中断来进行后续工作的处理</li><li>硬中断和软中断均会引起上下文切换(进程/线程之切换)，进程切换的过程是差不多的</li></ol><h3 id="查看中断情况"><a href="#查看中断情况" class="headerlink" title="查看中断情况"></a>查看中断情况</h3><p><strong>查看中断分布情况即CPU都在哪些设备上干活，干了多少(也可以使用itop工具实时查看)？</strong></p><pre><code>root@geekwolf:~# cat /proc/interrupts           CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7       CPU8       CPU9       CPU10      CPU11      CPU12      CPU13      CPU14      CPU15      CPU16      CPU17      CPU18      CPU19      CPU20      CPU21      CPU22      CPU23      CPU24      CPU25      CPU26      CPU27      CPU28      CPU29      CPU30      CPU31        0:        620          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-edge      timer  8:          1          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-edge      rtc0  9:      20774          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-fasteoi   acpi 16:         28          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-fasteoi   ehci_hcd:usb1 23:        243          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-fasteoi   ehci_hcd:usb2 88:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  DMAR_MSI-edge      dmar0 89:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  DMAR_MSI-edge      dmar1 90:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 91:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 92:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 93:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 94:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 95:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 96:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 97:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 98:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME 99:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME100:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME101:     169988          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      mpt2sas0-msix0134:    1900138          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      eth2-q0150:    4262209          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      eth3-q0166:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix167:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix168:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix169:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix170:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix171:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix172:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix173:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix174:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix175:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix176:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix177:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix178:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix179:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix180:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix181:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msixNMI:        710        280        658        235        114         91         76         74        208        123        176        128        106         93        102         95         30        360        790         46         28         17         10          8         10        129       1166         22         18         16         11          7   Non-maskable interruptsLOC:    4230314    2640664    2427443    1337890    1091372     892129     819153     816781    2695809    1563153    1368637    1608410    1241692    1166692    1205270    1124865     120831    1966946     328048     816162     163492     222276     129805     121126     111906     599782    1247371     194215     162828     145678     118762     114295   Local timer interruptsSPU:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Spurious interruptsPMI:        710        280        658        235        114         91         76         74        208        123        176        128        106         93        102         95         30        360        790         46         28         17         10          8         10        129       1166         22         18         16         11          7   Performance monitoring interruptsIWI:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   IRQ work interruptsRES:     679921    1369165    1013002     573776     543083     540027     593345     588120     842115     846190     874862     890102     873810     860080     867322     848916       3879      63916      10863      12850       7463       6350      10889      16041       2065      13207       6870       6817       4030       4700       5190       7430   Rescheduling interruptsCAL:      46507      67439      67569      67567      67565      67566      67566      67568     154689      67553      67511      67538      67568      67557      67534      67519      67520      26471      67470      67470      67476      67525      67518      67525      67545      64065      67210      67506      67485      67492      67526      67521   Function call interruptsTLB:       6547       3416       1798       1015        361        637        271        447        822        113       1079        222        259        198        265        844        157       1470       3468        767        499        262        338        230         41       1457       4023        290        105         93         46        177   TLB shootdownsTRM:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Thermal event interruptsTHR:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Threshold APIC interruptsMCE:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Machine check exceptionsMCP:        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569   Machine check pollsERR:          0MIS:          0`&lt;/pre&gt;从上面的数据可以看出网卡eth2、eth3软中断都落在CPU0可以通过cat /proc/softirqs查看具体的软中断情况,总的中断次数可以通过vmstat或者dstat查看，其中vmstat中的in表示每秒的中断次数；通过mpstat -P ALL 2,每隔两秒查看下所有核状态信息，其中%irq为硬中断，%soft为软中断&lt;pre&gt;`root@geekwolf:~# mpstat -P ALL 208:42:04 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle08:42:05 AM  all    4.31    0.00    0.70    0.00    0.00    0.06    0.00    0.00   94.9308:42:05 AM    0    5.26    0.00    1.05    0.00    0.00    60.05    0.00    0.00   92.6308:42:05 AM    1    7.07    0.00    1.01    0.00    0.00    0.00    0.00    0.00   91.9208:42:05 AM    2    8.91    0.00    0.99    0.00    0.00    0.00    0.00    0.00   90.1008:42:05 AM    3    8.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   91.0008:42:05 AM    4    8.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   91.0008:42:05 AM    5    7.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00   91.0008:42:05 AM    6    7.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   92.0008:42:05 AM    7    4.12    0.00    1.03    0.00    0.00    0.00    0.00    0.00   94.8508:42:05 AM    8    4.17    0.00    1.04    0.00    0.00    0.00    0.00    0.00   94.7908:42:05 AM    9    8.91    0.00    0.99    0.00    0.00    0.00    0.00    0.00   90.1008:42:05 AM   10    4.17    0.00    2.08    0.00    0.00    0.00    0.00    0.00   93.7508:42:05 AM   11    6.12    0.00    1.02    0.00    0.00    0.00    0.00    0.00   92.8608:42:05 AM   12    6.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00   92.0008:42:05 AM   13    3.16    0.00    1.05    0.00    0.00    0.00    0.00    0.00   95.7908:42:05 AM   14    8.16    0.00    1.02    0.00    0.00    0.00    0.00    0.00   90.8208:42:05 AM   15    6.06    0.00    1.01    0.00    0.00    1.01    0.00    0.00   91.9208:42:05 AM   16    3.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   96.0008:42:05 AM   17    2.02    0.00    1.01    0.00    0.00    0.00    0.00    0.00   96.9708:42:05 AM   18    2.04    0.00    1.02    0.00    0.00    0.00    0.00    0.00   96.9408:42:05 AM   19    2.97    0.00    0.99    0.00    0.00    0.00    0.00    0.00   96.0408:42:05 AM   20    2.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.9608:42:05 AM   21    2.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.0008:42:05 AM   22    3.03    0.00    0.00    0.00    0.00    0.00    0.00    0.00   96.9708:42:05 AM   23    2.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.9608:42:05 AM   24    4.95    0.00    0.00    0.00    0.00    0.00    0.00    0.00   95.0508:42:05 AM   25    2.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.9808:42:05 AM   26    3.03    0.00    0.00    0.00    0.00    0.00    0.00    0.00   96.9708:42:05 AM   27    2.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.9608:42:05 AM   28    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00   97.9808:42:05 AM   29    1.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.9808:42:05 AM   30    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.9908:42:05 AM   31    1.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.98`&lt;/pre&gt;### 何优化软中断CPU0过高问题#### RSS(Receive Side Scaling，需网卡支持多队列)##### 查看网卡是否支持队列&lt;pre&gt;`root@geekwolf:~# lscpi -vvv06:00.0 Ethernet controller: Broadcom Corporation BCM57840 NetXtreme II 10/20-Gigabit Ethernet (rev 11) Subsystem: Hewlett-Packard Company Device 22fa Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx+ Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &amp;gt;TAbort- &amp;lt;tabort - &amp;lt;MAbort- &amp;gt;SERR- &amp;lt;perr - INTx- Latency: 0, Cache Line Size: 64 bytes Interrupt: pin A routed to IRQ 32 Region 0: Memory at 93800000 (64-bit, prefetchable) [size=8M] Region 2: Memory at 93000000 (64-bit, prefetchable) [size=8M] Region 4: Memory at 95000000 (64-bit, prefetchable) [size=64K] [virtual] Expansion ROM at 95080000 [disabled] [size=512K] Capabilities: [48] Power Management version 3   Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1-,D2-,D3hot+,D3cold+)   Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=1 PME- Capabilities: [50] Vital Product Data   Product Name: HP FlexFabric 10Gb 2-port 536FLB Adapter   Read-only fields:     [PN] Part number: 766488-001     [EC] Engineering changes: A-5444     [MN] Manufacture ID: 31 30 33 43     [V0] Vendor specific: 12W PCIeGen3     [V1] Vendor specific: 7.10.55     [V3] Vendor specific: 7.10.72     [V5] Vendor specific: 0A     [V6] Vendor specific: 7.10.72     [V7] Vendor specific: 536FLB     [SN] Serial number: 7C444703LG     [V2] Vendor specific: 5447     [V4] Vendor specific: 8CDCD419D870     [RV] Reserved: checksum good, 186 byte(s) reserved   End Capabilities: [a0] MSI-X: Enable+ Count=32 Masked-`&lt;/pre&gt;找到Ethernet controller项，如果有MSI-X,Enable+ 并且Count&gt;1，表示该网卡支持多队列##### 查看网卡支持多少个队列&lt;pre&gt;`root@geekwolf:~# grep eth0 /proc/interrupts |awk &apos;{print $NF}&apos;eth0eth0-fp-0eth0-fp-1eth0-fp-2eth0-fp-3eth0-fp-4eth0-fp-5eth0-fp-6eth0-fp-7`&lt;/pre&gt;##### 配置SMP IRQ affinity(即绑定队列到不同CPU,Kernel&gt;2.4)方法1：开启系统irqbalance服务&lt;pre&gt;`apt-get -y install irqbalanceservice irqbalance start`&lt;/pre&gt;方法2: 手动绑定&lt;pre&gt;`/proc/irq/：该目录下存放的是以IRQ号命名的目录，如/proc/irq/40/，表示中断号为40的相关信息/proc/irq/[irq_num]/smp_affinity：该文件存放的是CPU位掩码（十六进制）。修改该文件中的值可以改变CPU和某中断的亲和性/proc/irq/[irq_num]/smp_affinity_list：该文件存放的是CPU列表（十进制）。注意，CPU核心个数用表示编号从0开始，如cpu0,cpu1等,smp_affinity和smp_affinity_list修改其一即可，下面修改smp_affinity：echo $bitmask &amp;gt; /proc/irq/IRQ#/smp_affinity示例(把140号中断绑定到前4个CPU[cpu0-3]上面):echo  f &amp;gt;/proc/irq/140/smp_affinity</code></pre><h5 id="CPU位掩码计算"><a href="#CPU位掩码计算" class="headerlink" title="CPU位掩码计算"></a>CPU位掩码计算</h5><p>一个十六进制f转换成二进制为1111，每一位表示一个CPU核，最靠右值是最低位即CPU0</p><pre>           Binary       Hex   CPU 0    0001         1   CPU 1    0010         2   CPU 2    0100         4   CPU 3    1000         8   其中十六进制2就表示CPU1，十六进制8就表示CPU3           Binary       Hex   CPU 0    0001         1 + CPU 2    0100         4   -----------------------   both     0101         5   其中得出的十六进制和5表示CPU0 和CPU2           Binary       Hex   CPU 0    0001         1   CPU 1    0010         2   CPU 2    0100         4 + CPU 3    1000         8   -----------------------   both     1111         f   4个CPU参与中断，即可设置为f，8个CPU参与中断可设置为ff，以此类推</pre><h5 id="配置RSS"><a href="#配置RSS" class="headerlink" title="配置RSS"></a>配置RSS</h5><pre>过滤eth0中断号，绑定到0-7号CPU核上（eth0-fp命名可能有所不同）:root@geekwolf:~# grep eth0-fp /proc/interrupts |awk '{print $1, $NF}'147: eth0-fp-0148: eth0-fp-1149: eth0-fp-2150: eth0-fp-3151: eth0-fp-4152: eth0-fp-5153: eth0-fp-6154: eth0-fp-7echo 1  >/proc/irq/147/smp_affinityecho 2  >/proc/irq/148/smp_affinityecho 4  >/proc/irq/149/smp_affinityecho 8  >/proc/irq/150/smp_affinityecho 10 >/proc/irq/151/smp_affinityecho 20 >/proc/irq/152/smp_affinityecho 40 >/proc/irq/153/smp_affinityecho 80 >/proc/irq/154/smp_affinity可以通过top命令查看%si是否均衡分摊到0-7核CPU</pre><h5 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h5><ol><li>启动irqbalance后，手动绑定将失效</li><li>当CPU工作在最高性能模式时，irqbalance会均匀分配中断到其他CPU，节能模式时中断会集中分配到CPU0</li><li>以上设置均以网卡支持多队列为前提，建议手动绑定SMP IRQ affinity</li><li>网卡多队列需tg3,bnx2,bnx2x,b44等驱动的支持，Broadcom的网卡驱动已经内置在内核中向后兼容大部分的2.6内核及大于2.4.24的2.4内核</li><li>笔者实际测试过程中遇到BladeCenter HS23刀片服务器Emulex Corporation OneConnect 10Gb NIC (be3)本身支持多队列，在连接到千兆网环境下无法使用多队列问题，万兆网络下可以使用，只好通过下面RPS/RFS方式实现</li></ol><h4 id="RPS-RFS"><a href="#RPS-RFS" class="headerlink" title="RPS/RFS"></a>RPS/RFS</h4><p>Receive Packet Steering/Receive Flow Streering,软件方式实现CPU均衡，接收包中断的优化<br>RPS: 网卡驱动对每一个数据库包根据四元组(SIP,SPORT,DIP,DPORT)生成HASH值,通过HASH值将每个连接和CPU 绑定<br>RFS： 由于RPS只是单纯的把数据包均衡到不同的CPU上，此时如果应用程序所在CPU和中断处理的CPU不在同一个核，将会对CPU Cache影响很大，RFS的作用就是将应用程序和软中断处理分配到同一个CPU<br>配置步骤:</p><p>根据上述说明一个十六进制f表示四个CPU核，那么均衡到32核即ffffffff</p><h5 id="配置RPS"><a href="#配置RPS" class="headerlink" title="配置RPS"></a>配置RPS</h5><pre>rps_cpus='ffffffffff'for rxdir in /sys/class/net/eth0/queues/rx-*do    echo $rps_cpus >$rxdir/rps_cpusdone</pre><h5 id="配置RFS"><a href="#配置RFS" class="headerlink" title="配置RFS"></a>配置RFS</h5><p>RFS扩展了RPS的性能以增加CPU缓存命中率，减少网络延迟,默认是禁用的<br><code>⁠/proc/sys/net/core/rps_sock_flow_entries设置此文件至同时活跃连接数的最大预期值。对于中等服务器负载，推荐值为 32768 。所有输入的值四舍五入至最接近的2的幂/sys/class/net/device/queues/rx-queue/rps_flow_cnt将 device 改为想要配置的网络设备名称（例如，eth0），将 rx-queue 改为想要配置的接收队列名称（例如，rx-0）。将此文件的值设为 rps_sock_flow_entries 除以 N，其中 N 是设备中接收队列的数量。例如，如果 rps_flow_entries 设为 32768，并且有 16 个配置接收队列，那么 rps_flow_cnt 就应设为 2048。对于单一队列的设备，rps_flow_cnt 的值和 rps_sock_flow_entries 的值是一样的</code></p><pre>ls /sys/class/net/eth0/queues/rx-*|grep queues|wc -l8rps_flow_cnt=32768/8=4096echo 32768 >/proc/sys/net/core/rps_sock_flow_entriesfor rxdir in /sys/class/net/eth0/queues/rx-*do    echo $rps_cpus >$rxdir/rps_cpus    echo $rps_flow_cnt >$rxdir/rps_flow_cntdoneecho 32768 >/proc/sys/net/core/rps_sock_flow_entries</pre><p>优化脚本可参考: <a href="https://github.com/geekwolf/sa-scripts/blob/master/ops-scripts/performance_tuning/set_rps.sh" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/blob/master/ops-scripts/performance_tuning/set_rps.sh</a></p><h4 id="网卡常规优化方案"><a href="#网卡常规优化方案" class="headerlink" title="网卡常规优化方案"></a>网卡常规优化方案</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/02/net_stack.jpg" alt=""><br>关于发包的优化XPS 还未做测试，有时间在做补充！</p><h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote><ul><li>TCP/UDP压测工具netperf  <a href="https://sanwen8.cn/p/P8bHgn.html" target="_blank" rel="external">https://sanwen8.cn/p/P8bHgn.html</a></li><li>多队列网卡及网卡中断绑定阐述  <a href="http://www.ywnds.com/?p=4380" target="_blank" rel="external">http://www.ywnds.com/?p=4380</a></li><li>Netperf压测数据分析   <a href="http://www.docin.com/p-1654134152.html" target="_blank" rel="external">http://www.docin.com/p-1654134152.html</a></li><li>RHEL7.0 Performance_Tuning_Guide  <a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Performance_Tuning_Guide/" target="_blank" rel="external">https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Performance_Tuning_Guide/</a></li><li>RPS/RFS/RSS 性能测试 <a href="http://www.cnblogs.com/Bozh/archive/2013/03/21/2973769.html" target="_blank" rel="external">http://www.cnblogs.com/Bozh/archive/2013/03/21/2973769.html</a></li></ul></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题背景&quot;&gt;&lt;a href=&quot;#问题背景&quot; class=&quot;headerlink&quot; title=&quot;问题背景&quot;&gt;&lt;/a&gt;问题背景&lt;/h3&gt;&lt;p&gt;游戏网关高峰期时出网络丢包,CPU0软中断%sys高达90%&lt;/p&gt;
&lt;h3 id=&quot;预备知识&quot;&gt;&lt;a href=&quot;#预备知
      
    
    </summary>
    
      <category term="Linux运维" scheme="http://www.simlinux.com/categories/Linux%E8%BF%90%E7%BB%B4/"/>
    
    
  </entry>
  
  <entry>
    <title>Centos6.5部署Zabbix3.2(备忘)</title>
    <link href="http://www.simlinux.com/2016/12/17/centos6-5-e9-83-a8-e7-bd-b2zabbix3-2-e5-a4-87-e5-bf-98.html"/>
    <id>http://www.simlinux.com/2016/12/17/centos6-5-e9-83-a8-e7-bd-b2zabbix3-2-e5-a4-87-e5-bf-98.html</id>
    <published>2016-12-17T05:48:45.000Z</published>
    <updated>2017-09-12T01:12:15.114Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1.配置yum源</strong></p><pre><code>wget --no-check-certificate http://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/epel?codeblock=0 -O epel.repowget --no-check-certificate http://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/epel?codeblock=1 -O epel-testing.repoyum install  -y http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpmrpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm `&lt;/pre&gt;**2.安装LNMP环境及依赖包**&lt;pre&gt;`yum -y install nginx Percona-Server-server-57 Percona-Server-client-57 Percona-Server-devel-57 Percona-Server-tokudb-57  php56w php56w-fpm php56w-mysql gcc-c++ libxml2-devel net-snmp-devel  libcurl-devel fping php56w-bcmath php56w-mbstring php56w-gd php56w-xmlwriter php56w-xmlreader`&lt;/pre&gt;**3.数据库初始化，支持TokuDB**&lt;pre&gt;`数据库初始化mysqld --initialize-insecure --user=mysql --datadir=/data/mysql/data/启用TokuDBps_tokudb_admin --enable -uroot -pgeekwolf若无法加载tokudb引擎，请查看huge pages是否关闭：echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabledecho never &amp;gt; /sys/kernel/mm/transparent_hugepage/defrag`&lt;/pre&gt;**4.安装Zabbix**&lt;pre&gt;`wget https://nchc.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.2.2/zabbix-3.2.2.tar.gzgroupadd zabbixuseradd -g zabbix -s /sbin/nologintar xf zabbix-3.2.2.tar.gz./configure --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2make -j8make install`&lt;/pre&gt;**5.配置zabbix_agent**&lt;pre&gt;`vim /usr/local/etc/zabbix_agentd.confPidFile=/tmp/zabbix_agentd.pidLogFile=/tmp/zabbix_agentd.logLogFileSize=0Server=192.168.1.1ServerActive=192.168.1.1Hostname=192.168.1.2UnsafeUserParameters=1`&lt;/pre&gt;**6.配置zabbix_server**&lt;pre&gt;`vim /usr/local/etc/zabbix_server.confDBHost=192.168.1.1DBName=zabbixDBUser=zabbixDBPassword=zabbixDebugLevel=3StartPollers=80CacheSize=32MTrendCacheSize=32MHistoryCacheSize=32MLogFile=/tmp/zabbix_server.logAlertScriptsPath=/usr/local/etc/scriptsFpingLocation=/usr/bin/fpingStartPingers=20HousekeepingFrequency=1MaxHousekeeperDelete=10000Timeout=10`&lt;/pre&gt;**7.拷贝Zabbix FrontEnd，创建数据库,修改php.ini配置**&lt;pre&gt;`cd  zabbix-3.2.2/cp frontends/php/* /usr/share/zabbix/chown apache.apache /usr/share/zabbix -Rmysql&amp;gt;create database zabbix;mysql&amp;gt;source database/mysql/schema.sql;mysql&amp;gt;source database/mysql/images.sql;mysql&amp;gt;source database/mysql/data.sql;拷贝启动脚本:cp  misc/init.d/fedora/core5/* /etc/rc.d/init.d/配置Nginx:vim /etc/nginx/conf.d/zabbix.confserver {    listen 80;    server_name zbx.simlinux.com;    index index.html index.php;    root /usr/share/zabbix;    location ~ \.php$ {        fastcgi_pass   127.0.0.1:9000;        fastcgi_index  index.php;        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;        include        fastcgi_params;    }}`&lt;/pre&gt;启动agent和server服务：&lt;pre&gt;`service zabbix_agentd startservice zabbix_server startservice nginx reload`&lt;/pre&gt;修改php.ini配置:&lt;pre&gt;`always_populate_raw_post_data = -1max_execution_time = 300max_input_time = 300data.timezone = PRC post_max_size=16Mservice php-fpm reload`&lt;/pre&gt;**8.修改数据表引擎和创建分区表**&lt;pre&gt;`alter table history engines=&apos;tokudb&apos;;alter table history_log engines=&apos;tokudb&apos;;alter table history_str engines=&apos;tokudb&apos;;alter table history_text engines=&apos;tokudb&apos;;alter table trends engines=&apos;tokudb&apos;;</code></pre><p>分区表可参考<a href="http://www.simlinux.com/archives/1776.html">http://www.simlinux.com/archives/1776.html</a></p><p><strong>9.安装Zabbix Web</strong><br>访问<a href="http://192.168.1.1" target="_blank" rel="external">http://192.168.1.1</a> 进行安装,默认账号密码: admin zabbix</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/zbx.png" alt=""></p><p><strong>10.遇到的问题</strong><br>A. Zabbix设置中文显示时，图形部分字体显示方框<br> <img src="http://www.simlinux.com/wp-content/uploads/2016/12/zbx-q1.png" alt=""></p><p>解决方法：<br>Zabbix默认使用DejaVuSan.ttf字体，不支持中文<br>拷贝本地C:\Windows\Fonts下的微软雅黑字体上传到Zabbix Web目录fonts下,即msyh.ttf<br>sed -i ‘s/DejaVuSans/msyh/g’ ./include/defines.inc.php</p><p>B. Zabbix_server日志提示20434:20161217:105010.997 fping failed: fping6: Address family for hostname not supported<br>解决方法:<br>zabbix_server.conf中指定fping和fping6路径<br>FpingLocation=/usr/sbin/fping<br>Fping6Location=/usr/sbin/fping6</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;1.配置yum源&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget --no-check-certificate http://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/epel?codeblock
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>Zabbix数据库优化总结</title>
    <link href="http://www.simlinux.com/2016/12/10/zabbix-e6-95-b0-e6-8d-ae-e5-ba-93-e4-bc-98-e5-8c-96-e6-80-bb-e7-bb-93.html"/>
    <id>http://www.simlinux.com/2016/12/10/zabbix-e6-95-b0-e6-8d-ae-e5-ba-93-e4-bc-98-e5-8c-96-e6-80-bb-e7-bb-93.html</id>
    <published>2016-12-10T09:48:46.000Z</published>
    <updated>2017-09-12T01:12:15.167Z</updated>
    
    <content type="html"><![CDATA[<blockquote><ul><li><strong>目的:</strong> 快速清理历史数据，并减少数据存储容量</li><li><strong>方法</strong>: 历史表使用分区表(删除分区表速度快),使用Tokudb引擎(适合大量insert少量update和select等日志表)</li><li><strong>Zabbix版本:</strong> 2.4</li><li><strong>涉及表项:</strong><br>存储不同类型item的历史数据，最终1小时或者1天等段时间的绘图数据从其中获取<br>history、history_log、history_str、history_text、history_uint<br>存储不同类型item的历史趋势数据，每隔一小时从历史数据中统计一次，并计算统计区间的平均值，最大值，最小值trends、trends_uint</li></ul></blockquote><p><strong>具体操作步骤:</strong></p><p><strong>1.关闭zabbix的housekeeper功能</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/housekeeper.jpg" alt=""></p><p><strong>2.备份原有历史数据表</strong></p><pre><code>rename table history to history_bak;rename table history_log to history_log_bak;rename table history_str to history_str_bak;rename table history_text to history_text_bak;rename table history_unit to history_unit_bak;rename table trends to trends_bak;rename table trends_unit to trends_unit_bak;`&lt;/pre&gt;**3.创建新表(使用tokudb引擎)**&lt;pre&gt;`CREATE TABLE `history` (  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,  KEY `history_1` (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8； CREATE TABLE `history_log` (  `id` bigint(20) unsigned NOT NULL,  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `timestamp` int(11) NOT NULL DEFAULT &apos;0&apos;,  `source` varchar(64) NOT NULL DEFAULT &apos;&apos;,  `severity` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value` text NOT NULL,  `logeventid` int(11) NOT NULL DEFAULT &apos;0&apos;,  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,  PRIMARY KEY (`id`),  UNIQUE KEY `history_log_2` (`itemid`,`id`),  KEY `history_log_1` (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8；CREATE TABLE `history_str` (  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value` varchar(255) NOT NULL DEFAULT &apos;&apos;,  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,  KEY `history_str_1` (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8；CREATE TABLE `history_text` (  `id` bigint(20) unsigned NOT NULL,  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value` text NOT NULL,  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,  PRIMARY KEY (`id`),  UNIQUE KEY `history_text_2` (`itemid`,`id`),  KEY `history_text_1` (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8；CREATE TABLE `history_uint` (  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,  KEY `history_uint_1` (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8；CREATE TABLE `trends` (  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `num` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value_min` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,  `value_avg` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,  `value_max` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,  PRIMARY KEY (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8；CREATE TABLE `trends_uint` (  `itemid` bigint(20) unsigned NOT NULL,  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,  `num` int(11) NOT NULL DEFAULT &apos;0&apos;,  `value_min` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,  `value_avg` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,  `value_max` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,  PRIMARY KEY (`itemid`,`clock`)) ENGINE=Tokudb DEFAULT CHARSET=utf8；`&lt;/pre&gt;**4.更改索引结构（新版本无需更改）**&lt;pre&gt;`ALTER TABLE history_text DROP PRIMARY KEY, ADD INDEX (id), DROP INDEX history_text_2, ADD INDEX history_text_2 (itemid, id);ALTER TABLE history_log DROP PRIMARY KEY, ADD INDEX (id), DROP INDEX history_log_2, ADD INDEX history_log_2 (itemid, id);`&lt;/pre&gt;**5.创建存储过程**&gt; *   partition_create 增加分区存储过程</code></pre><blockquote><ul><li>partition_drop 删除分区存储过程</li><li>partition_maintenance 分区维护(创建删除逻辑)存储过程</li><li>partition_maintenance_all 分区维护(调用partition_maintenance )</li><li>partition_verify 检查分区、创建第一个分区的存储过程</li></ul></blockquote><pre><code>&lt;pre&gt;`**************************************partition_create**************************************DELIMITER $$CREATE PROCEDURE `partition_create`(SCHEMANAME varchar(64), TABLENAME varchar(64), PARTITIONNAME varchar(64), CLOCK int)BEGIN        /*           SCHEMANAME = The DB schema in which to make changes           TABLENAME = The table with partitions to potentially delete           PARTITIONNAME = The name of the partition to create        */        /*           Verify that the partition does not already exist        */        DECLARE RETROWS INT;        SELECT COUNT(1) INTO RETROWS        FROM information_schema.partitions        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_description &amp;gt;= CLOCK;        IF RETROWS = 0 THEN                /*                   1\. Print a message indicating that a partition was created.                   2\. Create the SQL to create the partition.                   3\. Execute the SQL from #2.                */                SELECT CONCAT( &quot;partition_create(&quot;, SCHEMANAME, &quot;,&quot;, TABLENAME, &quot;,&quot;, PARTITIONNAME, &quot;,&quot;, CLOCK, &quot;)&quot; ) AS msg;                SET @sql = CONCAT( &apos;ALTER TABLE &apos;, SCHEMANAME, &apos;.&apos;, TABLENAME, &apos; ADD PARTITION (PARTITION &apos;, PARTITIONNAME, &apos; VALUES LESS THAN (&apos;, CLOCK, &apos;));&apos; );                PREPARE STMT FROM @sql;                EXECUTE STMT;                DEALLOCATE PREPARE STMT;        END IF;END$$DELIMITER ;**************************************partition_drop**************************************DELIMITER $$CREATE PROCEDURE `partition_drop`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), DELETE_BELOW_PARTITION_DATE BIGINT)BEGIN        /*           SCHEMANAME = The DB schema in which to make changes           TABLENAME = The table with partitions to potentially delete           DELETE_BELOW_PARTITION_DATE = Delete any partitions with names that are dates older than this one (yyyy-mm-dd)        */        DECLARE done INT DEFAULT FALSE;        DECLARE drop_part_name VARCHAR(16);        /*           Get a list of all the partitions that are older than the date           in DELETE_BELOW_PARTITION_DATE.  All partitions are prefixed with           a &quot;p&quot;, so use SUBSTRING TO get rid of that character.        */        DECLARE myCursor CURSOR FOR                SELECT partition_name                FROM information_schema.partitions                WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND CAST(SUBSTRING(partition_name FROM 2) AS UNSIGNED) &amp;lt; DELETE_BELOW_PARTITION_DATE;        DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;        /*           Create the basics for when we need to drop the partition.  Also, create           @drop_partitions to hold a comma-delimited list of all partitions that           should be deleted.        */        SET @alter_header = CONCAT(&quot;ALTER TABLE &quot;, SCHEMANAME, &quot;.&quot;, TABLENAME, &quot; DROP PARTITION &quot;);        SET @drop_partitions = &quot;&quot;;        /*           Start looping through all the partitions that are too old.        */        OPEN myCursor;        read_loop: LOOP                FETCH myCursor INTO drop_part_name;                IF done THEN                        LEAVE read_loop;                END IF;                SET @drop_partitions = IF(@drop_partitions = &quot;&quot;, drop_part_name, CONCAT(@drop_partitions, &quot;,&quot;, drop_part_name));        END LOOP;        IF @drop_partitions != &quot;&quot; THEN                /*                   1\. Build the SQL to drop all the necessary partitions.                   2\. Run the SQL to drop the partitions.                   3\. Print out the table partitions that were deleted.                */                SET @full_sql = CONCAT(@alter_header, @drop_partitions, &quot;;&quot;);                PREPARE STMT FROM @full_sql;                EXECUTE STMT;                DEALLOCATE PREPARE STMT;                SELECT CONCAT(SCHEMANAME, &quot;.&quot;, TABLENAME) AS `table`, @drop_partitions AS `partitions_deleted`;        ELSE                /*                   No partitions are being deleted, so print out &quot;N/A&quot; (Not applicable) to indicate                   that no changes were made.                */                SELECT CONCAT(SCHEMANAME, &quot;.&quot;, TABLENAME) AS `table`, &quot;N/A&quot; AS `partitions_deleted`;        END IF;END$$DELIMITER ;**************************************partition_verify**************************************DELIMITER $$CREATE PROCEDURE `partition_verify`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), HOURLYINTERVAL INT(11))BEGIN        DECLARE PARTITION_NAME VARCHAR(16);        DECLARE RETROWS INT(11);        DECLARE FUTURE_TIMESTAMP TIMESTAMP;        /*         * Check if any partitions exist for the given SCHEMANAME.TABLENAME.         */        SELECT COUNT(1) INTO RETROWS        FROM information_schema.partitions        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_name IS NULL;        /*         * If partitions do not exist, go ahead and partition the table         */        IF RETROWS = 1 THEN                /*                 * Take the current date at 00:00:00 and add HOURLYINTERVAL to it.  This is the timestamp below which we will store values.                 * We begin partitioning based on the beginning of a day.  This is because we don&apos;t want to generate a random partition                 * that won&apos;t necessarily fall in line with the desired partition naming (ie: if the hour interval is 24 hours, we could                 * end up creating a partition now named &quot;p201403270600&quot; when all other partitions will be like &quot;p201403280000&quot;).                 */                SET FUTURE_TIMESTAMP = TIMESTAMPADD(HOUR, HOURLYINTERVAL, CONCAT(CURDATE(), &quot; &quot;, &apos;00:00:00&apos;));                SET PARTITION_NAME = DATE_FORMAT(CURDATE(), &apos;p%Y%m%d%H00&apos;);                -- Create the partitioning query                SET @__PARTITION_SQL = CONCAT(&quot;ALTER TABLE &quot;, SCHEMANAME, &quot;.&quot;, TABLENAME, &quot; PARTITION BY RANGE(`clock`)&quot;);                SET @__PARTITION_SQL = CONCAT(@__PARTITION_SQL, &quot;(PARTITION &quot;, PARTITION_NAME, &quot; VALUES LESS THAN (&quot;, UNIX_TIMESTAMP(FUTURE_TIMESTAMP), &quot;));&quot;);                -- Run the partitioning query                PREPARE STMT FROM @__PARTITION_SQL;                EXECUTE STMT;                DEALLOCATE PREPARE STMT;        END IF;END$$DELIMITER ;**************************************partition_maintenance**************************************DELIMITER $$CREATE PROCEDURE `partition_maintenance`(SCHEMA_NAME VARCHAR(32), TABLE_NAME VARCHAR(32), KEEP_DATA_DAYS INT, HOURLY_INTERVAL INT, CREATE_NEXT_INTERVALS INT)BEGIN        DECLARE OLDER_THAN_PARTITION_DATE VARCHAR(16);        DECLARE PARTITION_NAME VARCHAR(16);        DECLARE OLD_PARTITION_NAME VARCHAR(16);        DECLARE LESS_THAN_TIMESTAMP INT;        DECLARE CUR_TIME INT;        CALL partition_verify(SCHEMA_NAME, TABLE_NAME, HOURLY_INTERVAL);        SET CUR_TIME = UNIX_TIMESTAMP(DATE_FORMAT(NOW(), &apos;%Y-%m-%d 00:00:00&apos;));        SET @__interval = 1;        create_loop: LOOP                IF @__interval &amp;gt; CREATE_NEXT_INTERVALS THEN                        LEAVE create_loop;                END IF;                SET LESS_THAN_TIMESTAMP = CUR_TIME + (HOURLY_INTERVAL * @__interval * 3600);                SET PARTITION_NAME = FROM_UNIXTIME(CUR_TIME + HOURLY_INTERVAL * (@__interval - 1) * 3600, &apos;p%Y%m%d%H00&apos;);                IF(PARTITION_NAME != OLD_PARTITION_NAME) THEN                        CALL partition_create(SCHEMA_NAME, TABLE_NAME, PARTITION_NAME, LESS_THAN_TIMESTAMP);                END IF;                SET @__interval=@__interval+1;                SET OLD_PARTITION_NAME = PARTITION_NAME;        END LOOP;        SET OLDER_THAN_PARTITION_DATE=DATE_FORMAT(DATE_SUB(NOW(), INTERVAL KEEP_DATA_DAYS DAY), &apos;%Y%m%d0000&apos;);        CALL partition_drop(SCHEMA_NAME, TABLE_NAME, OLDER_THAN_PARTITION_DATE);END$$DELIMITER ;**************************************partition_maintenance_all**************************************DELIMITER $$CREATE PROCEDURE `partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))BEGIN      CALL partition_maintenance(SCHEMA_NAME, &apos;history&apos;, 90, 24, 30);      #针对zabbix数据库（调用时传入zabbix数据库的库名）的history表创建分区，数据保留90天，分区时间间隔为24小时，每次创建30个分区      CALL partition_maintenance(SCHEMA_NAME, &apos;history_log&apos;, 90, 24, 30);      CALL partition_maintenance(SCHEMA_NAME, &apos;history_str&apos;, 90, 24, 30);      CALL partition_maintenance(SCHEMA_NAME, &apos;history_text&apos;, 90, 24, 30);      CALL partition_maintenance(SCHEMA_NAME, &apos;history_uint&apos;, 90, 24, 30);      CALL partition_maintenance(SCHEMA_NAME, &apos;trends&apos;, 730, 24, 15);      CALL partition_maintenance(SCHEMA_NAME, &apos;trends_uint&apos;, 730, 24, 30);END$$DELIMITER ;`&lt;/pre&gt;**6.设置分区表维护Event Scheduler**&lt;pre&gt;`开启数据库Event Scheduler功能set GLOBAL event_scheduler=ON;创建事件zbx_partition_maintenance 每月1号1点执行partition_maintenance_all:DELIMITER $$CREATE EVENT `zbx_partition_maintenance`ON SCHEDULE every 1 month starts date_add(date_add(date_sub(curdate(),interval day(curdate())-1 day),interval 1 month),interval 1 HOUR)ON COMPLETION PRESERVE DOBEGIN    CALL partition_maintenance_all(&apos;zabbix&apos;) ; END$$DELIMITER ;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目的:&lt;/strong&gt; 快速清理历史数据，并减少数据存储容量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;方法&lt;/strong&gt;: 历史表使用分区表(删除分区表速度快),使用Tokudb引擎(适合大量insert少量update
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>zabbix LLD之多核CPU监控(备忘)</title>
    <link href="http://www.simlinux.com/2016/12/10/zabbix-lld-e4-b9-8b-e5-a4-9a-e6-a0-b8cpu-e7-9b-91-e6-8e-a7-e5-a4-87-e5-bf-98.html"/>
    <id>http://www.simlinux.com/2016/12/10/zabbix-lld-e4-b9-8b-e5-a4-9a-e6-a0-b8cpu-e7-9b-91-e6-8e-a7-e5-a4-87-e5-bf-98.html</id>
    <published>2016-12-10T08:57:48.000Z</published>
    <updated>2017-09-12T01:12:15.167Z</updated>
    
    <content type="html"><![CDATA[<blockquote><ul><li><em>使用Zabbix自带的system.cpu.discovery实现CPU多核监控</em></li><li><em>Zabbix Agent 2.4+以上版本才开始支持</em></li></ul></blockquote><p><strong>一、创建发现规则</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu_multi.jpg" alt=""></p><p><strong>二、创建监控项</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu_item.png" alt=""></p><p><strong>三、根据监控项创建图形</strong></p><p><strong>四、创建触发器</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu_trigger.png" alt=""></p><p><strong>五、展示效果</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu-core-pic.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;使用Zabbix自带的system.cpu.discovery实现CPU多核监控&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Zabbix Agent 2.4+以上版本才开始支持&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>通过zabbix_sender实现批量传递key值(备忘)</title>
    <link href="http://www.simlinux.com/2016/10/26/e9-80-9a-e8-bf-87zabbix-sender-e5-ae-9e-e7-8e-b0-e6-89-b9-e9-87-8f-e4-bc-a0-e9-80-92key-e5-80-bc.html"/>
    <id>http://www.simlinux.com/2016/10/26/e9-80-9a-e8-bf-87zabbix-sender-e5-ae-9e-e7-8e-b0-e6-89-b9-e9-87-8f-e4-bc-a0-e9-80-92key-e5-80-bc.html</id>
    <published>2016-10-26T09:58:52.000Z</published>
    <updated>2017-09-12T01:12:15.133Z</updated>
    
    <content type="html"><![CDATA[<p>选择使用zabbix_sender的由来基于业务中需要从MySQL数据库中提取游戏在线人数(5个服务)，如果通过zabbix_get方式获取需要执行5次脚本获取，而通过zabbix_sender执行一次脚本可将5个服务的数据批量发送到zabbix trapper更为方便，减少了不必要的脚本执行</p><p><strong>配置步骤如下:</strong></p><p><strong>1.配置zabbix_agentd.conf 自定义UserParameter</strong></p><pre><code>UserParameter=send.online.count.data[*],/home/opt/scripts/online_count.sh $1/etc/init.d/zabbix_agent stop/etc/init.d/zabbix_agent start`&lt;/pre&gt;注释: 此步骤的目的是在zabbix server上创建key为send.online.count.data的item用于设置脚本的执行间隔，也可以在zabbix agent服务上设置crontab实现**2.数据获取脚本**&lt;pre&gt;`#!/bin/bashhost_ip=$1zabbix_server_ip=&quot;10.1.1.1&quot;mysql  -C -N  -h localhost -u geekwolf -pgeekwolf &quot;--execute=select total,dota,war3vs,war3rpg,first_login from online_table;&quot;&amp;gt;/tmp/.dataTotal=`cat /tmp/.data |awk &apos;{print $1}&apos;`Dota=`cat /tmp/.data |awk &apos;{print $2}&apos;`War3vs=`cat /tmp/.data |awk &apos;{print $3}&apos;`War3rpg=`cat /tmp/.data |awk &apos;{print $4}&apos;`First_Login=`cat /tmp/.data |awk &apos;{print $5}&apos;`echo &quot;$host_ip online_count[Total] $Total&quot; &amp;gt;/tmp/count.logecho &quot;$host_ip online_count[Dota] $Dota&quot; &amp;gt;&amp;gt;/tmp/count.logecho &quot;$host_ip online_count[War3vs] $War3vs&quot; &amp;gt;&amp;gt;/tmp/count.logecho &quot;$host_ip online_count[War3rpg] $War3rpg&quot; &amp;gt;&amp;gt;/tmp/count.logecho &quot;$host_ip online_count[First_login] $First_Login&quot; &amp;gt;&amp;gt;/tmp/count.logzabbix_sender -z $zabbix_server_ip -i /tmp/count.log &amp;amp;&amp;gt;/dev/null</code></pre><p><strong>3.创建模板和项目</strong><br>A. 创建模板Online_Count_Template<br>B. 创建项目send.count.data<br><img src="http://www.simlinux.com/wp-content/uploads/2016/10/t1.png" alt=""></p><p>C. 创建Total监控项,其他略<br><img src="http://www.simlinux.com/wp-content/uploads/2016/10/t2.png" alt=""></p><p><strong>4. 创建图形</strong><br><img src="http://www.simlinux.com/wp-content/uploads/2016/10/t3.png" alt=""></p><p><strong>5. 将模板关联到主机即可(可通过最新数据查看是否有数据上报 )</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;选择使用zabbix_sender的由来基于业务中需要从MySQL数据库中提取游戏在线人数(5个服务)，如果通过zabbix_get方式获取需要执行5次脚本获取，而通过zabbix_sender执行一次脚本可将5个服务的数据批量发送到zabbix trapper更为方便，减
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>利用Zabbix做流量聚合汇总</title>
    <link href="http://www.simlinux.com/2016/08/02/e5-88-a9-e7-94-a8zabbix-e5-81-9a-e6-b5-81-e9-87-8f-e8-81-9a-e5-90-88-e6-b1-87-e6-80-bb.html"/>
    <id>http://www.simlinux.com/2016/08/02/e5-88-a9-e7-94-a8zabbix-e5-81-9a-e6-b5-81-e9-87-8f-e8-81-9a-e5-90-88-e6-b1-87-e6-80-bb.html</id>
    <published>2016-08-02T08:20:46.000Z</published>
    <updated>2017-09-12T01:12:15.120Z</updated>
    
    <content type="html"><![CDATA[<blockquote><ul><li>创建主机群组 : 数据大盘</li><li>创建主机 : Geekwolf</li><li>创建监控项：网卡流入流出，grpsum实现聚合</li><li>创建图形：关联监控项</li></ul></blockquote><p><strong>1. 创建主机群组</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/dashboard.png" alt="此处输入图片的描述"></p><p><strong>2. 创建主机Geekwolf</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/host1.png" alt="此处输入图片的描述"></p><p><strong>3. 创建监控项：网卡流入流出，grpsum实现聚合</strong></p><p>点击创建主机界面上方的项目</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/host2.png" alt="此处输入图片的描述"><br> <img src="http://www.simlinux.com/wp-content/uploads/2016/08/host3.png" alt="此处输入图片的描述"></p><p><strong>4. 创建图形：关联监控项</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/host4.png" alt="此处输入图片的描述"></p><p><strong>5. 最终效果</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/traffic.png" alt="此处输入图片的描述"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;创建主机群组 : 数据大盘&lt;/li&gt;
&lt;li&gt;创建主机 : Geekwolf&lt;/li&gt;
&lt;li&gt;创建监控项：网卡流入流出，grpsum实现聚合&lt;/li&gt;
&lt;li&gt;创建图形：关联监控项&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>Grafana+InfluxDB+Collectd构建监控系统</title>
    <link href="http://www.simlinux.com/2016/04/28/grafanainfluxdbcollectd-e6-9e-84-e5-bb-ba-e7-9b-91-e6-8e-a7-e7-b3-bb-e7-bb-9f.html"/>
    <id>http://www.simlinux.com/2016/04/28/grafanainfluxdbcollectd-e6-9e-84-e5-bb-ba-e7-9b-91-e6-8e-a7-e7-b3-bb-e7-bb-9f.html</id>
    <published>2016-04-28T14:39:37.000Z</published>
    <updated>2017-09-12T01:12:15.136Z</updated>
    
    <content type="html"><![CDATA[<h3 id="架构原理"><a href="#架构原理" class="headerlink" title="架构原理"></a>架构原理</h3><p>Collectd(数据采集,配置Server连接InfluxDB的25826端口) -&gt; InfluxDB(数据存储,启用collectd插件监听25826端口) —&gt; Grafana(数据展示)</p><blockquote><ul><li>Collectd ： C 语言开发的一个守护(daemon)进程，周期性收集统计数据和存储，拥有丰富的插件包括监控Ceph,DRBD,OpenLDAP,ZK等，类似statD(graphite也可以用来采集数据，不过展示功能没有Grafana丰富)，数据可以存储在Kafka,InfluxDB，OpenTSDB等上*   InfluxDB:   GO开发的开源分布式时序数据库，适合存储指标，时间，分析等数据</li><li>Grafana： 是一个开源的，具有丰富指标仪表盘的数据展示和图表编辑工具，支持Graphite,Elasticsearch,OpenTSDB,Prometheus和influxDB,Zabbix等</li></ul></blockquote><h3 id="Collectd"><a href="#Collectd" class="headerlink" title="Collectd"></a>Collectd</h3><ol><li><p>安装collectd</p><p>yum -y  install perl-ExtUtils-Embed perl-ExtUtils-MakeMaker  liboping*<br>wget <a href="https://collectd.org/files/collectd-5.5.0.tar.gz" target="_blank" rel="external">https://collectd.org/files/collectd-5.5.0.tar.gz</a><br>tar xf collectd-5.5.0.tar.gz<br>cd collectd-5.5.0<br>./configure –enable-cpu  –enable-df –enable-disk –enable-interface –enable-load –enable-memory –enable-ping –enable-swap –enable-users –enable-uptime<br>make &amp;&amp; make install<br>cp contrib/redhat/init.d-collectd  /etc/rc.d/init.d/collectd<br>chmod +x /etc/rc.d/init.d/collectd<br>ln -s /opt/collectd/sbin/collectdmon  /usr/sbin/<br>ln -s /opt/collectd/sbin/collectd  /usr/sbin/<br>`</p></li><li><p>配置collectd</p><pre>`vim /etc/collectd.confBaseDir "/opt/collectd"PIDFile "/run/collectd.pid"Hostname "host.example.com"Interval 60&lt;loadplugin df&gt;Interval 120&lt;/loadplugin&gt;LoadPlugin diskLoadPlugin interfaceLoadPlugin loadLoadPlugin memoryLoadPlugin networkLoadPlugin processesLoadPlugin users&lt;plugin interface&gt;Interface "eth1"IgnoreSelected false&lt;/plugin&gt;&lt;plugin network&gt;Server "10.44.38.244" "25826"&lt;/plugin&gt;`</pre></li><li><p>说明<br>默认collectd进程会每10s中调用注册在配置文件中的插件，默认全局参数interval＝10s(10s上报一次数据到influxdb等)，针对不同的插件可以配置不同的搜集数据的时间间隔interval</p><h3 id="InfluxDB"><a href="#InfluxDB" class="headerlink" title="InfluxDB"></a>InfluxDB</h3></li><li><p>安装并启动服务</p><pre>`cat &lt; &lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo[influxdb]name = InfluxDB Repository - RHEL \$releaseverbaseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stableenabled = 1gpgcheck = 1gpgkey = https://repos.influxdata.com/influxdb.keyEOFyum -y install influxdbservice influxdb start启动后TCP端口:8083 为InfluxDB 管理控制台  TCP端口:8086 为客户端和InfluxDB通信时的HTTP API启动后InfluxDB用户认证默认是关闭的，先创建用户:geekwolf geekwolf命令行输入influx`</pre></li><li>基本使用<pre>`[root@geekwolf ~]# influxVisit https://enterprise.influxdata.com to register for updates, InfluxDB server management, and monitoring.Connected to http://localhost:8086 version 0.12.2InfluxDB shell 0.12.2&gt; create database collectdb&gt; create database collectdb&gt; show databasesname: databases\------name_internalcollectdb&gt; create user geekwolf with password 'geekwolf'&gt; show usersuser            admingeekwolf        false&gt; grant all on collectdb from to geekwolf&gt; help showUsage:    connect &lt;host:port&gt;   connects to another node specified by host:port    auth                  prompts for username and password    pretty                toggles pretty print for the json format    use &lt;db_name&gt;         sets current database    format &lt;format&gt;       specifies the format of the server responses: json, csv, or column    precision &lt;/format&gt;&lt;format&gt;    specifies the format of the timestamp: rfc3339, h, m, s, ms, u or ns    consistency &lt;level&gt;   sets write consistency level: any, one, quorum, or all    history               displays command history    settings              outputs the current settings for the shell    exit/quit/ctrl+d      quits the influx shell    show databases        show database names    show series           show series information    show measurements     show measurement information    show tag keys         show tag key information    show field keys       show field key information    A full list of influxql commands can be found at:    https://docs.influxdata.com/influxdb/v0.10/query_language/spec`</pre></li><li><p>启用认证</p><pre>`修改配置文件启用认证sed -i ’s#auth-enabled = false#auth-enabled = true#g’ /etc/influxdb/influxdb.confservice influxdb restart`</pre><h3 id="配置InfluxDB支持Collectd"><a href="#配置InfluxDB支持Collectd" class="headerlink" title="配置InfluxDB支持Collectd"></a>配置InfluxDB支持Collectd</h3></li><li><p>修改配置</p><pre>`vim /etc/influxdb/influxdb.conf[collectd]enabled = truebind-address = "10.44.38.244:25826"database = "collectdb"typesdb = "/opt/collectd/share/collectd/types.db"batch-size = 5000batch-pending = 10batch-timeout = "10s"read-buffer = 0service influxdb restart`</pre></li><li><p>查看metrics信息</p><pre>`[root@geekwolf ~]# influxVisit https://enterprise.influxdata.com to register for updates, InfluxDB server management, and monitoring.Connected to http://localhost:8086 version 0.12.2InfluxDB shell 0.12.2&gt; use collectdbUsing database collectdb&gt; show field keysname: cpu_value---------------fieldKeyvaluename: df_free-------------fieldKeyvaluename: df_used-------------fieldKeyvaluename: disk_read---------------fieldKeyvalue&gt; select * from cpu_value limit 15;name: cpu_value---------------time                    host                    instance        type    type_instance   value1461657293000000000     host.example.com        1               cpu     idle            1.59845e+061461657293000000000     host.example.com        1               cpu     system          23161461657293000000000     host.example.com        1               cpu     nice            5081461657293000000000     host.example.com        0               cpu     steal           01461657293000000000     host.example.com        1               cpu     user            116191461657293000000000     host.example.com        1               cpu     interrupt       01461657293000000000     host.example.com        1               cpu     steal           01461657293000000000     host.example.com        1               cpu     wait            1721461657293000000000     host.example.com        1               cpu     softirq         01461657303000000000     host.example.com        1               cpu     wait            1721461657303000000000     host.example.com        1               cpu     softirq         01461657303000000000     host.example.com        1               cpu     nice            5081461657303000000000     host.example.com        0               cpu     idle            1.587007e+061461657303000000000     host.example.com        0               cpu     softirq         1271461657303000000000     host.example.com        0               cpu     interrupt       54`</pre><h3 id="安装配置Grafana"><a href="#安装配置Grafana" class="headerlink" title="安装配置Grafana"></a>安装配置Grafana</h3><pre>`yum install https://grafanarel.s3.amazonaws.com/builds/grafana-3.0.0-beta51460725904.x86_64.rpm目录结构/usr/sbin/grafana-server/etc/init.d/grafana-server          上述命令的拷贝，启动脚本/etc/sysconfig/grafana-server       环境变量/etc/grafana/grafana.ini            配置文件/var/log/grafana/grafana.log        日志文件/var/lib/grafana/grafana.db     sqlite3数据库启动服务: service grafana-server start         chkconfig grafana-server on`</pre><p>访问地址:<a href="http://10.44.38.244:3000" target="_blank" rel="external">http://10.44.38.244:3000</a> 默认账号为admin admin<br>关闭Grafana注册功能:</p><p><pre>`sed -i ’s/#allow_sign_up = true/allow_sign_up = false/g’  /etc/grafana/grafana.ini,重启服务</pre></p></li></ol><ul><li>添加InfluxDB数据源</li></ul><p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/datasource.png" alt="此处输入图片的描述"></p><ul><li>添加ping图的例子</li></ul><p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/ping.png" alt="此处输入图片的描述"></p><ul><li>图表展示</li></ul><p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/view.png" alt="此处输入图片的描述"></p><p>详细demo可参考:<a href="http://play.grafana.org/" target="_blank" rel="external">http://play.grafana.org/</a></p><h3 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h3><p>问题 :在使用influxdb0.12.x版本和Grafana2.6时出现multiple query syntax的bug,原因是influxdb的apiwent</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/multiquery.png" alt="此处输入图片的描述"></p><p>解决方法: 升级Grafana2.6到Grafana3.0-beta1以上版本<br> <a href="https://github.com/grafana/grafana/commit/ed62822d442569e7ba287ff63d83a069a596c458" target="_blank" rel="external">https://github.com/grafana/grafana/commit/ed62822d442569e7ba287ff63d83a069a596c458</a></p><h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="http://docs.grafana.org" target="_blank" rel="external">http://docs.grafana.org</a></p><p><a href="https://collectd.org/wiki/index.php/Table_of_Plugins" target="_blank" rel="external">https://collectd.org/wiki/index.php/Table_of_Plugins</a></p><p><a href="https://docs.influxdata.com/influxdb/v0.12/introduction/getting_started/" target="_blank" rel="external">https://docs.influxdata.com/influxdb/v0.12/introduction/getting_started/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;架构原理&quot;&gt;&lt;a href=&quot;#架构原理&quot; class=&quot;headerlink&quot; title=&quot;架构原理&quot;&gt;&lt;/a&gt;架构原理&lt;/h3&gt;&lt;p&gt;Collectd(数据采集,配置Server连接InfluxDB的25826端口) -&amp;gt; InfluxDB(数据存储,
      
    
    </summary>
    
      <category term="系统监控" scheme="http://www.simlinux.com/categories/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7/"/>
    
    
  </entry>
  
  <entry>
    <title>Android多渠道打包这样做才酸爽！？</title>
    <link href="http://www.simlinux.com/2016/04/21/android-e5-a4-9a-e6-b8-a0-e9-81-93-e6-89-93-e5-8c-85-e8-bf-99-e6-a0-b7-e5-81-9a-e6-89-8d-e9-85-b8-e7-88-bd-ef-bc-81-ef-bc-9f.html"/>
    <id>http://www.simlinux.com/2016/04/21/android-e5-a4-9a-e6-b8-a0-e9-81-93-e6-89-93-e5-8c-85-e8-bf-99-e6-a0-b7-e5-81-9a-e6-89-8d-e9-85-b8-e7-88-bd-ef-bc-81-ef-bc-9f.html</id>
    <published>2016-04-21T08:51:16.000Z</published>
    <updated>2017-09-12T01:12:15.111Z</updated>
    
    <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>　　多渠道主要目的是为了统计各个应用市场用户数据分析(比如活跃数，崩溃率等)，收集用户信息，这时需要唯一标识来区分这些渠道，本文主要针对多渠道(几百个渠道甚至更多的情况)如何快速打包?</p><h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><blockquote><ul><li>Jenkins集成Gradle实现打包自动化</li><li>通过Jenkins参数化构建实现自定义环境和渠道打包，签名</li><li>测试包自动上传fir并通过钉钉发送通知</li><li>正式包按版本归档到OSS，发布时拷贝包到发布目录</li><li>自动刷新CDN</li></ul></blockquote><h4 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h4><blockquote><ul><li>系统 : Centos6.5 x64</li><li>jdk-7u79-linux-x64</li><li>android-sdk_r24.4.1-linux</li><li>gradle-2.2.1</li><li>Python-2.7.10(操作DingTalk和OSS API)</li><li>Jenkins2.0/Tomcat-7.0.65</li></ul></blockquote><h4 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h4><p>1.安装JDK</p><pre><code>wget &apos;http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.tar.gz?AuthParam=1460974294_526e0f8471004294cb163c9c730ba4f9&apos; -O jdk1.7.0_79.tar.gztar xf jdk-7u79-linux-x64.tar.gz -C /usr/local/jdk1.7.0_79`&lt;/pre&gt;2.安装Python2.7.10&lt;pre&gt;`wget https://www.python.org/ftp/python/2.7.10/Python-2.7.10.tgztar xf Python-2.7.10.tgzcd Python-2.7.10./configure make -j4make installsed -i &apos;s#python/python2.6#g&apos; /usr/bin/yum`&lt;/pre&gt;3.安装Android的SDK&lt;pre&gt;`wget http://dl.google.com/android/android-sdk_r24.4.1-linux.tgztar xf android-sdk_r24.4.1-linux.tgz -C /usr/local/android-sdk-linux`&lt;/pre&gt;4.安装tomcat和jenkins&lt;pre&gt;`yum -y install tomcatwget http://mirrors.jenkins-ci.org/war-rc/2.0/jenkins.war -O /usr/share/tomcat/webapps/jenkins.war`&lt;/pre&gt;5.配置环境变量，启动服务&lt;pre&gt;`vim /etc/profileexport ANDROID_HOME=/usr/local/android-sdk-linuxexport JAVA_HOME=/usr/local/jdk1.7.0_80export PATH=$PATH:$JAVA_HOME/bin:$ANDROID_HOME/tools:$ANDROID_HOME/platform-toolssource /etc/profileservice tomcat startJenkins访问地址:http://192.168.2.2:8080/jenkins/`&lt;/pre&gt;6.安装Android SDK依赖包&lt;pre&gt;`由于Android SDK工具基于32位在64位系统上需要安装32位必须安装的i386依赖库yum install -y glibc.i686 glibc-devel.i686 libstdc++.i686 zlib-devel.i686 ncurses-devel.i686 libX11-devel.i686 libXrender.i686 libXrandr.i686`&lt;/pre&gt;####安装更新对应版本的SDK&lt;pre&gt;`由于国内直接解析访问dl.google.com,dl-ssl.google.com域名较慢，可以通过更改hosts方式解决:dig dl.google.com dl-ssl.google.com将获得IP写入/etc/hosts,例如:203.208.43.110 dl.google.com74.125.23.91 dl-ssl.google.com查看SDK相关列表android  list sdk --allPackages available for installation or update: 150   1- Android SDK Tools, revision 25.1.1   2- Android SDK Tools, revision 25.1.3 rc1   3- Android SDK Platform-tools, revision 23.1   4- Android SDK Platform-tools, revision 24 rc2   5- Android SDK Build-tools, revision 24 rc3   6- Android SDK Build-tools, revision 23.0.3   7- Android SDK Build-tools, revision 23.0.2   8- Android SDK Build-tools, revision 23.0.1   9- Android SDK Build-tools, revision 23 (Obsolete)  10- Android SDK Build-tools, revision 22.0.1  11- Android SDK Build-tools, revision 22 (Obsolete)  12- Android SDK Build-tools, revision 21.1.2  13- Android SDK Build-tools, revision 21.1.1 (Obsolete)  14- Android SDK Build-tools, revision 21.1 (Obsolete)  15- Android SDK Build-tools, revision 21.0.2 (Obsolete)  16- Android SDK Build-tools, revision 21.0.1 (Obsolete)  17- Android SDK Build-tools, revision 21 (Obsolete)  18- Android SDK Build-tools, revision 20  19- Android SDK Build-tools, revision 19.1  20- Android SDK Build-tools, revision 19.0.3 (Obsolete)  21- Android SDK Build-tools, revision 19.0.2 (Obsolete)  22- Android SDK Build-tools, revision 19.0.1 (Obsolete)  23- Android SDK Build-tools, revision 19 (Obsolete)  24- Android SDK Build-tools, revision 18.1.1 (Obsolete)  ...选择要安装项目的序号android  update sdk -u -a -t 5,6,7,31,34,136,137 `&lt;/pre&gt;#### 手动编译测试Android项目&lt;pre&gt;`git clone git@git.maka.mobi:android/Android_demo.gitcd Android_demo查看当前项目包含的tasks(此时若无gradle会自动下载安装)./gradlew  tasks清空build目录./gradlew clean编译打包所有环境包./gradlew assemble编译打包Debug包./gradlew assembleDebug编译打包Release包./gradlew assembleRelease`&lt;/pre&gt;#### 多渠道打包项目改造</code></pre><ol><li>包的签名在build.gradle中配置，打包后自动签名</li><li>由于META-INF目录下是存放签名信息的，用来保证apk包的完整性和安全，在生成apk时对文件做校验计算并把结果存放在META-INF目录中，安装apk包时应用管理器会按照同样的算法对包里的文件做校验，如果和META-INF中的内容不一致，则无法安装，通过修改apk包在重新打包基本不可能，以此来保证apk包的安全，因此在打完第一个包时，可以在META-INF目录中添加一个channel_wandoujia空文件,代码匹配这个文件获取渠道名wandoujia，来快速实现多渠道打包的目的</li><li><p>代码库根目录channel文件存放渠道名</p><pre>`apk包解压后目录结构:├── AndroidManifest.xml├── assets├── classes.dex├── lib├── META-INF│   ├── CERT.RSA│   ├── CERT.SF│   ├── channel_huawei│   └── MANIFEST.MF├── org├── res└── resources.arsc`</pre><pre>`Gradle(apk通过gradle签名)例子app/build.gradle:apply plugin: 'com.android.application'android {    compileSdkVersion 22    buildToolsVersion '23.0.2'    defaultConfig {        applicationId "com.maka.app"        minSdkVersion 16        targetSdkVersion 22        versionCode 16        versionName '2.0.0'        //dex突破65535的限制        multiDexEnabled true    }    dexOptions {        jumboMode = true        incremental true        javaMaxHeapSize "4g"        preDexLibraries = false        incremental true    }    signingConfigs {        debug {            storeFile file("../key.jks")            storePassword "helloworld"            keyAlias "helloworld"            keyPassword "helloworld"        }    }    packagingOptions {        exclude 'META-INF/LICENCE.txt'        exclude 'META-INF/LICENSE.txt'        exclude 'META-INF/NOTICE.txt'    }    lintOptions {        checkReleaseBuilds false        // Or, if you prefer, you can continue to check for errors in release builds,        // but continue the build even when errors are found:        abortOnError false    }    buildTypes {        debug {            // 显示Log            buildConfigField "boolean", "LOG_DEBUG", "true"            versionNameSuffix "-debug"            minifyEnabled false            zipAlignEnabled true            shrinkResources false            signingConfig signingConfigs.debug            manifestPlaceholders = [                    UMENG_APP_KEY   : "556ac653162s58e06c0000218",                    UMENG_APP_SECRET: "2a231041d6aa10ec2b2s933003135a7"            ]            //Server config            buildConfigField "boolean", "SELECT_SERVER", "true"            buildConfigField "String", "TEST_IP", "\"http://test.api.simlinux.com/\""            buildConfigField "String", "TEST_PROJECT_URL", "\"http://test.viewer.simlinux.com/k/\""            buildConfigField "String", "TEST_PICTURE_URL", "\"http://test.img1.simlinux.com/\""            buildConfigField "String", "TEST_RES_URL", "\"http://test.res.simlinux.com/\""            buildConfigField "String", "FORMAL_IP", "\"http://api.simlinux.com/\""            buildConfigField "String", "FORMAL_PROJECT_URL", "\"http://viewer.simlinux.com/k/\""            buildConfigField "String", "FORMAL_PICTURE_URL", "\"http://img1.simlinux.com/\""            buildConfigField "String", "FORMAL_RES_URL", "\"http://res.simlinux.com/\""        }        release {            // 不显示Log            buildConfigField "boolean", "LOG_DEBUG", "false"            minifyEnabled true            zipAlignEnabled true            // 移除无用的resource文件            shrinkResources true            proguardFile 'proguard-project.txt'            debuggable false            shrinkResources false            signingConfig signingConfigs.debug            manifestPlaceholders = [                    UMENG_APP_KEY   : "556ac6s3162358e06c0000218",                    UMENG_APP_SECRET: "2a231041d6aa10ec2b2s933003135a7"            ]            //Server config            buildConfigField "boolean", "SELECT_SERVER", "false"            buildConfigField "String", "TEST_IP", "\"\""            buildConfigField "String", "TEST_PROJECT_URL", "\"\""            buildConfigField "String", "TEST_PICTURE_URL", "\"\""            buildConfigField "String", "TEST_RES_URL", "\"\""            buildConfigField "String", "FORMAL_IP", "\"http://api.simlinux.com/\""            buildConfigField "String", "FORMAL_PROJECT_URL", "\"http://viewer.simlinux.com/k/\""            buildConfigField "String", "FORMAL_PICTURE_URL", "\"http://img1.simlinux.com/\""            buildConfigField "String", "FORMAL_RES_URL", "\"http://res.simlinux.com/\""        }    }    applicationVariants.all { variant -&gt;        variant.outputs.each { output -&gt;            def outputFile = output.outputFile            if (outputFile != null &amp;&amp; outputFile.name.endsWith('.apk')) {                def fileName = outputFile.name.replace(".apk", "-${defaultConfig.versionName}.apk")                output.outputFile = new File(outputFile.parent, fileName)            }        }    }    productFlavors {    }}repositories {    flatDir {        dirs 'libs' //this way we can find the .aar file in libs    }}dependencies {    compile 'com.google.code.gson:gson:2.3.1'    compile 'com.github.japgolly.android:svg-android:2.0.6'    compile fileTree(dir: 'libs', include: ['*.jar'])    compile 'com.android.support:appcompat-v7:22.2.0'    compile 'com.github.rey5137:material:1.2.1'    compile 'com.squareup.okhttp:okhttp-apache:2.4.0'    compile(name: 'vds-sdk-release', ext: 'aar')    compile 'com.android.support:multidex:1.0.0'    compile project(':PushSDK')    compile 'com.google.zxing:core:3.2.1'    compile 'com.android.support:recyclerview-v7:24.0.0-alpha1'    compile 'com.rengwuxian.materialedittext:library:2.1.4'}`</pre><pre>`匹配META-INF/channel_wandoujia文件名读取wandoujia渠道    public static String readChanel() {        ApplicationInfo appInfo = ContextManager.getContext().getApplicationInfo();        String sourceDir = appInfo.sourceDir;        String ret = "";        ZipFile zipfile = null;        Log.i(TAG, "---begin-ret=" + ret);        try {            zipfile = new ZipFile(sourceDir);            Enumeration&lt;?&gt; entries = zipfile.entries();            while (entries.hasMoreElements()) {                ZipEntry entry = ((ZipEntry) entries.nextElement());                String entryName = entry.getName();                if (entryName.startsWith("META-INF/channel")) {                    ret = entryName;                    break;                }            }        } catch (IOException e) {            e.printStackTrace();        } finally {            if (zipfile != null) {                try {                    zipfile.close();                } catch (IOException e) {                    e.printStackTrace();                }            }        }`</pre><h4 id="Android多渠道打包流程"><a href="#Android多渠道打包流程" class="headerlink" title="Android多渠道打包流程"></a>Android多渠道打包流程</h4><p>基于上述方式实现多渠道打包流程如下:</p></li></ol><ul><li>执行gradlew clean清除build目录</li><li>执行gradlew assemble编译打包Debug/Release(已自动签名)</li><li>上传Debug包到Fir</li><li>通过DingTalk发送通知信息到QA讨论组(发送提测apk包版本，下载地址及扫描下载二维码)</li><li>提测不通过，修复bug后再次执行前四步</li><li>提测通过后，点击Jenkins打包归档多渠道按钮，将执行生成多渠道包并归档包到本地目录/data/2.0.1/xxx.apk</li><li>可选择此步上传归档文件到OSS</li><li>点击Jenkins发布按钮将最新版本相关渠道归档拷贝至OSS发布目录</li><li>刷新CDN生效</li><li><p>通过DingTalk发送通知信息到QA讨论组哪些渠道已经发布</p><h4 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h4><h5 id="配置Jenkins"><a href="#配置Jenkins" class="headerlink" title="配置Jenkins"></a>配置Jenkins</h5><pre>`插件: Dynamic Choice Parameter**创建打包测试项目:Android-Test**`</pre><p><img src="http:///www.simlinux.com/wp-content/uploads/2016/04/android-test.png" alt=""><br><img src="http://www.simlinux.com/wp-content/uploads/2016/04/android-test-choice.png" alt=""></p><pre>`通过Groovy脚本获取分支def ver_keys = [ 'bash', '-c', 'cd /usr/share/tomcat/.jenkins/workspace/Android-Test;git branch -a|grep remotes|cut -d "/" -f3|grep -v HEAD|sort' ]    ver_keys.execute().text.tokenize('\n')`</pre><pre>`构建脚本#!/bin/bashPATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/jdk1.7.0_80/bin:/usr/local/android-sdk-linux/tools:/usr/local/android-sdk-linux/platform-tools:/usr/local/gradle-2.2.1/bin:/usr/share/tomcat/bincd ${WORKSPACE}git checkout ${BranchToDeploy}git pull -fif [ "${EnvToDeploy}"  = "All Env" ];then        ${WORKSPACE}/gradlew clean        ${WORKSPACE}/gradlew assembleelse        ${WORKSPACE}/gradlew clean        ${WORKSPACE}/gradlew assemble${EnvToDeploy}fi#测试包上传fir，发钉钉通知/usr/local/bin/python /usr/share/tomcat/AndroidDeploy/androidtest.py`</pre><p><strong>创建多渠道包归档项目:Android-Archive</strong></p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/android-archive.png" alt=""><br><img src="http://www.simlinux.com/wp-content/uploads/2016/04/android-archive-channel.png" alt=""></p><pre>`获取channel列表def ver_keys = [ 'bash', '-c', 'echo "All Channels"; cat /usr/share/tomcat/.jenkins/workspace/MAKA-Android-Testing/channels' ]ver_keys.execute().text.tokenize('\n')构建脚本，更改渠道文件，上传OSS，发送钉钉通知python /usr/share/tomcat/AndroidDeploy/androidarchive.py`</pre><p><strong>创建发布多渠道包项目:Android-Deploy</strong></p><pre>`构建脚本，通过OSS API拷贝要发布的归档渠道包到发布目录，发送钉钉通知python /usr/share/tomcat/AndroidDeploy/androiddeploy.py`</pre><h4 id="相关脚本"><a href="#相关脚本" class="headerlink" title="相关脚本"></a>相关脚本</h4><p><pre>`├── androidarchive.py       多渠道打包归档脚本<br>├── androiddeploy.py        渠道包发布脚本<br>├── androidtest.py          测试打包脚本<br>└── libs</pre></p><pre><code>├── chinanetcenter.py   刷新CDN脚本├── dingtalk.py         钉钉发送消息,图片，分享脚本├── fir.py              测试包上传fir脚本├── __init__.py└── libsoss.py          oss相关操作脚本(上传，拷贝等)</code></pre><p>具体代码可根据<a href="https://github.com/geekwolf/AppDeployment按照实际业务进行修改" target="_blank" rel="external">https://github.com/geekwolf/AppDeployment按照实际业务进行修改</a></p></li></ul><h4 id="IOS打包流程"><a href="#IOS打包流程" class="headerlink" title="IOS打包流程"></a>IOS打包流程</h4><ul><li>xcodebuild clean 清理build目录</li><li>xcodebuild archive 选择不同的环境/BundleID/ProvisionProfile/CodeSigningIdentify 编译，签名生成xcarchive文件放到工程根路径下的 build 文件夹里</li><li>xcodebuild -exportArchive 打包生成ipa</li><li>测试包自动上传Fir,生产包手动更新AppStore</li><li>具体可参考脚本 <a href="https://github.com/geekwolf/AppDeployment/blob/master/IOSDeploy.sh" target="_blank" rel="external">https://github.com/geekwolf/AppDeployment/blob/master/IOSDeploy.sh</a></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>任何自动化的前提必须先规范化,针对Android多渠道打包渠道命名，apk包命名需要先统一，apk包不要多环境混用(生产环境和测试环境要分离,测试包可自定义切换)；到了这里，会发现我TM乱七八糟搞了这一陀哪里酸爽了？另外一个思路是通过修改apk文件的注释,程序在启动时读取apk文件注释获取渠道名(但是Android系统直到API 19，也就是4.4以上的版本才支持data/app/<package>.apk)<br><strong><em>爽在哪里？</em></strong><br> 1. 打包不再需要开发本地执行(避免中断开发,多人协作时优势更为明显)<br> 2. 多渠道打包时间在于第一个包编译生成和签名的时间,之后的无论多少渠道都只是修改包的META-INF/channel_wandoujia空文件名实现<br> 3. 点下Jenkins按钮无需在等待打包过程，打包完成后发送消息到钉钉会话，这下爽了吗？</package></p><h4 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h4><blockquote><p>Gradle入门  <a href="http://www.androidchina.net/2155.html" target="_blank" rel="external">http://www.androidchina.net/2155.html</a><br>  Android签名 <a href="http://www.tuicool.com/articles/2eMZJfu" target="_blank" rel="external">http://www.tuicool.com/articles/2eMZJfu</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h4&gt;&lt;p&gt;　　多渠道主要目的是为了统计各个应用市场用户数据分析(比如活跃数，崩溃率等)，收集用户信息，这时需要唯一标识来区分这些渠道，本文主要针对多渠
      
    
    </summary>
    
      <category term="CI/CD" scheme="http://www.simlinux.com/categories/CI-CD/"/>
    
    
  </entry>
  
  <entry>
    <title>初创公司应该如何做好持续集成和部署？</title>
    <link href="http://www.simlinux.com/2016/03/16/1638.html"/>
    <id>http://www.simlinux.com/2016/03/16/1638.html</id>
    <published>2016-03-16T11:11:45.000Z</published>
    <updated>2017-09-12T01:12:15.109Z</updated>
    
    <content type="html"><![CDATA[<p>　　　 持续集成和部署是每一个互联网团队都必须要面对的问题，特别是初创公司业务和技术团队快速增长，技术积累较弱的情况下，一个高效的，可遵循持续的运维规范尤为重要，最近一段时间一直在梳理项目开发流程以及自动化测试和部署规范，作为一个总结和大家分享，希望有所帮助：<br>高效可持续的运维环境需要合理的规范作为支撑:</p><blockquote><ul><li>应用管理规范</li><li>权限管理规范</li><li>配置变更规范</li><li>发布策略规范</li><li>日志运维规范</li><li>持续集成部署实战</li></ul></blockquote><h3 id="应用管理规范"><a href="#应用管理规范" class="headerlink" title="应用管理规范"></a>应用管理规范</h3><h4 id="应用版本化"><a href="#应用版本化" class="headerlink" title="应用版本化"></a>应用版本化</h4><p>　　　 可以使用SVN,Git对代码进行版本控制，建议使用Git(GitLab)<br>　　　 项目Group命名规范: 按大的原则根据产品域名区分  或者根据前后端业务模块进行分组(小写字母命名,横杠[-]作为连接字符)<br>　　　 比如: MAKA官网<a href="http://www.maka.im对应的Git仓库Group为official" target="_blank" rel="external">http://www.maka.im对应的Git仓库Group为official</a><br>　　　 按照功能模块分组如商城前端对应的Git仓库Group为store<br>项目名命名规范: 小写字母命名,横杠[-]作为连接字符,命名规则[产品名称]-[项目类型]-(自定义名称),如official-store<br><strong>注:</strong> 在创建项目仓库时就要权衡前后端或者大的功能模块的拆分保持低耦合度</p><h4 id="合理的分支策略"><a href="#合理的分支策略" class="headerlink" title="合理的分支策略"></a>合理的分支策略</h4><p>常用的Git工作流：</p><p><strong>集中式工作流</strong>：很多公司使用SVN,Git使用并不熟悉,如果迁移至Git之后可以考虑集中式工作流进行开发，代码库只有master一个分支,所有开发者只有本地master和远端master分支，集中式工作流使用起来虽然简单，但无法充分利用git的优势<br><strong>功能分支工作流</strong>： 与集中式工作流不同的地方在于除了master分支以外有功能分支(按功能需求创建的功能分支如third-party-login-feature)，日常开发在功能分支,提测集成时提交Merge Requests(在Bitbucket中是Pull Request)，此处开发者可以进行讨论审核代码,同意后可以合并至master分支,未同意或者让开发者修改后重新提交可以选择关闭该MR</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/featurebranch.png" alt=""><br><strong>Gitflow工作流</strong>：两个主干分支master(正式发布的历史)和develop(功能集成分支)，开发者应基于develop分支创建feature功能分支用于开发,开发完成后提交merge requests请求合并进develop分支,此时若到了发布窗口,基于此时的develop分支创建发布分支release用于测试,预发布,发布以避免影响develop分支的正常集成合并功能分支；release分支不再有新的功能合并进来，一旦创建只用于bug修复并将修复cherry-pick到develop分支;发布完成后，release分支合并进master并分配版本号打tag用于存放发布历史;Gitflow工作流方式适用于大型项目<br><strong>Forking工作流</strong>：开发者fork官方的repo到自己的账号空间,对于官方分支只有只读权限，开发者通过pr提交给官方审核是否合并进代码库;开发者通过同步上游官方的repo来使用其他人的代码,分支策略可参考上述三种工作流,适合开源项目</p><p>　　　 针对创业公司参与同一个项目的开发者并不多,过于复杂的分支策略并不能带来便利;可以参考leancloud的分支模式,根据团队的使用情况进行调整</p><p><strong>介绍下我们当前使用的分支策略：</strong><br>　　　 master：主干分支master用于日常开发的基线<br>　　　 userA：   开发者A日常开发所在分支<br>　　　 release-201603091106: master分支集成测试完成后,构建到预发布环境时自动创建release-201603091106用于发布<br>　　　 hotfix-201603091106 基于当前发布之后的release-201603091106分支用于修复bug,在通过提交merge requests方式合并进release-201603091106，并将修复cherry-pick到master分支<br>　　　 日常开发在userA分支操作，然后提交merge requests请求合并至master分支,本地通过git fetch origin master，然后在userA分支git rebase origin/master将master最新commit合并到本地userA分支从而形成闭环开发</p><h4 id="关于代码审核"><a href="#关于代码审核" class="headerlink" title="关于代码审核"></a>关于代码审核</h4><p>　　　三剑客GitLab+Jenkins+Gerrit,Gerrit作为创业公司代码审核的话略显复杂，不足够敏捷;建议使用GitLab的Merge Requests或者Github和Bitbucket中Pull Requests作为代码审核和讨论的工具,也可以选择Facebook的Phabricator(可同时作为代码托管和评审,非常敏捷,由于Phabricator提供的工具集在windows下使用起来不太友好,后来没有选用,后期会分享Phabricator的使用思路和工作流)</p><h4 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h4><p>　　　规范的目录结构不仅有利于开发者理解代码结构,更有利于代码的快速部署，以PHP为例目录结构建议将代码配置文件(数据库，Redis，OSS Key，语言开关，日志级别开关等),日志文件,其他文件缓存等独立于代码库之外存放，前端项目src为源码目录,dist为前端经过压缩合并等最终生成的代码目录(发布时可忽略src);<br>　　　每个项目详细写README.md:项目说明,各个环境对应的访问路径,目录说明,构建压缩方式,Nginx配置等,代码仓库中包含额外的test目录存放测试用例(本着谁开发谁写测试用例);</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/tree.png" alt=""></p><h3 id="权限管理规范"><a href="#权限管理规范" class="headerlink" title="权限管理规范"></a>权限管理规范</h3><p>　　　权限有两类一个是系统权限(包括服务器登陆，数据库/Redis等)另外一个是服务运行时的权限;</p><h4 id="针对系统权限层面"><a href="#针对系统权限层面" class="headerlink" title="针对系统权限层面"></a>针对系统权限层面</h4><p>　　　统一入口，受限访问IP，禁止空密码弱口令，生产环境服务器需要先拨入vpn之后通过跳板机才能连接成功（当然我们使用的是开源当中最好的跳板机Jumpserver），任何人的操作都需要审计;生产数据库及Redis禁止了外网访问,分别使用phpMyAdmin和RedisLive统一访问入口(增加了多主机访问及屏蔽了危险操作如DDL 数据的导入导出等，也需要先拨入vpn才能访问);</p><p>　　　开发测试环境权限控制现对宽松,DEV Leader和QA Leader同时具有开发和测试环境的服务器及数据库权限，便于测试和Debug;生产环境为了便于开发调试生产代码且不影响线上增加了低配的节点，未在线，但环境，代码及后端均和生产一致;</p><h4 id="针对服务权限层面"><a href="#针对服务权限层面" class="headerlink" title="针对服务权限层面"></a>针对服务权限层面</h4><p>　　　以web服务为例:Nginx和php-fpm运行用户和用户组为www-data,代码目录用户为www,这样代码目录默认情况下web服务只读,避免出现文件和目录777权限的情况；日志和缓存目录用户设置www-data，但要禁止访问php等动态文件</p><p>　　　禁止危险函数phpinfo exec eval system等,具体可参考<a href="http://www.sinacloud.com/doc/sae/php/runtime.html,禁止夸目录访问open_basedir，是否开启的性能对比请参考http://www.simlinux.com/archives/1531.html" target="_blank" rel="external">http://www.sinacloud.com/doc/sae/php/runtime.html,禁止夸目录访问open_basedir，是否开启的性能对比请参考http://www.simlinux.com/archives/1531.html</a></p><h3 id="配置变更规范"><a href="#配置变更规范" class="headerlink" title="配置变更规范"></a>配置变更规范</h3><h4 id="系统部署"><a href="#系统部署" class="headerlink" title="系统部署"></a>系统部署</h4><p>　　　传统IDC机房可以通过定制镜像或者使用cobbler定制安装，运行的服务也可以定制在镜像中,但建议安装系统时注册puppet/salt agent，再自动化署相关服务<br>　　　公有云中可以在服务器上部署相应环境后创建系统快照制作系统镜像,弹性扩容时可选择该镜像自动化安装   </p><h4 id="日常变更"><a href="#日常变更" class="headerlink" title="日常变更"></a>日常变更</h4><p>　　   日常变更包括服务配置的变更和代码配置的变更,这些操作我们是通过Ansible(对比puppet/salt的好处就是简单方便不用装agent，后面会详细介绍如何基于Ansible做发布回滚)，变更内容使用git进行版本控制制</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/ansible-dire.png" alt=""></p><h3 id="发布策略规范"><a href="#发布策略规范" class="headerlink" title="发布策略规范"></a>发布策略规范</h3><h4 id="发布时间"><a href="#发布时间" class="headerlink" title="发布时间"></a>发布时间</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/deploytime.jpg" alt=""></p><p><strong>注意:</strong>以上请根据自己业务做相应调整,避免在业务高峰期发布(除应急bug外),我们业务高峰期基本在18:00-23:30，低峰期基本在01:00-06:00,这也是微信分享阅读的高峰和低峰时段;无论应急Bug还是日常迭代都必须由QA测试通过和产品经理审核通过后才能上线(曾经出现过开发为了修复线上很急的bug,开发修复后自主上线导致生产出现更严重的问题)</p><h4 id="发布工具的选择"><a href="#发布工具的选择" class="headerlink" title="发布工具的选择"></a>发布工具的选择</h4><p>　　　 无论是自主开发发布系统亦或是使用开源的系统都要本着解决问题的原则,否则只能是重复造轮子,然并卵呀<br>　　　 开源的持续集成和发布里面个人觉得比较好的如:Jenkins,Walle,Spinnaker，go，Gitlab-ci，Bamboo(收费)等，其他参考<a href="https://github.com/geekwolf/sa-scripts/blob/master/devops.md" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/blob/master/devops.md</a><br>　　　 下面介绍我们基于GitLab+Jenkins+Ansible(Flamingo自动化代码发布工具)实现的自动化代码部署平台，流程如下:</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/cicdflow.png" alt=""></p><p>　　　<strong>Flamingo</strong>(“火烈鸟”,<a href="https://github.com/geekwolf/flamingo)是基于Ansible的自动化代码发布工具，目的是实现统一的代码发布方式,思路基于Capistrano,并对Ansisrano进行了改造可以通过传入语言环境,主机组(应用组/灰度机组等),项目代码库,分支名称,项目名称等参数来进行自动化打包发布,也可以将Flamingo工具二次打包使用" target="_blank" rel="external">https://github.com/geekwolf/flamingo)是基于Ansible的自动化代码发布工具，目的是实现统一的代码发布方式,思路基于Capistrano,并对Ansisrano进行了改造可以通过传入语言环境,主机组(应用组/灰度机组等),项目代码库,分支名称,项目名称等参数来进行自动化打包发布,也可以将Flamingo工具二次打包使用</a><br>　　　<strong>Flamingo</strong>本者回滚即发布的原则以简化发布流程，回滚时传入要回滚的分支即可，其他参数可参看defaults/main.yml进行了解;(注:依赖Git/rsync/ansible)<br>　　　 例子:</p><pre><code>ansible-playbook deploy.yml  --extra-vars=&apos;flamingo_git_repo=git@github.com:geekwolf/flamingo.git flamingo_product_name=flamingo&apos;</code></pre><p>　　　 执行后生成的目录结构如下图(目录定义请参考defaults/main.yml):</p><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/deploymentdire.jpg" alt=""></p><h3 id="日志运维规范"><a href="#日志运维规范" class="headerlink" title="日志运维规范"></a>日志运维规范</h3><p>　　　 毫无疑问规范的日志对于运维和开发排查问题有非常大的帮助，例如PHP项目日志格式可以规范为时间,日志级别,日志内容(比如对于连接多个DB时出现连接不上或超时应该把实例地址一同写入日志)，可以参考psr-3的标准: <a href="http://www.php-config.org/psr/psr-3" target="_blank" rel="external">http://www.php-config.org/psr/psr-3</a><br>　　　 通过ELK将业务日志,PHP自身错误日志/慢日志,Nginx慢日志等进行搜集统计并结合Zabbix实现报警,便于及早发现问题</p><h3 id="持续集成部署实战"><a href="#持续集成部署实战" class="headerlink" title="持续集成部署实战"></a>持续集成部署实战</h3><p>　　　 后续篇章会分享针对PHP/JAVA/前端以及Android/ios持续集成和部署实战,敬请关注</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>　　　 以上只是粗略对持续集成和部署过程中遇到的问题进行了总结，可能并不完美，但对于初创公司应该有些帮助,欢迎一起学习讨论！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;　　　 持续集成和部署是每一个互联网团队都必须要面对的问题，特别是初创公司业务和技术团队快速增长，技术积累较弱的情况下，一个高效的，可遵循持续的运维规范尤为重要，最近一段时间一直在梳理项目开发流程以及自动化测试和部署规范，作为一个总结和大家分享，希望有所帮助：&lt;br&gt;高效可
      
    
    </summary>
    
      <category term="CI/CD" scheme="http://www.simlinux.com/categories/CI-CD/"/>
    
    
  </entry>
  
  <entry>
    <title>node5.1使用npm安装依赖时提示  node/NAN/v8 requires a C++11 compiler</title>
    <link href="http://www.simlinux.com/2016/01/06/node5-1-e4-bd-bf-e7-94-a8npm-e5-ae-89-e8-a3-85-e4-be-9d-e8-b5-96-e6-97-b6-e6-8f-90-e7-a4-ba-nodenanv8-requires-a-c11-compiler.html"/>
    <id>http://www.simlinux.com/2016/01/06/node5-1-e4-bd-bf-e7-94-a8npm-e5-ae-89-e8-a3-85-e4-be-9d-e8-b5-96-e6-97-b6-e6-8f-90-e7-a4-ba-nodenanv8-requires-a-c11-compiler.html</id>
    <published>2016-01-06T08:26:05.000Z</published>
    <updated>2017-09-12T01:12:15.159Z</updated>
    
    <content type="html"><![CDATA[<p><strong>问题</strong>：Centos6.5 x64环境node5.1使用npm安装依赖时提示 requires a C++11 compiler错误</p><p><pre class="lang:php decode:true">[root@ front_end_v3]# cnpm install<br>npm WARN engine jest-cli@0.4.19: wanted: {“node”:”0.8.x || 0.10.x”} (current: {“node”:”5.1.0”,”npm”:”2.13.5”})<br>npm WARN peerDependencies The peer dependency file-loader@* included from url-loader will no<br>npm WARN peerDependencies longer be automatically installed to fulfill the peerDependency<br>npm WARN peerDependencies in npm 3+. Your application will need to depend on it explicitly.<br>npm WARN optional dep failed, continuing fsevents@1.0.6<br>npm WARN optional dep failed, continuing fsevents@1.0.6<br>npm WARN deprecated lodash@1.0.2: lodash@&lt;2.0.0 is no longer maintained. Upgrade to lodash@^3.0.0<br>npm WARN deprecated lodash@2.4.2: lodash@&lt;3.0.0 is no longer maintained. Upgrade to lodash@^3.0.0</pre></p><p>&gt; contextify@0.1.15 install /wwwroot/front_end_v3/node_modules/jest-cli/node_modules/jsdom/node_modules/contextify<br>&gt; node-gyp rebuild</p><p>make: Entering directory `/wwwroot/front_end_v3/node_modules/jest-cli/node_modules/jsdom/node_modules/contextify/build’<br>  CXX(target) Release/obj.target/contextify/src/contextify.o<br>In file included from ../src/contextify.cc:3:<br>../node_modules/nan/nan.h:41:3: error: #error This version of node/NAN/v8 requires a C++11 compiler<br>In file included from /root/.node-gyp/5.1.0/src/node.h:42,<br>                 from ../src/contextify.cc:1<br><strong>解决方法:</strong></p><p>由于node4.0升级了v8引擎,编译时需要gcc4.8以上版本,Centos6自带的gcc为gcc-4.4.7,<span style="color: #333333;">不支持编译所需的C++11标准,所以只好升级gcc(devtoolsset-3 -&gt; gcc-4.9)（直接升级到最新）</span></p><p><pre class="lang:php decode:true">rpm -ivh <a href="https://www.softwarecollections.org/en/scls/rhscl/devtoolset-3/epel-6-x86_64/download/rhscl-devtoolset-3-epel-6-x86_64.noarch.rpm" target="_blank" rel="external">https://www.softwarecollections.org/en/scls/rhscl/devtoolset-3/epel-6-x86_64/download/rhscl-devtoolset-3-epel-6-x86_64.noarch.rpm</a><br>yum install devtoolset-3-gcc-c++<br>临时使用最新版gcc：<br>scl enable devtoolset-3 bash<br>系统默认使用gcc-4.9<br>echo “source /opt/rh/devtoolset-3/enable” &gt;&gt;/etc/profile</pre><br>&nbsp;</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;：Centos6.5 x64环境node5.1使用npm安装依赖时提示 requires a C++11 compiler错误&lt;/p&gt;
&lt;p&gt;&lt;pre class=&quot;lang:php decode:true&quot;&gt;[root@ front_
      
    
    </summary>
    
      <category term="Linux运维" scheme="http://www.simlinux.com/categories/Linux%E8%BF%90%E7%BB%B4/"/>
    
    
  </entry>
  
</feed>
